<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <meta name="theme-color" content="#1D2D2D">
    <meta name="msapplication-TileColor" content="#1D2D2D">
    
    
    
    <meta name="keywords" content="flink, pravega, kubernetes, docker, streaming, storage">
    
    
    <link rel="apple-touch-icon" sizes="180x180" href="/favicons/apple-touch-icon.png">
    
    
    <link rel="icon" type="image/png" sizes="192x192" href="/favicons/android-chrome-192x192.png">
    
    
    <link rel="icon" type="image/png" sizes="32x32" href="/favicons/favicon-32x32.png">
    
    
    <link rel="icon" type="image/png" sizes="16x16" href="/favicons/favicon-16x16.png">
    
    
    <link rel="mask-icon" href="/favicons/safari-pinned-tab.svg" color="#1D2D2D">
    
    
    <link rel="manifest" href="/favicons/site.webmanifest">
    
    
    <meta name="msapplication-config" content="/favicons/browserconfig.xml">
    
    
    
    <link rel="shortcut icon" type="image/x-icon" href="/favicons/favicon.ico">
    
    
    <link rel="stylesheet" type="text/css" href="/css/normalize.css">
    <link rel="stylesheet" type="text/css" href="/css/index.css">
    
    <link rel="stylesheet" type="text/css" href="/css/sidebar.css">
    
    
<link rel="stylesheet" type="text/css" href="/css/page.css">
<link rel="stylesheet" type="text/css" href="/css/post.css">

    <link rel="stylesheet" type="text/css" href="/css/custom.css">
    <link rel="stylesheet" type="text/css" href="/css/atom-one-dark.css">
    <link rel="stylesheet" type="text/css" href="/css/lightgallery.min.css">
    <script type="text/javascript" src="/js/jquery.min.js"></script>
    <script defer type="text/javascript" src="/js/util.js"></script>
    <script defer type="text/javascript" src="/js/scrollspy.js"></script>
    <script defer type="text/javascript" src="/js/fontawesome-all.min.js"></script>
    <script defer type="text/javascript" src="/js/lightgallery.min.js"></script>
    <script defer type="text/javascript" src="/js/lg-fullscreen.min.js"></script>
    <script defer type="text/javascript" src="/js/lg-hash.min.js"></script>
    <script defer type="text/javascript" src="/js/lg-pager.min.js"></script>
    <script defer type="text/javascript" src="/js/lg-thumbnail.min.js"></script>
    <script defer type="text/javascript" src="/js/lg-zoom.min.js"></script>
    
    <script defer src="/js/busuanzi.pure.mini.js"></script>
    
    
    
    <script defer type="text/javascript" src="/js/index.js"></script>
    
    <script defer type="text/javascript" src="/js/custom.js"></script>
    <title>深度学习 - 第7篇 - huggingface格式大模型强转为megatron格式的掉坑点 | 常平的笔记 - 为学，闻道，践行</title>
  </head>
  <body itemscope itemtype="http://schema.org/WebPage" lang="zh_CN"  data-spy="scroll" data-target=".list-group">
    
<header id="header" class="header" style="background: #1D2D2D;">
  <div class="container">
    <div class="header-container">
      <div class="header-title">
        <h1 class="title"><a href="/">常平的笔记</a></h1>
        <h2 class="subtitle">https://www.changping.me</h2>
      </div>
      
      <div class="logo">
        <img src="/images/logo.png" alt="logo">
      </div>
      
    </div>
    <nav id="nav" class="nav">
      <a id="nav-toggle" class="nav-toggle" aria-hidden="true"><i class="fas fa-bars" aria-label="切换导航栏"></i></a>
      <ul id="menu" role="menubar" aria-hidden="false">
        
        <li role="menuitem"><a href="/">首页</a></li>
        
        <li role="menuitem"><a href="/archives">全部</a></li>
        
        <li role="menuitem"><a href="/categories">分类</a></li>
        
        <li role="menuitem"><a href="/tags">标签</a></li>
        
        <li role="menuitem"><a href="/about">关于</a></li>
        
      </ul>
    </nav>
  </div>
</header>


    <main id="main" class="main">
      <div class="container">
        <div class="main-container">
          <div class="content">
            
<div id="post" class="page">
  
  <article class="article post card" itemscope itemtype="http://schema.org/Article">
    <div class="post-block">
      <link itemprop="mainEntityOfPage" href="https://www.changping.me/2024/05/23/ai_7/">
      <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
       <meta itemprop="name" content="常平">
       <meta itemprop="description" content="“为学，闻道，践行”">
       <meta itemprop="image" content="/images/avatar.jpg">
      </span>
      <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
       <meta itemprop="name" content="常平的笔记">
      </span>
    </div>
    <header class="post-header">
      <h1 class="post-title" itemprop="name headline">深度学习 - 第7篇 - huggingface格式大模型强转为megatron格式的掉坑点</h1>
      <div class="post-meta">
        
        <span class="post-date">
          <i class="far fa-calendar-plus"></i><span><time title="post-date" itemprop="dateCreated datePublished" datetime="2024-05-23T22:58:38+08:00">2024-05-23 22:58:38</time></span>
        </span>
        
        
        
        <span class="post-meta-divider divider">|</span>
        
        <span class="post-categories">
          
          <i class="far fa-folder-open"></i><span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/AI/" itemprop="url" rel="index"><span itemprop="name">AI</span></a></span>
        </span>
        
        
      </div>
    </header>
    <main class="post-main" itemprop="articleBody">
      <p>​                </p>
<h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a><font color="#FF8C00">1. 概述</font></h2><p>对大模型进行张量并行或流水并行切分是个比较麻烦的工作，有些同学觉得这个过程比较麻烦，而采用取巧的策略选择绕开这个切分工作，选用将原生的，比如从huggingface下载的权重转为megatron格式，从而快速完成该大模型的预训练、微调或推理。</p>
<p>殊不知这一过程是从一个小坑掉到另外一个大坑： 先抛开模型转换对用户使用体验不大好的问题，格式转换的致命问题是会在一定概率下引起模型的准确率分数下降，从而造成推理结果的不一致。模型准确率分数的下降也会造成大模型在排行榜上的排名下降，因此，一些大模型厂家是不能接受这种行为的。</p>
<p>将所有的大模型权重都转为megatron gpt或其他格式也是一种一刀切的行为，没有考虑到各个模型的特殊性，以普遍打特殊也是违背这个世界的运行法则的一种行为，不是早上会出问题就是晚上会出问题。这里参考megatron的官方文档说明如下。</p>
<h2 id="2-模型转换与微调"><a href="#2-模型转换与微调" class="headerlink" title="2. 模型转换与微调"></a><font color="#FF8C00">2. 模型转换与微调</font></h2><p>megatron里微调一个大模型基本上可以分为以下几个步骤：</p>
<p>1）从huggingface下载大模型的权重；</p>
<p>2）使用大模型转换脚本将该权重从Huggingface格式转换为megatron格式；</p>
<p>3）基于这个转换后的权重设置微调参数，然后开始微调；</p>
<p>4）最后保存微调好的权重。</p>
<p>以LLama-2为例，将Llama 权重从huggingface下载下来，然后采用megatron自带的Llama-2 转换器转换为megatron格式，但是需要注意的是这一过程必须正确设置大模型的张量并行大小即TP参数，如下：</p>
<table>
<thead>
<tr>
<th>模型大小</th>
<th>张量并行大小（TP）</th>
</tr>
</thead>
<tbody>
<tr>
<td>7B</td>
<td>1</td>
</tr>
<tr>
<td>13B</td>
<td>2</td>
</tr>
<tr>
<td>70B</td>
<td>8</td>
</tr>
</tbody>
</table>
<p>基于TP值以及Llama-2 ${TOKENIZER_MODEL}路径，在megatron根目录下执行以下转换命令可以将Llama-2 权重从Huggingface格式转换为Megatron格式：</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-variable">$python</span> tools/checkpoint/convert.py \<br> --model-type GPT \<br> --loader llama2 \<br> --saver megatron \<br> --target-tensor-parallel-size <span class="hljs-variable">$&#123;TP&#125;</span> \<br> --checkpoint-type hf \<br> --load-dir <span class="hljs-variable">$&#123;HF_FORMAT_DIR&#125;</span> \<br> --save-dir <span class="hljs-variable">$&#123;MEGATRON_FORMAT_DIR&#125;</span> \<br> --tokenizer-model <span class="hljs-variable">$&#123;TOKENIZER_MODEL&#125;</span><br></code></pre></td></tr></table></figure>
<p>完成此转换后，可以将该权重采用megatron进行微调，微调结束后再保存该新的权重，然后这个权重就可以用于推理了。需要注意的是如果是只识别huggingface格式的推理工具则需要将该权重再转回huggingface格式才能用于推理。</p>
<h2 id="3-模型准确率分数说明"><a href="#3-模型准确率分数说明" class="headerlink" title="3.模型准确率分数说明"></a><font color="#FF8C00">3.模型准确率分数说明</font></h2><p>下列表格列出了原生的Llama-2与转换后的LLama-2 推理结果的准确率比较。表格里的数值是megatron格式与原生格式之间的基准测试百分误差，计算公式为：”|&lt;llama_score&gt; - &lt;megatron_score&gt;| / &lt;llama_score&gt;”。在所有测试中（每种模型大小共80个），平均误差为0.15%。</p>
<p>经过分析，两种模型之间基准分数的微小差异是由于实现中的小的算术差异造成的，这些差异稍微改变了数值，影响这种差异的因素包括：</p>
<ul>
<li><p>Megatron在几个地方执行批量矩阵乘法，例如在self attention 内部以及在SwiGLU中，而Llama分别执行这些操作；</p>
</li>
<li><p>Megatron在自注意力中使用torch.baddbmm，而Llama使用torch.matmul；</p>
</li>
<li><p>Megatron对旋转位置嵌入使用sin/cos实现，而Llama使用极坐标/复数实现；</p>
</li>
<li><p>Llama在初始化期间调用torch.set_default_dtype(torch.float16)，而Megatron则不调用。</p>
</li>
</ul>
<p>准确度分数比较说明见以下表格。 </p>
<h3 id="3-1-Big-Bench"><a href="#3-1-Big-Bench" class="headerlink" title="3.1 Big Bench"></a>3.1 Big Bench</h3><p>得分类型：多项选择成绩。</p>
<table>
<thead>
<tr>
<th>bigbench / standard</th>
<th>7b</th>
<th>13b</th>
<th>70b</th>
</tr>
</thead>
<tbody>
<tr>
<td>date_understanding</td>
<td>0.29%</td>
<td>0.13%</td>
<td>0.12%</td>
</tr>
<tr>
<td>general_knowledge</td>
<td>0.00%</td>
<td>0.00%</td>
<td>0.00%</td>
</tr>
<tr>
<td>human_organs_senses</td>
<td>0.00%</td>
<td>0.00%</td>
<td>0.00%</td>
</tr>
<tr>
<td>intent_recognition</td>
<td>0.00%</td>
<td>0.11%</td>
<td>0.00%</td>
</tr>
<tr>
<td>riddle_sense</td>
<td>0.00%</td>
<td>0.00%</td>
<td>0.00%</td>
</tr>
<tr>
<td>similarities_abstraction</td>
<td>0.00%</td>
<td>0.58%</td>
<td>0.00%</td>
</tr>
<tr>
<td>simple_arithmetic_json_multiple_choice</td>
<td>0.00%</td>
<td>0.00%</td>
<td>0.00%</td>
</tr>
<tr>
<td>undo_permutation</td>
<td>0.19%</td>
<td>0.19%</td>
<td>0.18%</td>
</tr>
</tbody>
</table>
<h3 id="3-2-Multilingual"><a href="#3-2-Multilingual" class="headerlink" title="3.2 Multilingual"></a>3.2 Multilingual</h3><p>得分类型：多项选择成绩。</p>
<table>
<thead>
<tr>
<th>multilingual / xcopa</th>
<th>7b</th>
<th>13b</th>
<th>70b</th>
</tr>
</thead>
<tbody>
<tr>
<td>en-template-mGPT-remove-punctuation</td>
<td>0.08%</td>
<td>0.00%</td>
<td>0.00%</td>
</tr>
<tr>
<td>et-template-mGPT-remove-punctuation</td>
<td>0.00%</td>
<td>0.13%</td>
<td>0.25%</td>
</tr>
<tr>
<td>ht-template-mGPT-remove-punctuation</td>
<td>0.26%</td>
<td>0.13%</td>
<td>0.26%</td>
</tr>
<tr>
<td>id-template-mGPT-remove-punctuation</td>
<td>0.11%</td>
<td>0.00%</td>
<td>0.19%</td>
</tr>
<tr>
<td>it-template-mGPT-remove-punctuation</td>
<td>0.00%</td>
<td>0.10%</td>
<td>0.09%</td>
</tr>
<tr>
<td>qu-template-mGPT-remove-punctuation</td>
<td>0.00%</td>
<td>0.00%</td>
<td>0.27%</td>
</tr>
<tr>
<td>sw-template-mGPT-remove-punctuation</td>
<td>0.14%</td>
<td>0.13%</td>
<td>0.13%</td>
</tr>
<tr>
<td>th-template-mGPT-remove-punctuation</td>
<td>0.25%</td>
<td>0.13%</td>
<td>0.13%</td>
</tr>
<tr>
<td>tr-template-mGPT-remove-punctuation</td>
<td>0.26%</td>
<td>0.00%</td>
<td>0.34%</td>
</tr>
<tr>
<td>vi-template-mGPT-remove-punctuation</td>
<td>0.00%</td>
<td>0.11%</td>
<td>0.00%</td>
</tr>
<tr>
<td>zh-template-mGPT-remove-punctuation</td>
<td>0.00%</td>
<td>0.10%</td>
<td>0.09%</td>
</tr>
</tbody>
</table>
<h3 id="3-3-LM-Evaluation-Harness"><a href="#3-3-LM-Evaluation-Harness" class="headerlink" title="3.3 LM Evaluation Harness"></a>3.3 LM Evaluation Harness</h3><p>得分类型：多项选择成绩。</p>
<table>
<thead>
<tr>
<th>lm-eval</th>
<th>7b</th>
<th>13b</th>
<th>70b</th>
</tr>
</thead>
<tbody>
<tr>
<td>boolq</td>
<td>0.04%</td>
<td>0.04%</td>
<td>0.07%</td>
</tr>
<tr>
<td>hellaswag</td>
<td>0.02%</td>
<td>0.03%</td>
<td>0.03%</td>
</tr>
<tr>
<td>piqa</td>
<td>0.00%</td>
<td>0.00%</td>
<td>0.07%</td>
</tr>
<tr>
<td>winogrande</td>
<td>0.00%</td>
<td>0.11%</td>
<td>0.20%</td>
</tr>
</tbody>
</table>
<h3 id="3-4-MMLU"><a href="#3-4-MMLU" class="headerlink" title="3.4 MMLU"></a>3.4 MMLU</h3><p>得分类型：多项选择成绩。</p>
<p>注意：括号内的数字是每个大类中子任务的数量。</p>
<table>
<thead>
<tr>
<th>mmlu</th>
<th>7b</th>
<th>13b</th>
<th>70b</th>
</tr>
</thead>
<tbody>
<tr>
<td>stem [18]</td>
<td>0.79%</td>
<td>0.05%</td>
<td>0.01%</td>
</tr>
<tr>
<td>humanities [13]</td>
<td>0.19%</td>
<td>0.01%</td>
<td>0.02%</td>
</tr>
<tr>
<td>other (business, health, misc.) [14]</td>
<td>0.08%</td>
<td>0.06%</td>
<td>0.12%</td>
</tr>
<tr>
<td>social sciences [12]</td>
<td>0.37%</td>
<td>0.21%</td>
<td>0.01%</td>
</tr>
</tbody>
</table>
<p>以上数据可知，模型权重从huggingface格式转换为megatron格式会引起准确率的下降，虽然下降的不多，但是这一结果不是所有的用户都愿意接受的。</p>
<h2 id="4-小结"><a href="#4-小结" class="headerlink" title="4. 小结"></a><font color="#FF8C00">4. 小结</font></h2><p>本文介绍了模型权重从huggingface格式转换为megatron格式进行训练所造成的影响，准确率只是模型质量的一个约束指标，从工程角度看 训练或微调的性能、收敛精度也是另外两个比较重要的约束指标。</p>
<p>日拱一卒，功不唐捐，分享是最好的学习，与其跟随不如创新，希望这个知识点对大家有用。另作者能力与认知都有限，”我讲的，可能都是错的“，欢迎大家拍砖留念。</p>
<h2 id="5-作者简介"><a href="#5-作者简介" class="headerlink" title="5. 作者简介"></a><font color="#FF8C00">5. 作者简介</font></h2><p>常平，为学，闻道，践行。</p>
<h2 id="6-参考资料"><a href="#6-参考资料" class="headerlink" title="6. 参考资料"></a><font color="#FF8C00">6. 参考资料</font></h2><p>[1] <a href="https://github.com/NVIDIA/Megatron-LM/blob/main/docs/llama2.md" target="_blank" rel="noopener">https://github.com/NVIDIA/Megatron-LM/blob/main/docs/llama2.md</a></p>
<h2 id="7-版权申明"><a href="#7-版权申明" class="headerlink" title="7. 版权申明"></a><font color="#FF8C00">7. 版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p>
<p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p>

    </main>
    <footer class="post-footer">
      
      <div class="post-tags">
        
        <a class="post-tag button" href="/tags/AI/" rel="tag"><i class="fas fa-tags"></i>AI</a>
        
      </div>
      
    </footer>
  </article>
  
  
  <nav class="page-nav">
    <div class="page-nav-next page-nav-item">
      
      <a href="/2023/06/24/ideology_6/" rel="next" title="认识与实践 – 第6篇 - 易经、道德经、矛盾论都在讲什么"><i class="fas fa-angle-left"></i><span class="nav-title">认识与实践 – 第6篇 - 易经、道德经、矛盾论都在讲什么</span></a>
      
    </div>
    <div class="page-nav-prev page-nav-item">
      
      <a href="/2024/07/27/ai_8/" rel="prev" title="深度学习 - 第8篇 - 国产Ai芯片CUDA生态兼容的一些思考"><span class="nav-title">深度学习 - 第8篇 - 国产Ai芯片CUDA生态兼容的一些思考</span><i class="fas fa-angle-right"></i></a>
      
    </div>
  </nav>
  
  
</div>

          </div>
          
          
          
<aside class="sidebar" id="sidebar" >
  
  
<div class="info sidebar-item" id="info">
  
  <img class="author-avatar" src="/images/avatar.jpg" alt="常平">
  
  <h1 class="author-name">常平</h1>
  <h2 class="author-description">“为学，闻道，践行”</h2>
  <div class="site-count">
    
    <div class="archives-count">
      <div class="site-count-title">全部</div>
      <div><a href="/archives">66</a></div>
    </div>
    
    
    
    <span class="site-count-divider divider">|</span>
    
    <div class="categories-count">
      <div class="site-count-title">分类</div>
      <div><a href="/categories">7</a></div>
    </div>
    
    
    
    <span class="site-count-divider divider">|</span>
    
    <div class="tags-count">
      <div class="site-count-title">标签</div>
      <div><a href="/tags">7</a></div>
    </div>
    
  </div>
  
</div>


  <div class="sidebar-sticky">
    
    
    
    
    
    <hr>
    <div class="post-toc sidebar-item" id="toc-div">
      <div><i class="fas fa-list-ol"></i>文章目录</div>
      <div class="post-toc-content"><ol class="list-group toc"><li class="toc-item toc-level-2"><a class="list-group-item toc-link" href="#1-概述"><span class="toc-text">1. 概述</span></a></li><li class="toc-item toc-level-2"><a class="list-group-item toc-link" href="#2-模型转换与微调"><span class="toc-text">2. 模型转换与微调</span></a></li><li class="toc-item toc-level-2"><a class="list-group-item toc-link" href="#3-模型准确率分数说明"><span class="toc-text">3.模型准确率分数说明</span></a><ol class="list-group toc-child"><li class="toc-item toc-level-3"><a class="list-group-item toc-link" href="#3-1-Big-Bench"><span class="toc-text">3.1 Big Bench</span></a></li><li class="toc-item toc-level-3"><a class="list-group-item toc-link" href="#3-2-Multilingual"><span class="toc-text">3.2 Multilingual</span></a></li><li class="toc-item toc-level-3"><a class="list-group-item toc-link" href="#3-3-LM-Evaluation-Harness"><span class="toc-text">3.3 LM Evaluation Harness</span></a></li><li class="toc-item toc-level-3"><a class="list-group-item toc-link" href="#3-4-MMLU"><span class="toc-text">3.4 MMLU</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="list-group-item toc-link" href="#4-小结"><span class="toc-text">4. 小结</span></a></li><li class="toc-item toc-level-2"><a class="list-group-item toc-link" href="#5-作者简介"><span class="toc-text">5. 作者简介</span></a></li><li class="toc-item toc-level-2"><a class="list-group-item toc-link" href="#6-参考资料"><span class="toc-text">6. 参考资料</span></a></li><li class="toc-item toc-level-2"><a class="list-group-item toc-link" href="#7-版权申明"><span class="toc-text">7. 版权申明</span></a></li></ol></div>
    </div>
    
    
    
    <hr>
    <div class="social-link sidebar-item">
      <div><i class="far fa-address-card"></i>链接</p></div>
      <ul>
        
        <li><i class="fab fa-github"></i><a href="https://github.com/wuchangping" target="_blank">GitHub</a></li>
        
      </ul>
    </div>
    
    
  </div>
</aside>


          
        </div>
      </div>
    </main>
    
<footer id="footer" class="footer" style="background: #1D2D2D;">
  <div class="container">
    <div class="back-to-top">
      <button id="back-to-top"><i class="fas fa-angle-double-up" aria-label="回到顶部"></i></button>
    </div>
    <div class="footer-container">
      <div class="footer-left">
        <div class="copyright">
          <span class="author">常平</span><span class="year"><i class="far fa-copyright"></i>2017 - 2024</span>
        </div>
        
        <div class="busuanzi">
          <span id="busuanzi_container_site_pv"><i class="fas fa-eye" aria-label="站点点击量" aria-hidden="false"></i><span id="busuanzi_value_site_pv"></span></span><span id="busuanzi_container_site_uv"><i class="fas fa-user" aria-label="站点用户数" aria-hidden="false"></i><span id="busuanzi_value_site_uv"></span></span><span id="busuanzi_container_page_pv"><i class="far fa-file-alt"></i><span id="busuanzi_value_page_pv" aria-label="页面点击量" aria-hidden="false"></span></span>
        </div>
        
      </div>
      <div class="footer-right">
        <div class="custom-info">
          
          PoweredBy<i class="fab fa-github-alt"></i><a href="https://github.com/wuchangping" target="_blank">GitHub</a>
          
        </div>
        <div class="powered-by">
          由 <a href="https://hexo.io/" target="_blank">Hexo</a> 强力驱动 | 主题 <a href="https://github.com/AlynxZhou/hexo-theme-aria/" target="_blank">ARIA</a>
        </div>
      </div>
    </div>
  </div>
</footer>


  </body>
</html>
