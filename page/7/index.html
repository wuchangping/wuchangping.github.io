<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <meta name="theme-color" content="#1D2D2D">
    <meta name="msapplication-TileColor" content="#1D2D2D">
    
    
    
    <meta name="keywords" content="flink, pravega, kubernetes, docker, streaming, storage">
    
    
    <link rel="apple-touch-icon" sizes="180x180" href="/favicons/apple-touch-icon.png">
    
    
    <link rel="icon" type="image/png" sizes="192x192" href="/favicons/android-chrome-192x192.png">
    
    
    <link rel="icon" type="image/png" sizes="32x32" href="/favicons/favicon-32x32.png">
    
    
    <link rel="icon" type="image/png" sizes="16x16" href="/favicons/favicon-16x16.png">
    
    
    <link rel="mask-icon" href="/favicons/safari-pinned-tab.svg" color="#1D2D2D">
    
    
    <link rel="manifest" href="/favicons/site.webmanifest">
    
    
    <meta name="msapplication-config" content="/favicons/browserconfig.xml">
    
    
    
    <link rel="shortcut icon" type="image/x-icon" href="/favicons/favicon.ico">
    
    
    <link rel="stylesheet" type="text/css" href="/css/normalize.css">
    <link rel="stylesheet" type="text/css" href="/css/index.css">
    
    <link rel="stylesheet" type="text/css" href="/css/sidebar.css">
    
    
<link rel="stylesheet" type="text/css" href="/css/page.css">
<link rel="stylesheet" type="text/css" href="/css/post.css">

    <link rel="stylesheet" type="text/css" href="/css/custom.css">
    <link rel="stylesheet" type="text/css" href="/css/atom-one-dark.css">
    <link rel="stylesheet" type="text/css" href="/css/lightgallery.min.css">
    <script type="text/javascript" src="/js/jquery.min.js"></script>
    <script defer type="text/javascript" src="/js/util.js"></script>
    <script defer type="text/javascript" src="/js/scrollspy.js"></script>
    <script defer type="text/javascript" src="/js/fontawesome-all.min.js"></script>
    <script defer type="text/javascript" src="/js/lightgallery.min.js"></script>
    <script defer type="text/javascript" src="/js/lg-fullscreen.min.js"></script>
    <script defer type="text/javascript" src="/js/lg-hash.min.js"></script>
    <script defer type="text/javascript" src="/js/lg-pager.min.js"></script>
    <script defer type="text/javascript" src="/js/lg-thumbnail.min.js"></script>
    <script defer type="text/javascript" src="/js/lg-zoom.min.js"></script>
    
    <script defer src="/js/busuanzi.pure.mini.js"></script>
    
    
    
    <script defer type="text/javascript" src="/js/index.js"></script>
    
    <script defer type="text/javascript" src="/js/custom.js"></script>
    <title>常平的技术博客 - 技术是有生命的，因为它可以进化</title>
  </head>
  <body itemscope itemtype="http://schema.org/WebPage" lang="zh_CN"  data-spy="scroll" data-target=".list-group">
    
<header id="header" class="header" style="background: #1D2D2D;">
  <div class="container">
    <div class="header-container">
      <div class="header-title">
        <h1 class="title"><a href="/">常平的技术博客</a></h1>
        <h2 class="subtitle">www.changping.me</h2>
      </div>
      
      <div class="logo">
        <img src="/images/logo.png" alt="logo">
      </div>
      
    </div>
    <nav id="nav" class="nav">
      <a id="nav-toggle" class="nav-toggle" aria-hidden="true"><i class="fas fa-bars" aria-label="切换导航栏"></i></a>
      <ul id="menu" role="menubar" aria-hidden="false">
        
        <li role="menuitem"><a href="/">首页</a></li>
        
        <li role="menuitem"><a href="/archives">全部</a></li>
        
        <li role="menuitem"><a href="/categories">分类</a></li>
        
        <li role="menuitem"><a href="/tags">标签</a></li>
        
        <li role="menuitem"><a href="/about">关于</a></li>
        
      </ul>
    </nav>
  </div>
</header>


    <main id="main" class="main">
      <div class="container">
        <div class="main-container">
          <div class="content">
            

<div id="index" class="index page">
  
  <article class="article post card" itemscope itemtype="http://schema.org/Article">
    <div class="post-block">
      <link itemprop="mainEntityOfPage" href="www.changping.me/2018/09/22/distributed-streaming-native-platform/">
      <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
        <meta itemprop="name" content="常平">
        <meta itemprop="description" content="“分布式系统架构设计师”">
        <meta itemprop="image" content="/images/avatar.jpg">
      </span>
      <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
        <meta itemprop="name" content="常平的技术博客">
      </span>
    </div>
    <header class="post-header">
      <h1 class="post-title" itemprop="name headline">
        <a class="post-title-link post-title-link-external" href="/2018/09/22/distributed-streaming-native-platform/" itemprop="url">打造“流原生”式大数据处理平台</a>
      </h1>
      <div class="post-meta">
        
        <span class="post-date">
          <i class="far fa-calendar-plus"></i><span><time title="post-date" itemprop="dateCreated datePublished" datetime="2018-09-22T21:25:18+08:00">2018-09-22 21:25:18</time></span>
        </span>
        
        
        
        <span class="post-meta-divider divider">|</span>
        
        <span class="post-categories">
          
          <i class="far fa-folder-open"></i><span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/distributed/" itemprop="url" rel="index"><span itemprop="name">distributed</span></a></span>
        </span>
        
        
      </div>
    </header>
    <main class="post-main" itemprop="articleBody">
      
      <h1 id="开篇-马斯克们的Hyperloop"><a href="#开篇-马斯克们的Hyperloop" class="headerlink" title="开篇,马斯克们的Hyperloop"></a>开篇,马斯克们的Hyperloop</h1><p>我们先来看张图，下图上部分是现在的高铁，它是跑在露天的轨道上的，下图是Elon Musk’s 在正吹的<a href="https://hyperloop-one.com" target="_blank" rel="noopener">hyperloop</a>，类似于跑在真空管道里的未来高铁。相比跑在露天轨道里的高铁，跑真空管道里的高铁好处多了：快，节能，安全，比飞机便宜。。。<br>技术是可以自己进化的，相信类似hyperloop的”高铁+真空管道”的模式就是未来的一种交通出行方式。</p>
<p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/streaming%2Fstreaming-native-platform-0.jpg" alt="hyperloop"></p>
<p>那么HYPERLOOP跟本文又有什么关系呢？ 是不是有点扯远了？其实本文讲的就是类似给高铁加上真空管道的活，二者本质上是相同的。</p>
<h2 id="管道-Unix-Linux的设计哲学"><a href="#管道-Unix-Linux的设计哲学" class="headerlink" title="管道,Unix/Linux的设计哲学"></a>管道,Unix/Linux的设计哲学</h2><p>在Linux或者Unix系统里,有时候我们为了查询某个信息，会输入类似如下的命令行：</p>
<figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs undefined">#cat *.log | grep –v ‘pipeline’ | sort –nr | head –n 10 | tail -5 | awk ‘&#123;print $2&#125;’ | wc –l  &gt; /dev/stdout<br></code></pre></td></tr></table></figure>
<p>这个命令行通过“|”来分隔多个命令，前面命令的输出是紧接着的后面命令的输入，命令之间通过“|”彼此相连，并且一个命令只做一件事情。这里的“|”就是管道，把一个程序的输出和另一个程序的输入连起来的一根管子。</p>
<p>在Unix/Linux里存在这样的管道命令设计哲学：</p>
<ul>
<li>程序是个过滤器</li>
<li>一个程序只做一件事并且做到最好</li>
<li>一个程序的输入是另外一个程序的输出</li>
</ul>
<p>下图体现了这样的管道设计哲学，应用之间通过管道相连相互作用：</p>
<p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/streaming%2Fstreaming-native-platform-1.PNG" alt="Uniux/linux pipeline"></p>
<p>管道所要解决的问题是：<code>高内聚，低耦合</code>。它以一种“链”的方式将这些程序组合起来，让这些程序组成一条工作流，而每个程序又只作一件事情，给定输入，经过各个程序的先后处理，最终得到输出结果，如下图所示：</p>
<p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/streaming%2Fstreaming-native-platform-2.PNG" alt="Uniux/linux pipeline"></p>
<p>Unix/Linux在<code>&quot;每个程序只做一件事并且做好，每个程序的输出是对另一个程序的输入，可组合性&quot;</code>方面是做的非常成功的。但是，UNIX/Linux也存在一些局限性，比如：<code>&quot;仅单机，只支持一对一通信，无容错，仅字节流,数据处理能力有限等&quot;</code>。意思是说 linux/unix的这些管道命令只能在一台机器上跑，没有分布式，并且只能支持一个命令和另外一个命令之间的一对一的输入输出，无法一对多或多对一；无容错，假如管道坏了数据就出错不能恢复；只支持字节流，不支持数据格式的多样性；处理的数据量有限。</p>
<p>因此，我们希望可以找到一个数据处理解决方案，这个方案在保留这些Unix/linux管道的设计哲学优点的同时还能克服其缺点。 幸运的是，我们通过Flink+Pravega打造的第三代“流原生”(stream native)式的大数据处理平台实现了这种设计思想。</p>
<h2 id="流原生-第三代大数据处理平台"><a href="#流原生-第三代大数据处理平台" class="headerlink" title="流原生,第三代大数据处理平台"></a>流原生,第三代大数据处理平台</h2><p>下图体现了“流原生”(stream native)式的设计哲学，Flink是“流原生”的计算，Pravega是“流原生”的存储管道，Flink + pravega 是“流原生”的大数据处理平台。数据从pravega管道输入经过map算子计算，输出中间计算结果到pravega的管道里，数据又从pravega的管道里读入到filter算子里，再经过计算，中间结果放到了pravega管道里，再最后的计算结果经过聚合算子的计算放到了目的地的pravega的管道里。这个过程体现了算子编排和管道式编程的设计哲学。在这里pravega起了大数据处理平台里的管道的作用。</p>
<p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/streaming%2Fstreaming-native-platform-3.PNG" alt="Stream processing pipeline"></p>
<p>在Unix/Linux中，系统提供管道和命令，用于从一个进程到另一个进程获取字节流。</p>
<p>在“流原生”处理平台上，Flink提供流处理服务，pravega提供流存储服务，数据源自pravega，被Flink算子们处理后输出到pravega，这是一种将事件从一个流处理作业转移到另一个流处理作业的机制。 Flink和Pravega 所遵循的流处理平台设计哲学是：</p>
<ul>
<li>每个算子都只做一件事，并且做到最好</li>
<li>每个算子的输出是另一个算子的输入</li>
<li>可组合</li>
<li>流式传输：数据是动态的，算子是静态的</li>
<li>算子可编排</li>
<li>Pravega是最好的Flink搭档</li>
<li>分布式，扩展到多台机器</li>
<li>可进化的编码/解码</li>
</ul>
<p>当前的流式处理平台一般是 Flink 加传统的存储类型，这种是”半流原生“式的大数据处理平台，计算是原生的流计算而存储却不是原生的流存储。<br>而Pravega就是专门给Flink们设计的原生流存储，它的数据传输方式类似于“管道”，不同于传统的块存储，文件存储以及对象存储，它是一个”管道式流存储“。</p>
<p>通过Flink + Pravega的组合可以实现 “流原生”(stream native)式的第三代大数据处理平台，未来已来。。。。。</p>
<h2 id="思考题"><a href="#思考题" class="headerlink" title="思考题"></a>思考题</h2><p>最后给大家留个思考题，“流原生”(stream native)的概念有了，Flink + Pravega 也有了，而且二者的代码都是开源的（flink.apache.org, pravega.io），那么怎么把这些开源的东西产品化？ 或者这个问题太伤脑筋，我们换个简单的问题：“今天中午吃什么？”</p>
<h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a>作者简介</h2><p>常平，毕业于中国科学技术大学，获硕士研究生学历学位，10年+ 存储、布式系统、云计算以及大数据经验，曾就职于Marvell、AMD等，现就职于EMC，资深首席工程师，主要负责流式大数据处理平台的架构设计、编码及产品交付等。</p>

      
    </main>
    <footer class="post-footer">
      
      <div class="post-tags">
        
        <a class="post-tag button" href="/tags/distributed/" rel="tag"><i class="fas fa-tags"></i>distributed</a>
        
      </div>
      
    </footer>
  </article>
  
  <article class="article post card" itemscope itemtype="http://schema.org/Article">
    <div class="post-block">
      <link itemprop="mainEntityOfPage" href="www.changping.me/2018/09/22/distributed-tradeoff/">
      <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
        <meta itemprop="name" content="常平">
        <meta itemprop="description" content="“分布式系统架构设计师”">
        <meta itemprop="image" content="/images/avatar.jpg">
      </span>
      <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
        <meta itemprop="name" content="常平的技术博客">
      </span>
    </div>
    <header class="post-header">
      <h1 class="post-title" itemprop="name headline">
        <a class="post-title-link post-title-link-external" href="/2018/09/22/distributed-tradeoff/" itemprop="url">算命先生的阴阳五行学说与码农们的分布式系统设计理论</a>
      </h1>
      <div class="post-meta">
        
        <span class="post-date">
          <i class="far fa-calendar-plus"></i><span><time title="post-date" itemprop="dateCreated datePublished" datetime="2018-09-22T15:26:02+08:00">2018-09-22 15:26:02</time></span>
        </span>
        
        
        
        <span class="post-meta-divider divider">|</span>
        
        <span class="post-categories">
          
          <i class="far fa-folder-open"></i><span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/distributed/" itemprop="url" rel="index"><span itemprop="name">distributed</span></a></span>
        </span>
        
        
      </div>
    </header>
    <main class="post-main" itemprop="articleBody">
      
      <h2 id="阴阳五行"><a href="#阴阳五行" class="headerlink" title="阴阳五行"></a>阴阳五行</h2><p>一说到阴阳五行就容易让人想到大街上的算命先生，然而阴阳五行学说却是中国古代解释世间万物的起源和多样性的哲学理论依据，是中国古代朴素的唯物论和自发的辩证法思想。</p>
<p>中国古代哲学的核心思想之一用“老子”的话来说就是：</p>
<blockquote>
<p>“道生一、一生二、二生三、三生万物，万物负阴而抱阳，冲气以为和。”。</p>
</blockquote>
<p>而五行学说讲的是:<code>“金 木 水 火 土”</code>这五行,五行相生又相克。<code>木头烧火——木生火；火烧木头成灰——火生土，土长期聚在一起生石头、石头里炼金——土生金，金销水——金生水，水又生土。</code>,<code>水克火，火克金，金克木，木克土，土克水。</code></p>
<p>但是如下图,五行虽然相生相克但都是为“和”字而服务的，即平衡：</p>
<p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed%2Fdistributed-tradeoff-1.PNG" alt="五行"></p>
<p>解读开来就是：</p>
<p><code>“天道生阴阳，阴阳成五行，五行变化成万物，而万物的存在方式和相互关系一直在追求一种“和谐”。</code>“道”在阴阳的相互作用下，产生五行，五行之间相互作用产生世间万物的无穷变化，并且阴阳之间对立消长，五行之间相生相克，自此万物得以和谐发展。借助于阴阳五行的核心要素以及由此而生的非核心要素关系把宇宙看成一个统一的整体，这样的整体：<code>循环平衡、相生相克、有刚有柔、和谐统一</code>。</p>
<p>那么这些玄乎的哲学理论跟码农又有什么关系呢？对于本人这么个靠技术混饭吃卖身又卖艺的码农来说，这实在太重要，归纳成一个字就是”和”，对应到技术实现体系里就是一个理念 ”权衡“，英文叫<code>tradeoff</code>。<code>“tradeoff”</code>这词实在是太妙了，啥都可以往上套，比如你十一准备到哪旅游啦，中午到哪吃饭啦，买哪里的房子啦，准备追哪个姑娘做老婆啦…….，都需要 <code>tradeoff</code>。技术如此人生又何尝不如是。</p>
<h2 id="分布式系统"><a href="#分布式系统" class="headerlink" title="分布式系统"></a>分布式系统</h2><p>通常来讲设计分布式系统的时候需要考虑的最重要的<code>核心要素</code>有五个，这里不是说其他要素就不重要，这是指经过<code>tradeoff</code>过的五个最重要的核心要素，如下图：</p>
<p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed%2Fdistributed-tradeoff-2.PNG" alt="分布式系统要素"></p>
<ol>
<li><p><code>Capacity</code>，容量，其实这个词翻译成”能力“会更合适，指的是分布式系统里的CPU，内存，硬盘，网络，文件描述符，socket连接数，老板的预期，开发周期，成本预算之类的限制条件,以下所有的要素都受 “容量”的限制，这是前提条件，就比如一辆车最多能跑多快，一个人最多能跳多高都是受自身“容量/能力”的限制的；</p>
</li>
<li><p><code>Performant</code>, performance + conformant, performant这词也是造的，指的是合适的性能，分布式系统的IOPS，TPS, QPS，Latency,Jitter之类的性能指标要求，性能受限于容量，性能同时又影响了可靠性以及可用性；</p>
</li>
<li><p><code>Availability</code>，可用性，可用性通常指的是产品或服务在随机时间内调用时处于可服务状态的概率，通常被定义为正常运行时间除以总时间（正常运行时间加停机时间），比如 5个9，6个9，还有个厂家都喜欢的号称的9个9之类的，可用性受容量的限制同时也受可伸缩性的影响，可用性又影响了性能；</p>
</li>
<li><p><code>Reliability</code>，可靠性，一般指的是出保证不出故障的概率，比如，企业级产品 5个9是保底，可测试性和可维护性通常被定义为可靠性当中的一部分，可伸缩性影响了可靠性，而可靠性又影响了可用性，同时性能又影响了可靠性，可靠性也影响着性能。</p>
</li>
<li><p><code>Scalability</code>，可伸缩性，这里很容易跟“可扩展性”混淆，可伸缩性可以指的是集群处理越来越多或越来越少的工作的能力，或者是为了适应这种增长或减少而扩大或缩小其能力的能力。可伸缩性影响了可用性，也影响了性能与可靠性，受限于容量。</p>
</li>
</ol>
<p>当然还有另外一些由此而衍生的非核心要素，就不多做详细解释了，比如：</p>
<ul>
<li>Testability，可测试性</li>
<li>Security，安全性</li>
<li>Observability，可观测性</li>
<li>Predictability，可预测性</li>
<li>Extensibility，可扩展性</li>
<li>Maintainability，可维护性</li>
<li>Serviceability， 可服务性</li>
</ul>
<p>这些非核心要素虽然是非核心但是也不是说就不重要，是<code>开源产品与商业产品</code>差异的关键，关键在如何<code>tradeoff</code>。</p>
<h2 id="阴阳五行与分布式系统"><a href="#阴阳五行与分布式系统" class="headerlink" title="阴阳五行与分布式系统"></a>阴阳五行与分布式系统</h2><p>将阴阳五行理论与分布式系统设计理论结合起来解读就是：</p>
<p><code>分布式系统里的“道”就是“产品”，“阴阳“ 就是 ”功能“ 与 “非功能”，五行就是 ”容量、性能、可用性、可伸缩性以及可靠性“，阴阳五行衍生的一些其他关系对应分布式系统五要素衍生的一些其他要素。</code></p>
<p>用人话来讲就是 开发产品的时候需要考虑功能与非功能两个方面，而要保证产品质量又需要考虑”容量、性能、可用性、可伸缩性以及可靠性“这些核心要素，但是也不能忽略由此而生的一些非核心要素。</p>
<p>那么从这些理论到产品又需要怎么做才能落地呢？ 那自然是需要 <code>懂得如何把从这些概念性的、功能的、非功能的、这些核心的、非核心的要素进行设计实现成代码</code>，这就涉及到 “术”的层面了，“道”的层面可以通过看书看论文获得，而<code>“术”</code>的获得除了自身努力还得靠机会，而且每个人的悟性还不一样，这些个”术“以后有空慢慢讲。</p>
<h2 id="思考题"><a href="#思考题" class="headerlink" title="思考题"></a>思考题</h2><p>最后给大家留一个思考题： 前面提过老子曰：<code>”道生一、一生二、二生三、三生万物，万物负阴而抱阳，冲气以为和。“</code>， 三之后就是万物，为什么不是 五、不是六、不是七之类的呢？为什么三之后就是万物了？</p>
<h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a>作者简介</h2><p>常平，毕业于中国科学技术大学，获硕士研究生学历学位，10年+ 存储、布式系统、云计算以及大数据经验，曾就职于Marvell、AMD等，现就职于EMC，资深首席工程师，主要负责流式大数据处理平台的架构设计、编码及产品交付等。</p>
<hr>
<h4 id="注："><a href="#注：" class="headerlink" title="注："></a>注：</h4><ol>
<li>这个用五行解释分布式系统的观点，以前在一个业内微信群里提出并且聊过，所以这个解读的方式为本人原创非COPY.</li>
<li>个人愚钝，悟性有限，欢迎拍砖，砖多了我就拿回去砌墙。</li>
</ol>
<h3 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h3><p>[1]. <a href="https://baike.sogou.com/v7556185.htm" target="_blank" rel="noopener">https://baike.sogou.com/v7556185.htm</a></p>

      
    </main>
    <footer class="post-footer">
      
      <div class="post-tags">
        
        <a class="post-tag button" href="/tags/distributed/" rel="tag"><i class="fas fa-tags"></i>distributed</a>
        
      </div>
      
    </footer>
  </article>
  
  <article class="article post card" itemscope itemtype="http://schema.org/Article">
    <div class="post-block">
      <link itemprop="mainEntityOfPage" href="www.changping.me/2018/09/21/pravega-streaming-put-several-event-types-kafka-topic/">
      <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
        <meta itemprop="name" content="常平">
        <meta itemprop="description" content="“分布式系统架构设计师”">
        <meta itemprop="image" content="/images/avatar.jpg">
      </span>
      <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
        <meta itemprop="name" content="常平的技术博客">
      </span>
    </div>
    <header class="post-header">
      <h1 class="post-title" itemprop="name headline">
        <a class="post-title-link post-title-link-external" href="/2018/09/21/pravega-streaming-put-several-event-types-kafka-topic/" itemprop="url">应该在同一个Kafka主题中放入几种事件类型吗？</a>
      </h1>
      <div class="post-meta">
        
        <span class="post-date">
          <i class="far fa-calendar-plus"></i><span><time title="post-date" itemprop="dateCreated datePublished" datetime="2018-09-21T06:46:43+08:00">2018-09-21 06:46:43</time></span>
        </span>
        
        
        
        <span class="post-meta-divider divider">|</span>
        
        <span class="post-categories">
          
          <i class="far fa-folder-open"></i><span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/pravega/" itemprop="url" rel="index"><span itemprop="name">pravega</span></a></span>
        </span>
        
        
      </div>
    </header>
    <main class="post-main" itemprop="articleBody">
      
      <p>如果您采用Apache Kafka等流平台，有个很重要的问题是：将使用哪些主题？特别是，如果要将一堆不同的事件作为消息发布到Kafka，是将它们放在同一主题中，还是将它们拆分为不同的主题？</p>
<p>主题最重要的功能是允许使用者指定它想要使用的消息子集。在一个极端情况下，所有数据都放在一个主题中可不是一个好主意，因为这意味着消费者无法选择感兴趣的事件 - 给他们的只会是所有的内容。在另一个极端，拥有数百万个不同的主题也不是一个好事，因为Kafka中的每个主题都会消耗资源消耗，因此拥有大量的主题就会对性能不利。</p>
<p>实际上，从性能的角度来看，重要的是分区数量。但由于Kafka中的每个主题至少有一个分区，如果你有n个主题，那么就不可避免地至少有n个分区。不久之前，[Jun Rao撰写了一篇博文]，解释了拥有多个分区的成本（端到端延迟，文件描述符，内存开销，故障后的恢复时间）。根据经验，如果您关注延迟问题，您应该关注每个代理节点上的（数量级）数百个主题分区。如果每个节点有数万个甚至数千个分区，则延迟会受到影响。</p>
<p>该性能参数给设计主题的结构提供了一些指导：如果您发现自己有数千个主题，那么将一些细粒度，低吞吐量的主题合并到粗粒度主题中是明智之举，从而减少分区的扩散。</p>
<p>然而，性能问题并不是结束。在我看来，更重要的是您的主题结构的数据完整性和数据建模方面。我们将在本文的其余部分讨论这些内容。</p>
<h2 id="主题-相同类型的事件的集合？"><a href="#主题-相同类型的事件的集合？" class="headerlink" title="主题=相同类型的事件的集合？"></a>主题=相同类型的事件的集合？</h2><p>常见的想法（根据我所拥有的几个对话，并根据邮件列表）似乎是：将同类型的所有事件放在同一主题中，并针对不同的事件类型使用不同的主题。这种思路让人联想到关系数据库，其中表是具有相同类型（即同一组列）的记录的集合，因此我们在关系表和Kafka主题之间进行类比。</p>
<p>该<a href="https://www.confluent.io/confluent-schema-registry/" target="_blank" rel="noopener">融合模式的注册表</a>本质上强化了这种模式，因为它鼓励你在主题中的所有消息使用相同的Avro模式。该模式可以在保持兼容性的同时进化（例如，通过添加可选字段），但最终所有消息都必须符合某种记录类型。在我们介绍了更多背景之后，我们将在后面的帖子中再次讨论这个问题。</p>
<p>对于某些类型的流数据（例如记录的活动事件），要求同一主题中的所有消息都符合相同的模式是有意义的。但是，有些人正在使用Kafka来实现更多类似数据库的目的，例如事件溯源，或者在微服务之间交换数据。在这种情况下，我相信，它定义一个主题为一组具有相同模式的消息并不重要。更重要的是Kafka维护主题分区内的消息排序。</p>
<p>想象一下，您有一些事物（比如客户），并且该事物可能发生许多不同的事情：创建客户，客户更改地址，客户向其帐户添加新信用卡，客户进行客户支持查询，客户支付发票，客户关闭其帐户。</p>
<p>这些事件的顺序很重要。例如，我们期望在客户做任何动作之前创建客户，并且我们也期望在客户关闭其帐户之后不再发生任何其他事情。使用Kafka时，您可以通过将它们全部放在同一个分区中来保留这些事件的顺序。在此示例中，您将使用客户ID作为分区键，然后将所有这些不同的事件放在同一主题中。它们必须位于同一主题中，因为不同的主题意味着不同的分区，并且不会跨分区保留排序。</p>
<h2 id="排序问题"><a href="#排序问题" class="headerlink" title="排序问题"></a>排序问题</h2><p>如果你没有使用（比方说）不同的主题<code>customerCreated</code>，<code>customerAddressChanged</code>和<code>customerInvoicePaid</code>事件，然后这些议题的消费者可能会看到荒谬的事件顺序。例如，消费者可能会看到不存在的客户的地址更改（因为尚未创建，因为相应的<code>customerCreate</code>事件已被延迟）。</p>
<p>如果消费者暂停一段时间（可能是维护或部署新版本），则重新排序的风险尤其高。当消费者停止时，事件将继续发布，并且这些事件将存储在Kafka代理的选定主题分区中。当消费者再次启动时，它会消耗来自其所有输入分区的积压事件。如果消费者只有一个输入，那就没问题了：挂起的事件只是按照它们存储的顺序依次处理。但是，如果消费者有几个输入主题，它将选择输入主题以按任意顺序读取。它可以在读取另一个输入主题上的积压之前从一个输入主题读取所有挂起事件，或者它可以以某种方式交错输入。</p>
<p>因此，如果你把<code>customerCreated</code>，<code>customerAddressChanged</code>以及<code>customerInvoicePaid</code>事件在三个独立的主题，消费者可能会看到所有的<code>customerAddressChanged</code>事件，它看到任何之前<code>customerCreated</code>的事件。因此，消费者可能会看到一个<code>customerAddressChanged</code>客户的事件，根据其对世界的看法，尚未创建。</p>
<p>您可能想要为每条消息附加时间戳，并将其用于事件排序。如果要将事件导入数据仓库，您可以在事后对事件进行排序，这可能就可以了。但是在流进程中，时间戳是不够的：如果你得到一个具有特定时间戳的事件，你不知道你是否仍然需要等待一个时间戳较低的先前事件，或者所有之前的事件是否已到达而你是’准备好处理这个事件。依靠时钟同步通常会导致噩梦;</p>
<h2 id="何时分割主题，何时结合？"><a href="#何时分割主题，何时结合？" class="headerlink" title="何时分割主题，何时结合？"></a>何时分割主题，何时结合？</h2><p>鉴于这种背景，我将提出一些经验法则来帮助您确定在同一主题中放入哪些内容，以及将哪些内容拆分为单独的主题：</p>
<ol>
<li><p>最重要的规则是，  任何需要保持固定顺序的事件必须放在同一主题中（并且它们也必须使用相同的分区键）。最常见的是，如果事件的顺序与同一事物有关，则事件的顺序很重要。因此，根据经验，我们可以说关于同一事物的所有事件都需要在同一主题中。如果您使用事件排序方法进行数据建模，事件的排序尤为重要。这里，聚合对象的状态是通过以特定顺序重放它们来从事件日志中导出的。因此，即使可能存在许多不同的事件类型，定义聚合的所有事件也必须在同一主题中。</p>
</li>
<li><p>当您有关于不同事物的事件时，它们应该是相同的主题还是不同的主题？我想说，如果一个事物依赖于另一个事物（例如，一个地址属于一个客户），或者如果它们经常需要在一起，那么它们也可能会出现在同一个主题中。另一方面，如果它们不相关并由不同的团队管理，则最好将它们放在单独的主题中。它还取决于事件的吞吐量：如果一个事物类型具有比另一个事物类型高得多的事件，它们是更好地分成单独的主题，以避免压倒性的消费者只想要具有低写入吞吐量的事物（参见第4点）。但是，几个都具有低事件率的事物可以很容易地合并。</p>
</li>
<li><p>如果一个事件涉及多个事物怎么办？例如，购买涉及产品和客户，并且从一个帐户到另一个帐户的转移涉及至少那两个帐户。我建议最初将事件记录为单个原子消息，而不是将其分成几个消息。主题，最好以完全按照您收到的方式记录事件，并尽可能采用原始形式。您可以随后使用流处理器拆分复合事件 - 但如果您过早地将其拆分，则重建原始事件要困难得多。更好的是，您可以为初始事件提供唯一ID（例如UUID）; 以后，当您将原始事件拆分为每个涉及的事物的一个事件时，您可以将该ID转发，从而使每个事件的起源都可追溯。</p>
</li>
<li><p>查看消费者需要订阅的主题数量。如果几个消费者都阅读了一组特定的主题，这表明可能应该将这些主题组合在一起。如果将细粒度的主题组合成粗粒度的主题，一些消费者可能会收到他们需要忽略的不需要的事件。这不是什么大问题：消费来自Kafka的消息非常便宜，所以即使消费者最终忽略了一半的事件，这种过度消费的成本可能也不大。只有当消费者需要忽略绝大多数消息（例如99.9％是不需要的）时，我才建议从高容量流中分割低容量事件流。</p>
</li>
<li><p>Kafka Streams状态存储（KTable）的更改日志主题应与所有其他主题分开。在这种情况下，主题由Kafka Streams流程管理，不应与其他任何内容共享。</p>
</li>
<li><p>最后，如果上述规则都没有告诉您是否将某些事件放在同一主题或不同主题中，该怎么办？然后，通过将相同类型的事件放在同一主题中，通过所有方法将它们按事件类型分组。但是，我认为这条规则是最不重要的。</p>
</li>
</ol>
<h2 id="模式管理"><a href="#模式管理" class="headerlink" title="模式管理"></a>模式管理</h2><p>如果您使用的是数据编码（如JSON），而没有静态定义的模式，则可以轻松地将许多不同的事件类型放在同一主题中。但是，如果您使用的是基于模式的编码（如Avro），则需要更多地考虑在单个主题中处理多个事件类型。</p>
<p>如上所述，基于Avro的<code>Kafka Confluent Schema Registry</code>目前依赖于每个主题都有一个模式的假设（或者更确切地说，一个模式用于密钥，一个模式用于消息的值）。您可以注册新版本的模式，注册表会检查模式更改是向前还是向后兼容。这个设计的一个好处是，您可以让不同的生产者和消费者同时使用不同的模式版本，并且它们仍然保持彼此兼容。</p>
<p>更确切地说，当Confluent的Avro序列化程序在注册表中注册模式时，它会在主题名称下注册。默认情况下，该主题<code>&lt;topic&gt;-key</code>用于消息键和<code>&lt;topic&gt;-value</code>消息值。然后，模式注册表检查在特定主题下注册的所有模式的相互兼容性。</p>
<p>我最近对<a href="https://github.com/confluentinc/schema-registry/pull/680" target="_blank" rel="noopener">Avro序列化程序进行了修补</a>，使兼容性检查更加灵活。该补丁添加了两个新的配置选项:(<code>key.subject.name.strategy</code>定义如何构造消息键的主题名称），以及<code>value.subject.name.strategy</code>（如何构造消息值的主题名称）。选项可以采用以下值之一：</p>
<ul>
<li><p><code>io.confluent.kafka.serializers.subject.TopicNameStrategy</code>（默认值）：消息键的主题名称是<code>&lt;topic&gt;-key</code>，<code>&lt;topic&gt;-value</code>对于消息值。这意味着主题中所有消息的模式必须相互兼容。</p>
</li>
<li><p><code>io.confluent.kafka.serializers.subject.RecordNameStrategy</code>：主题名称是邮件的Avro记录类型的完全限定名称。因此，模式注册表会检查特定记录类型的兼容性，而不考虑主题。此设置允许同一主题中的任意数量的不同事件类型。</p>
</li>
<li><p><code>io.confluent.kafka.serializers.subject.TopicRecordNameStrategy</code>：主题名称是<code>&lt;topic&gt;-&lt;type&gt;</code>，<code>&lt;topic&gt;Kafka</code>主题名称在哪里，并且<type>是邮件的Avro记录类型的完全限定名称。此设置还允许同一主题中的任意数量的事件类型，并进一步将兼容性检查限制为仅当前主题。</type></p>
</li>
</ul>
<p>使用此新功能，可以轻松，干净地将特定事物的所有不同事件放在同一主题中。现在，可以根据上述条件自由选择主题的粒度，而不仅限于每个主题的单个事件类型。</p>
<h2 id="原文："><a href="#原文：" class="headerlink" title="原文："></a>原文：</h2><p>[1] <a href="https://www.confluent.io/blog/put-several-event-types-kafka-topic/" target="_blank" rel="noopener">https://www.confluent.io/blog/put-several-event-types-kafka-topic/</a>, Martin KleppmannMartin Kleppmann</p>

      
    </main>
    <footer class="post-footer">
      
      <div class="post-tags">
        
        <a class="post-tag button" href="/tags/pravega/" rel="tag"><i class="fas fa-tags"></i>pravega</a>
        
      </div>
      
    </footer>
  </article>
  
  <article class="article post card" itemscope itemtype="http://schema.org/Article">
    <div class="post-block">
      <link itemprop="mainEntityOfPage" href="www.changping.me/2018/09/20/pravega-controller-service-3/">
      <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
        <meta itemprop="name" content="常平">
        <meta itemprop="description" content="“分布式系统架构设计师”">
        <meta itemprop="image" content="/images/avatar.jpg">
      </span>
      <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
        <meta itemprop="name" content="常平的技术博客">
      </span>
    </div>
    <header class="post-header">
      <h1 class="post-title" itemprop="name headline">
        <a class="post-title-link post-title-link-external" href="/2018/09/20/pravega-controller-service-3/" itemprop="url">Pravega handbook - 控制器服务之三</a>
      </h1>
      <div class="post-meta">
        
        <span class="post-date">
          <i class="far fa-calendar-plus"></i><span><time title="post-date" itemprop="dateCreated datePublished" datetime="2018-09-20T21:59:55+08:00">2018-09-20 21:59:55</time></span>
        </span>
        
        
        
        <span class="post-meta-divider divider">|</span>
        
        <span class="post-categories">
          
          <i class="far fa-folder-open"></i><span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/pravega/" itemprop="url" rel="index"><span itemprop="name">pravega</span></a></span>
        </span>
        
        
      </div>
    </header>
    <main class="post-main" itemprop="articleBody">
      
      <h2 id="角色和责任"><a href="#角色和责任" class="headerlink" title="角色和责任"></a>角色和责任</h2><h3 id="流操作"><a href="#流操作" class="headerlink" title="流操作"></a>流操作</h3><p>控制器是所有流相关元数据的真实存储。Pravega客户端（EventStreamReaders和EventStreamWriters）与控制器一起确保流不变量在流上工作时得到满足和尊重。控制器维护流的元数据，包括段的整个历史。访问流的客户端需要联系控制器以获取有关段的信息。<br>客户端查询控制器以了解如何导航流。为此，控制器公开适当的API以获取活动段，后继者，前驱者和段信息以及Uris。这些查询使用存储和通过流存储接口访问元数据来提供这些查询服务。<br>Controller还提供了修改流的状态和行为的工作流程。这些工作流程包括创建，缩放，截断，更新，密封和删除。这些工作流程既可以通过直接API调用，也可以通过后台策略管理器（自动调整和保留）调用。</p>
<p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega%2FRequestProcessing.png" alt="RequestProcessing"><br>请求处理流程</p>
<h2 id="创建流"><a href="#创建流" class="headerlink" title="创建流"></a>创建流</h2><p>创建流是作为任务框架上的任务来实现的。创建流工作流首先创建流状态设置为CREATING * 的初始流元数据。在此之后，它标识应该拥有的段容器并为此流创建段并同时调用create-segment。完成所有创建段后，创建流任务完成，从而将流移动到ACTIVE状态。所有故障都会以指数退避重试几次。但是，如果它无法完成任何步骤，则流将保持在CREATING状态。</p>
<h2 id="更新流"><a href="#更新流" class="headerlink" title="更新流"></a>更新流</h2><p>更新流被实现为序列化请求处理程序/并发事件处理器框架上的任务。更新流由显式API调用来调用到控制器中。它首先将更新请求事件发布到请求流中。之后，它尝试创建临时更新属性。如果它无法创建临时更新属性，则请求失败，并且会通知调用方由于与另一个正在进行的更新冲突而无法更新流。</p>
<p>事件由请求事件处理器选择。处理开始时，更新流任务期望找到要存在的临时更新流属性。如果找不到该属性，则通过将事件推回到内存中队列中来延迟更新处理，直到它认为事件已过期为止。如果在此期间找到要更新的属性，则在到期之前，处理该事件并执行更新流操作。现在处理开始，它首先将状态设置为UPDATING。在此之后，在元数据存储中更新流配置，然后通知段存储关于流的所有活动段关于策略的改变。现在状态重置为ACTIVE。</p>
<h3 id="缩放流"><a href="#缩放流" class="headerlink" title="缩放流"></a>缩放流</h3><p>可以通过显式API调用（称为手动缩放）调用缩放，也可以基于缩放策略自动执行缩放（称为自动缩放）。我们首先编写事件，然后通过为要创建的所需段创建新条目来更新段表。此步骤是幂等的，并确保如果正在进行现有的缩放操作，则此启动新的缩放的尝试失败。处理的开始类似于更新流中遵循的机制。如果更新元数据，则事件处理并继续执行任务。如果元数据未在期望的时间范围内更新，则事件被丢弃。</p>
<p>一旦缩放处理开始，它首先设置流状态SCALING。然后在段存储中创建新段。在成功创建新段之后，它使用对应于新时期的部分记录更新历史表，该新时期包含按比例显示的段列表。每个新的时期创建还创建新的根历元节点，在该节点下，来自该时期的所有事务的元数据驻留在该节点上。因此，当执行比例时，将存在与旧时期对应的节点，并且现在还将存在用于新时期的根节点。从这一点开始创建的任何事务都将针对新时期进行。现在，工作流尝试通过机会性地尝试删除旧时期来完成缩放。当且仅当其名下没有事务时，可以删除旧时期。一旦我们确定旧时期没有事务，我们就可以继续密封旧的段并完成规模。成功密封旧段后，历史表中的部分记录现已完成，从而完成了缩放工作流程。状态现在重置为ACTIVE。</p>
<h3 id="截断流"><a href="#截断流" class="headerlink" title="截断流"></a>截断流</h3><p>Truncate遵循类似的机制进行更新，并具有用于截断的临时流属性，用于为截断流提供输入。一旦截断工作流标识它可以继续，它首先将状态设置为TRUNCATING。然后截断工作流查看请求的流截断，并检查它是否大于或等于现有截断点，然后它才是截断的有效输入并且工作流程开始。截断工作流接受请求的流截断，并计算要作为此截断请求的一部分删除的所有段。然后它调用相应的段存储来删除已识别的段。删除后，我们称在截止流中截断的流中描述的截断段，如流截断中所述。在此之后，截断记录将使用新的截断点和已删除的段进行更新。状态重置为ACTIVE。</p>
<h2 id="密封流"><a href="#密封流" class="headerlink" title="密封流"></a>密封流</h2><p>可以通过对控制器的显式API调用来请求密封流。它首先将密封流事件发布到请求流中，然后尝试将流的状态设置为SEALING。如果事件被挑选并且没有找到流处于期望状态，则它通过将其重新发布在内存队列的后面来推迟密封流处理。一旦流被设置为密封状态，流的所有活动段都通过调用段存储来密封。在此之后，流在流元数据中被标记为SEALED。</p>
<h3 id="删除流"><a href="#删除流" class="headerlink" title="删除流"></a>删除流</h3><p>可以通过对控制器的显式API调用来请求删除流。请求首先验证流是否处于SEALED状态。只有密封的流才能被删除，并在请求流中发布这样的事件。当事件被处理，它会再次验证流状态，然后通过调用段存储来继续从一开始就删除属于该流的所有段。成功删除所有段后，将清除与此流对应的流元数据。</p>
<h2 id="流策略管理器"><a href="#流策略管理器" class="headerlink" title="流策略管理器"></a>流策略管理器</h2><p>如前所述，控制器负责执行的用户定义策略有两种类型，即自动缩放和自动保留。Controller不仅仅是流策略的存储，而是主动为其流实施这些用户定义的策略。</p>
<h3 id="缩放基础架构"><a href="#缩放基础架构" class="headerlink" title="缩放基础架构"></a>缩放基础架构</h3><p>缩放基础架构与段存储一起构建。当控制器在段存储中创建新段时，它会将用户定义的缩放策略传递给段存储。然后，段存储监视所述段的流量，并且如果违反了从策略确定的某些阈值，则向控制器报告。Controller通过在专用内部流中发布的事件接收这些通知。可以为段接收两种类型的流量报告。第一种类型标识是否应该按比例放大（拆分）段，第二种类型标识是否应按比例缩小段。对于符合条件进行缩放的段，控制器会立即在请求流中发布段缩放请求，以便处理请求事件处理器。但是，为了缩小规模，控制器需要等待至少两个相邻的段，才有资格进行缩小。为此，它只是在元数据存储中将该段标记为冷。如果有相邻的段标记为冷，控制器会将它们合并，并发布缩小请求。然后，在请求事件处理器上异步执行缩放处理请求。</p>
<h3 id="保留基础设施"><a href="#保留基础设施" class="headerlink" title="保留基础设施"></a>保留基础设施</h3><p>保留策略定义了应为给定流保留多少数据。这可以定义为基于时间或基于大小的。为了应用此策略，控制器定期收集流的流截断，并且如果策略指定，则有机会地对先前收集的流截断执行截断。由于这是需要为已定义保留策略的所有流执行的定期后台工作，因此迫切需要在所有可用的控制器实例之间公平地分配此工作负载。为实现这一点，我们依赖于将流转储到预定义集中，并在控制器实例之间分发这些集。这是通过使用zookeeper来存储此分发来完成的。在引导期间，每个控制器实例都尝试获取存储桶的所有权。拥有控制器监视桶下的所有流以保留机会。在每个周期里，控制器收集新的流截断并将其添加到所述流的保留集中。发布此消息后，它会查找存储在保留集中的候选流截断，这些流截断可以根据定义的保留策略进行截断。例如，在基于时间的保留中，选择早于指定保留期的最新流截断作为截断点。</p>
<h2 id="事务管理器"><a href="#事务管理器" class="headerlink" title="事务管理器"></a>事务管理器</h2><p>控制器扮演的另一个重要角色是事务管理器。它负责创建，提交和中止事务。由于控制器是我们集群中的核心大脑和机构，并且是关于流的真实的持有者，因此writer请求控制器执行关于事务的所有控制平面动作。从创建事务到提交或中止事务的时间起，控制器在为事务提供保证方面发挥着积极作用。控制器跟踪每个事务的指定超时，如果超时超过，它会自动中止事务。</p>
<p>控制器负责确保事务和潜在的并行规模操作相互配合，确保所有承诺都得到尊重和执行。</p>
<p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega%2FTransactionManagement.png" alt="TransactionManagement"></p>
<p>事务管理图</p>
<p>客户端调用控制器进程来创建，ping提交或中止事务。这些请求中的每一个都在控制器上接收并由Transaction Utility模块处理，该模块实现用于处理每个请求的业务逻辑。</p>
<h3 id="创建事务"><a href="#创建事务" class="headerlink" title="创建事务"></a>创建事务</h3><p>writer与Controller交互以创建新事务。Controller Service将创建事务请求传递给事务工具Utility模块。模块中的create transaction函数执行以下步骤以创建事务：1。为事务生成唯一的UUID。2.它从元数据存储中获取流的当前活动的一组段，并从历史中获取其对应的时期标识符。3.它使用元数据存储接口在zookeeper中创建新的事务记录。4.然后，它请求段存储创建特定的事务段，这些段本质上链接到父活动段。<br>在创建事务时，控制器确保在我们尝试创建相应的事务段时不会密封父段。并且在事务的生命周期中，如果缩放开始，它应该等待旧时期事务在缩放之前完成，以便从旧时期密封段。</p>
<h3 id="提交事务"><a href="#提交事务" class="headerlink" title="提交事务"></a>提交事务</h3><p>在收到提交事务的请求后，Controller Service将请求传递给Transaction Utility模块。该模块首先尝试通过元数据存储来标记事务特定元数据记录中的提交事务。在此之后，它在内部提交流中发布提交事件。提交事务工作流在提交事件处理器上实现，从而异步处理。提交事务工作流检查提交事务的是否合格，如果为true，则执行提交工作流，无限期重试，直到成功为止。如果事务不符合提交条件（通常在旧时期仍处于活动状态时在新时期上创建事务时发生），则此类事件将重新发布到内部流中以便稍后选取。</p>
<p>成功提交事务后，事务的记录将从其时期根下被删除。然后，如果存在一个正在进行的缩放，则它呼叫尝试完成正在进行的缩放。试图完成缩放取决于删除旧时期的能力，当且仅当没有针对所述时期的未完成的活动事务时才能删除（有关更多细节，请参阅缩放工作流程）。</p>
<h3 id="中止事务"><a href="#中止事务" class="headerlink" title="中止事务"></a>中止事务</h3><p>可以通过应用程序明确请求中止，类似于提交。但是，如果事务超时，则也可以自动启动中止。控制器跟踪系统中每个事务的超时，并且每当超时过去时，或者在显式用户请求时，事务实用程序模块在其各自元数据中将事务标记为中止。在此之后，事件被中止事件处理器处理，并立即尝试中止事务。中止事务没有排序要求，因此它同时并跨流执行。</p>
<p>与提交一样，一旦事务中止，其节点将从其时期根目录中删除，如果存在持续的缩放，则尝试完成缩放流。</p>
<h3 id="Ping事务"><a href="#Ping事务" class="headerlink" title="Ping事务"></a>Ping事务</h3><p>由于控制器对于正在写入事务中的段的数据没有对数据路径的可见性，因此控制器不知道是否正在主动处理事务，并且如果超时过去，它可能会尝试中止事务。为了使应用程序能够控制事务的命运，控制器公开API以允许应用程序更新事务超时期限。这种机制称为ping，只要应用程序ping事务，控制器就会为各自的事务重置其计时器。</p>
<h3 id="事务超时管理"><a href="#事务超时管理" class="headerlink" title="事务超时管理"></a>事务超时管理</h3><p>控制器跟踪每个事务的超时。这是作为定时轮服务实现的。创建后，每个事务都会在创建它的控制器上注册到计时器服务中。可以在不同的控制器实例上接收事务的后续ping，并且基于通过zookeeper实现的所有权机制将定时器管理转移到最新的控制器实例。超时到期后，将尝试自动中止，如果能够成功将事务状态设置为中止，则启动中止工作流。</p>
<p>控制器监视超时的每个事务都会添加到此进程索引中。如果此类控制器实例失败或崩溃，则其他控制器实例将收到节点失败通知，并尝试从失败的实例中扫描所有未完成的事务，并从该点开始监视其超时。</p>
<h2 id="段容器到主机映射"><a href="#段容器到主机映射" class="headerlink" title="段容器到主机映射"></a>段容器到主机映射</h2><p>Controller还负责将段容器分配给段存储节点。维护此映射的责任落在单个控制器实例上，该实例是通过使用zookeeper的领导者选举选择的。当段存储节点被添加到/从集群中移除时，该领导控制器监视段存储节点的生命周期，并且跨可用的段存储节点执行段容器的重新分配。此分发映射存储在专用ZNode中。每个段存储周期性地轮询此znode以查找更改，如果找到更改，它将关闭并放弃它不再拥有的容器，并尝试获取分配给它的容器的所有权。</p>
<p><a href="http://pravega.io/docs/latest/controller-service/#controllerClusterListener" target="_blank" rel="noopener">这里</a>已经讨论了有关实现的细节，特别是关于如何存储和管理元数据的细节。</p>

      
    </main>
    <footer class="post-footer">
      
      <div class="post-tags">
        
        <a class="post-tag button" href="/tags/pravega/" rel="tag"><i class="fas fa-tags"></i>pravega</a>
        
      </div>
      
    </footer>
  </article>
  
  <article class="article post card" itemscope itemtype="http://schema.org/Article">
    <div class="post-block">
      <link itemprop="mainEntityOfPage" href="www.changping.me/2018/09/20/pravega-controller-service-2/">
      <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
        <meta itemprop="name" content="常平">
        <meta itemprop="description" content="“分布式系统架构设计师”">
        <meta itemprop="image" content="/images/avatar.jpg">
      </span>
      <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
        <meta itemprop="name" content="常平的技术博客">
      </span>
    </div>
    <header class="post-header">
      <h1 class="post-title" itemprop="name headline">
        <a class="post-title-link post-title-link-external" href="/2018/09/20/pravega-controller-service-2/" itemprop="url">Pravega handbook - 控制器服务之二</a>
      </h1>
      <div class="post-meta">
        
        <span class="post-date">
          <i class="far fa-calendar-plus"></i><span><time title="post-date" itemprop="dateCreated datePublished" datetime="2018-09-20T21:39:45+08:00">2018-09-20 21:39:45</time></span>
        </span>
        
        
        
        <span class="post-meta-divider divider">|</span>
        
        <span class="post-categories">
          
          <i class="far fa-folder-open"></i><span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/pravega/" itemprop="url" rel="index"><span itemprop="name">pravega</span></a></span>
        </span>
        
        
      </div>
    </header>
    <main class="post-main" itemprop="articleBody">
      
      <h2 id="流元数据"><a href="#流元数据" class="headerlink" title="流元数据"></a>流元数据</h2><p>客户端需要有关哪些段构成流的信息以开始其处理，并且他们从控制器存储在流存储中的时期信息中获取它。读取器客户端通常从流的头部开始，但它也可以选择从任意有趣的位置开始访问流。另一方面，writer总是附加到流的尾部。<br>客户端需要能够有效地查询和查找在以下三种场景中的任何一个段。为了启用这些查询，流存储提供API调用来获取这些段的初始集合、在特定时间获取段以及获取段的当前集合。</p>
<p>如前所述，流可以从一组段（epoch）转换到构成流的另一组段。如果至少一个段被密封，并且被一个或多个精确覆盖密封段的密钥空间的段替换，则流从一个时期移动到另一个时期。当客户在流上工作时，他们可能会遇到密封段的末端，因此需要找到新的段才能继续前进。为了使客户端能够查询下一个段，流存储库通过控制器服务公开有效查询，以查找任意段的直接后继和前驱。</p>
<p>为了启用上述服务查询，我们需要有效地存储这些段转换的时间序列，并将它们与时间进行索引。我们在一组表中存储有关流段的当前和历史状态的信息，这些表被设计为旨在针对上述查询进行优化。除了特定于段的元数据记录之外，流的当前状态包括此后描述的其他元数据类型。</p>
<h2 id="表"><a href="#表" class="headerlink" title="表"></a>表</h2><p>为了有效地存储和查询段信息，我们将段数据拆分为三个仅附加表，即段表，历史表和索引表。</p>
<ul>
<li><p>段表<br>segment-info：segmentid，time，keySpace-start，keySpace-end<br>控制器将段表存储在仅附加表中，第 i 行对应于段id i的元数据。值得注意的是，段表中的每一行都是固定大小的。当添加新的段时，它们将按严格增加的顺序分配新的段ID。因此，该表非常有效地创建新段并使用O（1）处理来查询段信息响应方面非常有效。</p>
</li>
<li><p>历史表<br>epoch：时间，历史中的片段列表<br>历史表在从一个时期过渡到另一个时期时存储一系列活动段。历史表中的每一行都存储一个epoch，该epoch捕获一组逻辑上一致的（如前面定义的）段，这些段组成流，并且在该epoch的生命周期内是有效的。此表旨在优化查询以查找在任意时间形成流的段集。有三种最常用的场景，我们希望有效地知道形成流的段集 - 初始的段集，当前的段和段的任意时间段。前两个查询在O（1）时间内非常有效地回答，因为它们对应于表中的第一行和最后一行。由于表中的行是按时间的增加顺序排序的，并且捕获了流段集变化的时间序列，因此我们可以很容易地执行二进制搜索来查找在任何任意时间对应于段集的行。</p>
</li>
</ul>
<ul>
<li>索引表<br>index：⟨time，offset-in-history-table⟩<br>由于历史行的长度是可变的，因此我们为索引表中的时间戳索引历史记录行。这使我们能够浏览历史表并执行二分查找以有效地回答查询以在任意时间获得段集。我们还对历史表执行二分查找以确定任何给定段的后继。</li>
</ul>
<h2 id="流配置"><a href="#流配置" class="headerlink" title="流配置"></a>流配置</h2><p>Znode，其中流配置被序列化并持久化。流配置包含需要强制实施的流策略。缩放策略和保留策略由应用程序在创建流时提供，并由控制器通过监视流中数据的速率和大小来强制执行。缩放策略描述了是否以及何时根据流中的传入流量条件自动缩放。该策略支持两种风格 -每秒事件的速率的流量和每秒的字节速率的流量。应用程序通过缩放策略将它们所需的流量指定到每个段，并选择所提供的值来计算确定何时缩放给定流的阈值。保留策略描述了需要保留到此流的pravega集群中的数据量。我们支持基于时间和基于大小的保留策略，其中应用程序可以选择是否希望通过选择适当的策略并提供其所需值来按大小或时间保留流中的数据。</p>
<h2 id="流状态"><a href="#流状态" class="headerlink" title="流状态"></a>流状态</h2><p>Znode捕获流的状态。它是一个枚举，包含来自创建，活动，更新，缩放，截断，密封和密封流的值。一旦激活，流在执行特定操作和活动之间转换，直到它被密封。转换映射在State 类中定义 ，允许和禁止各种状态转换。流状态描述了流的当前状态。它基于在流上执行的动作从ACTIVE转换到相应的动作。例如，在缩放期间，流的状态从ACTIVE转换为SCALING一旦缩放完成，它就会转换回ACTIVE。流状态用作屏障，以确保在任何时间点仅对给定流执行一种类型的操作。仅允许某些状态转换，并在状态转换对象中进行描述。只允许合法的状态转换，任何不允许转换的尝试都会导致适当的异常。</p>
<h2 id="截断记录"><a href="#截断记录" class="headerlink" title="截断记录"></a>截断记录</h2><p>这对应于最后用于截断给定流的流截断。所有流段查询都会叠加截断记录并返回严格大于或等于截断记录中的流截断的段。</p>
<h2 id="密封段记录"><a href="#密封段记录" class="headerlink" title="密封段记录"></a>密封段记录</h2><p>由于段表仅附加，因此在密封段时我们需要保留的任何其他信息都存储在密封段记录中。目前，它简单地包含了段号到其密封大小的映射。</p>
<h2 id="与事务相关的元数据记录："><a href="#与事务相关的元数据记录：" class="headerlink" title="与事务相关的元数据记录："></a>与事务相关的元数据记录：</h2><h3 id="活动事务"><a href="#活动事务" class="headerlink" title="活动事务"></a>活动事务</h3><p>每个新事务都是在此Znode下创建的。这将与每个事务相对应的元数据存储为ActiveTransactionRecord。事务完成后，将在全局完成事务znode节点下创建一个新节点，并从流特定活动事务节点下删除该节点。</p>
<h3 id="完成事务"><a href="#完成事务" class="headerlink" title="完成事务"></a>完成事务</h3><p>完成后，所有流的所有已完成事务都将在此单个znode下移动（通过提交或中止路径）。随后，我们可以根据我们认为合适的任何收集方案定期回收这些值。不过在这一点上，我们此时尚未实施任何计划。</p>
<h2 id="流存储缓存"><a href="#流存储缓存" class="headerlink" title="流存储缓存"></a>流存储缓存</h2><p>由于同一个控制器实例可以处理给定流的多个并发请求，因此每次通过查询zookeeper来读取该值是不合理的。因此，我们引入了每个流存储维护的内存缓存。它缓存每个流的检索元数据，使得缓存中每个流最多有一个数据副本。我们有两个内存缓存 - a）存储中多个流对象的缓存，b）流对象中流的缓存属性。</p>
<p>我们引入了操作上下文的概念，并且在任何新操作开始时创建了新的操作上下文。新操作上下文的创建使流的高速缓存实体无效，并且每当请求时都从存储中懒惰地检索每个实体。如果在操作过程中更新了值，则该值在缓存中再次无效，以便流上的其他并发读取/更新操作获取其后续步骤的新值。<br>流桶</p>
<p>为了启用某些场景，我们可能需要我们的后台工作人员定期处理群集中的每个流，以对它们执行某些特定操作。我们引入了一个桶的概念，以便在所有可用的控制器实例中分发此定期后台工作。为此，我们将每个流散列到一个预定义的存储桶中，然后在可用的控制器实例之间分配存储桶。<br>群集的桶数是群集生命周期的固定（可配置）值。<br>控制器实例将系统中的所有可用流映射到桶中，并在它们之间分配桶，以便所有长时间运行的后台工作可以在多个控制器实例之间均匀分布。每个桶对应于zookeeper中的唯一Znode。完全限定范围流名称用于计算散列以将流分配给桶。所有控制器实例在启动时都会尝试获取存储桶的所有权。在故障转移时，所有权都会转移，因为幸存的节点竞争以获取孤立桶的所有权。拥有存储桶的控制器实例负责与存储桶下所有节点相对应的所有长时间运行的调度后台工作。目前，这需要运行周期性工作流来捕获每个流的流截断（称为保留集）。</p>
<h2 id="保留集"><a href="#保留集" class="headerlink" title="保留集"></a>保留集</h2><p>每个流的一个保留集存储在相应的桶/流Znode下。当我们定期计算流截断时，我们会在此Znode下保留它们。在执行某些自动截断时，将从此集中清除不再有效的流截断。</p>
<h2 id="控制器群集Listener"><a href="#控制器群集Listener" class="headerlink" title="控制器群集Listener"></a>控制器群集Listener</h2><p>Pravega 集群中的每个节点都在集群Znode下作为短暂节点注册。这包括控制器和段存储节点。每个控制器实例在集群Znode上注册监视，以侦听集群更改通知。这些通知是关于节点添加和删除的。</p>
<p>一个控制器实例承担所有控制器实例的领导。此领导者控制器实例负责处理段存储节点更改通知。根据拓扑结构的变化，控制器实例会定期将段容器重新平衡为段存储节点映射。</p>
<p>所有控制器实例都侦听控制器节点更改通知。每个控制器实例都有多个子组件，用于实现故障转移 - 清除程序接口。目前有三个组件实现故障转移清除程序接口，即 TaskSweeper，EventProcessors和TransactionSweeper。每当识别出控制器实例已从群集中删除时，群集侦听器将调用所有已注册的故障转移清除程序，以便乐观地尝试清除先前由故障控制器主机拥有的所有孤儿工作。</p>
<h3 id="主机存储"><a href="#主机存储" class="headerlink" title="主机存储"></a>主机存储</h3><p>主机存储接口用于将Segment Container存储到Segment Store节点映射。它公开了像getHostForSegment这样的API，它计算了段ID的一致哈希值来计算所有者Segment Container。然后基于容器 - 主机映射，它将适当的URL返回给调用者。</p>
<h2 id="后台工作者"><a href="#后台工作者" class="headerlink" title="后台工作者"></a>后台工作者</h2><p>控制器进程有两种不同的机制/框架来处理后台工作。这些后台工作通常需要多个步骤和更新特定元数据根实体下的元数据，以及与一个或多个段存储的潜在交互。</p>
<p>首先，我们从一个简单的任务框架开始，该框架允许运行对给定资源（通常是流）拥有独占权的任务，并允许任务从一个控制器实例故障转移到另一个控制器实例。然而，这个模型限制了它的范围和锁定语义，并且没有固有的任务排序概念，因为多个任务可以竞争地同时获取资源上的工作权限（锁定），并且其中任何一个都可以成功。</p>
<p>为了克服这个限制，我们提出了一种新基础架构，称为Event Processor。事件处理器是经典的自己的狗食自己吃。它使用pravega流建造。这为我们提供了一个简洁的机制，以确保互斥和有序的处理。</p>
<h3 id="任务框架"><a href="#任务框架" class="headerlink" title="任务框架"></a>任务框架</h3><p>任务框架被设计为在每个资源上运行独占的后台处理， 以便在控制器实例失败的情况下，工作可以轻松地转移到另一个控制器实例并完成。框架本身并不保证幂等处理，并且如果需要，任务的作者必须处理它。任务模型被定义为只在给定资源上专门工作，这意味着没有其他任务可以在同一资源上并发运行。这是通过在zookeeper上实现的持久分布式锁实现的。任务的故障转移是通过遵循索引给定进程正在执行的工作的索引方案来实现的。因此，如果一个流程失败，另一个流程将扫描所有未完成的工作并尝试将所有权转移给自己。注意：控制器进程失败时，多个幸存的控制器进程可以同时尝试扫描孤立的任务。它们中的每一个都将在其主机索引中索引任务，但只有其中一个能够成功获取对资源的锁定，从而获得处理任务的权限。执行任务的参数被序列化并存储在资源下。</p>
<p>目前，我们仅将任务框架用于创建流任务。所有其他后台处理都是使用事件处理器框架完成的。</p>
<h2 id="事件处理器框架"><a href="#事件处理器框架" class="headerlink" title="事件处理器框架"></a>事件处理器框架</h2><p>事件处理器框架是后台工作子系统，它从内部流中读取事件并对其进行处理，因此称为事件处理器。我们系统中的所有事件处理器至少 提供一次 处理保证。并且在其基本风格方面，该框架还提供强大的顺序保证。但我们也有不同的事件处理器子类型，允许并发处理。</p>
<p>我们为不同类型的工作创建不同的事件处理器。目前，我们的系统中有三个不同的事件处理器，用于提交事务，中止事务和处理流特定请求，如扩展更新密封等。每个控制器实例都有一个每种类型的事件处理器。事件处理器框架允许为每个事件处理器创建多个读取器。跨控制器实例的特定事件处理器的所有读者共享相同的读取器组，这保证了跨控制器实例的互斥分配工作。每个读者都获得一个专用线程，在该线程中，它读取事件，调用其处理并在完成处理后更新其检查点。事件被发布在事件处理器特定的流中，并且基于使用作用域流名称作为路由密钥被路由到特定的段。</p>
<p>我们有两种类型的事件处理器，一种执行串行处理，这基本上意味着它会读取一个事件并启动它的处理，并等待它完成后再继续进行下一个事件。这为处理过程提供了强有力的顺序保证。处理完每个事件后的检查点。提交事务是使用事件处理器的这种基本风格实现的。处理这些事件的并行度上限为内容流中段数，下限为读者取器数量的限制。来自不同流的多个事件可以在同一段中出现，并且由于我们执行串行处理，串行处理的缺点是处理停顿或来自一个流的事件泛滥会对不相关流的延迟产生不利影响。</p>
<p>为了克服这些缺点，我们设计了Concurrent Event Processor作为串行事件处理器的叠加。顾名思义，并发事件处理器允许我们同时处理多个事件。这里读者线程读取一个事件，调度它的异步处理并返回读取下一个事件。在任何时间点同时处理的事件数量都有上限，并且当某个事件的处理完成时，允许获取更新的事件。这里的检查点方案变得更加复杂，因为我们希望保证至少一次处理。</p>
<p>但是，随着并发处理，顺序保证会被破坏。但是，重要的是要注意，我们只需要顺序保证来处理来自流而不是跨流的事件提供顺序保证。为了满足排序保证，我们将Concurrent Event Processor与Serialized Request Handler重叠，后者将来自内存队列中相同流的事件排队并按顺序处理它们。</p>
<p>提交事务处理是在专用串行事件处理器上实现的，因为我们需要提交顺序的强力保证，同时确保提交不会干扰流上其他类型请求的处理。</p>
<p>中止事务处理是在专用并发事件处理器上实现的，该处理器同时对来自跨流的事务执行中止处理。</p>
<p>对流的所有其他请求都在序列化请求处理程序上实现，该处理程序确保在任何给定时间正在处理每个流的一个请求，并且在请求处理期间存在排序保证。但是，它允许来自跨流的并发请求同时进行。实现缩放，截断，密封，更新和删除流等工作流程，以便在请求事件处理器上进行处理。</p>

      
    </main>
    <footer class="post-footer">
      
      <div class="post-tags">
        
        <a class="post-tag button" href="/tags/pravega/" rel="tag"><i class="fas fa-tags"></i>pravega</a>
        
      </div>
      
    </footer>
  </article>
  
  <article class="article post card" itemscope itemtype="http://schema.org/Article">
    <div class="post-block">
      <link itemprop="mainEntityOfPage" href="www.changping.me/2018/09/20/pravega-controller-service-1/">
      <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
        <meta itemprop="name" content="常平">
        <meta itemprop="description" content="“分布式系统架构设计师”">
        <meta itemprop="image" content="/images/avatar.jpg">
      </span>
      <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
        <meta itemprop="name" content="常平的技术博客">
      </span>
    </div>
    <header class="post-header">
      <h1 class="post-title" itemprop="name headline">
        <a class="post-title-link post-title-link-external" href="/2018/09/20/pravega-controller-service-1/" itemprop="url">Pravega handbook - 控制器服务之一</a>
      </h1>
      <div class="post-meta">
        
        <span class="post-date">
          <i class="far fa-calendar-plus"></i><span><time title="post-date" itemprop="dateCreated datePublished" datetime="2018-09-20T21:29:36+08:00">2018-09-20 21:29:36</time></span>
        </span>
        
        
        
        <span class="post-meta-divider divider">|</span>
        
        <span class="post-categories">
          
          <i class="far fa-folder-open"></i><span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/pravega/" itemprop="url" rel="index"><span itemprop="name">pravega</span></a></span>
        </span>
        
        
      </div>
    </header>
    <main class="post-main" itemprop="articleBody">
      
      <h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>控制器服务是Pravega的核心组件，用于实现控制平面。它充当集群中执行的各种操作的中央协调器和管理器，主要分为两类：</p>
<ol>
<li>流管理</li>
<li>集群管理</li>
</ol>
<p>控制器服务，此后简称为控制器，负责提供<a href="http://pravega.io/docs/latest/pravega-concepts/#streams" target="_blank" rel="noopener">流</a>的抽象，这是Pravega向应用程序公开的主要抽象。流包括一个或多个<a href="http://pravega.io/docs/latest/pravega-concepts/#stream-segments" target="_blank" rel="noopener">段</a>。每个段都是仅附加数据结构，用于存储字节序列。一个段本身与其他段的存在无关，并且不知道它与其对等段的逻辑关系。拥有和管理这些段的段存储没有任何流的概念。流是由Controller概念化的逻辑视图通过组合动态变化的一组段来满足一组预定义的逻辑不变量。控制器提供流抽象并协调流上的所有生命周期操作，同时确保抽象保持一致。</p>
<p>控制器在流的生命周期中起着核心作用：创建，修改，<a href="http://pravega.io/docs/latest/pravega-concepts/#autoscalingthenumber-of-stream-segments-can-vary-over-time" target="_blank" rel="noopener">缩放</a>和删除。它通过维护每个流的元数据并在必要时对段执行必要的操作来完成这些操作。例如，作为流生命周期的一部分，可以创建新的段并密封现有的段。控制器决定何时执行这些操作，使得流继续可用并且对访问它们的客户端是一致的。</p>
<h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><p>控制器服务由一个或多个无状态工作节点实例组成。每个新的控制器实例都可以独立启动，并成为pravega集群的一部分，它只需要指向相同的Apache Zookeeper。对于高可用性，建议是每个群集具有不止一个控制器服务实例。</p>
<p>每个控制器实例都能够独立工作，并使用一个共享的持久存储作为控制器服务所拥有和管理的所属状态的真实来源。目前使用Apache ZooKeeper作为持久存储来保存所有的元数据。每个实例包括各种子系统，其负责对不同类别的元数据执行特定操作。这些子系统包括不同的API端点，元数据存储句柄，策略管理器和后台工作程序。</p>
<p>控制器暴露两个端点，这些端点可用于与控制器服务交互。第一个端口用于为pravega客户端提供编程访问，并使用gRPC实现为RPC。另一个端点用于管理操作，并作为REST端点实现。</p>
<h2 id="流管理"><a href="#流管理" class="headerlink" title="流管理"></a>流管理</h2><p>控制器拥有并管理流的概念，并负责维护每个流的元数据和生命周期。具体而言，它负责创建，更新，缩放，截断，密封和删除流。<br>流管理可以大致分为三类：</p>
<ol>
<li><p>流抽象<br>流可以被视为一系列动态变化的段集，其中流从一组一致的段转换到下一个。Controller是创建和管理此流抽象的地方。控制器决定流何时以及如何从一种状态转换到另一种状态，并负责执行这些转换，同时保持流的状态一致且可用。这些转换是受控制器强制执行的用户定义策略的支配。因此，作为流管理的一部分，控制器还会执行策略管理器的角色，以实现保留和缩放等策略。</p>
</li>
<li><p>自动策略管理<br>控制器负责通过主动监视流的状态来存储和实施用户定义的流策略。目前，我们有两个用户可以定义的策略，即<a href="https://github.com/pravega/pravega/blob/master/client/src/main/java/io/pravega/client/stream/ScalingPolicy.java" target="_blank" rel="noopener">缩放策略</a>和 <a href="https://github.com/pravega/pravega/blob/master/client/src/main/java/io/pravega/client/stream/RetentionPolicy.java" target="_blank" rel="noopener">保留策略</a>。缩放策略描述了流是否以及在何种情况下应自动缩放其段数。保留策略描述了有关在流中保留多少数据的策略。</p>
</li>
<li><p><a href="http://pravega.io/docs/latest/pravega-concepts/#transactions" target="_blank" rel="noopener">事务</a>管理<br>实现事务需要操作段。对于每个事务，Pravega创建一组事务段，这些事务段稍后在提交时合并到流段上或在中止时丢弃。控制器执行事务管理器的角色，负责在给定流上创建和提交事务。在创建事务时，控制器还跟踪事务超时并中止超时已过期的事务。事务管理的细节可以在文档的后面找到。</p>
</li>
</ol>
<h2 id="集群管理"><a href="#集群管理" class="headerlink" title="集群管理"></a>集群管理</h2><p>控制器负责管理段存储集群。控制器管理段存储节点的生命周期，因为它们被添加到群集/从群集中删除，并在可用的段存储节点上执行段容器的重新分发。</p>
<h2 id="系统图"><a href="#系统图" class="headerlink" title="系统图"></a>系统图</h2><p>下图显示了控制器进程的主要组件。我们接下来将详细讨论该图表的元素。</p>
<p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega%2FControllerSystemDiagram.png" alt="ControllerSystemDiagram"></p>
<p>控制器流程图</p>
<h1 id="组件"><a href="#组件" class="headerlink" title="组件"></a>组件</h1><h3 id="服务端点"><a href="#服务端点" class="headerlink" title="服务端点"></a>服务端点</h3><p>控制器公开了两个端口：客户端控制器API和管理API。客户端控制器通信被实现为RPC，RPC公开API以执行所有与流相关的控制平面操作。除此控制器外，还公开了一个作为REST实现的管理API集。</p>
<p>每个端点都对Controller Service后端子系统执行适当的调用，该控制器服务子系统 具有对控制器拥有和管理的实体进行各种创建，读取，更新和删除（CRUD）操作的实际实现。</p>
<h3 id="GRPC"><a href="#GRPC" class="headerlink" title="GRPC"></a>GRPC</h3><p>客户端控制器通信端点实现为gRPC 接口。完整的API列表可以在<a href="https://github.com/pravega/pravega/blob/master/shared/controller-api/src/main/proto/Controller.proto" target="_blank" rel="noopener">此处</a>找到 。这暴露了Pravega客户端（读者，写者和流管理器）使用的API，并启用了流管理。此API启用的请求包括创建，修改和删除流。底层gRPC框架提供同步和异步编程模型。我们在客户端控制器交互中使用异步模型，以便客户端线程不会阻止来自服务器的响应。</p>
<p>为了能够附加和读取来自流，writer和reader的数据，查询控制器以在使用流时获得活动的段集，后继段和前置段。对于事务，客户端使用特定的API调用来请求控制器创建和提交事务。</p>
<h3 id="REST"><a href="#REST" class="headerlink" title="REST"></a>REST</h3><p>对于管理，控制器实现并公开REST接口。这包括用于流管理的API调用以及主要处理范围创建和删除的其他管理API。我们使用swagger来描述我们的REST API。<a href="https://github.com/pravega/pravega/tree/master/shared/controller-api/src/main/swagger" target="_blank" rel="noopener">这里</a>可以找到swagger的yaml文件。</p>
<h3 id="控制器服务"><a href="#控制器服务" class="headerlink" title="控制器服务"></a>控制器服务</h3><p>Controller服务是控制器端点（gRPC和REST）后面的后端层。提供控制器API调用所需的所有业务逻辑都在此处实现。该层包含所有其他子系统的句柄，如各种存储实现（流存储，主机存储和检查点存储）和后台处理框架（任务框架，事件处理器框架）。存储是提供对Controller管理的各种类型元数据的访问的接口。后台处理框架用于执行异步处理，该异步处理通常实现涉及元数据更新和对分段存储的请求的工作流。</p>
<h3 id="流元数据存储"><a href="#流元数据存储" class="headerlink" title="流元数据存储"></a>流元数据存储</h3><p>流是动态改变的段序列，其中路由键空间的区域映射到开放段。随着流的段的集合发生变化，路由密钥空间到段的映射也会发生变化。<br>如果1）映射到集合中的段的关键空间区域的并集覆盖整个密钥空间，则该组段是一致的。2）密钥空间区域之间没有重叠。例如，假设集合S = { S 1，S 2，S 3 }，使得： - 区域[0,0.3]映射到区段S 1 - 区域[0.3,0.6]映射到区段S 2 - 区域[0.6 ，1.0）映射到段S 3<br>S是一致的段集。</p>
<p>随着时间的推移，流会经历转换。流以初始的段集合开始，这些初始段集合在创建时由流配置确定，并且随着对流执行缩放操作时转换为新的段集。在任何给定时间点构成流的每一段被认为属于一个时期。因此，流以初始时期开始，该初始时期是时期0，并且在每次转换时，它在其时期中向前移动以描述流中的段的生成的变化。</p>
<p>控制器维护流存储关于构成给定流的所有时期以及它们如何转换的信息。该存储旨在优化存储和查询与段及其相互关系相关的信息。<br>除了时期信息之外，它还保留了一些额外的元数据，例如状态及其策略以及流上的持续事务。</p>
<p>控制器的各种子组件通过定义良好的接口访问每个流的存储元数据 。我们目前有两个具体的流存储接口实现：内存和zookeeper支持的存储。两者共享一个公共的基础实现，该实现依赖于流对象，为所有特定于流的元数据提供特定于存储类型的实现。流存储的基本实现创建并缓存这些流对象。</p>
<p>流对象实现存储/流接口。具体的流实现特定于存储类型的，并负责实现存储特定的方法，以提供一致性和正确性。我们有一个提供乐观并发的所有存储类型的通用基础实现。此基类封装了针对支持Compare和Swap（CAS）的所有具体存储的流存储查询的逻辑。我们目前使用zookeeper作为我们的底层存储，它也支持CAS。我们在流特定的znodes（ZooKeeper数据节点）下以分层方式存储所有流元数据。</p>
<p>对于基于ZooKeeper的存储，我们将元数据组织到不同的组中，以支持针对此元数据的各种查询。所有特定于流的元数据都存储在作用域/流根节点下。针对该元数据的查询包括（但不限于）查询在不同时间点形成流的段集，段特定信息，段前驱和后继。有关流元数据存储公开的API的详细信息，请参阅流元数据接口。</p>

      
    </main>
    <footer class="post-footer">
      
      <div class="post-tags">
        
        <a class="post-tag button" href="/tags/pravega/" rel="tag"><i class="fas fa-tags"></i>pravega</a>
        
      </div>
      
    </footer>
  </article>
  
  <article class="article post card" itemscope itemtype="http://schema.org/Article">
    <div class="post-block">
      <link itemprop="mainEntityOfPage" href="www.changping.me/2018/09/20/flink-deployment-kubernetes/">
      <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
        <meta itemprop="name" content="常平">
        <meta itemprop="description" content="“分布式系统架构设计师”">
        <meta itemprop="image" content="/images/avatar.jpg">
      </span>
      <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
        <meta itemprop="name" content="常平的技术博客">
      </span>
    </div>
    <header class="post-header">
      <h1 class="post-title" itemprop="name headline">
        <a class="post-title-link post-title-link-external" href="/2018/09/20/flink-deployment-kubernetes/" itemprop="url">Flink handbook - flink集群与部署之kubernetes篇</a>
      </h1>
      <div class="post-meta">
        
        <span class="post-date">
          <i class="far fa-calendar-plus"></i><span><time title="post-date" itemprop="dateCreated datePublished" datetime="2018-09-20T06:46:49+08:00">2018-09-20 06:46:49</time></span>
        </span>
        
        
        
        <span class="post-meta-divider divider">|</span>
        
        <span class="post-categories">
          
          <i class="far fa-folder-open"></i><span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/flink/" itemprop="url" rel="index"><span itemprop="name">flink</span></a></span>
        </span>
        
        
      </div>
    </header>
    <main class="post-main" itemprop="articleBody">
      
      <p>本页介绍如何在Kubernetes上部署Flink作业和会话群集。</p>
<h2 id="设置Kubernetes"><a href="#设置Kubernetes" class="headerlink" title="设置Kubernetes"></a>设置Kubernetes</h2><p>请参照<a href="https://kubernetes.io/docs/setup/" target="_blank" rel="noopener">Kubernetes的设置指南</a>来部署Kubernetes集群。如果您想在本地运行Kubernetes，我们建议使用<a href="https://kubernetes.io/docs/setup/minikube/" target="_blank" rel="noopener">MiniKube</a>来部署集群。</p>
<blockquote>
<p>注意：如果使用MiniKube，请确保<code>minikube ssh &#39;sudo ip link set docker0 promisc on&#39;</code>在部署Flink群集之前执行。否则，Flink组件无法通过Kubernetes服务自行引用。</p>
</blockquote>
<h2 id="Kubernetes上的Flink会话群集"><a href="#Kubernetes上的Flink会话群集" class="headerlink" title="Kubernetes上的Flink会话群集"></a>Kubernetes上的Flink会话群集</h2><p>Flink会话群集作为长期运行的Kubernetes部署来执行，请注意，可以在会话群集上运行多个Flink作业。在部署了集群之后，每个作业都需要提交到群集。</p>
<p>一个基本的部署在Kubernetes上的Flink会话群集一般会有三个组件：</p>
<ul>
<li>一个运行JobManager的deployment或job</li>
<li>一个TaskManagers池 deployment</li>
<li>一个公开JobManager的REST和UI端口的service</li>
</ul>
<h2 id="在Kubernetes上部署Flink会话群集"><a href="#在Kubernetes上部署Flink会话群集" class="headerlink" title="在Kubernetes上部署Flink会话群集"></a>在Kubernetes上部署Flink会话群集</h2><p>使用会话群集的资源定义，采用kubectl命令启动群集：</p>
<figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs undefined">kubectl create -f jobmanager-service.yaml<br>kubectl create -f jobmanager-deployment.yaml<br>kubectl create -f taskmanager-deployment.yaml<br></code></pre></td></tr></table></figure>
<p>然后，您可以通过kubectl proxy按以下方式访问Flink UI ：</p>
<p>第一步，保证kubectl proxy在终端中运行</p>
<p>第二步，在浏览器里输入 <code>http://localhost:8001/api/v1/namespaces/default/services/flink-jobmanager:ui/proxy</code></p>
<p>如果要终止Flink会话群集，可以使用如下命令：</p>
<figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs undefined">kubectl delete -f jobmanager-deployment.yaml<br>kubectl delete -f taskmanager-deployment.yaml<br>kubectl delete -f jobmanager-service.yaml<br></code></pre></td></tr></table></figure>
<h2 id="Kubernetes上的Flink作业集群"><a href="#Kubernetes上的Flink作业集群" class="headerlink" title="Kubernetes上的Flink作业集群"></a>Kubernetes上的Flink作业集群</h2><p>Flink作业集群是运行单个作业的专用集群，这项作业是打包在flink镜像里的，因此，不需要提交额外的作业对象，步骤如下：</p>
<h3 id="创建特定于作业的镜像"><a href="#创建特定于作业的镜像" class="headerlink" title="创建特定于作业的镜像"></a>创建特定于作业的镜像</h3><p>Flink作业集群镜像需要包含启动集群的作业的用户代码jar。因此，需要为每个作业构建专用的容器镜像。请按照这些<a href="https://github.com/apache/flink/blob/master/flink-container/docker/README.md" target="_blank" rel="noopener">说明</a>构建Docker镜像。</p>
<h3 id="在Kubernetes上部署Flink作业集群"><a href="#在Kubernetes上部署Flink作业集群" class="headerlink" title="在Kubernetes上部署Flink作业集群"></a>在Kubernetes上部署Flink作业集群</h3><p>要在Kubernetes上部署作业集群，请按照这些<a href="https://github.com/apache/flink/blob/master/flink-container/kubernetes/README.md#deploy-flink-job-cluster" target="_blank" rel="noopener">说明</a>进行操作。</p>
<h2 id="高级群集部署"><a href="#高级群集部署" class="headerlink" title="高级群集部署"></a>高级群集部署</h2><p>GitHub上提供了早期版本的<a href="https://github.com/docker-flink/examples" target="_blank" rel="noopener">Flink Helm chart</a>。</p>
<h1 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h1><h2 id="会话群集资源定义"><a href="#会话群集资源定义" class="headerlink" title="会话群集资源定义"></a>会话群集资源定义</h2><p>部署使用的最新镜像 <code>flink:latest</code> 可在<a href="https://hub.docker.com/r/_/flink/" target="_blank" rel="noopener">Docker Hub</a>上找到。该镜像是用这个工具 <code>https://github.com/docker-flink/docker-flink</code> 构建的</p>
<p>jobmanager-deployment.yaml</p>
<figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs undefined">&quot;<br>apiVersion: extensions/v1beta1<br>kind: Deployment<br>metadata:<br>  name: flink-jobmanager<br>spec:<br>  replicas: 1<br>  template:<br>    metadata:<br>      labels:<br>        app: flink<br>        component: jobmanager<br>    spec:<br>      containers:<br>      - name: jobmanager<br>        image: flink:latest<br>        args:<br>        - jobmanager<br>        ports:<br>        - containerPort: 6123<br>          name: rpc<br>        - containerPort: 6124<br>          name: blob<br>        - containerPort: 6125<br>          name: query<br>        - containerPort: 8081<br>          name: ui<br>        env:<br>        - name: JOB_MANAGER_RPC_ADDRESS<br>          value: flink-jobmanager<br>&quot;<br></code></pre></td></tr></table></figure>
<p>taskmanager-deployment.yaml</p>
<figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs undefined">&quot;<br>apiVersion: extensions/v1beta1<br>kind: Deployment<br>metadata:<br>  name: flink-taskmanager<br>spec:<br>  replicas: 2<br>  template:<br>    metadata:<br>      labels:<br>        app: flink<br>        component: taskmanager<br>    spec:<br>      containers:<br>      - name: taskmanager<br>        image: flink:latest<br>        args:<br>        - taskmanager<br>        ports:<br>        - containerPort: 6121<br>          name: data<br>        - containerPort: 6122<br>          name: rpc<br>        - containerPort: 6125<br>          name: query<br>        env:<br>        - name: JOB_MANAGER_RPC_ADDRESS<br>          value: flink-jobmanager<br>&quot;<br></code></pre></td></tr></table></figure>
<p>jobmanager-service.yaml</p>
<figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs undefined">&quot;<br>apiVersion: v1<br>kind: Service<br>metadata:<br>  name: flink-jobmanager<br>spec:<br>  ports:<br>  - name: rpc<br>    port: 6123<br>  - name: blob<br>    port: 6124<br>  - name: query<br>    port: 6125<br>  - name: ui<br>    port: 8081<br>  selector:<br>    app: flink<br>    component: jobmanager<br>&quot;<br></code></pre></td></tr></table></figure>
      
    </main>
    <footer class="post-footer">
      
      <div class="post-tags">
        
        <a class="post-tag button" href="/tags/flink/" rel="tag"><i class="fas fa-tags"></i>flink</a>
        
      </div>
      
    </footer>
  </article>
  
  <article class="article post card" itemscope itemtype="http://schema.org/Article">
    <div class="post-block">
      <link itemprop="mainEntityOfPage" href="www.changping.me/2018/09/20/flink-deployment-docker/">
      <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
        <meta itemprop="name" content="常平">
        <meta itemprop="description" content="“分布式系统架构设计师”">
        <meta itemprop="image" content="/images/avatar.jpg">
      </span>
      <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
        <meta itemprop="name" content="常平的技术博客">
      </span>
    </div>
    <header class="post-header">
      <h1 class="post-title" itemprop="name headline">
        <a class="post-title-link post-title-link-external" href="/2018/09/20/flink-deployment-docker/" itemprop="url">Flink handbook - flink 集群与部署之docker篇</a>
      </h1>
      <div class="post-meta">
        
        <span class="post-date">
          <i class="far fa-calendar-plus"></i><span><time title="post-date" itemprop="dateCreated datePublished" datetime="2018-09-20T06:46:03+08:00">2018-09-20 06:46:03</time></span>
        </span>
        
        
        
        <span class="post-meta-divider divider">|</span>
        
        <span class="post-categories">
          
          <i class="far fa-folder-open"></i><span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/flink/" itemprop="url" rel="index"><span itemprop="name">flink</span></a></span>
        </span>
        
        
      </div>
    </header>
    <main class="post-main" itemprop="articleBody">
      
      <h2 id="作者标注"><a href="#作者标注" class="headerlink" title="作者标注"></a>作者标注</h2><p>经过验证， 到当前版本为止 flink-1.7 snapshot，构建 flink docker镜像需要采用这个flink docker 构建工具 <code>https://github.com/docker-flink/docker-flink</code>，按照<a href="https://github.com/apache/flink/tree/master/flink-container" target="_blank" rel="noopener">flink官方代码库</a>里的构建出来的flink镜像有些功能不能用，比如 flink-standalone模式，report metrics等。</p>
<h2 id="Docker设置"><a href="#Docker设置" class="headerlink" title="Docker设置"></a>Docker设置</h2><p>Docker Hub上有关于Apache Flink的Docker镜像，可用于部署flink群集。Flink镜像库还包含用于创建容器映像以部署flink工作集群的一些工具以及说明。</p>
<h2 id="Flink-session群集"><a href="#Flink-session群集" class="headerlink" title="Flink session群集"></a>Flink session群集</h2><p>Flink会话群集可用于运行多个业务。在部署后，每个业务都需要提交到集群才能跑起来。</p>
<h2 id="Docker镜像"><a href="#Docker镜像" class="headerlink" title="Docker镜像"></a>Docker镜像</h2><p>该<a href="https://hub.docker.com/_/flink/" target="_blank" rel="noopener">Flink镜像库</a>托管在docker hub，提供了flink1.2.1以及之后的版本镜像。</p>
<p>注意： Docker镜像是由个人提供的社区项目，它们并不是Apache Flink PMC的官方版本（作者标注：所以需要用这个个人的<a href="https://github.com/docker-flink/docker-flink" target="_blank" rel="noopener">构建工具</a>，而不是官方代码库里的构建工具）。</p>
<h2 id="Flink作业集群"><a href="#Flink作业集群" class="headerlink" title="Flink作业集群"></a>Flink作业集群</h2><p>Flink作业集群是运行单个作业的专用集群，这是镜像内容的一部分，因此，不需要额外的工作。</p>
<h2 id="Docker镜像-1"><a href="#Docker镜像-1" class="headerlink" title="Docker镜像"></a>Docker镜像</h2><p>Flink作业集群镜像需要包含启动集群的作业的用户代码jar。因此，需要为每个作业构建专用的容器镜像。该flink-container模块包含一个build.sh脚本，可用于创建此类镜像。有关详细信息，请参阅<a href="https://github.com/apache/flink/blob/master/flink-container/docker/README.md" target="_blank" rel="noopener">说明</a>。（作者注：这个是官方的构建方式，试过有问题，比如跑 flink-standalone再 report metrics）</p>
<h2 id="Flink与Docker-Compose"><a href="#Flink与Docker-Compose" class="headerlink" title="Flink与Docker Compose"></a>Flink与Docker Compose</h2><p>Docker Compose是一种很方便的用于在本地启动一组Flink Docker容器的方式。</p>
<p>GitHub上提供了<a href="https://github.com/docker-flink/examples/blob/master/docker-compose.yml" target="_blank" rel="noopener">集群部署实例</a>和<a href="https://github.com/apache/flink/blob/master/flink-container/docker/docker-compose.yml" target="_blank" rel="noopener">作业群集示例</a>的配置文件。</p>
<h2 id="用法"><a href="#用法" class="headerlink" title="用法"></a>用法</h2><p>启动集群</p>
<p><code>$docker-compose up</code></p>
<p>以deamon的方式启动集群</p>
<p> <code>$docker-compose up -d</code></p>
<p>集群扩展 N 个 TaskManagers</p>
<p><code>$docker-compose scale taskmanager=&lt;N&gt;</code></p>
<p>销毁集群</p>
<p><code>$docker-compose kill</code></p>
<p>当拉起一个Flink群集后，您可以访问 <code>http：// localhost：8081</code>的Web UI ，在界面里您还可以将作业提交到群集。</p>
<p>如果要通过命令行将作业提交到会话群集，必须将JAR复制到JobManager容器里并从那里执行作业。</p>
<p>例如：</p>
<figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs undefined">$ JOBMANAGER_CONTAINER=$(docker ps --filter name=jobmanager --format=&#123;&#123;.ID&#125;&#125;)<br>$ docker cp path/to/jar &quot;$JOBMANAGER_CONTAINER&quot;:/job.jar<br>$ docker exec -t -i &quot;$JOBMANAGER_CONTAINER&quot; flink run /job.jar<br></code></pre></td></tr></table></figure>
      
    </main>
    <footer class="post-footer">
      
      <div class="post-tags">
        
        <a class="post-tag button" href="/tags/flink/" rel="tag"><i class="fas fa-tags"></i>flink</a>
        
      </div>
      
    </footer>
  </article>
  
  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/6/"><i class="fas fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><span class="page-number current">7</span><a class="page-number" href="/page/8/">8</a><span class="space">&hellip;</span><a class="page-number" href="/page/10/">10</a><a class="extend next" rel="next" href="/page/8/"><i class="fas fa-angle-right" aria-label="下一页"></i></a>
  </nav>
  
  
</div>

          </div>
          
          
          
<aside class="sidebar" id="sidebar" >
  
  
<div class="info sidebar-item" id="info">
  
  <img class="author-avatar" src="/images/avatar.jpg" alt="常平">
  
  <h1 class="author-name">常平</h1>
  <h2 class="author-description">“分布式系统架构设计师”</h2>
  <div class="site-count">
    
    <div class="archives-count">
      <div class="site-count-title">全部</div>
      <div><a href="/archives">76</a></div>
    </div>
    
    
    
    <span class="site-count-divider divider">|</span>
    
    <div class="categories-count">
      <div class="site-count-title">分类</div>
      <div><a href="/categories">5</a></div>
    </div>
    
    
    
    <span class="site-count-divider divider">|</span>
    
    <div class="tags-count">
      <div class="site-count-title">标签</div>
      <div><a href="/tags">5</a></div>
    </div>
    
  </div>
  
</div>


  <div class="sidebar-sticky">
    
    
    <hr>
    <div class="social-link sidebar-item">
      <div><i class="far fa-address-card"></i>链接</p></div>
      <ul>
        
        <li><i class="fab fa-github"></i><a href="https://github.com/wuchangping" target="_blank">GitHub</a></li>
        
      </ul>
    </div>
    
    
  </div>
</aside>


          
        </div>
      </div>
    </main>
    
<footer id="footer" class="footer" style="background: #1D2D2D;">
  <div class="container">
    <div class="back-to-top">
      <button id="back-to-top"><i class="fas fa-angle-double-up" aria-label="回到顶部"></i></button>
    </div>
    <div class="footer-container">
      <div class="footer-left">
        <div class="copyright">
          <span class="author">常平</span><span class="year"><i class="far fa-copyright"></i>2017 - 2020</span>
        </div>
        
        <div class="busuanzi">
          <span id="busuanzi_container_site_pv"><i class="fas fa-eye" aria-label="站点点击量" aria-hidden="false"></i><span id="busuanzi_value_site_pv"></span></span><span id="busuanzi_container_site_uv"><i class="fas fa-user" aria-label="站点用户数" aria-hidden="false"></i><span id="busuanzi_value_site_uv"></span></span><span id="busuanzi_container_page_pv"><i class="far fa-file-alt"></i><span id="busuanzi_value_page_pv" aria-label="页面点击量" aria-hidden="false"></span></span>
        </div>
        
      </div>
      <div class="footer-right">
        <div class="custom-info">
          
          PoweredBy<i class="fab fa-github-alt"></i><a href="https://github.com/wuchangping" target="_blank">GitHub</a>
          
        </div>
        <div class="powered-by">
          由 <a href="https://hexo.io/" target="_blank">Hexo</a> 强力驱动 | 主题 <a href="https://github.com/AlynxZhou/hexo-theme-aria/" target="_blank">ARIA</a>
        </div>
      </div>
    </div>
  </div>
</footer>


  </body>
</html>
