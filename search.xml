<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>分布式系统架构设计36式 – 第20式 - 编程思维模型</title>
      <link href="/2020/03/15/distributed-ideamodel-programing/"/>
      <url>/2020/03/15/distributed-ideamodel-programing/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a><font color="#FF8C00">前言</font></h2><p>编程是一种创造性解决问题的能力， 其本质上是一种思维体操，可以大大的提升人的逻辑能力、推理能力以及解决问题的能力， 那么什么是分布式系统的编程思维呢？</p><h2 id="编程思维模型"><a href="#编程思维模型" class="headerlink" title="编程思维模型"></a><font color="#FF8C00">编程思维模型</font></h2><p>具体来看分布式系统的编程思维包含11大内容：抽象、分层、解耦、拆分、聚合、治理、取舍、模型、演化、质量、边界。</p><p>//TODO</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font color="#FF8C00">小结</font></h2><p>本文解读了分布式系统的编程思维模型。日拱一卒，功不唐捐，分享是最好的学习，与其跟随不如创新，希望这个知识点对大家有用。另作者能力与认知都有限，”我讲的，可能都是错的“，欢迎大家拍砖留念。</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中科大硕，DELL EMC 资深首席工程师，曾就职于Marvell、AMD，主要从事Linux内核以及分布式产品的交付、架构设计以及开发工作。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a><font color="#FF8C00">参考资料</font></h2><p>[1] <a href="https://a16z.com/2019/10/04/commercializing-open-source/" target="_blank" rel="noopener">https://a16z.com/2019/10/04/commercializing-open-source/</a></p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>分布式系统架构设计36式 – 第19式 - 分布式系统八卦思维模型</title>
      <link href="/2020/03/14/distributed-ideamodel-distributedsystem/"/>
      <url>/2020/03/14/distributed-ideamodel-distributedsystem/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a><font color="#FF8C00">前言</font></h2><p>懂得很多道理，仍旧过不好这一生。懂得很多分布式系统的概念以及设计方法，依旧做不好分布式系统。分布式系统设计是一门实践软件工程，只有你PK过设计方案，手把手的敲过一行行的代码，才能知道细节在哪里，难点在哪里，痛点、挑战点在哪里，不是看书或者看文章就可以完全掌握的。因此，宏观处着眼，微观处着手，才能完全掌握分布式系统设计的道理。本文抽象出分布式系统的思维模型，当你看到这个模型里的字眼与图画，就可以从脑海里分解出一个个设计方案、一行行代码的时候，那才是真的掌握了分布式系统的精髓。</p><h2 id="分布式系统八卦思维模型"><a href="#分布式系统八卦思维模型" class="headerlink" title="分布式系统八卦思维模型"></a><font color="#FF8C00">分布式系统八卦思维模型</font></h2><p>这里我提出一个分布式系统八卦思维模型，本文简单介绍一下这个思维模型的要义。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/ideamodel/idea-model-distributed-system.PNG" alt="分布式系统思维模型"></p><h3 id="方法论"><a href="#方法论" class="headerlink" title="方法论"></a><font color="#00CED1">方法论</font></h3><p>核心：在前面的文章里讲到可以用一句话来描述分布式系统：</p><blockquote><p>分布式系统是指其组件位于不同的网络计算机上的系统，这些组件通过相互传递消息来进行通信和协调其动作，且彼此相互交互以完成一个共同的任务目标。</p></blockquote><p>并且提到了“系统 = 要素 + 连接 + 目标”  ， 这个思维模型的核心即分布式系统的第一性原理， 公式：“分布式系统 = 计算机 + 网络 + 协同”，要素是计算机（新的虚机、容器也算），连接是网络，目标是协同以完成共同任务。</p><p>提供：即服务接入的提供，指的是对外提供restful 接口服务：权限、多组合、监控、审计、计费等，对外提供SQL服务接入接口服务、对外提供自然语言接入接口服务等<br>注册：即服务注册，将集群的工作负载注册到集群注册中心<br>配置：即配置管理，将集群的配置管理在配置中心；<br>调用，即服务调用，各种RPC调用，系统内的消息传递<br>路由：即服务路由，目的是集群的负载均衡与扩伸缩性<br>观测：指的是集群内部指标的可观测性，即监控、告警、追踪、日志<br>治理：指的是集群内部的服务治理：熔断、降级、限流、隔离、容错<br>编排：即服务编排，基于k8s+ docker，完成安装、升级、扩容、运维、调度等；<br>质量：指的是安装部署运维质量、客户质量、用户质量与开发质量<br>边界：指的是系统内的约束条件，涵盖 硬件资源、客户约束、用户约束以及团队约束</p><p>这10个功能与核心之间是互相联系、互联影响的，因此类似于一个八卦图。</p><h3 id="底层思维"><a href="#底层思维" class="headerlink" title="底层思维"></a><font color="#00CED1">底层思维</font></h3><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs undefined">抽象、分层、解耦、拆分、聚合、治理、取舍、质量、边界、模型、演化<br></code></pre></td></tr></table></figure><p>抽象、分层、解耦、拆分、聚合、治理、取舍、质量、边界、模型、演化是分布式系统设计的底层思维，也是软件工程的底层思维，这个主题很难掌握，目前，这里不展开讲。</p><h3 id="基石假设"><a href="#基石假设" class="headerlink" title="基石假设"></a><font color="#00CED1">基石假设</font></h3><p>分布式系统有两个隐含的基石假设，即 “资源协同与质量可预测”，资源即计算机、虚拟机、容器以及网络，基于此，分布式系统的第一性原理 即： “分布式系统 = 计算机 + 网络 + 协同 ，以质量为度量”。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font color="#FF8C00">小结</font></h2><p>本文提出一个分布式系统八卦思维模型。分布式系统不是我首创，用这个类八卦图形来表示思维模型也不是我首创，但是用这个类八卦图形表示分布式系统思维模型应该是我首创，目前不管是书籍还是网络都找不到这样的分布式系统思维模型。日拱一卒，功不唐捐，分享是最好的学习，与其跟随不如创新，希望这个知识点对大家有用。另作者能力与认知都有限，”我讲的，可能都是错的“，欢迎大家拍砖留念。</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中科大硕，DELL EMC 资深首席工程师，曾就职于Marvell、AMD，主要从事Linux内核以及分布式产品的交付、架构设计以及开发工作。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a><font color="#FF8C00">参考资料</font></h2><p>[1] <a href="https://a16z.com/2019/10/04/commercializing-open-source/" target="_blank" rel="noopener">https://a16z.com/2019/10/04/commercializing-open-source/</a></p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>分布式系统架构设计36式 – 第18式 - 以物理学思维破解分布式的本质</title>
      <link href="/2020/02/24/distributed-theory-of-essence/"/>
      <url>/2020/02/24/distributed-theory-of-essence/</url>
      
        <content type="html"><![CDATA[<h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a><font color="#FF8C00">动机</font></h2><p>本文的动机在于应用物理学思维模型破解分布式背后不变的本质，并以此解读分布式系统里的各种算法设计、功能设计以及非功能设计。在“分布式系统” 这个词语里，关键词可以分为“分布式”及“系统”，其中“分布式”是分布式系统的能力修饰关键词，而“系统 = 要素 + 连接 + 目标”，挖掘分布式系统背后的本质即是挖掘“分布式”的要素、连接以及目标的本质。</p><p>物理学的价值观在于追求所有物理现象背后的共同的底层规律，并以此解读各种物理现象，并且其具有“可解释、可重复、可预测”的可度量性，这种共同的底层规律，被称之为元认知，即第一性原理：“任何变化的背后都有不变的本质”。将这种思维模型应用于挖掘分布式的本质，需要解决两个问题，即：“ 什么是分布式系统的第一性原理？以及如何度量分布式系统？”</p><h2 id="分布式系统的价值与目的"><a href="#分布式系统的价值与目的" class="headerlink" title="分布式系统的价值与目的"></a><font color="#FF8C00">分布式系统的价值与目的</font></h2><p>分布式系统的出现是为了解决一个主要矛盾，即：“日益增长的数据计算、传输与存储的需求与当前单点计算机能力无法满足这个需求之间的矛盾”。分布式系统可以通过伸展集群规模解决这个矛盾，因此这就是分布式系统的价值，而可伸缩性(Scalability，避免与可扩展性extensibility混淆)也是分布式系统的根本目的。</p><h2 id="分布式系统必知的基础理论与算法"><a href="#分布式系统必知的基础理论与算法" class="headerlink" title="分布式系统必知的基础理论与算法"></a><font color="#FF8C00">分布式系统必知的基础理论与算法</font></h2><p>分布式系统必须理解、必须会的基础理论算法有：CAP/PACELC、BASE、2PC、3PC、TCC、ACID、PAXOS、RAFT这9个：</p><ul><li><p>CAP: CAP理论认为以下三者不能同时满足：</p><ul><li>一致性(Consistency): 所有的节点在同一时刻数据是完全一样的；</li><li>可用性(Availability): 节点失效不会影响系统的IO；</li><li>分区容忍性(Partition Tolerance): 系统能支持网络分区（网络连接故障），即使分区之间的消息丢失系统也正常工作。</li></ul></li><li><p>PACELC: PACELC理论是CAP理论的扩展，如果有分区partition (P)，系统就必须在availability 和consistency (A and C)之间取得平衡; 否则else (E) 当系统运行在无分区情况下,系统需要在 latency (L) 和 consistency (C)之间取得平衡”；</p></li><li><p>BASE: BASE是基本可用（Basically Available）、软状态（Soft state）和最终一致性（Eventually consistent）三个短语的缩写；</p></li><li><p>2PC：two-phase commit protocol，两阶段提交；</p></li><li><p>3PC: three-phase commit protocol ，三阶段提交，其在两阶段提交的基础上增加了CanCommit阶段，并引入了超时机制；</p></li><li><p>TCC: Try-Confirm-Cancel，又称补偿事务，其核心思想是：”针对每个操作都要注册一个与其对应的确认和补偿（撤销操作）”；</p></li><li><p>ACID: 原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持久性（Durablity）；</p></li><li><p>PAXOS/RAFT ：PAXOS与RAFT算法都是最有效的解决分布式一致性问题的算法。</p></li></ul><p>这几条基础理论与算法需要自己深入学习理解，其是分布式系统的必备知识点。</p><h2 id="分布式系统的功能与非功能"><a href="#分布式系统的功能与非功能" class="headerlink" title="分布式系统的功能与非功能"></a><font color="#FF8C00">分布式系统的功能与非功能</font></h2><h4 id="功能"><a href="#功能" class="headerlink" title="功能"></a>功能</h4><p>功能可按职责划分为服务功能与算法功能:</p><ul><li>分布式系统里的最主要的服务功能有：服务提供，服务注册，服务配置，服务调用、服务路由、服务治理设计，服务观测、服务安全这8项；</li><li>分布式系统里的最主要的算法功能有：幂等性设计、事务算法设计、端到端的校验算法设计、路由算法设计、分区分配算法设计、集群视图变更算法设计、心跳算法设计、注册算法设计、复制一致性算法设计以及容量规划算法设计。</li></ul><h4 id="非功能"><a href="#非功能" class="headerlink" title="非功能"></a>非功能</h4><p>非功能可划分为质量与约束：</p><ul><li><p>质量是分布式系统在约束条件下的度量方式，其涵盖：合适的性能（Performant）、可用性(Availability)、可靠性(Reliability)、可伸缩性(Scalability)、韧性(resilience)、可观测性(Observability)、安全性（security）、易用性（usability）、可运维性（operability）、可测试性(testability)、可维护性(maintainability)、可扩展性(extensibility)、可读性(readability)等。</p></li><li><p>约束是分布式系统的资源限制：网络物理容量与计算机节点的物理容量，以及客户、用户、团队的边界约束。</p></li></ul><p><strong>分布式系统交付的目的是功能的价值，但是产品的功夫却体现在非功能</strong>，分布式系统的质量是分布式系统的度量方式，分布式系统要可度量就需要具有“可解释、可复制、可预测”的质量保证。</p><h2 id="分布式系统的第一性原理"><a href="#分布式系统的第一性原理" class="headerlink" title="分布式系统的第一性原理"></a><font color="#FF8C00">分布式系统的第一性原理</font></h2><p>依据李善友老师的定义： <font color="#00CED1"><strong>“第一性原理思维 = 逻辑奇点 + 公理化方法 ”</strong></font>，逻辑奇点即基石假设，公理化方法我认为是”定公理、推定理、再公式化应用”。因此欲找出分布式系统的第一性原理，就需要先挖掘出分布式系统的公理化定义及其逻辑奇点。</p><p>首先把分布式系统概念化，Google 出来的对分布式系统的定义有：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs undefined">A distributed system is a system whose components are located on different networked<br>computers, which communicate and coordinate their actions by passing messages to one<br>another. The components interact with one another in order to achieve a common goal.<br></code></pre></td></tr></table></figure><p>即：</p><blockquote><p>分布式系统是指其组件位于不同的网络计算机上的系统，这些组件通过相互传递消息来进行通信和协调其动作，且彼此相互交互以完成一个共同的任务目标。</p></blockquote><p>拆解这句话，从中可以看到分布式系统里的要素即为组件，连接即网络，目标是共同的任务，并且还可以看出4个要点：</p><ul><li><p>分布式系统的组件是位于不同的网络计算机上；</p></li><li><p>分布式系统的组件通过传递消息进行通信其动作；</p></li><li><p>分布式系统的组件通过传递消息进行协调其动作；</p></li><li><p>分布式系统的组件是通过相互交互以完成一个共同的任务目标；</p></li></ul><p>其中最最重要的可以看作是分布式系统的基石假设的要点是：</p><p>1，分布式系统的组件是位于不同的网络计算机上；</p><p>2，这些组件通过相互传递消息来进行通信和协调其动作，且彼此相互交互以完成一个共同的任务目标。</p><p>这两点即为分布式系统的逻辑奇点，破除了这两点那就不是分布式系统，比如去掉网络计算机的定义，那就是单机系统，去掉协调以完成共同的任务目标，那就只是一个计算机网络。这两点基石假设构成分布式系统的逻辑奇点。</p><p>到此，可以得出分布式系统的公理化定义：</p><blockquote><p>分布式系统是指其组件位于不同的网络计算机上的系统，这些组件通过相互传递消息来进行通信和协调其动作，且彼此相互交互以完成一个共同的任务目标。</p></blockquote><p>以及分布式系统的逻辑起点：</p><blockquote><ul><li><p>分布式系统是指其组件位于不同的网络计算机上的系统：即计算机网络；</p></li><li><p>这些组件通过相互传递消息来进行通信和协调其动作，且彼此相互交互以完成一个共同的任务目标：即协同：“谐调一致，和合共同，协调两个或者两个以上的不同资源或者个体，一致地完成某一共同目标”；</p></li></ul></blockquote><p>再进一步抽象，可以推断出“分布式系统就是通过计算机网络进行协同工作的系统”， 至此，可以推出分布式的公理化定义公式：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs undefined">分布式 = 计算机 + 网络 + 协同，其以质量为度量。<br></code></pre></td></tr></table></figure><p>这个公式就是分布式的第一性原理公式，是分布式的本质理论定义，其中“计算机”是分布式系统的要素，“网络”是分布式系统的连接，“协同”是分布式系统的目标，从这公式里可以看出分布式系统的3个原生的难题：</p><ul><li><p>分布式系统是基于网络的系统，那么网络自身所具有的所有的优点与缺点它都有，那么如何提高服务的可靠性？如何保证服务的可用性？如何保证网络可运维？</p></li><li><p>分布式系统是基于消息传递的系统，消息传递是不可靠的，那么如何保证消息的正确性？如何保证消息传递的可靠性？如何传递消息到目的地？如何保证消息传递的负载均衡？</p></li><li><p>分布式系统是协同工作的系统，那么如何协调大量的计算机节点的完成一个共同的目标，如何解决协调的复杂性以及提高协调的可靠性、可用性？那么如何一起交互完成一个共同的目标任务？如何拆分目标？如何聚合目标，如何度量完成任务的质量与边界？</p></li></ul><p>因此还需要依据分布式系统的公理化定义推导出定理化定义。</p><h2 id="分布式系统的定理化推导"><a href="#分布式系统的定理化推导" class="headerlink" title="分布式系统的定理化推导"></a><font color="#FF8C00">分布式系统的定理化推导</font></h2><p>“公理是不证自明的，而定理是以若干的公理或其他定理为基础而推导的”。由公理推定理，从分布式的公理化公式<font color="#00CED1"><strong>“分布式 =  计算机  + 网络 + 协同”</strong></font>，可知分布式系统是组件位于“不同的计算机网络”上一起“协同”工作的系统，这句话得出分布式三要素：<font color="#00CED1">“计算机、网络，协同”</font>。</p><h3 id="计算机"><a href="#计算机" class="headerlink" title="计算机"></a>计算机</h3><p>分布式系统是基于不同的计算机上的系统，计算机也是分布式系统的要素之一，因此分布式系统也继承了计算机的原生缺点，</p><ul><li>计算机节点是会出故障的，主板、CPU、网卡、硬盘、内存、电源等都会出故障，比如老化、失效等；</li><li>计算机节点内的操作系统是会突然奔溃不能提供服务的；</li><li>计算机节点是会突然掉电的；</li><li>计算机节点里的内存下电是不保数据的；</li><li>计算机节点的资源是有限的：CPU是有算力上限的、内存是有大小限制的、网卡有吞吐量限制、硬盘有空间大小限制以及速率限制；</li></ul><p>这几个计算机的原生缺点意味着分布式系统需要能够知道计算机节点是失效的，以及在计算机节点失效的同时保证服务质量设计，那么就应当进行以下几点保证：</p><ul><li><p>可观测性（observability）设计：监控、告警、日志、追踪；</p></li><li><p>可靠性（Reliability）设计：冗余设计、分区分配设计、复制算法设计、幂等性设计、一致性算法设计；</p></li><li><p>容量（capacity）规划设计：计算机节点资源资源有限，就需要分布式系统进行进行容量规划；</p></li><li><p>服务治理（Service governance）设计：CPU算力有限、内存有限、网卡吞吐量有限、磁盘IO有限，因此需要进行服务治理之隔板设计以及限流、限并发设计。</p></li></ul><h3 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h3><p>分布式系统是基于不同的网络上的系统，网络是分布式系统的要素之一，因此分布式系统也继承了网络的原生缺点，即：</p><ul><li>网络是不可靠的；</li><li>网络是会出故障的；</li><li>网络是有时延的；</li><li>网络是会抖动的；</li><li>网络是不安全的；</li><li>网络是会丢包的；</li><li>网络是有带宽限制的；</li><li>网络消息是会乱序的；</li></ul><p>由此，为了保证分布式系统的服务质量：性能、可用性、可靠性、安全性等，那么就需要进行服务质量保证设计，其可以划分为：</p><ul><li><p>网络是不可靠以及会出现断网之类的故障的，因此分布式系统需要进行服务治理容错设计；</p></li><li><p>网络乱序以及丢包，因此分布式系统需要幂等性算法设计、端到端的校验算法设计；</p></li><li><p>网络带宽有限，因此分布式系统需要网络容量设计以及服务治理限流设计；</p></li><li><p>网络不安全：因此分布式系统需要服务安全设计；</p></li><li><p>网络是有时延的，因此分布式系统需要进行性能设计：更好的硬件、跟短的IO路径；</p></li><li><p>网络是会抖动的，因此分布式系统需要进行服务治理容错之超时处理设计。</p></li></ul><h2 id="协同"><a href="#协同" class="headerlink" title="协同"></a>协同</h2><blockquote><p>协同是指：“谐调一致，和合共同，协调两个或者两个以上的不同资源或者个体，一致地完成某一共同目标“，这些组件通过相互传递消息来进行通信和协调其动作，且彼此相互交互以完成一个共同的任务目标</p></blockquote><p>协同又可以拆分为协调动作与共同完成任务，即：</p><h4 id="协调动作"><a href="#协调动作" class="headerlink" title="协调动作"></a>协调动作</h4><p>分布式系统的组件通过传递消息进行通信及协调其动作，即：因此依据消息传递的特性以及缺点需要进行相应的协调动作设计：</p><ul><li>传递消息特性意味着需要进行RPC调用设计；</li><li>网络里传递的消息是经常不一样的，因此需要序列化编解码设计；</li><li>消息传递具有丢消息、丢处理的弊端，为了解决这个弊端就需要进行 ：幂等性设计、事务处理设计、日志设计；</li><li>消息的传递是会超时的，因此就需要服务治理容错之超时处理设计；</li><li>消息是基于网络传输的，而网络是可能随时出故障的，因此需要对消息进行可观测性设计即消息追踪设计；</li><li>需要知道消息从哪里来，往哪里去就需要一个配置中心管理集群各个计算机的信息，比如IP，因此需要进行配置中心设计；</li><li>光知道可以发往哪里还不够，还要知道发往的节点是活着的可服务的，需要知道计算机节点的服务状态，还需要保证消息路由的负载均衡，因此这就就需要一个协调的服务注册中心，进行服务组件的注册与心跳检测、消息路由以及按集群视图变更算法管理集群状态表，那么就需要注册中心设计、注册算法设计、负载均衡算法设计，心跳算法设计、集群视图变更算法设计以及集群状态表管理设计。</li></ul><h4 id="共同完成任务"><a href="#共同完成任务" class="headerlink" title="共同完成任务"></a>共同完成任务</h4><p>分布式系统的组件是通过相互交互以完成一个共同的任务目标，因此需要解决共同完成任务并且保证任务完成质量带来的难题：</p><ul><li><p>整个分布式系统需要能接收任务以及返回完成的任务，那么就需要有提供服务的能力，需要有服务调用接口设计，服务调用客户端以及可视化界面；</p></li><li><p>为了能让网络里的N台计算机相互交互完成一个共同的目标，就需要对任务进行拆分以及聚合设计；</p></li><li>任务拆分后要能知道发给哪个节点，那么就需要一个配置中心, 从配置中心获取目标节点信息；</li><li>任务拆分后分发给节点同时要保证处理的性能，那么就需要进行可伸缩性设计，一台机器处理不过来就需要N台机器一起处理从而保证处理的性能质量，因此又衍生出需要路由算法设计或分区分配算法设计，这样拆分后的任务可以被分发到不同的独立的节点进行处理，并且，但一个节点不可用时，还可以分发到其他的可用的节点，从而提升了系统性能与可用性；</li><li>任务又可以分为计算任务与存储任务，如果是存储任务，为了保证数据的可用性以及可靠性，就需要对分区进行冗余设计，即节点副本设计，如果需要节点副本设计又引入了选主算法设计、数据一致性复制算法设计与幂等性设计；</li><li>为了解决选主与复制一致性问题，又出现了PAXOS,RAFT,2PC,3PC 等，这样的基础一致性协议算法。</li></ul><p>至此，依据分布式的公理化公式：<font color="#00CED1"><strong>“分布式 = 计算机 + 网络 + 协同”</strong></font>，推导出了分布式的定理化推论，解读了分布式系统里为什么需要进行这些功能与非功能设计的问题，接下来还需要讲述分布式系统的度量。</p><h2 id="分布式系统的度量"><a href="#分布式系统的度量" class="headerlink" title="分布式系统的度量"></a><font color="#FF8C00">分布式系统的度量</font></h2><p>分布式系统是依据分布式公理定义的质量进行度量的，其涵盖以下几项内容：</p><ul><li><p>合适的性能（Performant），性能指标一般包括 TPS, QPS, Latency, IOPS， response time等，这里用”合适的性能“作为表达，指的是性能合适即可、够用即可，高性能当然好，但是高性能也意味着更高的成本，有些场景高性能反而是一种浪费行为，性能需求需要理解业务场景适可而止；</p></li><li><p>可用性(Availability)，可用性指的是系统长时间可对外提供服务的能力，通常采用小数点后的9的个数作为度量指标，按照这种约定“五个九”等于0.99999（或99.999％）的可用性，默认企业级达标的可用性为6个9。但是当前从时间维度来度量可用性已经没有太大的意义，因为设计得好的系统可以在系统出现故障得情况下也能保证对外提供得服务不中断，因此，当前更合适得可用性度量指标 是请求失败率；</p></li><li><p>可靠性(Reliability)，可靠性一般指系统在一定时间内、在一定条件下可以无故障地执行指定功能的能力或可能性， 也是采用小数点后的9的个数作为度量指标，通常5个9的可靠性就可以满足企业级达标；</p></li><li><p>可伸缩性(Scalability)，是指通过向系统添加资源来处理越来越多的工作并且维持高质量服务的能力，其受可用性以及可靠性的制约，集群规模越大出故障的概率越高从而降低可用性、可靠性，为了保证可用性以及可靠性达标，需要适配合理的可伸缩性指标；</p></li><li><p>韧性(resilience)，通常也叫容错性（fault-tolerant），也就是健壮和强壮的意思，指的是系统的对故障与异常的处理能力，比如在软件故障、硬件故障、认为故障这样的场景下，系统还能保持正常工作的能力；</p></li><li><p>可观测性(Observability)，是一种设计理念，包括告警、监控、日志与跟踪，可以实时地更深入地观测系统内部的工作状态；</p></li><li><p>安全性（security），指的是阻止非授权使用，阻止非法访问以及使用，保护合法用户的资产的能力；</p></li><li><p>易用性（usability），指的是软件的使用难易程度，对于产品的易用性来说， 易用性不仅仅 是软件使用角度的易用，还包括安装、部署、升级上的易用,升值还包括硬件层面的易用，比如产品的外观，形状等；</p></li><li><p>可运维性（operability），可运维性指的是运维人员对系统进行运维操作的难易程度，主要包含以下几个方面的难以程度： 系统的部署、升级、修改、监控以及告警等；</p></li><li>可测试性（ testability），指的是单元测试，集成测试，打桩测试等的难易；</li><li>可维护性（Maintainability）， 指的是代码升级，部署，定位bug，添加功能的难易；</li><li>可扩展性（ extensibility）， 指的是未来增加新的功能与模块的难易；</li><li><p>可读性（ readability），指的是代码的易理解程度。</p></li><li><p>边界约束：集群规模、计算机的容量等物理资源的限制，以及客户、用户、团队的约束需求。</p></li></ul><p>依据这几项质量度量指标，可以保证分布式的“可解释、可复制、可预测”。</p><h2 id="分布式系统的反熵增与数据守恒"><a href="#分布式系统的反熵增与数据守恒" class="headerlink" title="分布式系统的反熵增与数据守恒"></a><font color="#FF8C00">分布式系统的反熵增与数据守恒</font></h2><h3 id="熵增"><a href="#熵增" class="headerlink" title="熵增"></a>熵增</h3><p>熵增定律是物理学的基本定律之一，其被定义为：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs undefined">1, 熵（Entropy）是用以度量一个系统“内在的混乱程度”，即系统中的无效能量；<br>2, 熵增定律：在一个孤立系统里，如果没有外力做功，其总混乱度（熵）会不断增大；<br>3，熵增过程是一个自发的由有序向无序发展的过程并且具有必然性，为了保证有序就必须逆熵增做功。<br></code></pre></td></tr></table></figure><p>分布式系统也是一个孤立的系统，其中的网络与计算机节点（涵盖电源、主板、CPU、内存、网卡、硬盘等）等硬件会老化、会出故障，组件之间协同工作也会遇到负载过高、软件系统出现BUG等问题，这也是一个熵增的过程，并且因为熵增的必然性，分布式系统总是自发地或非自发地不断由有序走向无序，最终不可逆地走向失效不可用。为了保证分布式系统是有序可用的就必须逆熵增做功，即对其反熵增，分布式系统的反熵增过程与方法是：</p><ul><li>可运维设计：软硬件的部署与升级设计、可视化设计、可观测性（监控、告警、日志、追踪）设计；</li><li>可服务设计：由团队解决故障以及提供服务的支持；</li><li>服务治理设计：熔断、限流、降级、隔离、容错，触使分布式系统保持在有序状态；</li><li>智能化设计：参数自我优化、故障自我判断、工作负载自我预测等；</li><li>动态平衡设计：动态平衡是一种设计理念，有进有出；</li></ul><p>因此在分布式系统里将需要将可运维、可服务、可治理、可智能化、动态平衡的思想融合到架构设计与开发中。</p><h3 id="数据守恒"><a href="#数据守恒" class="headerlink" title="数据守恒"></a>数据守恒</h3><p>能量守恒定律也是物理学的基本定律之一，其被定义为：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs undefined">1，能量既不会凭空产生，也不会凭空消失，它只会从一种形式转化为另一种形式，或者从一个物体转移到其它物体，<br>   而能量的总量保持不变；<br>2，孤立系统的总能量保持不变。<br></code></pre></td></tr></table></figure><p>在分布式系统里<strong>“数据”</strong>即是分布式系统的能量，因此参照“能量守恒”定义，这里我给分布式系统一个<strong>“数据守恒”</strong>定义：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs undefined">孤立系统的总数据量保持不变。数据既不会凭空产生，也不会凭空消失，它只会从一种形式转化为另一种形式，<br>或者从一个物体转移到其它物体， 而数据的总量保持不变；<br></code></pre></td></tr></table></figure><p>依据上节的定理推导，我们知道分布式系统里网络是不可靠的、消息传递是不可靠的、计算机节点是不可靠的、磁盘是不可靠的、内存是不可靠的、软件组件是不可靠的等等，这些过程都会丢数据，因此为了保证分布式系统里的<strong>“数据守恒”</strong>就需要对分布式系统进行数据可靠性设计：即：</p><ul><li>分区设计、冗余设计、幂等性设计、端到端的校验设计、日志设计、事务处理设计，缓存的MESI设计等。</li></ul><p>因此在分布式系统里将也需要将<strong>“数据守恒”</strong>的思想融合到架构设计与开发中。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font color="#FF8C00">小结</font></h2><p>本文以物理学思维挖掘分布式系统的本质，推导出了分布式系统为什么需要这样的设计的缘由，并且文中阐述了分布式系统的基础理论、功能非功能、反熵增与数据守恒。日拱一卒，功不唐捐，分享是最好的学习，与其跟随不如创新，希望这个知识点对大家有用。另作者能力与认知都有限，”我讲的，可能都是错的“，欢迎大家拍砖留念。</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中科大硕，DELL EMC 资深首席工程师，曾就职于Marvell、AMD，主要从事Linux内核以及分布式产品的交付、架构设计以及开发工作。</p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>分布式系统架构设计36式 – 第16式 - 以第一性原理思维模型解读tensorFlow 2.0的架构设计</title>
      <link href="/2020/02/18/distributed-ideamodel-example_tensorflow/"/>
      <url>/2020/02/18/distributed-ideamodel-example_tensorflow/</url>
      
        <content type="html"><![CDATA[<h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a><font color="#FF8C00">动机</font></h2><p>依据李善友老师的定义“第一性原理思维 = 逻辑奇点 + 公理化方法”，逻辑奇点即基石假设。根据这个第一性原理思维 ，本文解读了tensorFlow 2.0的架构设计，其涵盖了tensorFlow2.0的第一性原理、设计原则以及架构视图，本文的动机是展示第一性原理的架构设计思想在分布式系统架构设计中的应用。</p><h2 id="TensorFlow-的第一性原理"><a href="#TensorFlow-的第一性原理" class="headerlink" title="TensorFlow 的第一性原理"></a><font color="#FF8C00">TensorFlow 的第一性原理</font></h2><p>欲从本质上理解Tensorflow，那么就需要找出tensorflow的第一性原理定义，再依据演绎法，从这个公理性质的定义演化出tensorFlow的设计理念、设计原则以及功能实现。这里首先把tensorFlow概念化，找出它的公理化定义以及基石假设，即TensorFlow是什么的定义。</p><p>通过tensorFlow官网以及Google，得到的6条关于tensorFlow的定义：</p><blockquote><p>1.A machine-learning library based on dataflow programming. </p><p>2.TensorFlow is a free and open-source software library for dataflow and differentiable programming across a range of tasks. </p><p>3.TensorFlow is an end-to-end open source platform for machine learning. </p><p>4.TensorFlow computations are expressed as stateful dataflow graphs. </p><p>5.TensorFlow is an end-to-end open source platform for machine learning. It has a comprehensive, flexible ecosystem of tools, libraries and community resources that lets researchers push the state-of-the-art in ML and developers easily build and deploy ML powered applications.</p><p>6.TensorFlow Enterprise incorporates: Enterprise-grade support, cloud scale performance，managed services</p></blockquote><p>从这6个定义中，可以概括出tensoFlow的<strong>公理化定义</strong>：</p><blockquote><p>TensorFlow is an scalable end-to-end  machine-learning platform based on <strong>stateful dataflow graphs</strong> programming,it has a comprehensive, flexible ecosystem.</p></blockquote><p>即</p><blockquote><p>tensorFlow是一个可伸缩的端到端的面向有状态的数据流图编程的机器学习平台,其具有一个全面而灵活的生态系统。</p></blockquote><p>以及两个<strong>基石假设</strong>，即逻辑奇点：</p><ul><li>可伸缩(scalable)：可伸缩性是分布式的目的，分布式能力是TensorFlow的构建与运维能力，分布式能力是tensorFlow的隐性基石假设；</li><li>机器学习(machine learning)：机器学习是Tensorflow的领域功能，是tensorFlow的显性基石假设。</li></ul><p>从这个公理化的定义以及两个基石假设里可以推导出设计tensorFlow的作者们的对tensorFlow的几条类似定理性质的设计理念：</p><ul><li><p>机器学习(machine learning): 指的是功能领域定位，依据这个设计定位，因此tensorFlow提供的是机器学习相关的功能，其涵盖数据、模型、策略、训练、推理等核心功能。</p></li><li><p>分布式：分布式能力是tensorFlow的构建与运维能力，从抽象的技术实现视角来看tensorFlow就是分布式框架+机器学习的lib库；</p></li><li><p>端到端(end-to-end): 端到端指的是“全程都包”的一种设计理念，用户输入原始数据，经过tensorFlow处理即可以直接得到可用的结果，这个结果可以直接服务于用户，用户无需关注tensorflow的中间过程如何。在tensorFlow里端到端的设计理念体现在 “准备数据 、定义模型、 训练模型、 评估模型、 保存模型以及使用模型”这几个过程，用户只要输入数据即可以得到可用的结果模型。</p></li><li><p>平台(platfrom)：平台化，通常的软件平台指的是能够让用户自己在上面进行业务开发的软件系统，它将业务与技术解耦，用户可以基于这个平台开发自己的业务。其具有可用户自我定义的灵活性、用户可二次开发的开放性、以及接口标准化的特性。在tensorFlow里的平台化的设计理念体现在用户可以自由的定义自己的业务模型而无需关注里头的技术实现即可以得到想要的输出结果。</p></li><li><p>有状态（stateful）：状态是指事物处于产生、发展、消亡时期或各转化临界点时的形态，有状态是指</p><blockquote><p>“该服务的实例可以将一部分上下文的数据随时进行备份，并且在创建一个新的有状态服务时，可以通过备份恢复这些数据，以达到数据持久化的目的。”。</p></blockquote><p>有状态服务在功能上可以保证数据的恰好一次，可以保证数据服务的强正确性，但是有状态服务需要维护大量的信息和状态，因此又引入了数据存储的复杂性，并且多了数据存储加载的过程，在性能方面要弱于无状态服务。而无状态服务不能保证数据的恰好一次处理，但是易于处理实例规模的伸缩性。tensorflow是有状态的设计理念，表明了tensorFlow可以保证数据处理的恰好一次的强正确性，但是又引入了数据存储与IO性能上的复杂性，需要平衡有状态服务下的正确性与复杂性就需要针对数据存储进行专门的设计。</p></li><li><p>数据流图（dataFlow graphs）: 数据流图指的是用节点和有向边描述数学运算的有向无环图，其要素有数据源或宿、数据流、数据处理节点以及数据存储，其中节点代表数学运算等，而有向边代表节点之间的输入与输出关系、数据在边上流动。依据这个设计理念，TensorFlow依据下图的工作过程计算数据：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/tensorflow/tf_arch_dataflow.gif" alt="计算流图示例"></p><p>在这个数据流图里，tensorFlow里需要事先准备数据，接着定义运算操作，然后计算单元被同步或者异步地分配到不同的计算设备上比如CPU、GPU、TPU进行计算，其在边上流动的数据叫tensors。</p></li><li><p>编程（programming）：可编程性，“编程就是指导计算机执行任务的行为”，编程是个动词，是为了让计算机干你想要干的事情。在面向对象编程里，程序=算法+数据结构+方法，依据这个设计理念，即用户可以依据一定的数据结构通过输入算法以及相应的工程方法，就可以指导tensorFlow执行用户想干的事情，其可以二次开发，具有灵活性以及开放性的特征。</p></li><li><p>生态系统（ecosystem）：生态化，指的是tensorFlow的产品商业模式理念，围绕tensorFlow为核心建立一个完整的工具、库以及社区资源生态系统。</p></li></ul><p>通过以上的分析，可以得出tensorFlow的第一性原理，即：tensorFlow是一个端到端的面向有状态的数据流图编程的机器学习平台，自带完整的产品生态系统，其逻辑基石为“分布式及机器学习”。就是这么简单的一句话，但是却是tensorFlow作者们的设计理念，整个tensorFlow的所有设计理念、设计原则以及功能实现都是依据这一句话来做指导的。</p><h2 id="TensorFlow的设计原则"><a href="#TensorFlow的设计原则" class="headerlink" title="TensorFlow的设计原则"></a><font color="#FF8C00">TensorFlow的设计原则</font></h2><p>从tensorflow的官网可以看到几个关键词“easy,robust,powerful,ecosystem”，这几个词即是temsorflow的设计原则，tensorFlow的设计原则是定理性质的定义，其也从tensorFlow的第一性原理定义中推导出来。“端到端”代表了易用性，“平台化”、“可编程”代表了功能强大，“分布式”代表可高可用性、高可靠性，另外tensorFlow还有一个生态化的运营理念，灵活、开放、完整。</p><p><strong>易用</strong>（Easy）</p><p>易用性的设计原则体现在与用户打交道的API接口层、模型的使用以及分布式训练：</p><ul><li><p>模型制作简单，API容易调用，TensorFlow 提供多个级别的抽象接口，可以使用高阶的 Keras API 轻松地构建和训练模型</p></li><li><p>开发过程可调试，支持Eager Execution 进行快速迭代和直观的进行调试</p></li><li>训练过程简单，可以使用 Distribution Strategy API 在不同的硬件配置上进行分布式训练而无需更改模型定义</li></ul><p><strong>可靠(Robust，鲁棒性、可靠)</strong></p><ul><li>支持随时随地进行可靠的机器学习生产。支持在本地服务器、边缘设备、云端、web端轻松地训练和部署模型，而无需关注开发语言。TensorFlow Extended (TFX)可用于生产型机器学习， TensorFlow Lite可用于移动设备和边缘设备的推断， 而 TensorFlow.js 支持在web端中训练和部署模型</li></ul><p><strong>强大</strong>（powerful）</p><ul><li>架构简单而灵活，支持最先进的模型，并且可以保证性能。借助 Keras Functional API 和 Model Subclassing API 等功能，TensorFlow 可以灵活地创建复杂拓扑并实现相关控制。TensorFlow 还支持强大的附加库和模型生态系统，包括 Ragged Tensors、TensorFlow Probability、Tensor2Tensor 和 BERT。</li></ul><p><strong>生态化</strong>(ecosystem)</p><ul><li>生态化是产品的商业模型，灵活、开放、强大，tensorFlow具有完整的一个生态环境，其拥有一个包含各种工具、库和社区资源的全面灵活生态系统，可以让研究人员推动机器学习领域的先进技术的发展，并让开发者轻松地构建和部署由机器学习提供支持的应用</li></ul><p>从tensorFlow 1.0 到tensorFlow 2.0 的升级，涵盖了API的易用性升级，动态图的支持、算法的更新、功能迭代以及文档完善，其本质目的还是遵循这四个设计原则，即简单、可靠、强大、生态化。如果只是追寻tensorFlow的版本迭代而不理解其背后的设计理念、设计原则，只会疲于奔命、知其然而不知其所以然。</p><h2 id="TensorFlow-架构视图"><a href="#TensorFlow-架构视图" class="headerlink" title="TensorFlow 架构视图"></a><font color="#FF8C00">TensorFlow 架构视图</font></h2><h4 id="逻辑架构视图"><a href="#逻辑架构视图" class="headerlink" title="逻辑架构视图"></a>逻辑架构视图</h4><p>TensorFlow的逻辑架构视图体现了tensorflow的功能需求，如下图，tensorFlow的功能可分为训练、部署、可视化以及模型仓库。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/tensorflow/tf_arch_logic_architecture.png" alt="逻辑架构图"></p><p><strong>训练</strong></p><ul><li>tf.data用于加载训练用的原始数据</li><li>tf. Keras 或 Premade Estimators 用于构建、训练和验证模型</li><li>eager execution 用于运行和调试</li><li>distribution strategy 用于进行分布式训练，支持单机多卡以及多机多卡的训练场景</li><li>SavedModel用于保存导出的训练模型，并且将训练模型标准化，作为 TensorFlowServing、TensorFlow Lite、TensorFlow.js、TensorFlow Hub 等的交换格式</li></ul><p><strong>部署</strong></p><ul><li>TensorFlow Serving，即TensorFlow允许模型通过REST以及gPRC对外提供服务</li><li>TensorFlow Lite，即TensorFlow针对移动和嵌入式设备提供了轻量级的解决方案</li><li>TensorFlow.js，即TensorFlow支持在 JavaScript 环境中部署模型</li><li>TensorFlow 还支持其他语言 包括 C, Java, Go, C#, Rust 等</li></ul><p><strong>可视化</strong></p><ul><li>TensorBoard 用于TensorFlow可视化</li></ul><p><strong>模型仓库</strong></p><ul><li>TensorFlow hub用于保存训练好的TensorFlow模型，供推理或重新训练使用</li></ul><h4 id="处理架构视图"><a href="#处理架构视图" class="headerlink" title="处理架构视图"></a>处理架构视图</h4><p>TensorFlow的处理架构视图表明了数据处理的流程，其具有tensorFlow的运行期间的质量需求。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/tensorflow/tf_arch_process_architecture.PNG" alt="处理架构视图"></p><p>本图是分布式工作模式，“/job：worker / task:0” 和 “/ job:ps / task:0” 都是工作节点上执行的任务。“PS” 表示 “参数服务器”，负责存储和更新模型参数。</p><p><strong>处理流程</strong></p><p>1）客户端负责将整个计算过程转义成数据流图，并且启动计算发送到分布式主节点；</p><p>2）分布式主节点基于用户传递给的参数对整个完整的图形进行修剪，提取其中的子图，接着将子图拆分成不同部分，并将其分发到不同的进程和设备当中；</p><p>3）工作节点执行其收到的主节点分发给它的数据图片段，并且与其他工作节点 相互发送和接收计算结果；</p><p>4）内核计算单元，执行单个图形操作的计算部分。</p><p><strong>数据处理期的质量与约束</strong></p><p>TensorFlow分布式模式是构建在分布式之上的，其具有分布式系统自身的质量与约束需求：</p><ul><li><p>TensorFlow的质量需求：性能指标：TPS、QPS、IOPS、Latency、ResponseTime、缓存抖动指标、缓存命中指标，可靠性指标: 6个9企业级代表，可用性指标：6个9企业级达标，数据一致性指标，可伸缩性，韧性，可观测性，可服务性，安全性，易用性，可运维性等</p></li><li><p>TensorFlow的约束需求：其可以是资源容量约束：CPU、磁盘、网络、线程、文件描述符个数，也可以是客户的约束、用户的约束等。</p></li></ul><h2 id="TensorFlow-2-0-的缺点"><a href="#TensorFlow-2-0-的缺点" class="headerlink" title="TensorFlow 2.0 的缺点"></a><font color="#FF8C00">TensorFlow 2.0 的缺点</font></h2><ul><li><p><strong>网络</strong>，开源的TensorFlow默认采用gRPC作为基础通信组件，违背<strong>“最佳物种”</strong>里的最佳原则设计哲学，机器学习本身是高吞吐量高性能要求的生产场景，而gRPC是基于HTTP2/Protobuf  协议通信的，而且发送接收都需要序列化，增加了网络传输的延时，并不是机器学习场景的最佳选择，但是好在TensorFlow也支持让你“DIY”的设计理念，例如在网络通信上支持GDP（GPU DIRECT）VERBS(IB,RDMA)以及MPI的扩展（“<a href="https://github.com/tensorflow/networking" target="_blank" rel="noopener">https://github.com/tensorflow/networking</a>: Currently support building GDR, VERBS, and MPI extensions），这相当于把这一部分产品化的工作给了用户或者GPU、TPU之类的芯片原厂。优化手段：将PS算法、RING ALLREDUCE算法融合进MPI，再根据工程实践情况取舍“容错、可服务化、可运维化、智能化“的设计理念，抽象出一个新的分布式调度中间件以替换gRPC，目的是获取更好的性能、更高的GPU、TPU性价比。</p></li><li><p><strong>计算</strong>，计算架构很有限还不能榨尽各种硬件的最佳性能。目前的分布式计算视图架构成熟的方案有：Parameter Server 架构以及Ring AllReduce架构，那么是否还有其它更好的架构，比如区块链的去中心化架构。</p></li><li><p><strong>存储</strong>，存储应用容易被忽视，系统太过于复杂。TesnorFlow里涉及到存储的地方有：海量或非海量的原始数据存储、ETL好的数据的存储、PS架构中的训练参数以及模型的存储，训练好的模型的存储，如果这四个存储需求都是分散的存储系统，其实复杂度挺高，可以专门针对这种场景以及数据特性设计一个专门的机器学习存储系统，除了可以同时满足这四个场景的质量指标外，还将四个系统统一成一个，减少机器学习场景下的系统复杂度。</p></li><li><p><strong>功能</strong>，功能的优化是无止境的，原则是要遵循客户需求适可而止。TensorFlow本质上也是<strong>分布式系统+机器学习领域的能力</strong>，除了机器学习的各种算法魔法的持续优化，分布式系统里的各种分布式算法也是适合迁移过来挖掘的，比如服务治理、路由负载均衡算法、集群视图变更、消息传输等。比如这么一个工程课题：“如何支持上万张训练卡的规模以及如何保证其质量可以达标？如何保证系统性能可以随着训练的卡数线性增长并且保证卡子的利用率在90%以上，同时可以保证训练过程的可靠性？”</p></li><li><p><strong>产品</strong>，一个开源项目的功能特性大多是取舍的结果，就算是缺点往往也会很快演化迭代掉，因此从技术角度看待一个开源项目缺乏可持续性。但是从产品的角度来看，开源项目自带开源的先天弊端，其缺乏“价值与市场的锲合“度，这是开源项目的先天缺点，越成功的开源项目越无法避免，如果避免了这个缺点，开源项目反而是失败的，因为做的太好反而无法收费，团队没法存活，TensorFlow2.0开源版是一个开源的项目因此也逃脱不了这个缺点。从“项目与社区锲合”以及“产品与市场锲合”的角度来看，依据点赞数、fork数、下载量、用户使用量、社区文章阅读量这几个指标做度量，TensorFlow 2.0 开源版是一个非常成功开源的软件，但是从”价值与市场锲合“这个角度看，其离商业产品还是有一段距离。</p><p>开源项目往往是靠一些增值功能、企业级特性以及服务的支持收费而存活，这些特性即为价值与市场的锲合点，是商业客户愿意买单的地方，是商业产品与开源项目差异化所在，这些特性有：更好的性能、更加易用的部署与升级功能，可运维化、更加易用的可视化功能、安全、可观测、质量的可度量性，此外客户往往需要的不只是一个产品，更进一步需要的是行业解决方案。例如，tensorFlow企业版就说明了支持企业级特性、可云端伸缩性能以及无缝管理的支持，而TensorFlow2.0 开源版只是一个开源项目，还没达到这个层度。</p><p>因此，从产品的角度看，开源的tensorFlow2.0开源版只能算是一个成功的开源项目还不是商业产品以及解决方案，它只完成了“项目与社区锲合”以及“产品与市场锲合”这两个层次，因此商业化就要求我们需要把开源的tensorFlow2.0产品化、解决方案化。</p></li></ul><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font color="#FF8C00">小结</font></h2><p>本文依据第一性原理架构设计思维模型解读了TensorFlow2.0。第一性原理思维模型我不是首创，分布式系统架构设计我不是首创，第一性原理思维模型在分布式系统架构设计中的应用我是首创。日拱一卒，功不唐捐，分享是最好的学习，与其跟随不如创新，希望这个知识点对大家有用。另作者能力与认知都有限，”我讲的，可能都是错的“，欢迎大家拍砖留念。</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中科大硕，DELL EMC 资深首席工程师，曾就职于Marvell、AMD，主要从事Linux内核以及分布式产品的交付、架构设计以及开发工作。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a><font color="#FF8C00">参考资料</font></h2><p>[1] <a href="https://blog.tensorflow.org/2019/09/tensorflow-20-is-now-available.html" target="_blank" rel="noopener">https://blog.tensorflow.org/2019/09/tensorflow-20-is-now-available.html</a></p><p>[2] <a href="https://github.com/tensorflow/tensorflow" target="_blank" rel="noopener">https://github.com/tensorflow/tensorflow</a></p><p>[3] <a href="https://en.wikipedia.org/wiki/TensorFlow" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/TensorFlow</a></p><p>[4] <a href="https://www.tensorflow.org/about" target="_blank" rel="noopener">https://www.tensorflow.org/about</a></p><p>[5] <a href="https://tensorflow.google.cn/guide/?hl=zh-CN" target="_blank" rel="noopener">https://tensorflow.google.cn/guide/?hl=zh-CN</a></p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>分布式系统架构设计36式 – 第15式 - 架构思维</title>
      <link href="/2020/02/16/distributed-ideamodel-architecture/"/>
      <url>/2020/02/16/distributed-ideamodel-architecture/</url>
      
        <content type="html"><![CDATA[<h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a><font color="#FF8C00">动机</font></h2><p>万事万物逃脱不出<strong>“不易、简易、变易”</strong>这三个层次，演绎法认为“道生一、一生二、二生三、三生万物”，而归纳法也可以认为“万物合三，三合二、二合一、一合道”。本文的目的之一是通过归纳法找出分布式系统架构设计最为本质的“道”，使之可以用于解读各式各样的分布式系统架构设计。</p><p>从应用领域来看分布式系统可以分为三大类：分布式计算、分布式存储以及分布式调度，本文做的是从这三大领域的”变易”中找出“不易、简易”，“以”不变“应”万变“，从而抽象出一种分布式架构思维使之可以应用于这三大领域的架构设计。</p><h2 id="架构思维模型"><a href="#架构思维模型" class="headerlink" title="架构思维模型"></a><font color="#FF8C00">架构思维模型</font></h2><p>在面向对象编程有四个最高的思想，即“抽象、封装、继承与多态”，将这个思想迁移应用到本文，可以解读为架构思维是第8式“火箭技术思维模型”的以及第0式”设计总决“的继承，这里我把它定义为“分布式系统火箭架构思维模型”，如下图：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/ideamodel/idea-model-architecture-1.PNG" alt="架构思维模型"></p><h4 id="火箭架构思维模型"><a href="#火箭架构思维模型" class="headerlink" title=" 火箭架构思维模型"></a><font color="#00CED1"> 火箭架构思维模型</font></h4><p>这个架构思维模型用图形是一个内部分层的三角形，类比为一个5级火箭体，它包括“势 道 法 术 器 界”这六个要素，其下一级为上一级的提供动力的同时又受三条边的约束。</p><p>狭义上的分布式系统架构通常指的是架构的技能，其属于“术”的范畴，而广义的分布式系统架构则是市场趋势、架构理念、架构方法论、架构技能、架构用的工具以及架构的边界这几个方面的组合体，应用抽象思维，即“势、道、法、术、器、界”这六个字 ，简称架构思维六元组。</p><h4 id="势：时势，是架构的方向"><a href="#势：时势，是架构的方向" class="headerlink" title=" 势：时势，是架构的方向"></a><font color="#00CED1"> 势：时势，是架构的方向</font></h4><p>“势”是架构的方向。从宏观处着眼，“势”是产品架构设计的市场趋势、是客户需求趋势也是技术的应用趋势；从微观处着手，“势”是功能设计的价值与目的。架构设计需要从宏观处着眼微观处着手，看清客户的需求趋势、市场趋势以及技术趋势，功能设计需要分析清楚当前功能的价值与目的。除了明白架构的是什麽的问题，还需要明白为什麽需要做这个架构设计，这就需要从“势”处定义问题、分析问题、过滤问题以及解决问题。</p><p>团队一起讨论架构选型与功能设计的问题，经常会遇到A说A有理，B说B有理，最终方案无法达成一致致使项目拖延甚至失败的情形。这就需要梳理清楚架构的目的、原则、质量与边界，对方案进行方向上的约束，那么“势”就是架构选型与功能设计的约束条件之一，其用于定义架构的目的。</p><h4 id="道：理念，是架构的认知"><a href="#道：理念，是架构的认知" class="headerlink" title=" 道：理念，是架构的认知"></a><font color="#00CED1"> 道：理念，是架构的认知</font></h4><p>“道”是架构的认知，是架构师的设计理念、设计意图，是产品架构的灵魂。美国学者布卢姆认为认知有六层次：识记、理解、应用、分析、评价、创造。产品架构是由人设计的，那么不可避免的就会带有人的因素在里头，”见其所欲“，你所看到的架构都是架构师欲让你看到的，对分布式系统认知层次不同的人，理念也是不同的，欲深入理解一个产品的架构必须要能找到设计它的人的设计”理念“。</p><p>进行分布式系统的架构设计，首先我们要知道分布式系统的第一性原理是什么？即分布式系统的类似公理性质的定义，Google 出来的对分布式系统的定义有：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs undefined">A distributed system is a system whose components are located on different networked computers, which communicate and coordinate their actions by passing messages to one another. The components interact with one another in order to achieve a common goal.<br>分布式系统是一个组件分布在不同的联网的计算机上，彼此之间仅仅通过消息传递进行通信和协调的系统，这些组件相互交互以实现一个共同的目标。<br></code></pre></td></tr></table></figure><p>这句话就是分布式系统的第一性原理，是分布式系统的类公理性质的理论定义，其非常重要，默认不变的公理性定义，解读开来就是：“分布式系统是由建立在网络上的通过消息进行通信和协调的系统，各个机器相互交互一起完成一个共同的目标。”，从这句话里可以推理出分布式系统的几个类似定理性质的特征定义：</p><ul><li><p>分布式系统是基于网络的，网络所具有的毛病它都有，网络会丢包、网络有带宽限制、网络有安全隐患、网络有负载均衡问题等，那么这些问题在分布式系统里需要怎么解决？那么如何提高服务的可靠性？如何保证服务的可用性？</p></li><li><p>分布式系统是基于消息传递的，那么如何保证消息的幂等性？如何保证消息的正确性？如何保证消息传递的性能？如何保证消息传递的可靠性？</p></li><li>分布式系统是协调工作的，那么如何协调大量的计算机节点的完成一个共同的目标，如何解决协调的复杂性以及提高协调的可靠性？</li><li>分布式系统是一起相互交互完成一个共同的目标的，那么如何一起交互？如何拆分目标？如何聚合目标，如何提高完成目标的性能？</li><li>分布式系统是分布式的，其具有分布性的特点，那么如何保证分布式所要求的负载均衡、可伸缩性、韧性等功能与质量需求？</li></ul><p>依据分布式系统的第一性原理，本文解读了分布式系统的理论认知，除此之外还可以依据个人对分布式系统的工程经验推理出分布式系统的实践认知，依据工程实践经验，这里我定于分布式系统为：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs undefined">分布式系统是面向集群状态的编程, 它是抽象、分层、解耦、拆分、聚合、治理、取舍、模型、质量、边界、演化思维的创造性应用，其要交付的是功能价值，但功夫却体现在非功能。<br></code></pre></td></tr></table></figure><p>不同于教科书以及一些论文对分布式系统的理论定义，这个定义来源于个人工程经验，是认知的创造。分布式系统的功能、质量与约束都来自于这两个理论定义与工程定义。</p><h4 id="法：方法论，是架构的套路"><a href="#法：方法论，是架构的套路" class="headerlink" title=" 法：方法论，是架构的套路"></a><font color="#00CED1"> 法：方法论，是架构的套路</font></h4><p>”法“是方法论，是架构设计的方法论，是架构设计的套路，它是认知论的上一级，方法论体现在产品的设计原则、设计心法以及设计功能。从工程经验的角度，本文认为分布式系统设计可以依从以下的”9法10项2原则“ 作为方法论。</p><h5 id="9法"><a href="#9法" class="headerlink" title="9法"></a><strong>9法</strong></h5><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs undefined">少读少写少依赖，业务拆业务合，功能拆性能聚，时空换同异换<br><br>硬件顺天性，服务需治理，数据保一致，哪都不可靠，事事慎权衡<br></code></pre></td></tr></table></figure><ul><li>少读少写少依赖: 少读，即减少读放大，减少需要读的数据量；少写，即减少写放大，减少需要写的数据量；少读少写的策略可以是提高cache命中率也可以是进行数据压缩，还可以是合适的读写算法与数据结构等，少依赖，即解耦，拆分，高内聚低耦合</li><li><p>业务拆业务合：分布式系统里要有拆有合，拆的目的是为了解耦、是为了集群业务可伸缩，是为了组件上的小可以支持集群规模上的大；合的目的是为了内聚，聚合拆分的服务返回的子结果，从而返回大结果；“业务拆业务合”，其理论依据来源于“康威定律”，即： 设计系统的组织其产生的设计等价于组织间的沟通结构，软件架构的拆合关系来源与团队的组织结构。</p></li><li><p>功能拆性能聚：在分布式系统里有拆有合，那么拆与合的取舍依据在哪里？这句话讲的就是拆与合的取舍关系：依据功能进行拆分，但是也要依据性能进行聚合，拆开后会影响性能的地方最好不拆</p></li><li><p>时空换同异换： 时空换同异换讲的是性能优化的路数，解读开来说即是：时间换空间、空间换时间、同步换异步、异步换同步。例如：采用cache的功能可以减少计算的时间，这是存储空间换时间从而提升性能；采用批处理的方式提升性能，这是减少计算时间；采用异步换同步的方式提升性能也是减少计算时间；减少IO的数据量从而提升性能，这是存储空间换时间；减少IO路径提升性能，这也是网络空间换时间；采用最新的硬件提升性能，这可以是计算换时间，也可以是存储或网络空间换时间</p></li><li><p>硬件顺天性：硬件顺天性讲的是软件设计要遵循硬件的原生特性，CPU的分核调度、机械盘性能不如固态硬盘、磁盘分块需要对齐、磁盘是有可能会电子位飘逸丢数据的、内存性能好适合做缓存但是下电就丢数据、网络是不可靠的并且有带宽限制、RDMA网络比IP网络性能好，机器学习采用GPU比CPU更能获得高计算性能；不同的应用场景要依据硬件的不同特性做架构选型以及架构设计等。</p></li><li>服务需治理：指的是分布式系统是由各种不同的组件进行组合连接而成，其需要服务治理设计，服务需治理背后的原因来源于分布式系统式搭建在网络上的，其继承了网络的毛病，背后的指导思想是“墨菲定律”，即“会出错的事总会出错”，服务治理的具体解决方案可分为容错、降级、限流、熔断、隔板这五个模式</li><li>数据保一致：要保证分布式系统对外提供的服务的数据的一致性，cache掉电会丢数据、网络不可靠会丢数据、磁盘电子不可靠会丢数据，计算丢请求会丢数据，各种场景下都需要保证数据的一致性，比如缓存的MESI算法保数据、掉电刷内存保数据、网络端到端的校验、磁盘扫描校验、数据副本保数据等</li><li>哪都不可靠：指的是磁盘不可靠、网络不可靠、计算不可靠、运维的人不可靠，何种场景都需要进行系统的韧性设计</li><li>事事慎权衡：指的是架构设计本身的设计方法论，即trade-off</li></ul><h5 id="10项"><a href="#10项" class="headerlink" title="10项"></a><strong>10项</strong></h5><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs undefined">提供 注册 配置 调用 路由<br>观测 治理 编排 质量 边界<br></code></pre></td></tr></table></figure><ul><li>提供：即服务接入的提供，指的是对外提供restful 接口服务：权限、多组合、监控、审计、计费等，对外提供SQL服务接入接口服务、对外提供自然语言接入接口服务等</li><li>注册：即服务注册，将集群的工作负载注册到集群注册中心</li><li>配置：即配置管理，将集群的配置管理在配置中心；</li><li>调用，即服务调用，各种RPC调用，系统内的消息传递</li><li>路由：即服务路由，目的是集群的负载均衡与扩伸缩性</li><li>观测：指的是集群内部指标的可观测性，即监控、告警、追踪、日志</li><li>治理：指的是集群内部的服务治理：熔断、降级、限流、隔离、容错</li><li>编排：即服务编排，基于k8s+ docker，完成安装、升级、扩容、运维、调度等；</li><li>质量：指的是安装部署运维质量、客户质量、用户质量与开发质量</li><li>边界：指的是系统内的约束条件，涵盖 硬件资源、客户约束、用户约束以及团队约束</li></ul><h5 id="2原则："><a href="#2原则：" class="headerlink" title="2原则："></a><strong>2原则：</strong></h5><ul><li>最佳物种原则</li><li>功能非功能原则</li></ul><h5 id="最佳物种原则"><a href="#最佳物种原则" class="headerlink" title="最佳物种原则"></a><strong>最佳物种原则</strong></h5><p>最佳物种原则其来源是生物的物种进化理论，讲的是产品原则，其可以一分为二：</p><p>1，最佳原则，做产品架构设计的时候要挖掘不同的业务特性以及其业务本质，从而设计出与业务最为匹配的架构。天上飞的是鸟儿，地上奔跑的是走兽，水里游的是鱼儿。架构设计由大及小，由外及内也是如此。比如计算用的是分布式计算、存储用的是分布式存储，调度用的是分布式调度，其负责的领域各不相同，不存在一个全能的分布式中间件可以最佳的完成计算、存储、调度三合一的功能。从小处来讲也是如此，比如分布式系统内部的注册、路由、成员管理、服务提供、复制、安全、算法模型、存储等各有其自己最佳的设计方案，再依据这些最佳组件、最佳方案组合出一个最佳分布式中间件。</p><p>2，进化原则，万物由微而显，由简而繁，物竞天择，优胜劣汰，好的架构是根据业务演化而来，而不是一开始就完美的设计好的。但是不管是微还是显，其最本质的功能还是不变的，一个产品从POC到MVP再到企业级达标其最核心的功能是不变的，比如计算、存储与调度。</p><h5 id="功能非功能原则"><a href="#功能非功能原则" class="headerlink" title="功能非功能原则"></a><strong>功能非功能原则</strong></h5><p>功能非功能原则，讲的是技术原则，从大体上来说，分布式系统的架构设计都是围绕其功能与非功能的量化设计来进行的，非功能又可以一分为二，即：质量与约束，比如：</p><p>客户对产品质量的需求一般可以用四个字概括，即”多、快、好、省“，然而客户在产品交付的时间、质量与成本上的取舍，客户原来遗留的系统，当前国家的法律法规，市场上的技术趋势以及竞争对手与行业标准等都属于当前客户需要考虑的约束条件。</p><p>用户的产品质量需求一般称为使用质量需求，其一般包括：性能、可用性、可靠性、可伸缩性、韧性、可观测性、可服务性、安全性、易用性、可运维性等，而用户的约束需求包括 用户的业务环境、用户的能力以及用户群的特征等。</p><p>团队的质量需求指的是产品开发周期内的质量需求，高质量的代码几个最重要的要素有：可测试性、可维护性、可扩展性、可读性等，而团队的约束需求有：资源预算、上级要求、开发团队的能力、产品规划、此外还有信息安全以及产品运行环境 的约束等。</p><h4 id="术：技能，是架构技能"><a href="#术：技能，是架构技能" class="headerlink" title=" 术：技能，是架构技能"></a><font color="#00CED1"> 术：技能，是架构技能</font></h4><p>术，技能，是架构技能，其可以分为需求分析、设计哲学定义、设计方法论定义、设计原则定义、架构制图、基础理论理解与应用、基础数据结构理解与应用、基础算法设计、基础组件设计、质量达标设计以及边界约束设计。即：</p><ul><li><p>分布式系统的需求分析：这里可以依据需求分析公式：需求 = [客户，用户，团队] x [功能，质量，约束]，进行全面的架构需求分析。</p></li><li><p>分布式系统的设计思想：抽象、 分层、 解耦、  拆分 、聚合、治理、取舍、模型、质量、边界、演化</p></li><li><p>分布式系统的设计原则：最佳物种原则，功能非功能原则</p></li><li><p>分布式系统的架构视图：我们在学习画法几何或机械制图的时候，要描述一个物体可以采用视图法来表示，比如机械制图里要制造一个零件的时候，需要依据这个零件画出可以根据这个图形加工的视图，其通常采用正视图、俯视图、侧视图，加上额外的细节视图与质量指标、材料约束的方法。同样我们做软件架构设计的时候，也需要将具体的”软件体“抽象成视图来表示，同时也需要标记上质量与边界约束。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/ideamodel/idea-model-architecture-2.PNG" alt="4+1架构模型"></p><p>如上图常用的4+1视图：物理视图、逻辑视图、处理视图、开发视图以及用例视图，其中与用例视图交叉的部分是描述共同的细节，同时每种视图中又有各自的需求，比如物理视图有安装、部署、升级、运维的需求，逻辑视图有功能需求，处理视图有非功能里的用户运行质量需求，开发视图有团队的开发质量需求。</p></li><li><p>分布式系统的基础理论：CAP/PACELC、BASE、ACID、2PC、3PC、PAXOS、RAFT</p></li><li><p>分布式系统的基础数据结构：Array、List、Map、Hash、Tree，及其变种</p></li><li><p>分布式系统的基础算法：负载均衡算法（一致性hash算法、分区分配算法）、选主算法、心跳算法、集群视图变更算法、幂等算法、复制算法、缓存MESI算法</p></li><li><p>分布式系统的基础组件：服务提供(Restful接口,SQL接口,自然语言接口)、服务注册(zookeeper,etcd,consul,etc)、服务配置(zookeeper,etcd, consul,etc)、服务调用(brpc,netty,etc)、服务路由(一致性Hash算法、分区分配算法)、服务追踪（zipkin,pinpoint,skywalking,cat,etc）、服务监控(Metrics)、服务治理(容错、降级、限流、熔断、隔板)、服务编排（k8s、docker）、服务安全(keycloak,etc)</p></li><li><p>分布式系统的质量指标：性能指标：TPS、QPS、IOPS、Latency、ResponseTime、缓存抖动指标、缓存命中指标，可靠性指标: 6个9企业级代表，可用性指标：6个9企业级达标，数据一致性指标，可伸缩性，韧性，可观测性，可服务性，安全性，易用性，可运维性，可测试性，可维护性，可扩展性，可读性等，质量指标要能可度量化，可执行化</p></li><li><p>分布式系统的约束边界：其可以是资源容量约束：CPU、磁盘、网络、线程、文件描述符个数，也可以是客户的约束、用户的约束以及团队的约束</p></li></ul><h4 id="器：工具，架构设计用的工具"><a href="#器：工具，架构设计用的工具" class="headerlink" title=" 器：工具，架构设计用的工具"></a><font color="#00CED1"> 器：工具，架构设计用的工具</font></h4><p>”器“是工具，是架构设计用的工具，”工欲善其事必先利其器“，常用的架构设计制图工具有MS Visio、Draw.io，UML制图用的Enterprise Architect、starUML等，当然组织提供的资源支持也可以算是工具之一。</p><h4 id="界：是边界，是架构的约束"><a href="#界：是边界，是架构的约束" class="headerlink" title=" 界：是边界，是架构的约束"></a><font color="#00CED1"> 界：是边界，是架构的约束</font></h4><p>”界“是边界，是架构的约束限制，火箭架构思维模型里的三角形的三条边代表着“界” ，是技术边界、也是技术约束与技术限制，也是架构的取舍因素之一，是架构能做什麽不能做什麽的解读，对市场来说它是技术壁垒，对产品来说它是法律法规、是功能约束，对团队来说它是资源约束、是自我能力约束。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font color="#FF8C00">小结</font></h2><p>本文讲述了分布式系统的架构思维模型，其目的希望以此架构思维模型应用于各种领域的分布式架构系统设计。日拱一卒，功不唐捐，分享是最好的学习，与其跟随不如创新，希望这个知识点对大家有用。另作者能力与认知都有限，”我讲的，可能都是错的“，欢迎大家拍砖留念。</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中科大硕，DELL EMC 资深首席工程师，曾就职于Marvell、AMD，主要从事Linux内核以及分布式产品的交付、架构设计以及开发工作。</p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>分布式系统架构设计36式 – 第0式 - 设计总决</title>
      <link href="/2020/02/15/distributed-general-principles/"/>
      <url>/2020/02/15/distributed-general-principles/</url>
      
        <content type="html"><![CDATA[<h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a><font color="#FF8C00">动机</font></h2><p>在<strong>“不易、简易、变易”</strong>这三个范畴里，技术是属于“变易”范畴的，其千变万化；“方法论”是属于“简易”范畴的，其具有领域普适性的指导能力；而架构设计总决属于“不易”的范畴，其具有第一性原理的本质指导能力。本文的目的之一即是挖掘出分布式系统架构设计的第一性原理，使其可以应用于千变万化的不同的技术领域。</p><p>架构是由人设计出来的，其与设计的人的架构理念强相关，欲彻底了解一个产品的架构必须要能量化它的设计理念，从而才能更好的由现象到本质了解一个技术，因此本文的目的之二即是量化人的架构设计理念。</p><h2 id="分布式系统"><a href="#分布式系统" class="headerlink" title="分布式系统"></a><font color="#FF8C00">分布式系统</font></h2><p>软件设计的第一性原理是“定义问题，分析问题，过滤问题以及解决问题。”，其最重要的第一步是“定义问题”，问题定义的准确与否直接决定了后面的分析问题，过滤问题以及解决问题的方向与准确性。那么，什么是分布式系统？各种论文以及书籍都有过自己的定义，比如《分布式系统原理与范型》定义分布式系统为：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs undefined">分布式系统是若干独立计算机的集合，这计算机对用户来说就像单个相关系统。<br></code></pre></td></tr></table></figure><p>还有Google出来的定义：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs undefined">A distributed system is a system whose components are located on different networked computers, which communicate and coordinate their actions by passing messages to one another. The components interact with one another in order to achieve a common goal.<br>分布式系统是一个组件分布在不同的联网的计算机上，彼此之间仅仅通过消息传递进行通信和协调的系统，这些组件相互交互以实现一个共同的目标。<br></code></pre></td></tr></table></figure><p>这是分布式系统理论的第一性原理，不同于这些从理论角度的定义，这里，我从工程实现的角度给分布式系统一个新的定义，即：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs undefined">分布式系统是面向集群状态的编程, 它是抽象、分层、解耦、拆分、聚合、治理、取舍、模型、演化、质量、边界思维的创造性应用，其要交付的是功能价值，但功夫却体现在非功能。<br></code></pre></td></tr></table></figure><p>从工程的角度来看，这个定义是分布式系统实践的第一性原理，分布式系统都是围绕着集群状态表来进行编程的，集群状态表是分布式系统的核心功能中的核心。因此本系列分布式系统文章都是依据理论结合实践的原则，从工程交付的角度来看待分布式系统的。</p><h2 id="设计哲学"><a href="#设计哲学" class="headerlink" title="设计哲学"></a><font color="#FF8C00">设计哲学</font></h2><p>什么是分布式系统的设计哲学？首先这里的设计哲学不是产品的设计哲学，它是一种工程哲学，是分布式系统架构设计原则以及设计方法论的指导思想，是架构师的内功。其目的是为了指导架构设计的过程，克服架构设计难题从而达到最终的架构设计目标。不同的架构师有自己不同的设计哲学观，这里我提出分布式系统架构设计哲学9式，即：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs undefined">抽象 分层  解耦 拆分 聚合 治理 模型 取舍 质量、边界 演化<br></code></pre></td></tr></table></figure><p>这9个词每个词展开来讲都可以是一篇大论，不同的架构设计师有自己不同的设计哲学观，也就形成了不同的架构设计原则以及设计方法论，并不存在一个普适的、统一的架构设计哲学，适合自己的才是最好的，每个人的领悟不同，因此这里也就不展开来讲。</p><h2 id="设计原则"><a href="#设计原则" class="headerlink" title="设计原则"></a><font color="#FF8C00">设计原则</font></h2><p>同设计哲学一样，不同的架构设计师有着自己不同的设计原则观，在这里，我认为最合适的分布式系统的架构设计原则有二，即：</p><ul><li><strong>最佳物种原则</strong></li><li><strong>功能非功能原则</strong></li></ul><h4 id="最佳物种原则"><a href="#最佳物种原则" class="headerlink" title=" 最佳物种原则"></a><font color="#00CED1"> 最佳物种原则</font></h4><p>最佳物种原则其来源是生物的物种进化理论，讲的是产品原则，其可以一分为二：</p><p>1，最佳原则，做产品架构设计的时候要挖掘不同的业务特性以及其业务本质，从而设计出与业务最为匹配的架构。天上飞的是鸟儿，地上奔跑的是走兽，水里游的是鱼儿。架构设计由大及小，由外及内也是如此。比如计算用的是分布式计算、存储用的是分布式存储，调度用的是分布式调度，其负责的领域各不相同，不存在一个全能的分布式中间件可以最佳的完成计算、存储、调度三合一的功能。从小处来讲也是如此，比如分布式系统内部的注册、路由、成员管理、服务提供、复制、安全、算法模型、存储等各有其自己最佳的设计方案，再依据这些最佳组件、最佳方案组合出一个最佳分布式中间件，从而计算的归计算、存储的归存储、调度的归调度。</p><p>2，进化原则，万物由微而显，由简而繁，物竞天择，优胜劣汰，好的架构是根据业务演化而来，而不是一开始就完美的设计好的。但是不管是微还是显，其最本质的功能还是不变的，一个产品从POC到MVP再到企业级达标其最核心的功能是不变的，比如计算、存储与调度。</p><h4 id="功能非功能原则"><a href="#功能非功能原则" class="headerlink" title=" 功能非功能原则"></a><font color="#00CED1"> 功能非功能原则</font></h4><p>功能非功能原则，讲的是技术原则，<strong>架构的目的是提供该领域的功能，然而功夫却是体现在非功能。</strong>比如常见的几个深度学习框架在功能上都具有深度学习训练与推理的能力，但是让用户决定是否选择这个框架的主要决定性因素却体现在其非功能，比如性能、可用性、可靠性、易用性、服务支持以及版权等。</p><p>从大体上来说，分布式系统的架构设计都是围绕其功能与非功能的<strong>量化</strong>设计来进行的，非功能又可以一分为二，即：质量与约束，比如：</p><p>客户对产品质量的需求一般可以用四个字概括，即”多、快、好、省“，然而客户在产品交付的时间、质量与成本上的取舍，客户原来遗留的系统，当前国家的法律法规，市场上的技术趋势以及竞争对手与行业标准等都属于当前客户需要考虑的约束条件。</p><p>用户的产品质量需求一般称为使用质量需求，其一般包括：合适的性能（Performant）、可用性(Availability)、可靠性(Reliability)、可伸缩性(Scalability)、韧性(resilience)、可观测性(Observability)、可服务性（Serviceability）、安全性（security）、易用性（usability）、可运维性（operability）等，而用户的约束需求包括 用户的业务环境、用户的能力以及用户群的特征等。</p><p>团队的质量需求指的是产品开发周期内的质量需求，高质量的代码几个最重要的要素有：可测试性（ testability）、可维护性（Maintainability）、可扩展性（ extensibility）、可读性（ readability）等，而团队的约束需求有：资源预算、上级要求、开发团队的能力、产品规划、此外还有信息安全以及产品运行环境 的约束等。</p><h2 id="设计方法论"><a href="#设计方法论" class="headerlink" title="设计方法论"></a><font color="#FF8C00">设计方法论</font></h2><p>同设计哲学与设计原则一样，不同的架构设计师有着自己不同的设计方法论，在这里，我认为分布式系统的架构设计方法论可以总结成以下口诀，即<strong>分布式9法10功能口诀</strong>，如下：</p><h4 id="分布式9法："><a href="#分布式9法：" class="headerlink" title="分布式9法："></a>分布式9法：</h4><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs undefined">少读少写少依赖<br>业务拆业务合<br>功能拆性能聚<br>时空换同异换<br>硬件顺天性<br>服务需治理<br>数据保一致<br>哪都不可靠<br>事事慎权衡<br></code></pre></td></tr></table></figure><h4 id="分布式10项"><a href="#分布式10项" class="headerlink" title="分布式10项:"></a>分布式10项:</h4><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs undefined">提供 注册 配置 调用 路由<br>观测 治理 编排 质量 边界<br></code></pre></td></tr></table></figure><p>在分布式系统里几乎所有的功能与设计思路都可以用这个<strong>“9法10项”</strong>口诀来解读，例如：</p><p>1，“业务拆业务合”，其理论依据来源于“康威定律”，即：</p><blockquote><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs undefined">&gt; 设计系统的组织其产生的设计等价于组织间的沟通结构。<br>&gt;<br></code></pre></td></tr></table></figure></blockquote><p>软件架构的拆合关系来源于团队的组织结构。</p><p>2，“功能拆性能聚”，在分布式系统里有拆有合，那么拆与合的取舍依据在哪里？这句话讲的就是这个拆与合的取舍关系：依据功能进行拆分，但是也要依据性能进行聚合，拆开后会影响性能的地方最好不拆。</p><p>3，“时空换同异换”， 讲的是性能优化的路数，解读开来说即是：时间换空间、空间换时间、同步换异步、异步换同步。例如：采用cache的功能可以减少计算的时间，这是存储空间换时间从而提升性能；采用批处理的方式提升性能，这是减少计算时间；采用异步换同步的方式提升性能也是减少计算时间；减少IO的数据量从而提升性能，这是存储空间换时间；减少IO路径提升性能，这也是网络空间换时间；采用最新的硬件提升性能，这可以是计算换时间，也可以是存储或网络空间换时间。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font color="#FF8C00">小结</font></h2><p>本文讲述了分布式系统架构设计总决，其可分为设计哲学、设计原则以及设计方法论，从而可以依据这三个方面量化人的设计理念。日拱一卒，功不唐捐，分享是最好的学习，与其跟随不如创新，希望这个知识点对大家有用。另作者能力与认知都有限，”我讲的，可能都是错的“，欢迎大家拍砖留念。</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中科大硕，DELL EMC 资深首席工程师，曾就职于Marvell、AMD，主要从事Linux内核以及分布式产品的交付、架构设计以及开发工作。</p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>分布式系统架构设计36式 – 第13式 - toB产品交付之双轮驱动思维模型</title>
      <link href="/2020/01/21/distributed-ideamodel-cicd-toowheel/"/>
      <url>/2020/01/21/distributed-ideamodel-cicd-toowheel/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a><font color="#FF8C00">前言</font></h2><p>日拱一卒，功不唐捐，一个知识领域里的 “道 法 术 器” 这四个境界需要从 微观、中观以及宏观 三个角度来把握。微观是实践，中观讲套路，宏观靠领悟。本系列文章我把它命名为《分布式系统架构设计36式》，讲诉分布式系统里最重要的三十六个的中观套路，而微服务的本质也是分布式，因此搞明白这三十六个最重要的知识点也就同时能搞明白微服务。</p><p><strong>“兵者，国之大事，死生之地，存亡之道，不可不察也”</strong>，这句话对企业来讲，兵即产品，国即企业，察即研究探讨，产品关系到企业的存亡，所以不可以不慎重地加以研究探讨。本文提出toB产品交付双轮驱动思维模型以探讨toB软件产品的交付方法论。</p><h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a><font color="#FF8C00">动机</font></h2><p>架构设计人员是业务与技术之间的桥梁，其既需要保证产品需求合理，也要保证产品交付的功能是对客户、用户有用、有价值的。为了能够准确的落地业务需求同时又能保证产品按时交付，架构设计人员就需要一个可以量化执行的产品业务需求与产品交付的思维模型。</p><h2 id="双轮驱动思维模型"><a href="#双轮驱动思维模型" class="headerlink" title="双轮驱动思维模型"></a><font color="#FF8C00">双轮驱动思维模型</font></h2><p>受 《持续交付2.0》的启发这里提出toB产品交付之双轮驱动思维模型。双轮驱动思维模型以业务需求为出发点，探索业务真实有用的价值，以最节约的成本和最可控的风险，通过持续的业务价值探索和产品迭代交付快速交付价值与市场锲合的产品，其思维模型如下图所示：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/ideamodel/idea-model-cicd-twoWheel.PNG" alt="双轮驱动模型"></p><h4 id="总则"><a href="#总则" class="headerlink" title="总则"></a><font color="#00CED1">总则</font></h4><p>产品的交付的是价值，因此双轮驱动思维模型是一个产品价值交付模型，总的理念是以“真北业务价值”为导向，以“产品快速交付”为动力，将“业务价值”与“产品交付”双个环节紧密结合，前轮业务价值把握方向，后轮产品交付提供动力，从而驱动业务与产品一起前进。它以“产品价值与市场锲合”为指导思想，以“以客户为中心”为工作理念，以“指北需求”，“精简过滤”、“量化分解”、“快速反馈”和“演化迭代”为工作原则，是一套持续集成持续交付产品的思维模型。</p><ul><li><p><strong>产品价值与市场锲合</strong>，指的是客户需要什么以及你能提供什么的从而获得产品商业成功的问题。朴素的说法就是产品的价值是市场需要的，是客户的痛点、恐惧点、难点以及挑战点，是客户要什么你就给什么，而不是从自己的角度出发，自我感觉良好地强塞给客户什么，是自身提供的产品能否准确满足市场真实需求的问题，度量的指标是<strong>”客户是否愿意快速的为你的产品买单“</strong>。</p></li><li><p><strong>以客户为中心</strong>，指的是“以客户需求为导向、为客户提供高质量低价格的产品、为客户提供满意的服务以及快速响应客户需求”，以客户为中心不是没有底线的跪添客户或者一些违法的行为，而是走正道为客户提供优质低价的产品或服务，快速响应客户的需求，帮助客户取得商业上的成功的问题。</p></li><li><p><strong>“指北需求”，“精简过滤”、“量化分解”、“快速反馈”和“演化迭代”</strong>，指的是挖掘客户的真需求，需要对客户的需求精简过滤、去伪存真，再通过量化分解客户的需求为可落地执行的行为，这样才能快速交付产品、快速验证、迭代演进。</p></li></ul><h4 id="价值轮"><a href="#价值轮" class="headerlink" title=" 价值轮 "></a><font color="#00CED1"> 价值轮 </font></h4><p>价值轮是一个理解真北需求、去伪存真的过程，具体包括以下四个环节：</p><ul><li><p>需求：通过”客户、用户、团队“三个维度收集需求，将收集到的业务需求信息输入到价值轮；</p></li><li><p>确定：针对输入的需求去伪存真、去粗存精确定真北需求，识别客户的痛点、难点、恐惧点以及挑战点；</p></li><li><p>探讨：团队讨论，深入理解需求，拿出可行的解决方案以及实现方案；</p></li><li><p>精炼：为了节约团队资源，不是所有的方案都需要传递给产品交付环去执行，因此需要精炼过滤这些方案，有些通过常识就可以判断不合理的方案就不需要往交付轮传递，其次要进行价值优先级评估，筛选出最有价值的需求与方案，以作为交付轮的输入，并等待交付轮的交付与反馈。</p></li></ul><h4 id="交付轮"><a href="#交付轮" class="headerlink" title="交付轮"></a><font color="#00CED1">交付轮</font></h4><p>产品或服务在被客户买单之前都是成本，只有被客户采购并且最终能够买单或者被用户使用并且最终兑现，才能证明其价值的存在。因此在价值轮达成共识后要借助“交付轮”快速交付，才能将其传递到客户或用户手中，从而得到真实且可靠的反馈以验证之。</p><p>交付轮它也包含四个环节，分别是（1）开发；（2）测试；（3）运维；（4）反馈：</p><ul><li><p>开发：指以及价值轮的输入需求以及精简过的方案，依据质量要求进行软件架构设计以及进行软件开发并且达到可运行要求；</p></li><li><p>测试：指的是测试以及验证设计开发阶段交付的软件是否达到功能、质量与约束的要求；</p></li><li><p>运维：指的是将开发以及测试好的软件包部署到生产环境中运行或交付给客户为客户提供生产服务；</p></li><li><p>反馈：指的是监测生产运行情况以及收集用户使用情况与反馈的信息，再将收集到的信息反馈给价值轮，作为业务参考以便做出下一步的业务决策与判断。</p></li></ul><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font color="#FF8C00">小结</font></h2><p>本文讲述”toB产品交付双轮驱动思维模型“，日拱一卒，功不唐捐，分享是最好的学习，与其跟随不如创新，希望这几个思维模型对大家有用。另作者能力与认知都有限，”我讲的，可能都是错的“[1]，欢迎大家拍砖留念。</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中科大硕，DELL EMC 资深首席工程师，主要从事分布式产品的交付、架构设计以及开发工作。</p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a><font color="#FF8C00">参考资料</font></h2><p>[1]《持续交付2.0 - 业务引领的DevOps精要》 乔梁著</p>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>分布式计算中间件 - 信息分析基础</title>
      <link href="/2019/12/21/distributed-product-info-analysis-basic-knowledge/"/>
      <url>/2019/12/21/distributed-product-info-analysis-basic-knowledge/</url>
      
        <content type="html"><![CDATA[<h3 id="分布式计算中间件之信息分析基础"><a href="#分布式计算中间件之信息分析基础" class="headerlink" title="分布式计算中间件之信息分析基础"></a><font color="#FF8C00">分布式计算中间件之信息分析基础</font></h3><h4 id="构建与领域设计"><a href="#构建与领域设计" class="headerlink" title="构建与领域设计"></a><font color="#00CED1">构建与领域设计</font></h4><p>通常分布式计算中间件可以从两个层面进行划分：</p><p>1，构建与运维 ： 分布式功能的设计与实现</p><p>2，领域设计 ： 具体领域相关功能的设计与实现</p><ul><li>数据计算与分析中间件，实现数据计算与分析领域功能，比如 Flink, Spark, elasticsearch等</li><li>深度学习计算中间件， 实现深度学习领域功能，比如 tensorflow, caffe等；</li></ul><h4 id="信息分析基础"><a href="#信息分析基础" class="headerlink" title="信息分析基础"></a><font color="#00CED1">信息分析基础</font></h4><p>信息分析基础：下图从功能，质量、模型、定义、本质、视角、职责、相关性、难题以及Lucene 等方面归纳了检索与分析技术领域基础10项。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/analysis/distributed-infomation-analysis-basic-knowledge.PNG" alt="信息检索模型"></p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中科大硕，DELL EMC 资深首席工程师，主要从事分布式产品的交付、架构设计以及开发工作。</p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a><font color="#FF8C00">参考资料</font></h2><p>[1]《信息检索导论》 </p>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>分布式系统架构设计36式之思维模型 – 第12式- 需求分析思维模型</title>
      <link href="/2019/12/21/distributed-ideamodel-requirement/"/>
      <url>/2019/12/21/distributed-ideamodel-requirement/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a><font color="#FF8C00">前言</font></h2><p>日拱一卒，功不唐捐，一个知识领域里的 “道 法 术 器” 这四个境界需要从 微观、中观以及宏观 三个角度来把握。微观是实践，中观讲套路，宏观靠领悟。本系列文章我把它命名为《分布式系统架构设计36式》，讲诉分布式系统里最重要的三十六个的中观套路，而微服务的本质也是分布式，因此搞明白这三十六个最重要的知识点也就同时能搞明白微服务。</p><p>实现一个分布式系统通常会面临只见“点与线”而不见“面与体”的难题 。本系列中的思维模型章节主要是为了解决分布式系统设计中的“面与体”的难题，它包括：需求分析思维模型、 技术思维模型、产品思维模型、创新思维模型以及商业思维模型，依据这些模型往上套就可以从“点、线、面、体”这四个层面系统性的设计一个分布式系统。</p><p>如果说技术是分布式系统工程师的一根DNA螺旋线，那么“产品、创新、商业”等就是DNA的另外一根螺旋线，只有两根螺旋线俱全并且不停的演化才能进化出新物种，本文将讲述思维模型里的 “需求分析思维” 模型。</p><h2 id="需求分析思维模型"><a href="#需求分析思维模型" class="headerlink" title="需求分析思维模型"></a><font color="#FF8C00">需求分析思维模型</font></h2><p>架构师是业务需求与产品落地之间的桥梁，因此准确地理解业务需求也是架构师必备的一个基本能力，准确地理解业务需求需要从理解业务愿景、策略与执行以及软件需求开始。理解业务愿景需要理清楚业务目标与产品的技术目标，理解策略与执行需要看清楚企业的战略方针、团队定位以及执行方法论，再次才是理解软件的产品需求。</p><h4 id="业务愿景"><a href="#业务愿景" class="headerlink" title=" 业务愿景"></a><font color="#00CED1"> 业务愿景</font></h4><p>1，业务目标</p><p>业务目标是很粗略的业务描述，比如需要提供物联网数据的存储服务或者比如给深度学习框架提供专门的训练芯片等.</p><p>2，技术目标</p><p>技术目标分为功能目标与非功能目标，功能目标是跟业务需求强相关的软件功能需求，比如提供原生的时序数据存储功能，还比如分布式计算功能。非功能目标可以分为质量目标与约束目标，比如性能质量、可用质量以及系统硬件规格约束等，对于产品来说质量与约束都需要可度量化、可验证化。</p><h4 id="策略与执行"><a href="#策略与执行" class="headerlink" title=" 策略与执行"></a><font color="#00CED1"> 策略与执行</font></h4><p>1, 战略方针</p><p>产品的战略意味着方向、资源以及取舍，方针是如何打造出这么一款产品的策略，一开始从全方位复制再处处差异化竞争也是一个思路，比如全面复制市场上已有的产品，再从产品、技术、销售、服务、运营、客户定位等方面处处差异化竞争。</p><p>2, 团队定位</p><p>团队文化即产品文化，打造一款产品需要一个团队，组织文化也深刻的影响着产品，团队不同意味着不同。国内一些企业团队复制国外产品的时候，往往有其形而无其神，原因之一往往是团队定位以及企业文化的不同。</p><p>通常来讲团队可以用四种类型来类比：海盗、特种兵、军队以及警察。海盗团队求生存，特种作战团队求根据地，军队团队求统一全国，警察团队求维稳。采用不愁吃喝的警察维稳的思路开发一款新产品又怎么能跟需要打下根据地的特种作战部队一样呢，跟需要求生存的海盗部队更不一样。</p><p>3, 执行策略</p><p>执行策略是指产品落地的方法论，持续交付2.0的方法论就很类似火箭思维，采用火箭思维意味着先开工再在过程中矫正，先确保大方向正确，开工过程中矫正直至准确命中目标。</p><h4 id="软件需求"><a href="#软件需求" class="headerlink" title=" 软件需求"></a><font color="#00CED1"> 软件需求</font></h4><p>架构师需要能准确理解业务愿景、产品策略，将抽象的愿景、目标、策略等分解成可量化的、可执行的具体任务，从而准确实现业务到产品的落地。</p><p>从业务到产品的过程中，能够准确的理解业务的软件需求也是一个非常重要的思维能力，这样可以保证大方向的正确性，这里提出一种从业务到产品的需求分析模型，以准确的理解软件需求，从而保证软件产品的落地方向的准确性。这里我提出一个公式：</p><p><strong><font color="#00CE00">软件需求 = [客户，用户，团队] x [功能，质量，约束]</font></strong></p><p>依据这个公式我提出<strong><font color="#00CE00">“三三制需求分析思维模型”</font></strong>以抛砖引玉，如下图：</p><table><thead><tr><th style="text-align:center">需求分析</th><th style="text-align:center">功能</th><th style="text-align:center">质量</th><th style="text-align:center">约束</th></tr></thead><tbody><tr><td style="text-align:center">“大”客户</td><td style="text-align:center">业务目标</td><td style="text-align:center">多、快、好、省</td><td style="text-align:center">时间、质量、成本<br>遗留系统，法律法规<br>技术趋势，竞争对手<br>行业标准等</td></tr><tr><td style="text-align:center">“大”用户</td><td style="text-align:center">业务需求</td><td style="text-align:center">性能，可用性<br>可靠性，可伸缩性<br>可观测性，可运维性<br>易用性，安全性，韧性</td><td style="text-align:center">业务环境<br>用户能力<br>用户群特征</td></tr><tr><td style="text-align:center">“大”团队</td><td style="text-align:center">基本功能 ，核心功能 <br>增值功能 ，可有可无功能 <br>有害无益功能</td><td style="text-align:center">可扩展<br>可读性<br>可测试性<br>可维护性</td><td style="text-align:center">资源预算，上级要求<br>开发团队能力<br>产品规划，信息安全<br>运行环境</td></tr></tbody></table><h5 id="“大”客户"><a href="#“大”客户" class="headerlink" title="“大”客户"></a><font color="#00CE00">“大”客户</font></h5><p>这里的“大”字有两个层面的意思，首先是范围上的”大“，三三制模型里的客户不只是狭义上的产品的客户，还包括整个产品利益链上的客户，比如客户的客户，因此这里称之为 “大“客户。第二这里的”大“字是规模上的大，从商业的角度来看大订单客户理应获得更大的关注。</p><p><strong>功能</strong></p><p>客户关注的功能即为业务目标，比如获取商业上的成功、业务难点、恐惧点、挑战点以及压力点等。对架构师来说 “以客户为中心”导向的业务功能目标不只是提供“高质量、低成本、服务好、响应及时”的基本产品或服务需求，还包括帮助客户获取商业上的成功，帮助客户解决难点、痛点、恐惧点、挑战点以及压力点。</p><p><strong>质量</strong></p><p>客户对产品质量的需求一般可以用四个字概括，即”多、快、好、省“，当然从软件工程的角度来说，四个方面全满足是极其困难的，因此应该根据实际情况合理取舍，对客户的需求需要进行合理的”过滤“，去粗存精，去伪纯真。</p><p><strong>约束</strong></p><p>对于客户的需求只关注功能和质量而忽视约束也是不够全面的。客户在产品交付的时间、质量与成本上需要取舍，客户原来遗留的系统以及资产，当前国家的法律法规，市场上的技术趋势，以及竞争对手与行业标准等都属于当前需要考虑的约束需求。</p><h5 id="”大“用户"><a href="#”大“用户" class="headerlink" title="”大“用户"></a><font color="#00CE00">”大“用户</font></h5><p>这里的”大“用户的”大“字，也分为两个层面的意思，一是范围”大“，不只是当前产品的用户，还包括用户的用户以及整个产品使用链上的所有用户，二是规模”大“，主流用户的需求更应该第一时间满足，有限的资源应该在第一时间满足主流用户的需求。</p><p><strong>功能</strong></p><p> 功能需求指的是满足用户对业务的需求，用户需要什么就提供什么，而不是我有什么就非要给用户什么，以”用户“为中心的思路也是正确的。    </p><p><strong>质量</strong></p><p>用户的产品质量需求一般称为使用质量需求，可以从以下几个维度进行分析：</p><ul><li><p>合适的性能（Performant），性能指标一般包括 TPS,  QPS,  Latency, IOPS， response time等，这里用”合适的性能“作为表达，指的是性能合适即可、够用即可，高性能当然好，但是高性能也意味着更高的成本，有些场景高性能反而是一种浪费行为，性能需求需要理解业务场景适可而止；</p></li><li><p>可用性(Availability)，可用性指的是系统长时间可对外提供服务的能力，通常采用小数点后的9的个数作为度量指标，按照这种约定“五个九”等于0.99999（或99.999％）的可用性，默认企业级达标的可用性为6个9。但是当前从时间维度来度量可用性已经没有太大的意义，因为设计得好的系统可以在系统出现故障得情况下也能保证对外提供得服务不中断，因此，当前更合适得可用性度量指标 是请求失败率；</p></li><li><p>可靠性(Reliability)，可靠性一般指系统在一定时间内、在一定条件下可以无故障地执行指定功能的能力或可能性， 也是采用小数点后的9的个数作为度量指标，通常5个9的可靠性就可以满足企业级达标；</p></li><li><p>可伸缩性(Scalability)，是指通过向系统添加资源来处理越来越多的工作并且维持高质量服务的能力；</p></li><li><p>韧性(resilience)，通常也叫容错性（fault-tolerant），也就是健壮和强壮的意思，指的是系统的对故障与异常的处理能力，比如在软件故障、硬件故障、认为故障这样的场景下，系统还能保持正常工作的能力；</p></li><li><p>可观测性(Observability)，是一种设计理念，包括告警、监控、日志与跟踪，可以实时地更深入地观测系统内部的工作状态；</p></li><li><p>安全性（security），指的是阻止非授权使用，阻止非法访问以及使用，保护合法用户的资产的能力；</p></li><li><p>易用性（usability），指的是软件的使用难易程度，对于产品的易用性来说，  易用性不仅仅 是软件使用角度的易用，还包括安装、部署、升级上的易用,升值还包括硬件层面的易用，比如产品的外观，形状等；</p></li><li><p>可运维性（operability），可运维性指的是运维人员对系统进行运维操作的难易程度，主要包含以下几个方面的难以程度： 系统的部署、升级、修改、监控以及告警等。</p></li></ul><p><strong>约束</strong></p><p>用户的约束需求包括 用户的业务环境，用户的能力以及用户群的特征等。</p><h5 id="”大“团队"><a href="#”大“团队" class="headerlink" title="”大“团队"></a><font color="#00CE00">”大“团队</font></h5><p>这里的大团队的”大“指的是范围上的大，不只是直接开发人员，还包括跨职级、跨部门的利益相关人员。</p><p><strong>功能</strong></p><p>软件功能需求从产品的角度来说可以分为五种，即：</p><ul><li>基本功能，这是在产品概念阶段就必须实现的功能也是在产品的第一个发布版本中必须提供的功能，比如数据处理产品的”读与写“；</li><li><p>核心功能，核心功能是产品的主要功能，扩展了基本功能的外延，比如为了保证性能达标的缓存功能、分布式功能等；</p></li><li><p>增值功能，这里指的是一些产品差异化的能力，比如安全、监控、告警、日志、升级、部署等；</p></li><li><p>可有可无功能，有些特性存在还是不存在不影响产品的使用也不会带来产品的优势，只起到锦上添花的作用，因此属于可有可无的功能；</p></li><li>有害无益功能，指的一些功能不只没用还有害，没有识别出来消耗了团队资源不说还对产品有拉后腿的作用。</li></ul><p><strong>质量</strong></p><p>团队的质量需求，指的是产品开发周期内的质量需求，高质量的代码几个最重要的要素有：</p><ul><li><p>可测试性（ testability），指的是单元测试，集成测试，打桩测试等的难易；</p></li><li><p>可维护性（Maintainability）， 指的是代码升级，部署，定位bug，添加功能的难易；</p></li><li><p>可扩展性（ extensibility）， 指的是未来增加新的功能与模块的难易；</p></li><li><p>可读性（ readability），指的是代码的易理解程度。</p></li></ul><p><strong>约束</strong></p><p>几个中药得团队的约束需求有：</p><ul><li><p>资源预算，产品的质量与功能以及发布周期受限于预算；</p></li><li><p>上级要求，上级的要求相当于客户要求也是非常重要的约束条件；</p></li><li><p>开发团队的能力，开发团队的能力组成、知识结构组成决定了产品是否能够交付以及能否高质量的交付；</p></li><li><p>产品规划，产品规划得进度是产品的交付周期以及开发进度得约束条件；</p></li><li><p>此外还有信息安全以及产品运行环境 的约束。</p></li></ul><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font color="#FF8C00">小结</font></h2><p>本系列文章讲述了五个思维模型： “需求分析思维模型、技术思维模型、创新思维模型、商业思维模型以及产品思维模型”，再结合分布式流存储做了简单的举例分析。本文讲述”需求思维模型“，日拱一卒，功不唐捐，分享是最好的学习，与其跟随不如创新，希望这几个思维模型对大家有用。另作者能力与认知都有限，”我讲的，可能都是错的“[1]，欢迎大家拍砖留念。</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中科大硕，DELL EMC 资深首席工程师，主要从事分布式产品的交付、架构设计以及开发工作。</p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a><font color="#FF8C00">参考资料</font></h2><p>[1]《软件架构设计》 温昱著</p>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>进EMC马上两年，里程碑两件</title>
      <link href="/2019/12/21/person-emc-codeline-and-awarded/"/>
      <url>/2019/12/21/person-emc-codeline-and-awarded/</url>
      
        <content type="html"><![CDATA[<p>进EMC马上两年，12月份里程碑两件。</p><p>一是硬技能，项目里个人提交的代码突破6万行，产品第一个版本月底发布；</p><p>二是软技能，专利公司内过审3个，写文章推广产品以及提升团队的技术影响力获得公司副总裁认可给了个奖。</p><h2 id="代码行数突破6万行"><a href="#代码行数突破6万行" class="headerlink" title="代码行数突破6万行"></a>代码行数突破6万行</h2><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/person/emc-20191220-codeline.png" alt="codeline"></p><h4 id="专利过三"><a href="#专利过三" class="headerlink" title="专利过三"></a>专利过三</h4><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/person/emc-2019-patent-1.PNG" alt="patent"></p><h4 id="GEEK-BANG-技术文章活动奖"><a href="#GEEK-BANG-技术文章活动奖" class="headerlink" title="GEEK BANG 技术文章活动奖"></a>GEEK BANG 技术文章活动奖</h4><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/person/emc-201912-award-1.JPG" alt="award"></p>]]></content>
      
      
      <categories>
          
          <category> person </category>
          
      </categories>
      
      
        <tags>
            
            <tag> person </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>分布式系统架构设计36式之思维模型 – 第11式-产品思维模型</title>
      <link href="/2019/11/20/distributed-ideamodel-product/"/>
      <url>/2019/11/20/distributed-ideamodel-product/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a><font color="#FF8C00">前言</font></h2><font color="#FF8C00">注：本思维模型系列文章已被infoq采纳并推荐至首页：<a href="https://www.infoq.cn/article/JjycubQz3YTBgozaZ4G9" target="_blank" rel="noopener">https://www.infoq.cn/article/JjycubQz3YTBgozaZ4G9</a></font><p>日拱一卒，功不唐捐，一个知识领域里的 “道 法 术 器” 这四个境界需要从 微观、中观以及宏观 三个角度来把握。微观是实践，中观讲套路，宏观靠领悟。本系列文章我把它命名为《分布式系统架构设计36式》，讲诉分布式系统里最重要的三十六个的中观套路，而微服务的本质也是分布式，因此搞明白这三十六个最重要的知识点也就同时能搞明白微服务。</p><p><strong>“兵者，国之大事，死生之地，存亡之道，不可不察也”</strong>，这句话对企业来讲，兵即产品，国即企业，察即研究探讨，产品关系到企业的存亡，所以不可以不慎重地加以研究探讨。</p><p>我们知道一个产品的成功不只是技术的成功，它还包括商业、创新、管理、资本、运营以及销售等的成功。当打造一个产品的时候，通常来说工程人员往往会比较关注技术层面的东西： 方案、功能、难点、亮点以及如何实现等，深度有余但高度与广度往往不足 。一般有点经验的工程人员都可以从点或线的层面考虑一个产品的实现，但往往缺乏从面及体的层面看待一个产品的能力。</p><p>因此，如果说技术思维是架构师的一根DNA螺旋线，那么产品思维、创新思维以及商业思维等就是架构师的另外一根DNA螺旋线，只有两根DNA螺旋线俱全才能有机会进化出新物种。</p><h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a><font color="#FF8C00">动机</font></h2><p>人的知识与能力可以从“时空”这两个角度进行评价，其可分为四个维度：深度、广度、高度以及跨度。空间角度指的是深度、广度、高度，时间角度指的是跨度。深度靠专研，广度靠学习，高度靠抽象，而跨度靠长久地积累经验。这四个维度组合成了一个人的知识与能力的时空度。</p><p>万事万物逃脱不出<strong>“不易、简易、变易”</strong>这三个层次，金庸先生的《天龙八部》里少林寺有72技，其每一技又千变万化，想要样样精通，今生无望，然而练就“小无相功”却可以以这功法催动不同的“技”，甚至可以比原版更具威力，以“不易 简易”之功施展“变易”之术。那么对于技术开发人员来说技术也是“变易”的，更新快，领域多，复杂度高，样样精通也是今生无望，那么需要的就是找出适合自己的“功”，技术思维模型、产品思维模型、创新思维模型、商业思维模型就是这样的“功”。</p><p>因此本系列文章提出了技术、产品、创新与商业这四个思维模型，这一系列文章不是为了解决具体的某个分布式系统设计里的难题，它提出了一种思维框架，从技术、产品、创新以及商业的角度，给工程人员以一种系统性的分析分布式系统设计难题的模型，这也是一种系统思维的体现。</p><h2 id="产品思维模型"><a href="#产品思维模型" class="headerlink" title="产品思维模型"></a><font color="#FF8C00">产品思维模型</font></h2><p>最后一个思维模型是产品思维模型，它是以上三个思维模型的组合与新生，如下图：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/ideamodel/idea-model-product.PNG" alt="产品思维模型"></p><p>产品思维模型灵感来自于阿基米德的一句话:”给我一个支点,我可以撬起地球。“，因此定义它为阿基米德产品思维模型。</p><p>如上图所示，在产品思维模型里产品被看作是一个圆，在圆之外还有一个杠杆、一个支点以及一个作用力。在产品圆里除了技术火箭六元组、产品创新奇点、五看三定六要素之外还补充了 产品价值网，企业文化、企业制度以及组织结构这三个要素。</p><h4 id="价值网"><a href="#价值网" class="headerlink" title=" 价值网"></a><font color="#00CED1"> 价值网</font></h4><p>产品价值网指的是产品所在的市场，是产品需要去匹配的市场，也是产品的市场天花板，市场空间的大小意味着产品的增长局限性，它可以是10倍增长的、缓缓增长的或者存量市场等。一个自我快速膨胀的市场空间里往往可以事半功倍，比如2000年后的互联网市场。</p><p>价值网是产品所在的市场，通常采用三个指标来描述产品是否适合价值网：<font color="#00CED1">技术-产品匹配，产品-市场匹配以及价值-市场匹配</font>。</p><h5 id="技术-产品匹配（Technology-Product-Fit）"><a href="#技术-产品匹配（Technology-Product-Fit）" class="headerlink" title="技术-产品匹配（Technology-Product Fit）"></a><font color="#00CED1">技术-产品匹配（Technology-Product Fit）</font></h5><p>TPF这个概念是我新提出的，做工程不同做研究，工程当中技术取舍的关键在于适合即可，技术超前于产品是优势但是也是成本，技术落后于产品，缺乏创新，也容易被市场淘汰。技术于产品锲合度的度量在于满足客户需求即可，包括核心需求与增值需求。</p><h5 id="产品-市场匹配（Product-Market-Fit）"><a href="#产品-市场匹配（Product-Market-Fit）" class="headerlink" title="产品-市场匹配（Product-Market Fit）"></a><font color="#00CED1">产品-市场匹配（Product-Market Fit）</font></h5><p>产品-市场匹配的意思指的是产品确定是可以满足市场真正的需求的，并且产品可以从客户那边获取生存下来。</p><p>产品-市场匹配度的度量标准有： 客户的下载数量、客户付费数量、客户求购的数量、客户愿意付钱。</p><h5 id="价值-市场匹配（Value-Market-Fit）"><a href="#价值-市场匹配（Value-Market-Fit）" class="headerlink" title="价值-市场匹配（Value-Market Fit）"></a><font color="#00CED1">价值-市场匹配（Value-Market Fit）</font></h5><p>价值-市场匹配指的是产品所提供的价值是真正满足市场需求的，从软件的角度来说可以匹配的价值有：产品质量、性能、可扩展性、可靠性、可视化、安全、审计、辅助工具以及各种插件等。                                                                                                                                                                                                                                                                                                                </p><h4 id="企业文化、企业制度以及组织结构"><a href="#企业文化、企业制度以及组织结构" class="headerlink" title=" 企业文化、企业制度以及组织结构"></a><font color="#00CED1"> 企业文化、企业制度以及组织结构</font></h4><p>产品也是受企业文化、企业制度以及企业组织结构影响的，对于”这三要素如何影响产品？“这一主题没有研究过，这里不敢展开讲。但是可以确定的是“诚信 以人为本”的企业比“KPI导向 利益驱动”的企业更能出现优秀的作品。</p><h4 id="支点"><a href="#支点" class="headerlink" title=" 支点"></a><font color="#00CED1"> 支点</font></h4><p>支点即关键着力点，它是撬动产品的着力点，它也可以是”以客户为中心，为客户创造价值“的理念，也可以是关键资源、战略投入等，最适合自己的、自己最拿手的要素就是支点。</p><h4 id="杠杆"><a href="#杠杆" class="headerlink" title=" 杠杆"></a><font color="#00CED1"> 杠杆</font></h4><p>杠杆可以是创新，也可以是资本，是撬动产品从而获得10倍增长效应的关键要素，关键时刻需要对产品启动杠杆效应以获取大规模爆发机会。</p><h4 id="关键能力"><a href="#关键能力" class="headerlink" title=" 关键能力"></a><font color="#00CED1"> 关键能力</font></h4><p>一个企业的能力包括：技术，产品，渠道、市场、资源，资本，管理，运营，人力，销售，财务等，这里的关键能力，指的是最拿手的一个或几个能力， 选出最适合自己的， 比如技术领先的能力、打造产品的能力等，当然也可以认为是管理能力或财务能力，然后作为驱动产品的杠杆作用力。</p><p>分布式流存储所在的市场是物联网以及IT运维这样的高速增长市场，产品的支点是”以客户为中心，为客户创造价值“这样的理念，同时在关键能力上，团队组成、企业的存储基因等都是关键能力。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font color="#FF8C00">小结</font></h2><p>本系列文章讲述了四个思维模型： “技术思维模型、创新思维模型、商业思维模型以及产品思维模型”，再结合分布式流存储做了简单的举例分析。本文讲述”产品思维模型“，日拱一卒，功不唐捐，分享是最好的学习，与其跟随不如创新，希望这几个思维模型对大家有用。另作者能力与认知都有限，”我讲的，可能都是错的“[1]，欢迎大家拍砖留念。</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中科大硕，DELL EMC 资深首席工程师，主要从事分布式产品的交付、架构设计以及开发工作。</p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a><font color="#FF8C00">参考资料</font></h2><p>[1]《第二曲线创新》 李善友</p><p>[2]《如何在一分钟内用5个问题讲清你的商业模式》 中欧商业评论，关苏哲 </p><p>[3] Pravega.io</p>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>分布式系统架构设计36式之思维模型 – 第10式-商业思维模型</title>
      <link href="/2019/11/20/distributed-ideamodel-business/"/>
      <url>/2019/11/20/distributed-ideamodel-business/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a><font color="#FF8C00">前言</font></h2><font color="#FF8C00">注：本思维模型系列文章已被infoq采纳并推荐至首页：<a href="https://www.infoq.cn/article/JjycubQz3YTBgozaZ4G9" target="_blank" rel="noopener">https://www.infoq.cn/article/JjycubQz3YTBgozaZ4G9</a></font><p>日拱一卒，功不唐捐，一个知识领域里的 “道 法 术 器” 这四个境界需要从 微观、中观以及宏观 三个角度来把握。微观是实践，中观讲套路，宏观靠领悟。本系列文章我把它命名为《分布式系统架构设计36式》，讲诉分布式系统里最重要的三十六个的中观套路，而微服务的本质也是分布式，因此搞明白这三十六个最重要的知识点也就同时能搞明白微服务。</p><p><strong>“兵者，国之大事，死生之地，存亡之道，不可不察也”</strong>，这句话对企业来讲，兵即产品，国即企业，察即研究探讨，产品关系到企业的存亡，所以不可以不慎重地加以研究探讨。</p><p>我们知道一个产品的成功不只是技术的成功，它还包括商业、创新、管理、资本、运营以及销售等的成功。当打造一个产品的时候，通常来说工程人员往往会比较关注技术层面的东西： 方案、功能、难点、亮点以及如何实现等，深度有余但高度与广度往往不足 。一般有点经验的工程人员都可以从点或线的层面考虑一个产品的实现，但往往缺乏从面及体的层面看待一个产品的能力。</p><p>因此，如果说技术思维是架构师的一根DNA螺旋线，那么产品思维、创新思维以及商业思维等就是架构师的另外一根DNA螺旋线，只有两根DNA螺旋线俱全才能有机会进化出新物种。</p><h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a><font color="#FF8C00">动机</font></h2><p>人的知识与能力可以从“时空”这两个角度进行评价，其可分为四个维度：深度、广度、高度以及跨度。空间角度指的是深度、广度、高度，时间角度指的是跨度。深度靠专研，广度靠学习，高度靠抽象，而跨度靠长久地积累经验。这四个维度组合成了一个人的知识与能力的时空度。</p><p>万事万物逃脱不出<strong>“不易、简易、变易”</strong>这三个层次，金庸先生的《天龙八部》里少林寺有72技，其每一技又千变万化，想要样样精通，今生无望，然而练就“小无相功”却可以以这功法催动不同的“技”，甚至可以比原版更具威力，以“不易 简易”之功施展“变易”之术。那么对于技术开发人员来说技术也是“变易”的，更新快，领域多，复杂度高，样样精通也是今生无望，那么需要的就是找出适合自己的“功”，技术思维模型、产品思维模型、创新思维模型、商业思维模型就是这样的“功”。</p><p>因此本系列文章提出了技术、产品、创新与商业这四个思维模型，这一系列文章不是为了解决具体的某个分布式系统设计里的难题，它提出了一种思维框架，从技术、产品、创新以及商业的角度，给工程人员以一种系统性的分析分布式系统设计难题的模型，这也是一种系统思维的体现。</p><h2 id="商业思维模型"><a href="#商业思维模型" class="headerlink" title="商业思维模型"></a><font color="#FF8C00">商业思维模型</font></h2><p>IBM有个商业战略思维模型叫做”五看三定“， 经过很多家企业的验证，表示效果很好。这里扩充”五看三定“思维模型为“五看三定六要素”思维模型，作为产品的商业模式思维模型。”五看三定六要素“即：五看：看趋势、看市场、看对手、看自己、看机会，三定：定目标、定策略、定执行，六要素：客户、产品、供给、盈利、创新及风险。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/ideamodel/idea-model-business.PNG" alt="商业思维模型"></p><h4 id="五看"><a href="#五看" class="headerlink" title=" 五看"></a><font color="#00CED1"> 五看</font></h4><p>1，五看，首先要看的是趋势，属于宏观的范畴，行业趋势、行业风向，国家政策，经济周期，技术趋势，资源方向等，从而判断出正确的资源投入方向；</p><p>2，接着看市场，看看市场需求在哪里？客户的真实需求在哪里？客户愿意买单的点在哪里？产品与市场的最佳适配点在哪里？从而输出正确的客户目标；</p><p>3，再看对手，可以从三个方面进行看对手：</p><ul><li><p>赚得到钱，如果有对手已经验证过了这个市场可以获取高额利润，那么就可以确定这个方向的正确性；</p></li><li><p>赚不到钱，如果对手正在介入的市场领域属于赚不到钱的领域，那么自己去做赚不到钱的概率也一样非常的大，现在新介入的话就需要非常非常的谨慎；- </p></li><li>没有对手，如果是一个没有对手的领域，要么是新开拓的市场空白机会，要么根本就是没有真实的客户需求的伪需求市场，这也是需要非常谨慎介入方向。</li></ul><p>4，看完对手就要看自己，看自己说的是，看看自己的优势在哪里，劣势在哪里，有什么关键资源能力，自己能做什么不能做什么，介入这个市场领域的话，对比其他对手有什么优势胜出，如果没有胜出优势就需要谨慎介入。</p><p>5，最后看机会，判断真机会的依据是：行业趋势正确，有真实的客户需求，对手有钱赚，自己团队有优势，那么这样的机会输出点就是”真机会“。</p><h4 id="三定"><a href="#三定" class="headerlink" title=" 三定"></a><font color="#00CED1"> 三定</font></h4><p>五看后就要三定，看好机会后，需要定目标，定策略以及定执行。</p><p>1，首先定好需要达到的市场目标，比如3年利润1个小目标（1亿￥）；</p><p>2，然后开始着手制定如何达到这个目标的策略，比如：1）分解这个目标，1年到什么阶段、2年到什么阶段、3年到什么阶段等；2）是先单点突破最佳盈利点，再以此为树干长出树枝？还是借助资源优势全面铺开？</p><p>3，再就是定执行，定策略是如何做的范畴，而定执行是让谁做，什么时候做出来的问题，属于生成资料、生成工具分配的范畴。</p><h4 id="六要素"><a href="#六要素" class="headerlink" title=" 六要素"></a><font color="#00CED1"> 六要素</font></h4><p>”五看三定“分析完后，更进一步需要进行商业模型六要素的分析[2]。</p><p>1，客户，客户指的是市场定位，是想赚谁的钱、不想赚谁的钱的问题，是客户是谁、又不是谁的问题，是客户如何取舍的问题。</p><p>2，产品，产品指的是打算用什么东西去赚钱，是卖产品还是卖服务，是提供的满客户需求的价值是什么又不是什么的问题。</p><p>3，供应，供应指的是如何生产出好产品以及怎么样把产品卖出去。如何打造与市场最佳适配的产品？如何保证技术与产品的最佳适配，如何交付出这样的好产品？然后又准备怎么把这样的产品卖出去？渠道在哪? 价格怎么定义？然后自己又有哪些强力的资源优势？这也是产品成败的一个非常关键的点。</p><p>4，盈利，盈利讲的是如何赚钱的问题，是做产品？还是做平台？或者做生态？然后又怎么保证可以持续地赚钱？做产品离钱近，一手交钱一手交货；做平台，投入大、但是空间也大；做生态，投入巨大、周期长，但是如果成了，那么收益也巨大。</p><p>5，创新，创新指的是以上四点如何创新，如何持续的创新，可以从寻找差异化入手，也可以从先同质化模仿再处处差异化创新入手，可以是 ”更好“，也可以是”不同“，还可以是”新生“。</p><p>6，风险，风险指的是风险管理，居安思危，失败风险是否在可承受的范围之内？以上五点的风险在哪里，方方面面是否都考虑周全？</p><p>依据以上近乎穷举的系统分析法，可以发现，为物联网以及IT运维市场专门设计一个存储系统是值得投入的一个机会点。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font color="#FF8C00">小结</font></h2><p>本系列文章讲述了四个思维模型： “技术思维模型、创新思维模型、商业思维模型以及产品思维模型”，再结合分布式流存储做了简单的举例分析。本文讲述”商业思维模型“，日拱一卒，功不唐捐，分享是最好的学习，与其跟随不如创新，希望这几个思维模型对大家有用。另作者能力与认知都有限，”我讲的，可能都是错的“[1]，欢迎大家拍砖留念。</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中科大硕，DELL EMC 资深首席工程师，主要从事分布式产品的交付、架构设计以及开发工作。</p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a><font color="#FF8C00">参考资料</font></h2><p>[1]《第二曲线创新》 李善友</p><p>[2]《如何在一分钟内用5个问题讲清你的商业模式》 中欧商业评论，关苏哲 </p><p>[3] Pravega.io</p>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>分布式系统架构设计36式之思维模型 – 第9式- 创新思维模型</title>
      <link href="/2019/11/20/distributed-ideamodel-innovation/"/>
      <url>/2019/11/20/distributed-ideamodel-innovation/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a><font color="#FF8C00">前言</font></h2><font color="#FF8C00">注：本思维模型系列文章已被infoq采纳并推荐至首页：<a href="https://www.infoq.cn/article/JjycubQz3YTBgozaZ4G9" target="_blank" rel="noopener">https://www.infoq.cn/article/JjycubQz3YTBgozaZ4G9</a></font><p>日拱一卒，功不唐捐，一个知识领域里的 “道 法 术 器” 这四个境界需要从 微观、中观以及宏观 三个角度来把握。微观是实践，中观讲套路，宏观靠领悟。本系列文章我把它命名为《分布式系统架构设计36式》，讲诉分布式系统里最重要的三十六个的中观套路，而微服务的本质也是分布式，因此搞明白这三十六个最重要的知识点也就同时能搞明白微服务。</p><p><strong>“兵者，国之大事，死生之地，存亡之道，不可不察也”</strong>，这句话对企业来讲，兵即产品，国即企业，察即研究探讨，产品关系到企业的存亡，所以不可以不慎重地加以研究探讨。</p><p>我们知道一个产品的成功不只是技术的成功，它还包括商业、创新、管理、资本、运营以及销售等的成功。当打造一个产品的时候，通常来说工程人员往往会比较关注技术层面的东西： 方案、功能、难点、亮点以及如何实现等，深度有余但高度与广度往往不足 。一般有点经验的工程人员都可以从点或线的层面考虑一个产品的实现，但往往缺乏从面及体的层面看待一个产品的能力。</p><p>因此，如果说技术思维是架构师的一根DNA螺旋线，那么产品思维、创新思维以及商业思维等就是架构师的另外一根DNA螺旋线，只有两根DNA螺旋线俱全才能有机会进化出新物种。</p><h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a><font color="#FF8C00">动机</font></h2><p>人的知识与能力可以从“时空”这两个角度进行评价，其可分为四个维度：深度、广度、高度以及跨度。空间角度指的是深度、广度、高度，时间角度指的是跨度。深度靠专研，广度靠学习，高度靠抽象，而跨度靠长久地积累经验。这四个维度组合成了一个人的知识与能力的时空度。</p><p>万事万物逃脱不出<strong>“不易、简易、变易”</strong>这三个层次，金庸先生的《天龙八部》里少林寺有72技，其每一技又千变万化，想要样样精通，今生无望，然而练就“小无相功”却可以以这功法催动不同的“技”，甚至可以比原版更具威力，以“不易 简易”之功施展“变易”之术。那么对于技术开发人员来说技术也是“变易”的，更新快，领域多，复杂度高，样样精通也是今生无望，那么需要的就是找出适合自己的“功”，技术思维模型、产品思维模型、创新思维模型、商业思维模型就是这样的“功”。</p><p>因此本系列文章提出了技术、产品、创新与商业这四个思维模型，这一系列文章不是为了解决具体的某个分布式系统设计里的难题，它提出了一种思维框架，从技术、产品、创新以及商业的角度，给工程人员以一种系统性的分析分布式系统设计难题的模型，这也是一种系统思维的体现。</p><h2 id="创新思维模型"><a href="#创新思维模型" class="headerlink" title="创新思维模型"></a><font color="#FF8C00">创新思维模型</font></h2><p>受李善友老师的《第二曲线创新》的启发，这里提出“奇点破界”创新思维模型，如下图：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/ideamodel/idea-model-creative.PNG" alt="创新思维模型"></p><h4 id="创新三重境：”更好、不同、新生“"><a href="#创新三重境：”更好、不同、新生“" class="headerlink" title=" 创新三重境：”更好、不同、新生“"></a><font color="#00CED1"> 创新三重境：”更好、不同、新生“</font></h4><ul><li><p><strong>更好，</strong>指的是市场是明确存在需求的，但是提供的新产品在质量、功能、渠道、价格等方面比原有产品更具优势，是用更好的体验来满足客户的真需求；</p></li><li><p><strong>不同，</strong>指的是差异化竞争，”与其更好不如不同”[1]，不同不只是技术面的不同，而是处处差异化不同，理念、技术、渠道，运营，销售等处处差异化竞争；</p></li><li><p><strong>新生，</strong>指的是 从0到1，从无到有的创造一个新物种，是指用凭空创造出一个新产品来满足客户需求，这种形态的产品要么是颠覆式的创造带来巨大的商业上的成功，要么就是没有真实客户需求的新事物，商业上完全失败。</p></li></ul><p>这里，分布式流存储采用的是“<strong>更好与不同”</strong>这两个产品创新方法论，组合原有的技术开拓出新产品，规避风险，满足客户真实的需求。</p><h4 id="奇点破界"><a href="#奇点破界" class="headerlink" title=" 奇点破界"></a><font color="#00CED1"> 奇点破界</font></h4><p>物理学认为宇宙从无到有始于一个点，这个点叫做“奇点”，它积聚了形成现有宇宙中所有物质的势能，当这一个点的能量平衡被破坏后，宇宙大爆炸发生，从而生成我们现在的宇宙。如果把宇宙比作我们的产品，奇点就是这个产品赖以出现与存在的关键点，“奇点破界”创新思维模型的理论依据是奇点创新三部曲：“破坏，外延，重生”，即：</p><p>1，破坏，找到产品奇点并加以破坏。产品缺点不是奇点，奇点是产品赖以出现与存在的点，找到它，然后破坏它，类似于使得宇宙奇点能量失去平衡；</p><p>2，外延，产品奇点下移，产品边界外延，类似于宇宙大爆炸从而造成宇宙边界外延；</p><p>3，重生，重构产品奇点，形成新的产品体系，类似于新宇宙的形成。</p><p>以分布式流存储的创新为例，这里只涉及技术面的创新，销售、渠道、运营、管理、商业模式等方面的创新不在本文范围。可以知道的是目前市面上的分布式流存储的最大竞争对手是Kafka，对其应用奇点创新思维模型的步骤有：</p><p>1， 破坏，找出产品奇点，然后破坏它的奇点。例如，我们知道Kafka的赖以依存的关键点有：提供消息服务语义；分布式的；依赖于代理中心的横向扩展以及依赖于分区的数据冗余；依据初代版本时间点的硬件特性进行软件的设计；</p><p>2，外延，产品奇点下移，破界，新的产品边界外延。针对以上Kafka的四条关键点，提出分布式流存储的新奇点：提供存储语义服务而不是消息语义；依据云原生、微服务的理念进行产品架构，扩展分布式系统外延；软件定义，抽象1层存储与2层存储，平衡高性能与无限扩容的问题；抓住技术进步的福利，依据当前最新的硬件特性进行产品软件设计；</p><p>3， 重生，最后更新的、更具有技术竞争力的、针对流式数据而实现的新产品”分布式流存储“诞生。</p><p>这一套创新思维模型的关键点在于找出原有的产品赖以出现以及存在的“奇点”，然后破界重生。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font color="#FF8C00">小结</font></h2><p>本系列文章讲述了四个思维模型： “技术思维模型、创新思维模型、商业思维模型以及产品思维模型”，再结合分布式流存储做了简单的举例分析。本文讲述”创新思维模型“，日拱一卒，功不唐捐，分享是最好的学习，与其跟随不如创新，希望这几个思维模型对大家有用。另作者能力与认知都有限，”我讲的，可能都是错的“[1]，欢迎大家拍砖留念。</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中科大硕，DELL EMC 资深首席工程师，主要从事分布式产品的交付、架构设计以及开发工作。</p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a><font color="#FF8C00">参考资料</font></h2><p>[1]《第二曲线创新》 李善友</p><p>[2]《如何在一分钟内用5个问题讲清你的商业模式》 中欧商业评论，关苏哲 </p><p>[3] Pravega.io</p>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>分布式系统架构设计36式之思维模型 – 第8式-技术思维模型</title>
      <link href="/2019/11/20/distributed-ideamodel-technology/"/>
      <url>/2019/11/20/distributed-ideamodel-technology/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a><font color="#FF8C00">前言</font></h2><font color="#FF8C00">注：本思维模型系列文章已被infoq采纳并推荐至首页：<a href="https://www.infoq.cn/article/JjycubQz3YTBgozaZ4G9" target="_blank" rel="noopener">https://www.infoq.cn/article/JjycubQz3YTBgozaZ4G9</a></font><p>日拱一卒，功不唐捐，一个知识领域里的 “道 法 术 器” 这四个境界需要从 微观、中观以及宏观 三个角度来把握。微观是实践，中观讲套路，宏观靠领悟。本系列文章我把它命名为《分布式系统架构设计36式》，讲诉分布式系统里最重要的三十六个的中观套路，而微服务的本质也是分布式，因此搞明白这三十六个最重要的知识点也就同时能搞明白微服务。</p><p><strong>“兵者，国之大事，死生之地，存亡之道，不可不察也”</strong>，这句话对企业来讲，兵即产品，国即企业，察即研究探讨，产品关系到企业的存亡，所以不可以不慎重地加以研究探讨。</p><p>我们知道一个产品的成功不只是技术的成功，它还包括商业、创新、管理、资本、运营以及销售等的成功。当打造一个产品的时候，通常来说工程人员往往会比较关注技术层面的东西： 方案、功能、难点、亮点以及如何实现等，深度有余但高度与广度往往不足 。一般有点经验的工程人员都可以从点或线的层面考虑一个产品的实现，但往往缺乏从面及体的层面看待一个产品的能力。</p><p>因此，如果说技术思维是架构师的一根DNA螺旋线，那么产品思维、创新思维以及商业思维等就是架构师的另外一根DNA螺旋线，只有两根DNA螺旋线俱全才能有机会进化出新物种。</p><h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a><font color="#FF8C00">动机</font></h2><p>人的知识与能力可以从“时空”这两个角度进行评价，其可分为四个维度：深度、广度、高度以及跨度。空间角度指的是深度、广度、高度，时间角度指的是跨度。深度靠专研，广度靠学习，高度靠抽象，而跨度靠长久地积累经验。这四个维度组合成了一个人的知识与能力的时空度。</p><p>万事万物逃脱不出<strong>“不易、简易、变易”</strong>这三个层次，金庸先生的《天龙八部》里少林寺有72技，其每一技又千变万化，想要样样精通，今生无望，然而练就“小无相功”却可以以这功法催动不同的“技”，甚至可以比原版更具威力，以“不易 简易”之功施展“变易”之术。那么对于技术开发人员来说技术也是“变易”的，更新快，领域多，复杂度高，样样精通也是今生无望，那么需要的就是找出适合自己的“功”，技术思维模型、产品思维模型、创新思维模型、商业思维模型就是这样的“功”。</p><p>因此本系列文章提出了技术、产品、创新与商业这四个思维模型，这一系列文章不是为了解决具体的某个分布式系统设计里的难题，它提出了一种思维框架，从技术、产品、创新以及商业的角度，给工程人员以一种系统性的分析分布式系统设计难题的模型，这也是一种系统思维的体现。</p><h2 id="技术思维模型"><a href="#技术思维模型" class="headerlink" title="技术思维模型"></a><font color="#FF8C00">技术思维模型</font></h2><p>技术思维模型很多，适合自己的才是最好的，这里提出“火箭技术思维模型”以抛砖引玉，如下图：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/ideamodel/idea-model-technology.PNG" alt="技术思维模型"></p><h4 id="火箭思维"><a href="#火箭思维" class="headerlink" title=" 火箭思维"></a><font color="#00CED1"> 火箭思维</font></h4><p>在这个技术思维模型里，产品被看作一个圆，技术是一个三角形火箭，它包括“势 道 法 术 器 界”这六个要素。其中技术只是产品当中的一个子集，在产品圆内还有企业文化、企业制度以及组织关系，这也是影响产品的几个非常重要的因素。</p><p>在这个技术思维模型中的火箭也体现了一种产品开发思维，开发产品的时候应该先确定好大概的方向（趋势），这时并不需要非常精确但是方向一定要对，然后发射（开工），在过程中不断矫正迭代更新，使得短期目标与长期目标相符合，在这个火箭模型中每一级都都是上一级的动力，一级一级地推动，直至最终命中目标（产品满足市场需求，从而获取商业上的成功）。</p><h4 id="技术与产品匹配-TPF-Technology-Product-Fit"><a href="#技术与产品匹配-TPF-Technology-Product-Fit" class="headerlink" title=" 技术与产品匹配(TPF: Technology-Product Fit)"></a><font color="#00CED1"> 技术与产品匹配(TPF: Technology-Product Fit)</font></h4><p>在做产品的时候第一步讲的是产品需要与市场匹配 (PMF: Product-Market Fit)，找出与市场匹配的产品，然后进行最小可行性验证(MVP:  Minimal Viable Product)。同样在做技术的时候，技术需要与产品匹配，这里提出一个新的概念TPF：Technology-Product Fit, 即技术与产品匹配。在技术思维模型里，当技术三角大于产品圆时，技术领先与产品需求，当技术三角小于圆时，技术落后于产品需求，但技术三角的三个点与圆刚好相交时，技术与产品达到最佳匹配，匹配合适度的评判标准是看是否符合下面的“五看三定六要素”的商业思维模型里的输出。</p><h4 id="“势、道、法、术、器、界“-六元组"><a href="#“势、道、法、术、器、界“-六元组" class="headerlink" title=" “势、道、法、术、器、界“ 六元组"></a><font color="#00CED1"> “势、道、法、术、器、界“ 六元组</font></h4><p>狭义上的技术通常指的是技能属于“术”的范畴，而广义的技术则是市场趋势、自己的优势与劣势、产品设计理念、工程方法论、技术技能、工程工具以及约束限制这几个方面的组合体，抽象成工程哲学即“势、道、法、术、器、界”这六个字 ，简称技术思维六元组。</p><h5 id="势：时势，是市场趋势、是产品定位同时也是自我的优势与劣势"><a href="#势：时势，是市场趋势、是产品定位同时也是自我的优势与劣势" class="headerlink" title=" 势：时势，是市场趋势、是产品定位同时也是自我的优势与劣势"></a><font color="#00CED1"> 势：时势，是市场趋势、是产品定位同时也是自我的优势与劣势</font></h5><p>“天时、地利、人和”，打造的产品必须符合市场趋势、准确定位客户需求，同时也要看看自己团队的优势与劣势。例如：依据市场的趋势判断，未来IOT 以及 IT运维市场是处于快速增长状态的，这可以成为为这两个市场提供数据存储服务的决策支持。同时，也要看清自我团队的优势与劣势，是否有能力打造这样的产品。</p><h5 id="道：本质，是“不变”的范畴，是一个产品的灵魂、设计理念以及价值观"><a href="#道：本质，是“不变”的范畴，是一个产品的灵魂、设计理念以及价值观" class="headerlink" title=" 道：本质，是“不变”的范畴，是一个产品的灵魂、设计理念以及价值观"></a><font color="#00CED1"> 道：本质，是“不变”的范畴，是一个产品的灵魂、设计理念以及价值观</font></h5><p>“能工摹其形，巧匠摄其魂”，代码本身是没有灵魂、没有设计理念、没有价值观的，由打造它的人铸其形而赋其神。如同雕塑与画画一般，好的匠人与宗师可以赋予作品以灵魂。同样的产品由不同的人打造，不同的设计理念体现了不同的产品灵魂，这跟打造它的人相关、也跟企业制度、企业文化、组织结构等相关。</p><p>分布式流存储从工程哲学以及设计理念的角度定义了自己的产品灵魂，工程哲学体现在“Best of Breed” 即“最佳物种”这句话，专门为物联网以及日志场景下的流式数据而设计，产品与市场适配，技术与产品适配。而它的设计理念又涵盖了：可度量化的高质量，云原生、微服务架构，软件定义存储，资源自动伸缩，消除数据冗余，数据无限存储，开箱即用，安全等。</p><h5 id="法：方法论，是”简变“的范畴，是工程的套路方法"><a href="#法：方法论，是”简变“的范畴，是工程的套路方法" class="headerlink" title=" 法：方法论，是”简变“的范畴，是工程的套路方法"></a><font color="#00CED1"> 法：方法论，是”简变“的范畴，是工程的套路方法</font></h5><p>方法论体现在产品的设计原则、产品创新、产品交付以及功能与非功能特性的定义。 分布式流存储的设计原则是最佳物种的工程哲学方法论以及以客户为中心的设计理念，产品创新依据是 ”奇点创新“三部曲：破坏、下移、重生，这一点在”奇点创新思维模型”这一章里会讲述。产品交付依从“持续交付2.0” ，探索环与验证环互补互利、互为驱动。功能特性：分布式流存储系统的核心功能就一个：提供分布式流存储服务，而非功能特性可以一分为二：质量与约束。</p><h5 id="术：技能，是”易变”的范畴，狭义上的技术，通常指的就是这一点"><a href="#术：技能，是”易变”的范畴，狭义上的技术，通常指的就是这一点" class="headerlink" title=" 术：技能，是”易变”的范畴，狭义上的技术，通常指的就是这一点"></a><font color="#00CED1"> 术：技能，是”易变”的范畴，狭义上的技术，通常指的就是这一点</font></h5><p>术，指的是技术上的设计方案与实现，在产品里占据了最大的一块版图。分布式流存储里的术可分为：</p><ul><li><p>架构视图：通常架构可以分为场景、物理、逻辑、数据处理以及开发这五个架构视图。分布式流存储最为朴素的数据处理架构视图即为抽象缓存与2层存储资源为流资源，实时性的读和写都在缓存里，数据恢复采用分布式日志系统，而长期存储采用了2层分布式文件存储系统，这也是分布式流存储最重要的一个设计理念。</p></li><li><p>控制面：分布式流存储的控制面最重要的两个工作就是：流管理与集群管理。流管理负责流的抽象、流的生命周期管理，而集群管理体现在集群状态管理以及集群的可服务管理。</p></li><li><p>数据面：数据面最重要的职责是数据“段“的抽象与管理：创建、删除、修改、使用。</p></li><li><p>高级企业特性：分布式流存储也提供了多租户、安全、监控告警、事务、读群组、状态同步器以及保序等企业级特性。</p></li></ul><h5 id="器：工具，也是”易变”的范畴-“工欲善其事-必先利其器”"><a href="#器：工具，也是”易变”的范畴-“工欲善其事-必先利其器”" class="headerlink" title=" 器：工具，也是”易变”的范畴, “工欲善其事,必先利其器”"></a><font color="#00CED1"> 器：工具，也是”易变”的范畴, “工欲善其事,必先利其器”</font></h5><p>工具的使用对人类的进化起到至关重要的作用，生产工具是人类进步的一大要素，用好“器”可以事半功倍。在分布式流存储里采用的器可分为：</p><ul><li><p>构建与运维工具：k8s、Docker, 部署，版本回滚、升级、发布，监控、告警等组件；</p></li><li><p>测试验证工具：集成测试的Jenkins, 单元测试的 Mock ， 以及A/B测试的方法论等；</p></li><li><p>此外企业平台提供的资源支持也可以属于器的范畴。</p></li></ul><h4 id="界：是约束，也是限制"><a href="#界：是约束，也是限制" class="headerlink" title=" 界：是约束，也是限制"></a><font color="#00CED1"> 界：是约束，也是限制</font></h4><p>技术思维模型里的三角形的三条边代表着“界” ，是技术边界也是技术约束与技术限制，对市场来说它是技术壁垒，对产品来说它是法律法规、是功能约束，对团队来说它是资源约束、是自我能力约束。分布式流存储的最大的技术优势也是最大的技术约束就是它是为 物联网、IT日志这样的数据格式而设计的，不是所有的数据类型存储都适用。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font color="#FF8C00">小结</font></h2><p>本系列文章讲述了四个思维模型： “技术思维模型、创新思维模型、商业思维模型以及产品思维模型”，再结合分布式流存储做了简单的举例分析。本文讲述”技术思维模型“，日拱一卒，功不唐捐，分享是最好的学习，与其跟随不如创新，希望这几个思维模型对大家有用。另作者能力与认知都有限，”我讲的，可能都是错的“[1]，欢迎大家拍砖留念。</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中科大硕，DELL EMC 资深首席工程师，主要从事分布式产品的交付、架构设计以及开发工作。</p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a><font color="#FF8C00">参考资料</font></h2><p>[1]《第二曲线创新》 李善友</p><p>[2]《如何在一分钟内用5个问题讲清你的商业模式》 中欧商业评论，关苏哲 </p><p>[3] Pravega.io</p>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>产品思维奇点图</title>
      <link href="/2019/10/21/distributed-product-architecture-daoist/"/>
      <url>/2019/10/21/distributed-product-architecture-daoist/</url>
      
        <content type="html"><![CDATA[<h2 id="产品思维奇点图"><a href="#产品思维奇点图" class="headerlink" title="产品思维奇点图"></a>产品思维奇点图</h2><p>理解技术、产品与商业是产品架构师的基本职责，架构思维、产品思维与商业思维是架构师的底层思维，就个人领悟来说技术与产品是其实不分家的，二者互补互利。</p><p>这里先放出一张我自己用的产品思维图（如下），接下来会写一篇文章详细解读这个产品思维模型，这张图我称之为产品思维奇点图，结合了“第一性原理”、“奇点理论”以及中国古朴的哲学，口诀是“四点一线五元组”。</p><p>四点分为“产品定位点、价值点、业务点以及奇点”，一线是指“能力线”，五元组是指 “势、道、法、术、器”，对应产品的“趋势、优势、劣势”，“本质、灵魂、规律、价值”，“方法论”，“技能”，“工具”。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/product/daoist/product-architecture-daoist.PNG" alt="产品架构奇点图"></p>]]></content>
      
      
      <categories>
          
          <category> product </category>
          
      </categories>
      
      
        <tags>
            
            <tag> product </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>重构工业物联网大数据处理平台的存储栈</title>
      <link href="/2019/06/23/distributed-streaming-refactor-iot-platform/"/>
      <url>/2019/06/23/distributed-streaming-refactor-iot-platform/</url>
      
        <content type="html"><![CDATA[<p>本文为《下一个分布式存储系统，为万物互联的智能世界而发》升级版。</p><h2 id="导言"><a href="#导言" class="headerlink" title="导言"></a><font color="#FF8C00">导言</font></h2><p>纵观人类历史，各种技术变革都是以人类活动为中心，然后发明各种工具。石器时代，原始人发明了石器以及用火从而提升了生活品质和社会文明。现代社会，人类为了解决各种寂寞空虚冷吃穿住用行、生理和心理上的各种需求从而发明了各种社交空间、社交工具、网络购物、生活服务APP等，为了更好的服务这些应用场景，挖掘这些场景所生产的数据的价值，从而有了今天的各种大数据技术。</p><p>在互联网时代，数据主要来源于网页、APP以及一些相应的日志系统，而在万物互联的世界，数据还可以来源于有各种传感器、工业设备、监控设备、检测设备、智能家居、自动驾驶等。大数据的四个特征：数据量、时效性、多样性、价值密度在万物互联的场景下被进一步的深化，这就意味着商业成本以及技术成本的增加。</p><p>理论奠定技术的基础，业务驱使技术的变革。在万物互联的智能时代，我们有一个愿景：<font color="#FF0000"> <strong>能够将万物互联下生成的海量原始数据转化为可用的信息以及行为决策，并且这个转换的时间差需要能够接近于零。</strong></font>通过现有技术的组合，技术人员打造了工业物联网平台从而希望能达成这个愿景。</p><h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a><font color="#FF8C00">动机</font></h2><p>现有的工业物联网大数据处理平台很多是基于开源的技术<font color="#00CED1"><strong>“D-I-Y”</strong></font>而来，它是一个”DIY“系统，往往为了一个功能而引入一个复杂的组件，这就容易造成平台只关注功能而忽略“质量与约束”，在复杂之上堆积复杂，致使客户商业成本、技术成本以及运维成本高昂。</p><p>从商业角度来说，在构建物联网大数据处理平台的时候，大家都用的开源的技术，构建出来的平台同质化严重，那么有个问题需要回答的就是：“大家都用的同样的开源技术，客户凭什么需要买单你的？”</p><p>从产品的角度来看，一个好的产品既能<font color="#00CED1"><strong>“顶天”</strong></font>，还能<font color="#00CED1"><strong>“立地”</strong></font>，它除了能有自己独到的灵魂与创新，还能将自己扎根于用户，替客户解决实际的生产问题，而不是又给客户带来新的问题。然而现有的工业物联网大数据处理平台除了给客户解决了一部分的生产问题，但是又引入了新的问题：成本高昂以及平台质量还往往难以达标。</p><font color="#00CED1"><strong>新的技术不仅可以来源于已有技术的组合与进化，还可以来自于对现有现象的理解与征服。</strong></font>因此，出于对现有的工业物联网平台的理解以及降低客户的商业成本、技术成本以及运维成本的目的，这里提出了重构工业物联网大数据平台存储栈的理念。<br><br><font> </font><h2 id="工业物联网平台"><a href="#工业物联网平台" class="headerlink" title="工业物联网平台"></a><font color="#FF8C00">工业物联网平台</font></h2><p>如下图所示，通常一个工业物联网平台是以<font color="#FF0000"> <strong>“云-管-端”</strong></font>三部分组成的，类似x86服务器主板南桥北桥的叫法，工业物联网平台也是如此，在“管”的左边跟外设传感器之类打交道的地方我们称之为“南向”，跟数据处理相关“管”的右边我们称之为“北向”。南向由各种传感器以及SCADA/PLC/HMI组成，负责数据的采集，然后数据再经过RTU、DTU、网关或路由传输到云端的工业大数据处理平台进行处理，从而完成监控、告警、预测性维护、分析等功能。</p><p>​                             </p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/streaming/iot_platform.PNG" alt="工业物联网平台"></p><h5 id="流数据-时序数据"><a href="#流数据-时序数据" class="headerlink" title="流数据/时序数据"></a><font color="#FF00FF">流数据/时序数据</font></h5><p>如下表所示，工业物联网平台南向传感器采集的数据，具有时间属性并且自带标签与数值，每条数据代表一个监测指标并且反应数值的变化，同时这些数据又随时间延续而无限增长，因此被称之为流数据或时序数据。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/streaming/iot_data_format.PNG" alt="时序数据"></p><p> 南向采集数据的设备虽然多种多样，然而本质上它们的数据格式是一样的，都由“timestamp,tags,metrics”这三部分组成。数据格式看上去是很简单的，但是对于数据处理系统来说复杂度的来源在于：</p><ol><li>数据自带时间戳具有时间有效性，这意味着数据处理的实时性;</li><li>数据都是小数据，这意味着数据存储系统需要对此进行专门的高性能设计；</li><li>数据随时间延续而无限增长，这意味着数据的无限性；</li><li>数据到达的速度有快有慢、负载有高有低，这意味着灵活又细粒度的资源弹性需求；</li><li>数据有序、无序、持久化以及复杂的传输环境而又要保证数据处理结果的唯一正确性。</li></ol><p>这是几个特性转换成存储技术的语义对应着：<font color="#FF0000"> <strong>实时性、高性能、无限性、可伸缩性以及恰好一次：持久化、有序、一致性以及事务。</strong></font>从<font color="#FF0000"> <strong>存储的视角</strong></font>来说，每种类型的数据都有其原生的属性和需求，对应有最佳的适用场景以及最合适的存储系统。那么目前又有哪种存储系统最适合用于<font color="#FF0000"> <strong>“流数据”</strong></font>呢？正如当前技术条件下最适合<font color="#FF0000"> <strong>“流数据”</strong></font>计算的是类似Flink这样的分布式流计算应用，最适合“流数据”的我们认为应当是专门针对流数据而设计的<font color="#00CED1"><strong>分布式流存储系统。</strong></font> </p><h5 id="工业大数据处理"><a href="#工业大数据处理" class="headerlink" title="工业大数据处理"></a><font color="#FF00FF">工业大数据处理</font></h5><p>工业物联网平台北向负责大数据的处理，万物互联场景下无限量的数据给数据处理技术带来巨大的挑战与压力，不同的应用场景意味着不同的数据处理要求与复杂度，要把这些不同的甚至矛盾的数据处理要求都很好的综合在一个大数据处理系统里，对现有的大数据处理技术来说是个非常大的挑战，比如无人车的处理要求毫秒甚至纳秒级的数据处理实时性、而有些工业设备数据只需要分析历史数据，要让一个大数据处理系统既能能处理历史数据又能提供毫秒级甚至纳秒级的实时性处理能力还能应对各种不同格式不同传输场景的数据，而且每种数据处理都能达到这些应用场景原生指标的处理需求，相信这样的场景对工程技术人员来说是个很大的挑战。为了解决上述问题，按照现有的成熟的技术能力，通常开发人员采用类似Lambda架构（如下图）这样的大数据处理平台组合了各种复杂的中间件来达成这个数据处理的目标。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/streaming/streaming-bigdata-lambda-arch.PNG" alt="Lambda架构"></p><p>Lambda架构即支持批处理也支持实时处理，能应对数据的多样性、具有容错功能、复杂性分离、能处理流式数据也能处理历史数据等优点，但是缺点也很明显：批处理一套独立的数据处理路径，实时处理又一套数据处理路径，然后还要合并结果再输出展示，同时系统里同样的数据存在存储多份的问题，比如同样的数据在Elasticsearch里有、HDFS里有、ceph里有、Kafka里也有，除了这些甚至还存在其他一些复杂的存储组件，而且同样的数据还都是多份冗余的，因此存储成本太高太过于复杂。Lambda架构里为了提供一个功能却引入一个组件，在复杂之上堆积复杂，存储成本、开发与运维成本都太过于复杂。</p><p>那么应当如何解决Lambda架构带来的这些缺点？<font color="#FF0000"><strong>以数据流向为核心</strong></font>重构大数据处理平台是一个比较好的方案，它具体包括数据的采集、聚合、传输、处理、展示等。依据这种设计理念我们可以推出一个端到端的原生的流式大数据处理平台：原生的流式计算加上一个原生的流式存储并且可以平衡商业成本与技术成本。</p><p>流式计算可以采用Flink，然而并没有发现当前有合适的流式存储可以使用，因此，综合思考万物互联场景下的数据处理场景也需要一个原生的分布式流存储系统，<font color="#FF0000"><strong>重构Lambda架构里的存储栈</strong></font>，使得分布式流计算加上分布式流存储即为原生的流式大数据处理系统，同时还能很好的平衡商业成本与技术成本之间的关系。</p><h2 id="设计思路"><a href="#设计思路" class="headerlink" title="设计思路"></a><font color="#FF8C00">设计思路</font></h2><h3 id="数据中台"><a href="#数据中台" class="headerlink" title="数据中台"></a><font color="#00CED1">数据中台</font></h3><p>通常数据中台的目标是：<font color="#FF0000"><strong>“治理与聚合数据，将数据抽象封装成服务提供给前台业务使用”</strong></font>，因此，数据的治理、聚合以及抽象是数据中台的关键点。当前的大数据处理平台，不管是Kappa架构还是lambda架构，数据的存储都是多组件化、多份化的。比如同样的数据在Kafka里有、在HDFS里有、在Elasticsearch里又有，有些用户还使用了更多的存储中间件，而且这些数据还是多份冗余的。这一方面增加了数据的存储成本，另一方面也降低了数据的可信性、可靠性、合规性，给数据标准化以及数据的重复利用带来了困难，不利于数据的分享、合规、降低成本以及安全可靠地支持业务和决策。因此需要对数据进行治理、聚合以及抽象。通过使用分布式流存储，大数据处理平台的架构可以进化成<font color="#FF0000"><strong>”分布式流计算+ 分布式流存储“</strong></font>这样的原生流式数据处理平台架构，这也体现了<font color="#FF0000"><strong>“数据中台”</strong></font>的理念。</p><h3 id="流原生架构"><a href="#流原生架构" class="headerlink" title="流原生架构"></a><font color="#00CED1">流原生架构</font></h3><p>依据<font color="#FF0000"> <strong>“流原生”</strong> </font>的架构设计哲学以及数据中台的理念，这里提出<font color="#FF0000"><strong>”分布式流计算+ 分布式流存储“</strong></font>这样的原生流式工业大数据处理平台的架构理念，不同于Lambda架构与Kappa架构，流原生架构最主要的工作是对数据进行了治理、聚合与抽象，使得工业大数据平台的计算层通过统一的数据API接口调用底层的流存储系统。如下图所示，Spark,Flink以及检索系统等都调用统一的流存储接口，从而减少了平台复杂度以及降低数据存储成本和运维成本。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/streaming/stream_native_platform.PNG" alt="流原生架构"></p><h3 id="算子编排"><a href="#算子编排" class="headerlink" title="算子编排"></a><font color="#00CED1">算子编排</font></h3><p>工业大数据处理平台虽然很复杂，然而抽象到最后就一个简单的数学公式：<font color="#FF0000"><strong>“Y = F(X)”</strong></font>，输入数据x，经过F算子计算再输出结果Y，数学表达式并不复杂，如同质能方程E=mc²，但是从理论到落地还有一个浩大的工程，Y=F(x)其复杂度主要来源于：</p><ol><li><p>每个数据算子都认为是一个Y=F(x)，需要对无数个这样的算子进行高性能的计算，算子无限性；</p></li><li><p>需要对无限个随时可能乱序的Y=F(x)算子进行编排、组合、拆分，算子编排。</p></li><li>需要对无限个Y=F(x)算子的中间结果进行持久化、保序，以及保证计算结果的正确性，算子结果确定性；</li></ol><p>因此需要一个专门的数据处理架构来解决这些复杂度。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/streaming/stream_platform.PNG" alt="流式架构"></p><p>如上图所示，“流原生”的Flink计算加上“流原生”的存储管道组成了“流原生”的大数据处理平台。数据从分布式流存储输入经过map算子计算，输出中间计算结果到分布式流存储里，数据又从分布式流存储里读入到Filter算子里，再经过计算，中间结果放到了分布式流存储里，再最后的计算结果经过Apply算子的计算放到了目的地的分布式流存储里。这个过程体现了算子编排和管道式编程的设计哲学，在这里分布式流存储起了大数据处理平台里的管道的作用。</p><h2 id="分布式流存储"><a href="#分布式流存储" class="headerlink" title="分布式流存储"></a><font color="#FF8C00">分布式流存储</font></h2><p>分布式流存储的产品定位是给万物互联这样的应用场景服务的，从技术角度来看它具有自身的特点，正如标题里提到的三个关键词：<font color="#FF8C00"> <strong>“分布式”、“流”、“存储”</strong></font>。首先是分布式的，它具有分布式系统本身所具有的一切能力，接着表示是专门给流式数据设计和实现的，最后的存储表示的是一个原生的存储解决方案，它讲究数据的<font color="#FF8C00"> <strong>可靠性、持久化、一致性、资源隔离等</strong></font>，它从<font color="#FF0000"> <strong>存储的视角</strong></font>处理流数据。分布式流存储针对 <strong>“流数据”</strong> 的自身属性以及相应的特殊的业务需求场景做了专门的设计与实现，下面从<font color="#FF8C00"> <strong>命名空间、业务场景、无限性、可伸缩性、恰好一次、字节流、数据管道、租户隔离、海量小文件</strong></font>的角度依据 <strong>最佳实践原则</strong> 讲述了为什么需要专门设计和实现一个流式存储系统。</p><h3 id="命名空间"><a href="#命名空间" class="headerlink" title="命名空间"></a><font color="#00CED1">命名空间</font></h3><p>通常，块存储系统以<font color="#FF0000"><strong>分区、目录、文件</strong></font>，文件存储系统以<font color="#FF0000"><strong>目录、文件</strong></font>，以及对象存储以<font color="#FF0000"><strong>租户、桶、对象</strong></font>来定义数据的存储路径以及命名空间，而流存储系统则以<font color="#FF0000"><strong>范围(scope)、流(stream)、段(segment)、事件(event)</strong></font>来描述数据的存储路径以及命名空间。</p><div align="center"> <table><thead><tr><th>类型</th><th>命名空间</th></tr></thead><tbody><tr><td>块存储</td><td>分区、目录、文件</td></tr><tr><td>文件存储</td><td>目录、文件</td></tr><tr><td>对象存储</td><td>租户、桶、对象</td></tr><tr><td>流存储</td><td>范围、流、段、事件</td></tr></tbody></table><div align="left"> <p>在流存储系统里，如下图所示，数据的组织形式被抽象成范围、流、段和事件，范围由流组成，流由段组成，段由事件组成，事件由字节(bytes)组成。</p><div align="center"> <p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/pravega-infoq-scope-stream.png" alt="流的组成"></p><div align="left"> <h3 id="业务场景"><a href="#业务场景" class="headerlink" title="业务场景"></a><font color="#00CED1">业务场景</font></h3><p>在自动驾驶的场景里采用分布式流存储，我们可以这样处理自动驾驶的数据：给每一辆无人车定义一个1TB存储空间的范围，车上的每个传感器都归属于一个流，传感器上报的事件都在段内持久化。再假设每辆车都有1000个传感器（实际情况只多不少），那么10万辆车就需要定义1亿个流，可以想象要进行这种规模的隔离也就只有这种专门针对流数据而设计的流存储系统能够支持。</p><p>在工业厂房的场景下，还可以这样定义工业设备的数据：给一个厂房里的每台设备定义一个范围，每台设备里的每个传感器都对应一个流，传感器上传的事件数据保存在流内的段里，这样就很方便的对工业设备进行了大规模的租户数据隔离。</p><p>因此，以<font color="#FF0000"><strong>“范围、流、段、事件”</strong></font>的方式很方便的进行了大规模的租户隔离保证了用户信息安全同时又进行了存储资源配额的隔离。</p><h3 id="数据无限性"><a href="#数据无限性" class="headerlink" title="数据无限性"></a><font color="#00CED1">数据无限性</font></h3><p>无限性是分布式流存储最为重要的设计原则。从流数据的角度来看，数据是大量、快速、连续而又无限的，这就给流存储系统的设计与实现带来极大的困难，无限的数据使得存储系统必须能支持连续且无限规模的数据流，光这一点就对存储系统的可扩展性要求非常的高，同时还要求存储系统能够根据到达的数据量动态而又优雅地进行扩容与缩容。从技术与成本的角度来看，数据无限性意味着冷热数据分离，长期不用的数据淘汰到长期存储系统里，热点数据需要缓存，同时还需要能支持历史数据的读取与实时数据的读取与写入。</p><h3 id="可伸缩性"><a href="#可伸缩性" class="headerlink" title="可伸缩性"></a><font color="#00CED1">可伸缩性</font></h3><p>可伸缩性也是分布式流存储最为重要的设计原则之一，而且流存储里的可伸缩性要求还是自动化的资源细粒度的可伸缩。通常，在云原生的场景下，资源的缩放是以主机、虚机或容器为单位的，这样的缩放对流存储来说粒度太大。在流存储的场景下需要能够以数据的<strong>“流段”</strong>为单位，比如一个流段2MB，那么就需要能支持一次自动扩容或缩容2MB的存储空间。另外在流存储里还要求写入与读取对数据子集的操作是解耦分离的，并且写入与读取二者之间跟数据流段还要有一个合理的平衡。</p><h3 id="恰好一次"><a href="#恰好一次" class="headerlink" title="恰好一次"></a><font color="#00CED1">恰好一次</font></h3><p>恰好一次也是分布式流存储最为重要的设计原则之一，恰好一次意味着数据的可持久化、有序、一致性以及事务性的支持。持久性意味着一旦得到确认，即使存储组件发生故障，写入的数据也不会丢失。有序意味着读客户端将严格按照写入的顺序处理数据。一致性意味着所有的读客户端即使面对存储故障、网络故障也都会看到相同的有序数据视图。事务性写入对于保证Flink这样的计算应用处理结果的完全正确是非常必要的。</p><h3 id="字节流"><a href="#字节流" class="headerlink" title="字节流"></a><font color="#00CED1">字节流</font></h3><p>分布式流存储里采用字节流的格式组织数据而不是像消息系统里采用消息报文的方式，这意味着接口的通用性。二进制的字节流是与数据格式无关的，字节流可以组成事件封装在分布式存储的流段里。而消息系统里数据是消息头消息体的格式封装的，在兼容性上不如字节流。</p><h3 id="数据管道"><a href="#数据管道" class="headerlink" title=" 数据管道"></a><font color="#00CED1"> 数据管道</font></h3><p>在存储界通常喜欢用跑车、卡车、渡轮来比喻块存储、文件存储以及对象存储，打个比方来说块存储类似跑车：极快、极稳、装的人少、成本高；文件存储类似卡车：快、稳、装的人比跑车多，但是没跑车那么快；对象存储类似渡轮：可以装非常多的货，讲究量大、成本低；那么分布式流存储像什么呢？ 在我们的定义里它就像管道：<font color="#FF0000"><strong>数据如同流水一般流过管道，又快又稳源源不断而又永无止境</strong>。</font></p><h3 id="租户隔离"><a href="#租户隔离" class="headerlink" title="租户隔离"></a><font color="#00CED1">租户隔离</font></h3><p>分布式流存储从一开始设计的时候就将”租户隔离“作为其基本特性进行实现，”隔离“是分布式流存储的最基本的特性之一，在分布式流存储里租户隔离不只是租户B绝对不能看的到租户A的任何信息这样的信息安全层面的隔离，它支持范围、流、段、事件层面的隔离还将支持的租户规模作为设计的目标之一，在分布式流存储里单集群需要能支持千万量级起的租户数，另外还有资源、命名、可视空间、权限以及服务质量层面的隔离。</p><h3 id="海量小文件"><a href="#海量小文件" class="headerlink" title="海量小文件"></a><font color="#00CED1">海量小文件</font></h3><p>对巨量小文件的支持是分布式流存储的设计原则之一。正如前面提到的，万物互联下的海量数据来源于传感器，而传感器上传的数据都是类似温度、地理位置、告警信息这样的几个字节几个字节的小数据，这就意味着在万物互联的场景下会有巨量的小数据上传，而且90%以上的数据操作行为都是写入。为了保证数据写入的性能以及可靠性、正确性、持久性以及保证介质的使用寿命降低成本，这也需要存储系统针对这种业务场景进行专门的设计。</p><p>在分布式流存储里每个事件第一步是被仅附加写入一个缓存的段内进行封装的，在段达到一定的尺寸（比如64MB）后会被封闭不再写入，这时再将整个段写入下一级的持久化存储里。通过这样的设计，实现小数据在缓存里封装成大块的数据，再将大块数据写入持久化存储设备的方式保证了存储系统整体的性能。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font color="#FF8C00">小结</font></h2><p>电影《一代宗师》里提到习武之人有三个境界：<font color="#00CED1"><strong>“见自己，见天地，见众生”</strong></font>。做技术做产品也同样如是，“三见”如同一体三面不可分割，认知上从关注自己到关注格局创新，再扎根到用户当中替用户解决有价值的实际问题。现有的工业物联网大数据处理平台有创新也有替客户解决了部分工业数据处理的难题，但是还是属于一个”DIY“的系统，离产品化还有距离，因此需要我们继续扎根下去替客户解决新的实际问题。</p><p>综上所述，在万物互联的智能世界里，为了实现将海量数据近实时转化成信息和决策的愿景，除了流式计算应用还需要一个流式存储系统，未来已来，已有开源的分布式流存储系统正走在这条路上。另本文仅为作者愚见，与任何组织机构无关，作者能力也很有限，如有不足之处欢迎留言批评指正。</p><h2 id="问题思考"><a href="#问题思考" class="headerlink" title="问题思考"></a><font color="#FF8C00">问题思考</font></h2><p>最后给大家留一个思考题：<font color="#00CED1"><strong>如果让你来设计一个工业物联网平台产品，你会如何定义它的产品灵魂？</strong></font></p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中科大硕，10年+数据相关经验，主要工作背景为分布式系统、存储、缓存、微服务、云计算以及工业物联网大数据，现就职于DELL EMC。个人技术博客：<a href="https://changping.me" target="_blank" rel="noopener">https://changping.me</a></p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a> ，可以自由阅读、分享、转发、复制、分发等，限制是需署名、非商业使用（以获利为准）以及禁止演绎。</p></div></div></div></div>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>下一个分布式存储系统，为万物互联的智能世界而发</title>
      <link href="/2019/05/24/distributed-streaming-the-next-storage/"/>
      <url>/2019/05/24/distributed-streaming-the-next-storage/</url>
      
        <content type="html"><![CDATA[<p>如果说互联网和云计算使得对象存储在存储市场上与块存储、文件存储三分天下，相应的业务需求直接奠定了对象存储与块存储、文件存储并列存储江湖一哥的地位，那么接下来也许我们需要为下一场数据变革的大事做好准备 – <font color="#00CED1"><strong>万物互联这样的商业场景将给数据存储带来极大的商业挑战和技术挑战。</strong></font></p><h2 id="万物互联下的数据"><a href="#万物互联下的数据" class="headerlink" title="万物互联下的数据"></a><font color="#FF8C00">万物互联下的数据</font></h2><p>纵观人类历史，各种技术变革都是以人类活动为中心，然后发明各种工具。石器时代，原始人发明了石器以及用火从而提升了生活品质和社会文明。现代社会，人类为了解决各种寂寞空虚冷吃穿住用行、生理和心理上的各种需求从而发明了各种社交空间、社交工具、网络购物、生活服务APP等，为了更好的服务这些应用场景，挖掘这些场景所生产的数据的价值，从而有了今天的各种大数据技术。</p><p>在互联网时代，数据主要来源于网页、APP以及一些相应的日志系统，而在万物互联的世界，数据还可以来源于有各种传感器、工业设备、监控设备、检测设备、智能家居、自动驾驶等。大数据的四个特征：数据量、时效性、多样性、价值密度在万物互联的场景下被进一步的深化，这就意味着商业成本以及技术成本的增加。</p><p>理论奠定技术的基础，业务驱使技术的变革。在万物互联的智能时代，我们有一个愿景：<font color="#FF0000"> <strong>能够将万物互联下生成的海量原始数据转化为可用的信息以及行为决策，并且这个转换的时间差需要能够接近于零。</strong></font>而需要实现这个愿景，从技术角度来看，需要有计算层面的解决方案也需要有存储层面的，如今在计算层面已经有Flink、Spark等这类成熟的分布式计算应用，然而在存储层面还没有。</p><h2 id="流数据与流存储"><a href="#流数据与流存储" class="headerlink" title="流数据与流存储  "></a><font color="#FF8C00">流数据与流存储  </font></h2><p>在万物互联的场景下，各种传感器以及设备生成的数据有其原生的属性，这种数据自带时间戳、实时性要求高，而且是<font color="#FF0000"> <strong>“流数据”</strong></font>。</p><p>首先流数据在百度百科里是这样被定义的：</p><blockquote><p>流数据是一组顺序、大量、快速、连续到达的数据序列，一般情况下，数据流可被视为一个随时间延续而无限增长的动态数据集合。应用于网络监控、传感器网络、航空航天、气象测控和金融服务等领域。</p></blockquote><p>从数据的生产与传输场景来看流数据具有几个与众不同的带有破坏性的特性：</p><ol><li>数据随时间延续而无限增长，这意味着数据的无限性；</li><li>数据到达的速度有快有慢、负载有高有低，这意味着灵活又细粒度的资源弹性需求；</li><li>数据有序、无序、持久化以及复杂的传输环境而又要保证数据处理结果的唯一正确性。</li></ol><p>这是三个特性转换成存储技术的语义对应着：<font color="#FF0000"> <strong>无限性、可伸缩性以及恰好一次：持久化、有序、一致性以及事务。</strong></font></p><p>从<font color="#FF0000"> <strong>存储的视角</strong></font>来说，每种类型的数据都有其原生的属性和需求，对应有最佳的适用场景以及最合适的存储系统。跑在数据库里的数据对实时性和可靠性要求非常的高，因此适合采用块存储系统。文件共享场景下需要向用户共享文件，多个用户可以共享读取一个文件，因此适合采用文件存储系统。而互联网网页与APP里的文件、图像、视频可以看作一个个的数据对象又需要租户隔离以及无限扩展，因此又非常适合采用对象存储系统。那么目前又有哪种存储系统最适合用于<font color="#FF0000"> <strong>“流数据”</strong></font>呢？</p><p>正如当前技术条件下最适合<font color="#FF0000"> <strong>“流数据”</strong></font>计算的是类似Flink这样的分布式流计算应用，最适合“流数据”的应当是<font color="#00CED1"><strong>分布式流存储系统。</strong></font> </p><h2 id="分布式流存储系统"><a href="#分布式流存储系统" class="headerlink" title="分布式流存储系统"></a><font color="#FF8C00">分布式流存储系统</font></h2><h3 id="产品定位"><a href="#产品定位" class="headerlink" title="产品定位"></a><font color="#00CED1">产品定位</font></h3><p>分布式流存储系统的产品定位是给万物互联这样的应用场景服务的，从技术角度来看它具有自身的特点，正如标题里提到的三个关键词：<font color="#FF8C00"> <strong>“分布式”、“流”、“存储”</strong></font>。首先是分布式的，它具有分布式系统本身所具有的一切能力，接着表示是专门给流式数据设计和实现的，最后的存储表示的是一个原生的存储解决方案，它讲究数据的<font color="#FF8C00"> <strong>可靠性、持久化、一致性、资源隔离等</strong></font>，它从<font color="#FF0000"> <strong>存储的视角</strong></font>处理流数据。分布式流存储针对 <strong>“流数据”</strong> 的自身属性以及相应的特殊的业务需求场景做了专门的设计与实现，下面从<font color="#FF8C00"> <strong>命名空间、业务场景、无限性、可伸缩性、恰好一次、字节流、数据管道、租户隔离、海量小文件、数据治理、流式架构</strong></font>的角度依据 <strong>最佳实践原则</strong> 讲述了为什么需要专门设计和实现一个流式存储系统。</p><h3 id="命名空间"><a href="#命名空间" class="headerlink" title="命名空间"></a><font color="#00CED1">命名空间</font></h3><p>通常，块存储系统以<font color="#FF0000"><strong>分区、目录、文件</strong></font>，文件存储系统以<font color="#FF0000"><strong>目录、文件</strong></font>，以及对象存储以<font color="#FF0000"><strong>租户、桶、对象</strong></font>来定义数据的存储路径以及命名空间，而流存储系统则以<font color="#FF0000"><strong>范围(scope)、流(stream)、段(segment)、事件(event)</strong></font>来描述数据的存储路径以及命名空间。</p><div align="center"> <table><thead><tr><th>类型</th><th>命名空间</th></tr></thead><tbody><tr><td>块存储</td><td>分区、目录、文件</td></tr><tr><td>文件存储</td><td>目录、文件</td></tr><tr><td>对象存储</td><td>租户、桶、对象</td></tr><tr><td>流存储</td><td>范围、流、段、事件</td></tr></tbody></table><div align="left"> <p>在流存储系统里，如下图所示，数据的组织形式被抽象成范围、流、段和事件，范围由流组成，流由段组成，段由事件组成，事件由字节(bytes)组成。</p><div align="center"> <p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/pravega-infoq-scope-stream.png" alt="流的组成"></p><div align="left"> <h3 id="业务场景"><a href="#业务场景" class="headerlink" title="业务场景"></a><font color="#00CED1">业务场景</font></h3><h5 id="可穿戴设备、自动驾驶与工业厂房"><a href="#可穿戴设备、自动驾驶与工业厂房" class="headerlink" title=" 可穿戴设备、自动驾驶与工业厂房"></a><font color="#FF00ff"> 可穿戴设备、自动驾驶与工业厂房</font></h5><p>可以想象一下这样的业务场景：某个商家销售了几千万个智能手表，这些智能手表可以记录每个用户每天走了多少步，同时还可以分析过往的历史数据，用柱状图给用户展示历史数据，如下图所示：</p><div align="center"> <p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/pravega-infoq-watch.png" alt="步数分析"></p><div align="left">  <p>考虑到信息安全，用户A是不能看到用户B的数据的，那么就需要按智能手表为单位进行租户隔离，这种的场景下就有几千万个租户，同时每个租户还有自己的存储空间配额，比如给每个智能手表分配5GB 存储空间。光是这样的租户隔离场景，依据<strong>最佳实践</strong>的系统设计原则，不管是块存储系统、文件存储系统、对象存储系统还是Kafka这样的消息系统，按他们本身的隔离特性以及支持的租户规模都是难以在单个系统里支持这样的租户隔离场景。但是用流存储来实现就很方便，比如以智能手表的业务场景为例：</p><ul><li>默认分配5GB存储空间给一个智能手表，然后定义一个智能手表类型的命名空间用于与其他智能设备进行隔离，给每个智能手表分配一个流，每个智能手表上报的字节数据以事件为单位存储在流内的段里。</li><li>也可以这样来定义：给每个智能手表分配一个5GB 存储空间的命名空间，手表里的每个传感器都对应一个流，每个传感器以事件为单位上报字节数据存储到流的段里。</li></ul><p>还可以想象一下这样的业务场景：自动驾驶。采用分布式流存储的话，我们可以这样处理自动驾驶的数据：给每一辆无人车定义一个1TB存储空间的范围，车上的每个传感器都归属于一个流，传感器上报的事件都在段内持久化。再假设每辆车都有1000个传感器（实际情况只多不少），那么10万辆车就需要定义1亿个流，可以想象要进行这种规模的隔离也就只有这种专门针对流数据而设计的流存储系统能够支持。</p><p>在工业互联网的场景下，还可以这样定义工业设备的数据：给一个厂房里的每台设备定义一个范围，每台设备里的每个传感器都对应一个流，传感器上传的事件数据保存在流内的段里，这样就很方便的对工业设备进行了大规模的租户数据隔离。</p><p>因此，以<font color="#FF0000"><strong>“范围、流、段、事件”</strong></font>的方式很方便的进行了大规模的租户隔离保证了用户信息安全同时又进行了存储资源配额的隔离。</p><h5 id="大数据处理平台"><a href="#大数据处理平台" class="headerlink" title=" 大数据处理平台"></a><font color="#FF00FF"> 大数据处理平台</font></h5><p>万物互联场景下无限量的数据给数据处理技术带来巨大的挑战与压力，不同的应用场景意味着不同的数据处理要求与复杂度，要把这些不同的甚至矛盾的数据处理要求都很好的综合在一个大数据处理系统里，对现有的大数据处理技术来说是个非常大的挑战，比如无人车的处理要求毫秒甚至纳秒级的数据处理实时性、而有些工业设备数据只需要分析历史数据，要让一个大数据处理系统既能能处理历史数据又能提供毫秒级甚至纳秒级的实时性处理能力还能应对各种不同格式不同传输场景的数据，而且每种数据处理都能达到这些应用场景原生指标的处理需求。相信这样的场景对工程技术人员来说是个很大的挑战。为了解决上述问题，按照现有的成熟的技术能力，通常开发人员采用类似Lambda架构（如下图）这样的大数据处理平台来处理大数据。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/streaming/streaming-bigdata-lambda-arch.PNG" alt="Lambda架构"></p><p>Lambda架构即支持批处理也支持实时处理，能应对数据的多样性、具有容错功能、复杂性分离、能处理流式数据也能处理历史数据等优点，但是缺点也很明显：<strong>批处理一套独立的数据处理路径，实时处理又一套数据处理路径，然后还要合并结果再输出展示，同时系统里同样的数据存在存储多份的问题，比如同样的数据在Elasticsearch里有、HDFS里有、ceph里有、Kafka里也有，除了这些甚至还存在其他一些复杂的存储组件，而且同样的数据还都是多份冗余的，因此存储成本太高太过于复杂。Lambda架构里为了提供一个功能却引入一个组件，在复杂之上堆积复杂，存储成本、开发与运维成本都太过于复杂。</strong></p><p>那么应当如何解决Lambda架构带来的这些缺点？<font color="#FF0000"><strong>以数据流向为核心</strong></font>重构大数据处理平台是一个比较好的方案，它具体包括数据的采集、聚合、传输、缓存、持久化、处理、展示等。依据这种设计理念我们可以推出一个端到端的原生的流式大数据处理平台：原生的流式计算加上一个原生的流式存储并且可以平衡商业成本与技术成本。</p><p>流式计算可以采用Flink，然而并没有发现当前有合适的流式存储可以使用，如果采用Flink加上传统的文件存储或者块存储、对象存储的方式，也只能认为是半原生的大数据处理平台：<font color="#FF0000"><strong>计算是原生的流式计算而存储却不是原生的流式存储</strong></font>。</p><p>因此，综合思考万物互联场景下的数据处理场景也需要一个原生的分布式流存储系统，<font color="#FF0000"><strong>重构Lambda架构里的存储栈</strong></font>，使得分布式流计算加上分布式流存储即为原生的流式大数据处理系统，同时还能很好的平衡商业成本与技术成本之间的关系。</p><h3 id="数据无限性"><a href="#数据无限性" class="headerlink" title="数据无限性"></a><font color="#00CED1">数据无限性</font></h3><p>无限性是分布式流存储最为重要的设计原则。从流数据的角度来看，数据是大量、快速、连续而又无限的，这就给流存储系统的设计与实现带来极大的困难，无限的数据使得存储系统必须能支持连续且无限规模的数据流，光这一点就对存储系统的可扩展性要求非常的高，同时还要求存储系统能够根据到达的数据量动态而又优雅地进行扩容与缩容。从技术与成本的角度来看，数据无限性意味着冷热数据分离，长期不用的数据淘汰到长期存储系统里，热点数据需要缓存，同时还需要能支持历史数据的读取与实时数据的读取与写入。</p><h3 id="可伸缩性"><a href="#可伸缩性" class="headerlink" title="可伸缩性"></a><font color="#00CED1">可伸缩性</font></h3><p>可伸缩性也是分布式流存储最为重要的设计原则之一，而且流存储里的可伸缩性要求还是自动化的资源细粒度的可伸缩。通常，在云原生的场景下，资源的缩放是以主机、虚机或容器为单位的，这样的缩放对流存储来说粒度太大。在流存储的场景下需要能够以数据的<strong>“流段”</strong>为单位，比如一个流段2MB，那么就需要能支持一次自动扩容或缩容2MB的存储空间。另外在流存储里还要求写入与读取对数据子集的操作是解耦分离的，并且写入与读取二者之间跟数据流段还要有一个合理的平衡。</p><h3 id="恰好一次"><a href="#恰好一次" class="headerlink" title="恰好一次"></a><font color="#00CED1">恰好一次</font></h3><p>恰好一次也是分布式流存储最为重要的设计原则之一，恰好一次意味着数据的可持久化、有序、一致性以及事务性的支持。持久性意味着一旦得到确认，即使存储组件发生故障，写入的数据也不会丢失。有序意味着读客户端将严格按照写入的顺序处理数据。一致性意味着所有的读客户端即使面对存储故障、网络故障也都会看到相同的有序数据视图。事务性写入对于保证Flink这样的计算应用处理结果的完全正确是非常必要的。</p><h3 id="字节流"><a href="#字节流" class="headerlink" title="字节流"></a><font color="#00CED1">字节流</font></h3><p>分布式流存储里采用字节流的格式组织数据而不是像消息系统里采用消息报文的方式，这意味着接口的通用性。二进制的字节流是与数据格式无关的，字节流可以组成事件封装在分布式存储的流段里。而消息系统里数据是消息头消息体的格式封装的，在兼容性上不如字节流。</p><h3 id="数据管道"><a href="#数据管道" class="headerlink" title=" 数据管道"></a><font color="#00CED1"> 数据管道</font></h3><p>在存储界通常喜欢用跑车、卡车、渡轮来比喻块存储、文件存储以及对象存储，打个比方来说块存储类似跑车：极快、极稳、装的人少、成本高；文件存储类似卡车：快、稳、装的人比跑车多，但是没跑车那么快；对象存储类似渡轮：可以装非常多的货，讲究量大、成本低；那么分布式流存储像什么呢？ 在我们的定义里它就像管道：<font color="#FF0000"><strong>数据如同流水一般流过管道，又快又稳源源不断而又永无止境</strong>。</font></p><h3 id="租户隔离"><a href="#租户隔离" class="headerlink" title="租户隔离"></a><font color="#00CED1">租户隔离</font></h3><p>分布式流存储从一开始设计的时候就将”租户隔离“作为其基本特性进行实现，”隔离“是分布式流存储的最基本的特性之一，在分布式流存储里租户隔离不只是租户B绝对不能看的到租户A的任何信息这样的信息安全层面的隔离，它支持范围、流、段、事件层面的隔离还将支持的租户规模作为设计的目标之一，在分布式流存储里单集群需要能支持千万量级起的租户数，另外还有资源、命名、可视空间、权限以及服务质量层面的隔离。</p><h3 id="海量小文件"><a href="#海量小文件" class="headerlink" title="海量小文件"></a><font color="#00CED1">海量小文件</font></h3><p>对巨量小文件的支持是分布式流存储的设计原则之一。正如前面提到的，万物互联下的海量数据来源于传感器，而传感器上传的数据都是类似温度、地理位置、告警信息这样的几个字节几个字节的小数据，这就意味着在万物互联的场景下会有巨量的小数据上传，而且90%以上的数据操作行为都是写入。为了保证数据写入的性能以及可靠性、正确性、持久性以及保证介质的使用寿命降低成本，这也需要存储系统针对这种业务场景进行专门的设计。</p><p>在分布式流存储里每个事件第一步是被仅附加写入一个缓存的段内进行封装的，在段达到一定的尺寸（比如64MB）后会被封闭不再写入，这时再将整个段写入下一级的持久化存储里。通过这样的设计，实现小数据在缓存里封装成大块的数据，再将大块数据写入持久化存储设备的方式保证了存储系统整体的性能。</p><h3 id="数据治理"><a href="#数据治理" class="headerlink" title="数据治理"></a><font color="#00CED1">数据治理</font></h3><p>当前的大数据处理平台，不管是Kappa架构还是lambda架构，数据的存储都是多组件化、多份化的。比如同样的数据在Kafka里有、在HDFS里有、在Elasticsearch里又有，有些用户还使用了更多的存储中间件，而且这些数据还是多份冗余的。这一方面增加了数据的存储成本，另一方面也降低了数据的可信性、可靠性、合规性，给数据标准化以及数据的重复利用带来了困难，不利于数据的分享、合规、降低成本以及安全可靠地支持业务和决策。数据治理也是分布式流存储的基本设计原则之一，通过使用分布式流存储，大数据处理平台的架构可以进化成<font color="#FF0000"><strong>”分布式流计算+ 分布式流存储“</strong></font>这样的原生流式数据处理平台架构。</p><h3 id="流式架构"><a href="#流式架构" class="headerlink" title="流式架构"></a><font color="#00CED1">流式架构</font></h3><p>下图体现了<font color="#FF0000"><strong>”分布式流计算+ 分布式流存储“</strong></font>这样的原生流式大数据处理平台的架构理念。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/streaming/streaming-bigdata-processor.PNG" alt="流式架构"></p><p>这个架构体现了<font color="#FF0000"> <strong>“流原生”(stream native)式</strong> </font>的设计哲学，“流原生”的计算加上“流原生”的存储管道组成了“流原生”的大数据处理平台。数据从分布式流存储输入经过map算子计算，输出中间计算结果到分布式流存储里，数据又从分布式流存储里读入到Filter算子里，再经过计算，中间结果放到了分布式流存储里，再最后的计算结果经过聚合算子的计算放到了目的地的分布式流存储里。这个过程体现了算子编排和管道式编程的设计哲学，在这里分布式流存储起了大数据处理平台里的管道的作用。</p><p>同时，在分布式流存储里数据的存储单位是流段，当输入的数据速率或者负载增加时，流段就会自动扩容，通过流协议联动，流计算应用的算子也相应扩容。相应的，如果输入的数据速率或负载降低，流段就自动收缩，通过流协议联动，流计算应用的算子也相应的缩容，所有这些行为都是自动完成的，无需人工干预，这种行为体现了分布式流存储的细粒度可伸缩性。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font color="#FF8C00">小结</font></h2><p>综上所述，在万物互联的智能世界里，为了实现将海量数据近实时转化成信息和决策的愿景，除了流式计算应用还需要一个流式存储系统，未来已来，已有开源的分布式流存储系统正走在这条路上。另本文仅为作者愚见，与任何组织机构无关，作者能力也很有限，如有不足之处欢迎留言批评指正。</p><h2 id="问题思考"><a href="#问题思考" class="headerlink" title="问题思考"></a><font color="#FF8C00">问题思考</font></h2><p>最后给大家留一个思考题：<font color="#00CED1"><strong>如果让你来设计一个分布式流存储产品，你会如何定义它的产品灵魂？</strong></font></p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中科大硕，10年+数据相关经验，主要工作背景为分布式系统、存储、缓存、微服务、云计算以及大数据，现就职于DELL EMC。个人技术博客：<a href="https://changping.me" target="_blank" rel="noopener">https://changping.me</a></p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a> ，可以自由阅读、分享、转发、复制、分发等，限制是需署名、非商业使用（以获利为准）以及禁止演绎。</p></div></div></div></div></div></div>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>分布式系统架构设计三十六式之服务治理 – 第7式 - 系统自适应模式</title>
      <link href="/2019/04/21/distributed-servicegovernance-systemadaptive/"/>
      <url>/2019/04/21/distributed-servicegovernance-systemadaptive/</url>
      
        <content type="html"><![CDATA[<h2 id="导读"><a href="#导读" class="headerlink" title="导读"></a><font color="#FF8C00">导读</font></h2><p>日拱一卒，功不唐捐，分享是最好的学习，一个知识领域里的 <font color="#00CED1"> <strong>“道 法 术 器”</strong> </font> 这四个境界需要从 <font color="#00CED1"> <strong>微观、中观以及宏观</strong> </font>三个角度来把握。微观是实践，中观讲套路，宏观靠领悟。本系列文章我把它命名为《分布式系统架构设计三十六式》，讲诉分布式系统里最重要的三十六个虚数的中观套路，而微服务的本质也是分布式，因此搞明白这三十六个最重要的知识点也就同时能搞明白微服务。</p><p>实现一个分布式系统通常会面临三大难题： <font color="#00CED1"> <strong>故障传播性、业务拆分与聚合以及分布式事务</strong> </font>。本系列中的服务治理章节主要是为了解决故障传播性的难题，它包括： <font color="#00CED1"> <strong>隔离、熔断、降级、限流、容错以及资源管控-系统自适应算法</strong> </font>，本文将讲述服务治理里的 <font color="#00CED1"> <strong>“系统自适应模式”</strong> </font>模式。</p><h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a><font color="#FF8C00">动机</font></h2><font color="#00CED1"> <strong>分布式系统的灵魂</strong>  </font>：从产品思维的角度来看，好的产品都是有自己灵魂的。比如微信的产品灵魂被定位成“善良”，善有大善、上善、小善。《道德经》有言：“上善若水，水善利万物而不争，处众人之所恶（wù），故几于道。”，水善利万物而不与万物争，水无处不在，万物感觉不到水的存在又离不开水，不争故天下莫能与之争。每种好的产品背后都隐藏着自己的设计哲学，有自己的灵魂。而一个分布式系统的灵魂又应该怎么定义呢？认知层次不同，对分布式系统的理解也不同，度量一个分布式系统的灵魂，在我看来可以采用分布式系统的SLO图形指标来表达。好的分布式系统SLO指标也是很有规律很漂亮的，如下图所示，左图波形上跳下串，很明显不如右边波形来的漂亮。<br><br><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/systemadaptive/system-jitter.PNG" alt="系统抖动"><br><br>波形上跳下串带来的后果是什么呢？想象一下在高速路开车的场景，如果一辆车一会快，一会慢，后面的车会发生什么事？这样开车是很容易出事故的，而开得很稳的车出故障的概率就较小。波形上跳下串，说明该系统里头没有解决好资源竞用性以及服务治理的问题。<br><br><font color="#00CED1"> <strong>可靠性与高性能的平衡</strong>  </font>：我们知道要让一个水管里的水流的又快又多，一是给水管灌满水，二是水管通畅同时保证不炸裂水管。同样的道理，在分布式系统里要让系统跑出最好的性能和最可靠的效果，一方面压榨整个系统的资源，另一方面又要保证系统不出故障，在系统不出故障的前提下，尽量榨尽系统资源。<br><br>因此为了解决以上问题，这里提出了系统自适应模式。<br><br><font></font><h2 id="系统自适应模式设计思路"><a href="#系统自适应模式设计思路" class="headerlink" title="系统自适应模式设计思路"></a><font color="#FF8C00">系统自适应模式设计思路</font></h2><h3 id="资源平衡"><a href="#资源平衡" class="headerlink" title="资源平衡"></a><font color="#00CED1">资源平衡</font></h3><p>服务治理与其说是分布式下的套路，不如说是控制论下的套路，其本质是资源的细粒度管控，精巧的平衡整个系统里的资源竞用，从而保证分布式系统对外提供高质量的服务。如下图《一根羽毛的力量》所示，其将平衡的思想用到极致，我们也希望在分布式系统里体现有限资源下的平衡。</p><div align="center"> <p> <img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/systemadaptive/balance.jpg" alt=" 图片来源于网络版权归原作者所有"></p><div align="left"> <p>我们将平衡的思想融入分布式系统，在系统健康的前提下，极致的压榨系统的能力(capacity)，同时又保证不会主动造成系统故障，如果发现系统内部出现故障，又会自动调整下发的压力，这就是系统自适应保护。</p><h3 id="最佳衡量指标"><a href="#最佳衡量指标" class="headerlink" title="最佳衡量指标"></a><font color="#00CED1"><strong>最佳衡量指标</strong></font></h3><p>如何确定最佳的衡量指标？通常比较的原始情况下，是以工作负载比如1分钟、5分钟、15分钟的CPU负载作为系统衡量指标，但是这并不大正确。比如假设 CPU load &gt; 2 就 触发一个系统保护，如果这个 时候系统的CPU load是在下降的，它虽然此时刻大于2， 但是趋势却是下降，因此没必要触发系统保护。还有就是干扰性，比如 按 1分钟负载&amp;&amp; 5分钟负载&amp;&amp;15分钟负载，全都是满足大于2的条件就触发系统保护。但是实际上，也许 5分钟负载是不大于2的，因此这个条件就不成立，并不会触发系统过载保护， 这种行为我称之为负载干扰性。</p><p>参考水管的流量算法只依赖于管的截面大小以及流速，我们定义系统的自适应算法依赖的参数为系统入口处的 QPS或TPS ，以及请求的返回时间（RT），这里我将这个公式定义为 System Balance Capacity = QPS * RT。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/systemadaptive/qps-and-rt.PNG" alt="最佳值"></p><p>如上图，最好的情况就是即满足 最大的QPS 又满足最小的RT，通过一个时间窗口计算QPS 和 RT ，自适应调整整个系统。</p><h3 id="系统自适应算法"><a href="#系统自适应算法" class="headerlink" title="系统自适应算法"></a><font color="#00CED1"><strong>系统自适应算法</strong></font></h3><p>下图表示了一个自适应算法，造成系统负载过高以及故障传播的因素很多，比如不合适的线程数、TPS或QPS过大、返回时间过长都有可能，通过合适的算法可以自动调整下发的压力从而保持系统的内部资源平衡。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/systemadaptive/systemadaptive.PNG" alt="自适应算法"></p><p>通过采用系统自适应算法在系统的入口处，实时采集QPS/TPS 以及RT， 然后跟最佳样本值进行比较，依据调节系数进行计算，再调节发送的请求量，发送请求后又采集造成的影响，再反馈在系统入口处。其中，样本值可以在系统启动时按动态采样的方式计算，逐渐增加QPS ，当发现时延发生转折时，我们就确定这个转折点为分布式系统自适应最佳平衡点，记下该值作为当前样本。 </p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font color="#FF8C00">小结</font></h2><p>本文讲诉了服务治理里的 <font color="#00CED1"><strong>“系统自适应”</strong></font>模式，在前一篇《分布式系统架构设计三十六式之服务治理-5F容错模式》里讲诉了分布式系统服务治理的容错模式。另作者能力与认知都有限，欢迎大家拍砖留念。</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中科大硕，10年+数据相关经验，主要工作背景为分布式系统、存储、缓存、微服务、云计算以及大数据，现就职于DELL EMC。个人技术博客：<a href="https://changping.me" target="_blank" rel="noopener">https://changping.me</a></p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a> ，可以自由阅读、分享、转发、复制、分发等，限制是需署名、非商业使用（以获利为准）以及禁止演绎。</p></div></div>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>黑客马拉松 2019</title>
      <link href="/2019/04/12/person-emc-hackson-2019/"/>
      <url>/2019/04/12/person-emc-hackson-2019/</url>
      
        <content type="html"><![CDATA[<p>参加公司的hackathson 2019 获奖了。。。。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/person/hackson-2019.png" alt="hackson"></p>]]></content>
      
      
      <categories>
          
          <category> person </category>
          
      </categories>
      
      
        <tags>
            
            <tag> person </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>分布式系统架构设计三十六式之服务治理 – 第6式 - 5F容错模式</title>
      <link href="/2019/04/06/distributed-servicegovernance-failure-handling/"/>
      <url>/2019/04/06/distributed-servicegovernance-failure-handling/</url>
      
        <content type="html"><![CDATA[<h2 id="导读"><a href="#导读" class="headerlink" title="导读"></a><font color="#FF8C00">导读</font></h2><p>日拱一卒，功不唐捐，分享是最好的学习，一个知识领域里的 <font color="#00CED1"> <strong>“道 法 术 器”</strong> </font> 这四个境界需要从 <font color="#00CED1"> <strong>微观、中观以及宏观</strong> </font>三个角度来把握。微观是实践，中观讲套路，宏观靠领悟。本系列文章我把它命名为《分布式系统架构设计三十六式》，讲诉分布式系统里最重要的三十六个虚数的中观套路，而微服务的本质也是分布式，因此搞明白这三十六个最重要的知识点也就同时能搞明白微服务。</p><p>实现一个分布式系统通常会面临三大难题： <font color="#00CED1"> <strong>故障传播性、业务拆分与聚合以及分布式事务</strong> </font>。本系列中的服务治理章节主要是为了解决故障传播性的难题，它包括： <font color="#00CED1"> <strong>隔离、熔断、降级、限流、容错以及资源管控</strong> </font>，本文将讲诉服务治理里的 <font color="#00CED1"> <strong>“5F容错”</strong> </font>模式，下一篇将讲诉<font color="#00CED1"> <strong>“关联资源管控”</strong> </font>模式。</p><h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a><font color="#FF8C00">动机</font></h2><font color="#00CED1"> <strong>出错重试</strong>  </font>：在分布式系统里，系统里出现故障时需要进行出错处理，当执行熔断或降级处理策略时，通常也需要有相应的重试处理策略，而这些策略又需要根据不同的业务场景进行设计。<br><br><font color="#00CED1">  <strong>超时处理</strong>  </font>：在分布式系统里，为了保证高可用以及高可靠性，也需要相应的超时处理策略，比如超时后怎么重试？超时后重试几次还是失败应该怎么处理？超时处理是让用户感知还是不让用户感知?<br><br><br><br><font></font><h2 id="5F容错模式设计思路"><a href="#5F容错模式设计思路" class="headerlink" title="5F容错模式设计思路"></a><font color="#FF8C00">5F容错模式设计思路</font></h2><p>这里借用Dubbo里的概念讲述5种容错处理策略，我定义它们为5F容错法，下图是一个简单的分布式系统逻辑架构图。</p><div align="center"> <p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/failurehandling/failure-handling-five-solution.PNG" alt="容错模式"></p><div align="left"> <h3 id="Failover-失败切换"><a href="#Failover-失败切换" class="headerlink" title="Failover 失败切换"></a><font color="#00CED1">Failover 失败切换</font></h3><p>在分布式系统里，为了保证高可用性以及高可靠性，通常会对服务或者设备进行冗余，当一个服务或者设备出现故障时，就直接切换到另外一个服务或设备上，这种设计模式叫做 故障切换。</p><p>如上图所示，服务10本来是路由到服务20的，当服务20出现故障时，从服务10路由到服务20的请求，服务20并没办法处理，这时候服务10收到一个请求超时的返回，发现服务20没法处理这个请求，为了保证高可用性，服务10的请求就被路由到服务21，从而保证了服务的高可用与可靠性，这个过程用户是不感知的</p><h3 id="Failfast-快速失败"><a href="#Failfast-快速失败" class="headerlink" title="Failfast  快速失败"></a><font color="#00CED1">Failfast  快速失败</font></h3><p>快速失败是指当发现服务请求调用失败时，就立即上报故障，快速失败的一个重要目的是用于检测错误以便降低出错成本为系统提供足够的信息来保证高可用与高可靠，这个过程用户是感知的。</p><p>比如上图中服务20出现故障就快速上报故障给服务10，然后服务10就可以采用Failover策略将服务请求切换到服务21，从而避免更多的不可用时间。</p><h3 id="Failback-失败恢复"><a href="#Failback-失败恢复" class="headerlink" title="Failback 失败恢复"></a><font color="#00CED1">Failback 失败恢复</font></h3><p>Failback跟Failover有点类似，但是Failover是发现故障时就把请求切换到别的服务或设备上去，而Failback是在发现下游的故障后，把请求扔到一个临时的设备或者服务或者组件（比如队列）上，然后待下游故障修复后，重新同步数据以及请求，把这些数据或者请求还原到原来的服务或者设备上。比如上图所示，在服务20出现故障后，服务10发过来的请求被放到一个临时的队列里，然后在服务20在一定的时间内被恢复后，又把这些请求从队列中恢复发到服务20，这个过程用户时不感知的。</p><h3 id="Failsafe-失败安全"><a href="#Failsafe-失败安全" class="headerlink" title="Failsafe 失败安全"></a><font color="#00CED1">Failsafe 失败安全</font></h3><p>FailSafe 是指系统出现故障时可以直接忽略这个故障，不进行相应的故障处理，在Failsafe的场景下，故障不会给系统带来伤害，对服务质量也不会有什么影响，简单的处理方式就是把故障的信息写到日志里保存。</p><h3 id="Forking-请求分叉"><a href="#Forking-请求分叉" class="headerlink" title="Forking 请求分叉"></a><font color="#00CED1">Forking 请求分叉</font></h3><p>在Forking策略下，将请求进行裂变下发，只要一个请求处理成功整体请求就成功。比如上图所示，一个读请求到网关后被分裂成同样的请求三份，然后这三个请求被下发到服务10，11，12，只要有一个请求处理成功就返回成功。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font color="#FF8C00">小结</font></h2><p>本文讲诉了服务治理里的 <font color="#00CED1"><strong>“5F容错”</strong></font>模式，内容也没有多少，但是需要应用合适保证服务质量却并不容易，在应用的时候一般会根据实际的业务场景进行策略组合使用，在前一篇《分布式系统架构设计三十六式之服务治理-横向限流模式》里讲诉了分布式系统服务治理的横向限流模式。另作者能力与认知都有限，欢迎大家拍砖留念。</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中科大硕，10年+数据相关经验，主要工作背景为分布式系统、存储、缓存、微服务、云计算以及大数据，现就职于DELL EMC。个人技术博客：<a href="https://changping.me" target="_blank" rel="noopener">https://changping.me</a></p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a> ，可以自由阅读、分享、转发、复制、分发等，限制是需署名、非商业使用（以获利为准）以及禁止演绎。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a><font color="#FF8C00">参考资料</font></h2><p>[1]<a href="http://dubbo.apache.org/zh-cn/docs/source_code_guide/cluster.html" target="_blank" rel="noopener">http://dubbo.apache.org/zh-cn/docs/source_code_guide/cluster.html</a></p></div></div>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>分布式系统架构设计三十六式之服务治理 – 第5式 - 横向限流模式</title>
      <link href="/2019/03/30/distributed-servicegovernance-flowcontrol-2/"/>
      <url>/2019/03/30/distributed-servicegovernance-flowcontrol-2/</url>
      
        <content type="html"><![CDATA[<h2 id="导读"><a href="#导读" class="headerlink" title="导读"></a><font color="#FF8C00">导读</font></h2><p>日拱一卒，功不唐捐，分享是最好的学习，一个知识领域里的 <font color="#00CED1"> <strong>“道 法 术 器”</strong> </font> 这四个境界需要从 <font color="#00CED1"> <strong>微观、中观以及宏观</strong> </font>三个角度来把握。微观是实践，中观讲套路，宏观靠领悟。本系列文章我把它命名为《分布式系统架构设计三十六式》，讲诉分布式系统里最重要的三十六个虚数的中观套路，而微服务的本质也是分布式，因此搞明白这三十六个最重要的知识点也就同时能搞明白微服务。</p><p>实现一个分布式系统通常会面临三大难题： <font color="#00CED1"> <strong>故障传播性、业务拆分与聚合以及分布式事务</strong> </font>。本系列中的服务治理章节主要是为了解决故障传播性的难题，它包括： <font color="#00CED1"> <strong>隔离、熔断、降级、限流、容错以及资源管控</strong> </font>，本文将讲诉服务治理里的 <font color="#00CED1"> <strong>“限流-横向限流”</strong> </font>模式，下一篇将讲诉<font color="#00CED1"> <strong>“容错”</strong> </font>模式。</p><h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a><font color="#FF8C00">动机</font></h2><p>上一篇文章讲诉了纵向限流，那么为什么还需要横向限流呢？如下图所示：</p><div align="center"> <p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/flowcontrol/flow-control-distributed-qos-0.png" alt="流量控制"></p><div align="left"> <font color="#00CED1"> <strong>解决限流不均匀问题</strong> </font>: 如上图所示纵向限流只解决了网关-服务1，网关-服务2，网关-服务N的纵向路径的限流问题，但是并没有解决 这几个服务路径的限流是否均匀的问题，比如在某些情况下，网关-服务1 QPS 是 200，网关-服务2 QPS是 500,网关-服务N QPS 是 20，但是服务1-服务N的配置都是一样的，很明显，这里的限流并不均匀。<br><br><font color="#00CED1"> <strong>更细粒度的用户/租户的限流问题</strong> </font>: 如上图所示，用户1-用户N都发请求到网关，但是想限制每个用户可以进入系统的请求的个数，这里纵向限流并没有办法统计并控制每个用户的可以进入系统的请求数，纵向限流只能限制整体的进入网关的请求数，因此需要一个计数中心用于登记每个用户的请求数，从而进行更细粒度的流量控制，控制每个用户的请求数。<br><br><br><font></font><h2 id="横向限流模式"><a href="#横向限流模式" class="headerlink" title=" 横向限流模式 "></a><font color="#FF8C00"> 横向限流模式 </font></h2><p>如下图，通常采用一个类似配置中心或分布式事务中心的方式实现横向限流。</p><div align="center"> <p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/flowcontrol/flow-control-distributed-qos-3.png" alt="限流中心"></p><div align="left"> <ul><li><p>如左图所示，将集群限流服务中心实现在一个网关实例里，与网关一起提供服务，好处是无需再独立部署一个限流实例，缺点是网关如果挂掉，那么限流服务也会一起挂掉，而且无法对网关进行横向限流，只实现了网关底下的服务的横向限流；</p></li><li><p>如右图所示，独立拉起一个集群限流服务中心实例，用于提供全局限流计数服务，好处是与业务解耦，缺点是在集群内增加了一个额外的服务实例，增加了系统复杂度。</p></li></ul><h2 id="横向限流模式设计思路"><a href="#横向限流模式设计思路" class="headerlink" title="横向限流模式设计思路"></a><font color="#FF8C00">横向限流模式设计思路</font></h2><p>常用的横向限流算法有计数算法以及时间标签算法。</p><h3 id="计数算法"><a href="#计数算法" class="headerlink" title=" 计数算法 "></a><font color="#00CED1"> 计数算法 </font></h3><p>如图所示，独立的限流服务中心，拉起一个独立的分布式配置中心/事务中心，在里头实现限流算法，比如固定窗口算法、滑动窗口算法、漏桶算法、令牌桶算法等用于全局计数，而且保证这个计数是全局唯一的，不管集群规模多大，保证每个服务所使用的计数器和计时器都是唯一的，服务拿到这个计数ID后在进行限流调度。</p><p><div align="center"><br> <img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/flowcontrol/flow-control-distributed-qos-1.png" alt="全局限流算法"></div></p><div align="left"> <ul><li><p>CP模式：采用独立的限流中心，如果每个用户进入系统的请求都需要去远程的限流服务中心取一个计数返回，这就多了一个远程读取限流计数值的过程，很明显增加的这一步会影响请求的性能，但是在某些对限流可靠性比较苛刻的场景里，这是以牺牲请求性能的方式换取限流的可靠性；</p></li><li><p>AP模式：计数还是在限流服务中心，但在本地维护了一个限流计数的缓存，这样每个用户进来的请求并不是去远程读取计数值，而是直接在本地获取限流计数，而这个限流计数是通过一个独立的调度线程维护着的，这里这个本地的限流计数与远程限流服务中心的限流计数是不保证一致性的，这种方式牺牲了限流的可靠性，但是保证了请求的性能，在对限流要求不是很苛刻的场景下比较合适，而且配合纵向限流，还是可以解决绝大部分的系统的限流调度问题的。</p></li></ul><h3 id="时间标签算法"><a href="#时间标签算法" class="headerlink" title=" 时间标签算法 "></a><font color="#00CED1"> 时间标签算法 </font></h3><p>计数算法只是实现了限制用户或者服务请求量的最大值，并不能提供最小值保障，因此基于时间标签的算法被提出，例如DMCLOCK算法[1]。<br>在dmclock算法里，不只实现了限流，还实现了用户权重的划分以及最小值的预留。</p><p>例如在云服务里，用户1与用户2，付费不一样，因此给提供的最大限流上限是不一样的，但是采用计数限流算法，并不能保证付费多的用户就一定能得到最低的服务质量保证，在系统负载高的时候，付费高的用户与付费低的用户一样难以得到服务资源保底，这是不合理的，因此需要一个可以预留资源的算法。如下图所示，系统里流量资源的调度可以按<font color="#00CED1"> <strong>“预留、权重、上限”</strong> </font>这三个维度进行调度。</p><p><div align="center"><br> <img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/flowcontrol/flow-control-distributed-qos-2.png" alt="流量预留"></div></p><div align="left"> <p>例如，在时间标签算法里， 有三个用户：user1, user2,user3 根据付费的高低，给他们分别分配了不同的权重与预留值。如果系统里最大的QPS资源量是 4000，用户1与拥护2的QPS预留值是 1000，权重比例是 1：2：3.那么应当如何分配这些QPS资源？ 按dmclock算法可以这样计算：</p><p>用户1 ： (4000/(1+2+3)) <em> 1 =  667 &lt; 1000,但是保底的QPS是1000，因此分配了1000 QPS 给用户1.<br>用户2：( (4000-800) / (2+3)) </em> 2 = 1200 QPS<br>用户 3：4000-1200 – 667 = 2133 QPS        </p><p>基本的计算思路是，先保证最低的预留值，再根据权重划分剩下的资源，并且保证不要超过最大值。</p><h2 id="算法实践"><a href="#算法实践" class="headerlink" title="算法实践"></a><font color="#FF8C00">算法实践</font></h2><ul><li><p>通常如非必要或者业务场景要求苛刻，纵向限流就够，实现横向限流会引入新的组件，增加复杂度，同时还影响系统性能；</p></li><li><p>如果必须实现横向限流，那么性能要求高就采用AP模式，限流可靠性要求高就采用 CP模式；</p></li><li><p>权衡利弊，根据业务场景合理组合纵向限流与横向限流，才是最佳实践。</p></li></ul><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font color="#FF8C00">小结</font></h2><p>本文讲诉了服务治理里的 <font color="#00CED1"><strong>“横向限流”</strong></font>模式，在前一篇《分布式系统架构设计三十六式之服务治理-纵向限流模式》里讲诉了分布式系统服务治理的纵向限流模式。另作者能力与认知都有限，欢迎大家拍砖留念。</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中科大硕，10年+数据相关经验，主要工作背景为分布式系统、存储、缓存、微服务、云计算以及大数据，现就职于DELL EMC。个人技术博客：<a href="https://changping.me" target="_blank" rel="noopener">https://changping.me</a></p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a> ，可以自由阅读、分享、转发、复制、分发等，限制是需署名、非商业使用（以获利为准）以及禁止演绎。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a><font color="#FF8C00">参考资料</font></h2><p>[1]<a href="https://github.com/ceph/dmclock" target="_blank" rel="noopener">https://github.com/ceph/dmclock</a></p></div></div></div></div></div></div>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>分布式系统架构设计三十六式之服务治理 – 第4式 - 纵向限流模式</title>
      <link href="/2019/03/24/distributed-servicegovernance-flowcontrol-1/"/>
      <url>/2019/03/24/distributed-servicegovernance-flowcontrol-1/</url>
      
        <content type="html"><![CDATA[<h2 id="导读"><a href="#导读" class="headerlink" title="导读"></a><font color="#FF8C00">导读</font></h2><p>日拱一卒，功不唐捐，分享是最好的学习，一个知识领域里的 <font color="#00CED1"> <strong>“道 法 术 器”</strong> </font> 这四个境界需要从 <font color="#00CED1"> <strong>微观、中观以及宏观</strong> </font>三个角度来把握。微观是实践，中观讲套路，宏观靠领悟。本系列文章我把它命名为《分布式系统架构设计三十六式》，讲诉分布式系统里最重要的三十六个虚数的中观套路，而微服务的本质也是分布式，因此搞明白这三十六个最重要的知识点也就同时能搞明白微服务。</p><p>实现一个分布式系统通常会面临三大难题： <font color="#00CED1"> <strong>故障传播性、业务拆分与聚合以及分布式事务</strong> </font>。本系列中的服务治理章节主要是为了解决故障传播性的难题，它包括： <font color="#00CED1"> <strong>隔离、熔断、降级、限流、容错以及资源管控</strong> </font>，本文将讲诉服务治理里的 <font color="#00CED1"> <strong>“限流-纵向限流”</strong> </font>模式，下一篇将讲诉<font color="#00CED1"> <strong>“限流-横向限流”</strong> </font>模式。</p><h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a><font color="#FF8C00">动机</font></h2><font color="#00CED1"> <strong>可靠性</strong> </font>： 在分布式系统里，每个系统都有自己的容量限制，它所能处理的业务请求能力是有限的，如果不控制这些输入的请求数，突发输入过多的请求量会造成过度的资源竞争从而引发系统故障降低系统的可靠性。<br><br><font color="#00CED1"> <strong>可用性</strong> </font>： 限流有利于控制系统资源的消耗速率有利于过载保护，有利于保护业务资源不被耗尽。例如，当服务A所依赖的下游服务B由于某种原因不稳定、响应增加、延迟增加，对于调用者服务A意味着吞吐量下降和更多的资源占用，极端情况下甚至导致资源耗尽造成服务可用性故障。<br><br><font color="#00CED1"> <strong>流量监管</strong> </font>： 流量监管就是对输入的请求流量进行细粒度的控制，通过监管输入的请求量速率，对超出的部分进行”惩罚”， 比如直接丢弃，使得进入系统里的请求量被限制在一个系统所能承受的合理的范围之内，流量监管比较适合对延时要求较高的业务。<br><br><font color="#00CED1"> <strong>流量整形</strong> </font>： 流量整形就是控制最大输出请求速率提供可能，以确保请求量符合系统容量配置的最大传输速率规定。请求的流量被整形，以使它符合下游服务的速率需求，流量整形比较适合可靠性要求较高的业务。<br><br><font></font><h2 id="限流限的是什么"><a href="#限流限的是什么" class="headerlink" title=" 限流限的是什么 "></a><font color="#FF8C00"> 限流限的是什么 </font></h2><p>限流其原理是监控输入的请求量，当达到指定的阈值时对量进行控制，以避免系统被瞬时的请求量高峰冲垮，从而保障系统的高可用、高可靠。因此，限流的限的自然是“流”，对于不同的场景“流”是不同的：</p><ul><li>网络限流，流指的是带宽、流量；</li><li>I/O限流的“流”指的是TPS或QPS；</li><li>并发限流的“流”指的是并发请求数；</li><li>线程资源限流的“流”指的是线程数。</li></ul><p>这些“流” 通常具有资源竞用性、延迟性、抖动性以及不可靠性的特征。资源竞用性以及不可靠性需要控制流的资源使用，延迟性、抖动性需要对“流”进行整形，削峰填谷，控制请求的指标波形图。</p><h2 id="限流处理策略"><a href="#限流处理策略" class="headerlink" title="限流处理策略"></a><font color="#FF8C00">限流处理策略</font></h2><ul><li><p>直接拒绝：当请求量超过阈值后，新的请求就会被直接拒绝，方式为直接返回或者抛出异常。这种方式比较适合于对分布式系统的负载容量已知的情况下，比如通过全链路压测已经确定了准确的系统处理能力及系统容量，对应固定窗口、滑动窗口算法。</p></li><li><p>冷启动：当分布式系统长期处于低负载的情况下，请求量突发时，会把系统负载很快拉到很高的水准，这样就可能瞬间就把系统击垮。通过”冷启动”方式，让输入的请求量缓慢增加，在一个时间段内慢慢增加到系统所能承载的阈值上限，给冷系统一个预热的时间，避免系统被压垮，对应令牌桶算法。</p></li><li><p>匀速排队：匀速排队的方式也就是控制请求以均匀的速率通过，对应的是漏桶算法。</p></li></ul><h2 id="限流模式设计思路"><a href="#限流模式设计思路" class="headerlink" title="限流模式设计思路"></a><font color="#FF8C00">限流模式设计思路</font></h2><p>如下图所示，在分布式系统里，限流通常可以按空间维度划分为纵向限流以及横向限流，本文讲述纵向限流，下一篇将讲诉 横向限流。</p><div align="center"> <p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/flowcontrol/flow-control.png" alt="流量控制"></p><div align="left"> <p>常用的纵向限流算法有两窗算法：固定窗口、滑动窗口以及两桶算法：令牌桶算法、漏桶算法，按其工作原理又可以划分为 保险丝模式以及变压器模式。</p><h2 id="保险丝模式"><a href="#保险丝模式" class="headerlink" title="保险丝模式"></a><font color="#FF8C00">保险丝模式</font></h2><p>在电路中保险丝主要是起电流过载保护作用，当电路中的电流过载时，保险丝自身就会烧坏从而切断电流，保护后续电路的安全运行，但是保险丝有个问题就是在切断电流后，需要人工或者自动更换保险丝后，电路才能继续运行。</p><p>限流算法里的固定窗口算法以及滑动窗口算法应用原理与此类似，在拒绝请求后，需要重新设置计数，因此我定义它们为限流保险丝模式。</p><h3 id="固定窗口"><a href="#固定窗口" class="headerlink" title="固定窗口"></a><font color="#00CED1">固定窗口</font></h3><p>固定窗口算法类似人工保险丝模式，在切断流量后需要等很久才能重新工作。固定窗口算法将时间线划分成一个个固定大小的时间窗口，并且每个窗口都有一个计数器用于统计这一时间窗口内的访问次数，如果访问的次数超过了一个预先定义的阈值，则拒绝接下来的请求直到下一个时间窗口开始重新计数，又超过则继续拒绝，再在下一个时间窗口重新设置计数器继续计数，依次类推。</p><div align="center"> <p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/flowcontrol/flow-control-fixedwindow.png" alt="固定窗口"></p><div align="left"> <p>如上图所示，如果我们将时间线的窗口大小设置为5秒，上图里的窗口有[0, 5), [5, 10), …。假设限制是每5秒500个请求，如果在这个5秒内 计数器没超过 500就继续，超过500就拒绝后续的请求进入，直到下一个[5,10]的时间窗口内计数器被重新置0 再继续开始计数服务，再超过500，就继续拒绝服务，依次类推。</p><p>很明显，固定窗口的优点很明确，那就是实现很简单，一个计数器就可以实现。但是缺点也很明显，例如：</p><ol><li><p>边界场景，在第一个[0,5]的时间窗口内，第1秒就把计数器打到超过500，则后续的4秒将无法服务，得等到下一个[5,10]的时间窗口内计数器被重新置0，才可以对外提供服务。</p></li><li><p>跨窗口场景，当在第一个时间窗口的 [4,5]计数器的计数是300，没有超过阈值，然后第二个时间窗口的[5,6]计数器是320，也没超过阈值，但是 在 [4,6]的时间窗口内计数器的计数是 300+320=620,很明显超过阈值，因此，固定窗口的缺陷也很明显。</p></li></ol><h3 id="滑动窗口"><a href="#滑动窗口" class="headerlink" title="滑动窗口"></a><font color="#00CED1">滑动窗口</font></h3><p>滑动窗口算法类似自动保险丝模式，在切断流量不像固定窗口那样需要等较长的时间才能重新工作。滑动窗口的计数器也类似固定窗口的计数器，但是将时间线做了进一步的细分，每次往后移动一个细分单元，再每一次都对一个小的窗口进行计数统计实现流量控制，这种方法可以很好的解决之前的固定窗口的跨窗口问题。</p><div align="center"> <p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/flowcontrol/flow-control-slidewindow.png" alt="滑动窗口"></p><div align="left"> <p>如上图所示，还是定义请求的阈值为500，我们将[0,5]划分为5个窗口，则每个窗口对应1s。假设还是在[4,5]有300个请求和下一秒的[5,6]有320个突发请求，按照滑动窗口的原理，此时统计的将是[1,6]窗口，很明显 300+320=620 &gt; 500，超出了阈值，从而触发拒绝服务，避免了固定窗口算法的请求量突增的问题。</p><p>但是对于边界场景，例如[0,5]秒的窗口内，因为是按1s的时间单元进行窗口划分的，假设在第1ms的时间内，请求就超过500，然后就拒绝服务，然后需要等到下一个1s才可以继续出发服务，这很明显有59ms的时间窗式不能提供服务的，因此体现出来请求的指标也不大平滑。</p><h2 id="变压器模式"><a href="#变压器模式" class="headerlink" title="变压器模式"></a><font color="#FF8C00">变压器模式</font></h2><p>因为保险丝模式都不能解决请求的边界问题，因此引出变压器模式，变压器是电路中将某一等级的电压或电流转换成另外一种同频率的电压或电流的设备，有利于稳流稳压。限流算法里的漏桶算法以及令牌桶算法工作原理与此类似，因此我定义它们为变压器模式。</p><h3 id="漏桶"><a href="#漏桶" class="headerlink" title="漏桶"></a><font color="#00CED1">漏桶</font></h3><div align="center"> <p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/flowcontrol/flow-control-leakybucket-1.png" alt="漏桶算法"></p><div align="left"> <p>上图显示了漏桶算法在流量整形和速率限制中的用法，突发的不均匀的请求到达后被扔到一个桶里，这个桶底下有个固定大小的孔，请求按固定大小稳定的输出。</p><div align="center"> <p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/flowcontrol/flow-control-leakybucket-2.png" alt="漏桶算法"></p><div align="left"> <p>如上图所示，漏桶算法工作步骤：</p><ul><li>请求随意的被输入，有突发的请求量也有比较小的请求量，有快的请求也有慢的请求，然后这些请求进入系统后不是立马被处理，而是被扔到一个桶里；</li><li>当桶里缓冲的请求超过设定的水位时，输入的请求将被拒绝进入，从而丢失的后续请求</li><li>这个桶以恒定的速率将输入的请求输出；</li><li>对比窗口算法，漏桶算法多了一个缓冲。</li></ul><p>优点：</p><ul><li>漏桶算法里，桶的存在有利于削峰填谷，且输出总是按恒定的速率输出的，因此有利于流量整形，从而平滑了突发的请求量。</li></ul><p>缺点：</p><ul><li><p>很明显，漏桶里的请求超过水位后，后续请求会被丢弃，在需要保证幂等性请求的场景不适合使用。</p></li><li><p>漏桶总是按恒定速率输出请求，这是在假设后续的服务能承接这个速率的前提下的，它无法保证这些输出的请求能够稳定地在一个固定的时间内处理完，假如后续的服务出现资源抢用，或者故障，那么将无法处理这个很定的输出速率，从而引发更大的级联故障。</p></li></ul><p>如上图所示，如果服务2变慢，就会一直占用线程资源不释放，从而导致无法响应服务1的请求，而服务1还是以恒定的速率处理漏桶的请求，而其下游资源不够，因此也会引起级联故障。</p><h3 id="令牌桶"><a href="#令牌桶" class="headerlink" title="令牌桶"></a><font color="#00CED1">令牌桶</font></h3><p>下图显示了令牌桶的主要工作步骤：</p><div align="center"> <p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/flowcontrol/flow-control-tockenbucket.png" alt="令牌桶算法"></p><div align="left"> <p>如上图所示，令牌桶算法工作步骤：</p><ul><li>在这个桶中有按一定时间周期定期生成的令牌，令牌按预先定义的时间周期进行填充；</li><li>令牌桶有最大的令牌个数限制；</li><li>如果请求到来时，必须从令牌桶中取得令牌，之后才可以对这个请求进行处理，并且从令牌桶中删除这个被获取的令牌；</li><li>如果令牌桶中没有令牌，则无法发送请求，请求必须稍后重试。</li></ul><p>优点</p><ul><li>如果令牌桶中令牌已满，则丢令牌而不是丢请求。</li><li>可以支持突发的请求。</li></ul><p>缺点</p><ul><li>令牌被耗光后需要等下一次令牌填充，这意味着需要等待一段时间令牌填充后后续请求才可以使用。</li><li>对请求的处理速率没做限制，这意味着输入的请求处理速率有可能高过设置的阈值从而引发故障。</li></ul><h3 id="漏桶VS令牌桶-3"><a href="#漏桶VS令牌桶-3" class="headerlink" title="漏桶VS令牌桶[3]"></a><font color="#00CED1">漏桶VS令牌桶[3]</font></h3><ul><li><p>漏桶算法控制输出的请求量，输入的请求量可以变化，但输出的请求量保持恒定不变。令牌桶算法控制输入的令牌量，但不限制输出的请求量，输出的请求量可以根据突发的大小而变化。</p></li><li><p>漏桶算法不依赖令牌。令牌桶算法是令牌依赖的。</p></li><li><p>在漏桶算法中，如果桶已满，则丢弃请求。在令牌桶中，如果桶已满，则丢弃令牌但不会丢弃该请求。</p></li><li><p>在漏桶中，请求不断被输出。在令牌桶中，只有在拿到令牌时请求才能通过。</p></li><li><p>漏桶以恒定速率发送请求。令牌桶允许在恒定速率之后以更快的速率发送突发请求。</p></li></ul><h2 id="算法实践"><a href="#算法实践" class="headerlink" title="算法实践"></a><font color="#FF8C00">算法实践</font></h2><ul><li><p>固定窗口与滑动窗口实现都比较简单，性能较好，但是在超出限流阈值后，请求都会被直接拒绝，因此适用于非幂等性的请求场景；</p></li><li><p>漏桶算法，有利于控制输出的请求速率，但是在超出桶的水位后请求也会被丢失，也不适用于幂等性请求的场景;</p></li><li><p>令牌算法，可以支持突发的请求量，但是不控制输出的请求速率，在超出阈值后，只丢失令牌但不丢失请求，因此可以结合在幂等性请求的场景使用;</p></li><li><p>权衡利弊，根据业务场景合理组合以上4个算法，才是最佳实践。</p></li></ul><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font color="#FF8C00">小结</font></h2><p>本文讲诉了服务治理里的 <font color="#00CED1"><strong>“纵向限流”</strong></font>模式，在前一篇《分布式系统架构设计三十六式之服务治理-降级模式》里讲诉了分布式系统服务治理的降级模式。另作者能力与认知都有限，欢迎大家拍砖留念。</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中科大硕，10年+数据相关经验，主要工作背景为分布式系统、存储、缓存、微服务、云计算以及大数据，现就职于DELL EMC。个人技术博客：<a href="https://changping.me" target="_blank" rel="noopener">https://changping.me</a></p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a> ，可以自由阅读、分享、转发、复制、分发等，限制是需署名、非商业使用（以获利为准）以及禁止演绎。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a><font color="#FF8C00">参考资料</font></h2><p>[1]<a href="https://tech.domain.com.au/2017/11/protect-your-api-resources-with-rate-limiting" target="_blank" rel="noopener">https://tech.domain.com.au/2017/11/protect-your-api-resources-with-rate-limiting</a><br>[2]<a href="https://github.com/alibaba/Sentinel/wiki/%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6" target="_blank" rel="noopener">https://github.com/alibaba/Sentinel/wiki/%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6</a><br>[3]<a href="https://www.quora.com/What-is-the-difference-between-token-bucket-and-leaky-bucket-algorithms" target="_blank" rel="noopener">https://www.quora.com/What-is-the-difference-between-token-bucket-and-leaky-bucket-algorithms</a><br>[4]<a href="https://en.wikipedia.org/wiki/Rate_limiting" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Rate_limiting</a><br>[5]<a href="https://en.wikipedia.org/wiki/Bandwidth_throttling" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Bandwidth_throttling</a><br>[6]<a href="https://en.wikipedia.org/wiki/Bandwidth_management" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Bandwidth_management</a><br>[7]<a href="https://en.wikipedia.org/wiki/Token_bucket" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Token_bucket</a><br>[8]<a href="https://en.wikipedia.org/wiki/Leaky_bucket" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Leaky_bucket</a></p></div></div></div></div></div></div></div></div></div></div></div></div>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>分布式系统架构设计三十六式之服务治理 – 第3式 -  降级模式</title>
      <link href="/2019/03/21/distributed-servicegovernance-degraded/"/>
      <url>/2019/03/21/distributed-servicegovernance-degraded/</url>
      
        <content type="html"><![CDATA[<h2 id="导读"><a href="#导读" class="headerlink" title="导读"></a><font color="#FF8C00">导读</font></h2><p>日拱一卒，功不唐捐，分享是最好的学习，一个知识领域里的 <font color="#00CED1"> <strong>“道 法 术 器”</strong> </font> 这四个境界需要从 <font color="#00CED1"> <strong>微观、中观以及宏观</strong> </font>三个角度来把握。微观是实践，中观讲套路，宏观靠领悟。本系列文章我把它命名为《分布式系统架构设计三十六式》，讲诉分布式系统里最重要的三十六个虚数的中观套路，而微服务的本质也是分布式，因此搞明白这三十六个最重要的知识点也就同时能搞明白微服务。</p><p>实现一个分布式系统通常会面临三大难题： <font color="#00CED1"> <strong>故障传播性、业务拆分与聚合以及分布式事务</strong> </font>。本系列中的服务治理章节主要是为了解决故障传播性的难题，它包括： <font color="#00CED1"> <strong>隔离、熔断、降级、限流、容错以及资源管控</strong> </font>，本文将讲诉服务治理里的 <font color="#00CED1"> <strong>“降级”</strong> </font>模式。</p><h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a><font color="#FF8C00">动机</font></h2><ol><li><p>某些时候系统会遇到负载过高的问题，当系统外来的或内部的负载过高超过预先定义的阈值，为了保证更重要的更紧急的业务的服务质量，希望将一些非核心的、不紧急的业务降低服务质量，从而释放一些额外的资源给紧急业务使用。比如一个分布式系统里的读、写、数据校验、空间回收都比较消耗资源，在白天为了保证读和写的服务质量，可以把数据校验的服务通过限流或减少线程数之类的方式使得可以调用的资源配额减少，从而释放部分资源给读和写使用，保证读写的服务质量。同样在读和写业务不繁忙的时候，降低读和写的资源配额，从而释放资源给空间回收使用，通过这种方式动态调整局部业务的服务质量从而保证关键业务的服务质量，提升用户体验。</p></li><li><p>在云服务里“可用性”指标是一个非常重要的SLA指标，在可用性出现不达标的情况下需要根据SLA进行赔偿，因此，我们希望分布式系统不管出现怎么样的故障，比如服务器故障，磁盘故障，网络故障都能保持可用性，起码要保证单点故障不会造成系统故障，比如，在系统出现严重故障的时候，可以停止负载较高的写操作从而保证“读”或者“查询“服务。</p></li></ol><h2 id="降级模式"><a href="#降级模式" class="headerlink" title="降级模式"></a><font color="#FF8C00">降级模式</font></h2><p>从故障处理角度来讲，服务降级简单来说就是这一功能或服务直接不能用，而在动态调整系统整体的服务质量的时候，降级是降低某些当前非重要或非核心业务的资源，从而释放部分资源给重要的或紧急的业务使用。</p><p>在故障处理的时候，对比“熔断”，降级是更严重的故障处理方式，最后拿来兜底用的。比如某个功能出故障，“熔断”是不管怎么样，都希望这个功能还能救活，降级是发现试着救了几次发现还是救不活，就下狠心砍掉这个部分，断臂求生，起码要保证整体是活的，这样整体还有救活的希望。</p><p>从系统的角度来说降级有 读功能降级，写功能降级以及级联组件降级，还有自动降级或者人工降级。比如，在云服务里，为了保证高可用性，在出现系统级的故障后，可以把写功能降级，就是这个服务只能读，只能查询不能写了，因此在设计的比较好的云服务里，按时间的维度来度量可用性已经没有太大的意义，因为不管怎么样它都是服务可用的，系统都是活着的，起码部分服务可用，因此在云服务里更合理的新的衡量可用性的指标方式是请求失败比率。</p><h2 id="降级模式设计思路"><a href="#降级模式设计思路" class="headerlink" title="降级模式设计思路"></a><font color="#FF8C00">降级模式设计思路</font></h2><h3 id="降级触发策略"><a href="#降级触发策略" class="headerlink" title="降级触发策略"></a><font color="#00CED1">降级触发策略</font></h3><ul><li>超时降级：在超时重试的次数达到一个阈值后就触发降级；</li><li>失败比率降级：当某个服务的失败的比率达到一定比率后就开始降级；</li><li>系统故障降级：比如网络故障，硬盘故障，电源故障，服务器故障，数据中心故障等；</li><li>限流降级：某些访问量太大的场景会触发限流，当达到限流阈值后，请求也会被降级；</li><li>重要业务救急降级：比如为了保证读或者查询的功能，降低写或者数据校验的资源配额，从而实现读服务的质量保证。</li></ul><h3 id="降级处理措施"><a href="#降级处理措施" class="headerlink" title="降级处理措施"></a><font color="#00CED1">降级处理措施</font></h3><ul><li>资源配额调度，调度不紧急的业务支援紧急的重要的业务；</li><li>抛出异常，直接抛出异常，打印出出错日志，然后就不管了，请求会丢失，这在需要保证幂等性的请求里不合适；</li><li>直接返回， 直接返回拒绝服务，这里请求也会丢失，这在需要保证幂等性的请求里不合适；</li><li>调用回退方法，调用出现服务降级时对应的业务处理逻辑，不同场景降级处理的逻辑不同，比如可以把请求再挂到等待队列里继续重试之类，这里需要根据业务场景合理设计回退方法；</li></ul><h3 id="降级分级策略"><a href="#降级分级策略" class="headerlink" title="降级分级策略"></a><font color="#00CED1">降级分级策略</font></h3><p>一般可以把降级的等级分为几个层次，比如P0级，P1级，P2级，P3级，级别越高表示问题越严重， 比如：</p><ol><li>重要业务救急降级可以定义为P0级降级，只是调度次要的资源去救急，并不会出现故障；</li><li>限流降级可以定义为P1级降级，只是为了保证服务质量，而且如果不限流可能会出现系统负载过高从而出现故障；</li><li>超时降级以及失败比率降级可以定义为P2级降级，出现小范围故障，触发P2级降级，保证小故障不蔓延不传播从而造成大范围的故障；</li><li>系统故障降级可以定义为P3级降级，系统出现大范围故障，从而触发P3级降级，比如，此时可以只保证最低资源的的读请求服务，写和其他业务全部被禁止。</li></ol><h3 id="配置中心"><a href="#配置中心" class="headerlink" title="配置中心"></a><font color="#00CED1">配置中心</font></h3><p>如下图所示是一个简单的配置中心物理架构图：</p><div align="center"> <p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/distributed-degraded-config-center.png" alt="配置中心"></p><div align="left"> <p>在分布式系统里每个服务的配置信息会给保存在一个配置中心里，这个配置中心里有每个服务的开关信息以及一些重要的资源配置信息。通过动态调整服务的配置信息，比如降级触发策略、降级处理措施、降级分级策略或者开关信息可以实现服务降级功能。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font color="#FF8C00">小结</font></h2><p>本文讲诉了服务治理里的 <font color="#00CED1"><strong>“降级”</strong></font>模式，在前一篇《分布式系统架构设计三十六式之服务治理-熔断模式》里讲诉了分布式系统服务治理的熔断模式。另作者能力与认知都有限，欢迎大家拍砖留念。</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中科大硕，10年+数据相关经验，主要工作背景为分布式系统、存储、缓存、微服务、云计算以及大数据，现就职于DELL EMC。</p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a><font color="#FF8C00">参考资料</font></h2><p>[1] <a href="https://medium.com/@felipedutratine/microservices-should-be-design-for-failure-b58bccdce0b6" target="_blank" rel="noopener">https://medium.com/@felipedutratine/microservices-should-be-design-for-failure-b58bccdce0b6</a></p><p>[2] <a href="https://blog.risingstack.com/designing-microservices-architecture-for-failure" target="_blank" rel="noopener">https://blog.risingstack.com/designing-microservices-architecture-for-failure</a></p></div></div>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>分布式系统架构设计三十六式之服务治理 – 第2式 - 熔断模式</title>
      <link href="/2019/03/16/distributed-servicegovernance-circuitbreaker/"/>
      <url>/2019/03/16/distributed-servicegovernance-circuitbreaker/</url>
      
        <content type="html"><![CDATA[<h2 id="导读"><a href="#导读" class="headerlink" title="导读"></a><font color="#FF8C00">导读</font></h2><p>日拱一卒，功不唐捐，分享是最好的学习，一个知识领域里的 <font color="#00CED1"> <strong>“道 法 术 器”</strong> </font> 这四个境界需要从 <font color="#00CED1"> <strong>微观、中观以及宏观</strong> </font>三个角度来把握。微观是实践，中观讲套路，宏观靠领悟。本系列文章我把它命名为《分布式系统架构设计三十六式》，讲诉分布式系统里最重要的三十六个虚数的中观套路，而微服务的本质也是分布式，因此搞明白这三十六个最重要的知识点也就同时能搞明白微服务。</p><p>实现一个分布式系统通常会面临三大难题： <font color="#00CED1"> <strong>故障传播性、业务拆分与聚合以及分布式事务</strong> </font>。本系列中的服务治理章节主要是为了解决故障传播性的难题，它包括：<font color="#00CED1"> <strong>隔离、熔断、降级、限流、容错以及资源管控</strong> </font>，本文将讲诉服务治理里的 <font color="#00CED1"> <strong>“熔断”</strong> </font>模式。</p><h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a><font color="#FF8C00">动机</font></h2><p>在分布式系统里经常会遇到这样的场景：</p><ol><li><p>系统负载突然过高，比如突发的访问量、过多的请求并发数以及过多的IO等都会造成某个节点故障，比如节点A，然后节点A挂了，又把负载转给节点B，然后节点B又负载过高，接着B又挂了，就这样一连串的挂过去从单点故障造成系统级的级联故障。</p></li><li><p>当一个服务出现故障时，希望这个服务能在一个时间段内恢复，在请求被拒绝后隔一段时间再自动的去探测服务的可服务性。</p></li></ol><p>对应这两个场景，我们希望在分布式系统里能避免级联故障、提供快速失败快速恢复服务的能力，因此，这里引出 <font color="#00CED1"><strong>“熔断模式”</strong></font> 。</p><h2 id="熔断模式"><a href="#熔断模式" class="headerlink" title="熔断模式"></a><font color="#FF8C00">熔断模式</font></h2><p>熔断模式也称之为断路器模式，英文单词是“circuit breaker”，“circuit breaker”是一个电路开关，其基本功能是检测到电流过载就中断电路，在检测到电流正常时又能自动或手动恢复工作，从而保护断路器背后的电源设备安全。这里需要将”断路器“与 “保险丝”进行区分，断路器可以通过手动或自动的复位从而恢复正常工作，而保险丝是运行一次必须更换。</p><p>实现一个分布式系统通常会面临三大难题： <font color="#00CED1"><strong>业务拆分与聚合，分布式事务以及故障传播性</strong></font>。本系列中的服务治理章节主要是为了解决故障传播性的难题，它包括：隔离、熔断、降级、限流、容错以及资源管控，本文将讲诉服务治理里的 <font color="#00CED1"><strong>“熔断”</strong></font>模式。</p><p>在分布式系统里 <font color="#00CED1"><strong>“熔断模式”</strong></font>的设计思想来源于此，当系统里响应时间或者异常比率或者异常数超过某个阈值时，比如超时次数或重试次数超过某个阈值就会触发熔断，接着所有的调用都快速失败，从而保证下游系统的负载安全，在断开一段时间后，熔断器又打开一点试着让部分请求负载通过，如果这些请求成功那么断路器就恢复正常工作，如果继续失败，则继续关闭服务走快速失败通道，接着继续这个过程直到重试的次数超过一定的阈值从而触发更为严重的<font color="#00CED1"><strong>“降级模式”</strong></font>。</p><h3 id="熔断模式设计思路"><a href="#熔断模式设计思路" class="headerlink" title="熔断模式设计思路"></a><font color="#00CED1">熔断模式设计思路</font></h3><p>下图是一个熔断模式的设计思路：</p><div align="center"> <p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/distributed-circuitbreaker.png" alt="熔断器"></p><p>图片来源于引文[2]，版权归原作者所有</p><div align="left"> <ol><li><p>首先熔断器是处于闭合（closed）状态的，如果请求超时次数，异常数或者异常比率超过一定的阈值则熔断器会被打开；</p></li><li><p>接着熔断器处于打开（Open）状态，所有走到这个路径里的请求会走快速失败通道从而避免负载下行，但是这里不会一直都是打开的，过一个时间周期会自动切换到半打开（Half-open）状态；</p></li><li><p>在接下来是半打开（half-open）状态，在这里认为之前的错误可能被修复了，因此允许通过部分请求试着看看能不能处理成功，如果这些请求处理成功，那么就认为之前导致失败的错误已被修复，此时熔断器就切换到闭合状态并且将错误计数器重置。如果这些试着发送的请求还是处理失败，则认为导致之前失败的问题仍然存在，熔断器切回到打开方式，然后开始重置计时器给系统一定的时间来修复错误。半打开状态能够有效防止正在恢复中的服务被突然而来的大量请求再次打挂；</p></li><li><p>接着重复以上过程，直到半打开状态重复的次数达到一定的阈值发现故障还没被修复，从而触发”降级“状态</p></li></ol><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font color="#FF8C00">小结</font></h2><p>本文讲诉了服务治理里的 <font color="#00CED1"><strong>“熔断”</strong></font>模式，在前一篇《分布式系统架构设计三十六式之服务治理-隔板模式》里讲诉了分布式系统服务治理的隔板模式。另作者能力与认知都有限，欢迎大家拍砖留念。</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中科大硕，10年+数据相关经验，主要工作背景为分布式系统、存储、缓存、微服务、云计算以及大数据，现就职于DELL EMC。</p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a><font color="#FF8C00">参考资料</font></h2><p>[1] <a href="https://en.wikipedia.org/wiki/Circuit_breaker" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Circuit_breaker</a></p><p>[2] <a href="https://martinfowler.com/bliki/CircuitBreaker.html" target="_blank" rel="noopener">https://martinfowler.com/bliki/CircuitBreaker.html</a></p></div></div>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>分布式系统架构设计36式之服务治理 – 第1式 - 隔板模式</title>
      <link href="/2019/03/10/distributed-servicegovernance-bulkhead/"/>
      <url>/2019/03/10/distributed-servicegovernance-bulkhead/</url>
      
        <content type="html"><![CDATA[<h2 id="导读"><a href="#导读" class="headerlink" title="导读"></a><font color="#FF8C00">导读</font></h2><p>日拱一卒，功不唐捐，分享是最好的学习，一个知识领域里的 <font color="#00CED1"> <strong>“道 法 术 器”</strong> </font> 这四个境界需要从 <font color="#00CED1"> <strong>微观、中观以及宏观</strong> </font>三个角度来把握。微观是实践，中观讲套路，宏观靠领悟。本系列文章我把它命名为《分布式系统架构设计三十六式》，讲诉分布式系统里最重要的三十六个虚数的中观套路，而微服务的本质也是分布式，因此搞明白这三十六个最重要的知识点也就同时能搞明白微服务。</p><p>实现一个分布式系统通常会面临三大难题： <font color="#00CED1"> <strong>故障传播性、业务拆分与聚合以及分布式事务</strong> </font>。本系列中的服务治理章节主要是为了解决故障传播性的难题，它包括： <font color="#00CED1"> <strong>隔离、熔断、降级、限流、容错以及资源管控</strong> </font>，本文将讲诉服务治理里的 <font color="#00CED1"> <strong>“隔板”</strong> </font>模式。</p><h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a><font color="#FF8C00">动机</font></h2><p>在分布式系统里通常将进程容器化以进行资源隔离，然后在同一个进程里的各种业务都共享线程池对外提供服务，这就经常会遇到这样的问题：</p><ol><li>业务A负载较高，抢占了线程池里的大部分线程资源，从而造成其他业务的服务质量下降；</li><li>同一个进程内新加入一个业务，这个业务会抢占其他业务的资源，从而造成系统的不稳定，比如业务性能抖动；</li><li>难以调试，比如同一个进程里的10个业务共享同一个线程池，当出现故障时难以通过简单的日志判断是哪个业务出了问题。</li></ol><p>因此，我们希望找出一个机制解决这样的问题。</p><h2 id="隔板模式"><a href="#隔板模式" class="headerlink" title="隔板模式"></a><font color="#FF8C00">隔板模式</font></h2><p>首先我来看一个英文单词“Bulkhead”，翻译成中文就是“舱壁”‘或“隔板”，在分布式系统里有个资源隔离的设计模式叫做”舱壁模式”或者“隔板模式”。</p><font color="#00CED1"><strong>模式来源:</strong></font> 通过万能的Wiki百科我们可以了解到轮船里的两个舱位之间的挡板就是隔板/舱壁（Bulkhead），如下图：<br><div align="center"><br><br><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/distributed-resource-isolation-1.jpg" alt="bulkhead"><br><br>图片来源于引文[1]，版权归原作者所有<br><br><div align="left"><br><br><br>在造船的时候，<font color="#FF0000">”船农们“（对应码农）</font>通常会把一个大的船舱用隔板分成N个小的空间，以便万一船体破裂或着火的时候，只有这个被分割开的小船舱受到影响，而其他的船舱是被隔离而不受影响的，从而提高整个船只的安全度。<br><br>同样这种隔板模式可以应用在分布式系统的资源隔离设计里，在分布式系统里，资源隔离通常按业务分为进程级别的隔离和线程级别的隔离，某些简单的服务质量要求不高的业务场景下实现进程级别的隔离就够了，但是在某些对服务质量要求较高的分布式场景下需要线程级别的细粒度隔离。<br><br><br><font></font><h3 id="进程隔离"><a href="#进程隔离" class="headerlink" title="进程隔离"></a><font color="#00CED1">进程隔离</font></h3><p>进程级别隔离通常指的是容器化隔离，比如通过使用docker实现业务进程之间的资源隔离。</p><h3 id="线程隔离"><a href="#线程隔离" class="headerlink" title="线程隔离"></a><font color="#00CED1">线程隔离</font></h3><p>线程级别隔离是指给每个跑在进程里的业务都按业务类型创建一个线程池，从而实现线程级别细粒度的资源隔离，线程隔离具有以下优势：</p><ol><li>提高业务可靠性，减少业务受其他业务影响的程度，当一个业务耗尽自身的线程资源后也不会影响另外一个业务的服务质量；</li><li>降低新加入的业务的给系统带来的风险，比如当前系统的一个进程用例中有10个业务。当新加入一个业务时，必然会抢占此前10个业务的线程资源，从而给系统带来不稳定，比如性能抖动；</li><li>利于调试，给每一个业务都分配一个线程池名称，当业务出故障时，通过线程池名称可以很方便地定位是哪个业务出了故障，并且通过监控线程池的请求失败次数、超时次数、拒绝请求次数等可以实时的反应当前业务服务质量。</li></ol><p>事物都有二元性，线程池隔离，有利自然也有弊，线程池隔离也会引入额外的一些开销，开销类型有：</p><ol><li>对象分配，每个调用都会实例化一个新的线程对象及其中的关联对象，占用系统资源；</li><li>并发，共享数据结构，计数器等，也占用系统资源；</li><li>线程的执行开销：切换，调度，执行，同样也占用资源。</li></ol><p>因此，线程池的隔离带来了好处但是也会引起一些顾虑，比如给每个业务都创建一个线程池是否会给系统带来太大的开销。通过Hystrix的数据分析可以得出结论是：<font color="#FF0000"><strong> “开销是有的，但是对比好处，通过权衡，其开销在一些要求不苛刻的场景可以忽略。”</strong></font></p><h2 id="线程池的开销分析"><a href="#线程池的开销分析" class="headerlink" title="线程池的开销分析"></a><font color="#FF8C00">线程池的开销分析</font></h2><p>Hystrix官网[3]，统计了线程池带来的开销成本，如下图表示在单个API实例上以60个请求/秒执行一个HystrixCommand：</p><div align="center"> <p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/distributed-resource-isolation-2.png" alt="Hystrix"></p><p>图片来源于引文[3]，版权归原作者所有</p><div align="left"> <p>通过分析这个统计图（注意不同的颜色），我们可以看到：</p><ol><li>中位数（P50）和更低的场景下，对比不使用线程池隔离模式，隔离线程池基本没有成本开销。</li><li>在P90的场景下，对比不使用线程池隔离模式，隔离线程池的耗时差距为3毫秒。</li><li>在P99的场景下，对比不使用线程池隔离模式，隔离线程池的耗时差距为9毫秒。</li></ol><p>但是从上图可以看出，成本增加的幅度远小于单独一个线程的执行时间增加的幅度，当未使用线程池隔离的线程执行时间从2ms跳到28ms时，线程池隔离的耗时成本从0ms跳到9ms。</p><p>因此，对于大多数的使用场景而言，在P90及以上的线程池隔离带来的开销被认为是可接受的，从而获得资源隔离带来的好处。</p><p>但是在某些场景这样的开销可能过高，比如缓存场景，在这种情况下，可以选用信号量来进行隔离，缺点是信号量不允许设置超时，难以实现熔断、降级之类的服务治理行为。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font color="#FF8C00">小结</font></h2><p>本文讲诉了服务治理里的 <font color="#00CED1"><strong>“隔板”</strong></font>模式，在下一篇将讲诉分布式系统服务治理的熔断模式。另作者能力与认知都有限，欢迎大家拍砖留念。</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中科大硕，10年+数据相关经验，主要工作背景为分布式系统、存储、缓存、微服务、云计算以及大数据，现就职于DELL EMC。</p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a><font color="#FF8C00">参考资料</font></h2><p>[1] <a href="https://en.wikipedia.org/wiki/Bulkhead_(partition)" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Bulkhead_(partition)</a></p><p>[2] <a href="http://writing.engr.psu.edu/uer/bassett.html" target="_blank" rel="noopener">http://writing.engr.psu.edu/uer/bassett.html</a></p><p>[3] <a href="https://github.com/Netflix/Hystrix/wiki/FAQ%20:%20General" target="_blank" rel="noopener">https://github.com/Netflix/Hystrix/wiki/FAQ%20:%20General</a></p></div></div></div></div>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ceph fileStore与blueStore架构简单对比</title>
      <link href="/2019/03/09/distributed-ceph-bluestore-filestore/"/>
      <url>/2019/03/09/distributed-ceph-bluestore-filestore/</url>
      
        <content type="html"><![CDATA[<h2 id="ceph逻辑架构图"><a href="#ceph逻辑架构图" class="headerlink" title=" ceph逻辑架构图  "></a><font color="#FF8C00"> ceph逻辑架构图  </font></h2><p>ceph后端支持多种存储引擎，以插件化的形式来进行管理使用，目前支持filestore，kvstore，memstore以及bluestore，目前默认使用的是filestore，但是目前bluestore也可以上生产。下图是ceph的逻辑架构图：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/ceph/distributed-ceph-blusetore-1.png" alt="ceph-bluestore"></p><p><strong>Firestore存在的问题是：</strong></p><ol><li><p>在写数据前需要先写journal，会有一倍的写放大；</p></li><li><p>若是另外配备SSD盘给journal使用又增加额外的成本；</p></li><li><p>filestore一开始只是对于SATA/SAS这一类机械盘进行设计的，没有专门针对SSD这一类的Flash介质盘做考虑。</p></li></ol><p><strong>而Bluestore的优势在于：</strong></p><ol><li><p>减少写放大；</p></li><li><p>针对FLASH介质盘做优化；</p></li><li><p>直接管理裸盘，进一步减少文件系统部分的开销。</p></li></ol><p>但是在机械盘场景Bluestore与firestore在性能上并没有太大的优势，bluestore的优势在于flash介质盘。</p><h2 id="FileStore逻辑架构"><a href="#FileStore逻辑架构" class="headerlink" title=" FileStore逻辑架构 "></a><font color="#FF8C00"> FileStore逻辑架构 </font></h2><p>下图为ceph filestore逻辑架构图：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/ceph/distributed-ceph-blusetore-2.png" alt="ceph-bluestore"></p><ol><li><p>首先，为了提高写事务的性能，FileStore增加了fileJournal功能，所有的写事务在被FileJournal处理以后都会立即callback(上图中的第2步)。日志是按append only的方式处理的，每次都是被append到journal文件末尾，同时该事务会被塞到FileStore op queue；</p></li><li><p>接着，FileStore采用多个thread的方式从op queue 这个 thread pool里获取op，然后真正apply事务数据到disk（文件系统pagecache）。当FileStore将事务落到disk上之后，后续的读请求才会继续(上图中的第5步)。</p></li><li><p>当FileStore完成一个op后，对应的Journal才可以丢弃这部分Journal。对于每一个副本都有这两步操作，先写journal，再写到disk，如果是3副本，就涉及到6次写操作，因此性能上体现不是很好。</p></li></ol><h2 id="Bluestore逻辑架构"><a href="#Bluestore逻辑架构" class="headerlink" title=" Bluestore逻辑架构 "></a><font color="#FF8C00"> Bluestore逻辑架构 </font></h2><p>下图为ceph bluestore逻辑架构图：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/ceph/distributed-ceph-blusetore-3.png" alt="ceph-bluestore"></p><ol><li><p>Bluestore实现了直接管理裸设备的方式，抛弃了本地文件系统，BlockDevice实现在用户态下使用linux aio直接对裸设备进行I/O操作，去除了本地文件系统的消耗，减少系统复杂度，更有利于Flash介质盘发挥性能优势；</p></li><li><p>为了惯例裸设备就需要一个磁盘的空间管理系统，Bluestore采用Allocator进行裸设备的空间管理，目前支持StupidAllocator和BitmapAllocator两种方式；</p></li><li><p>Bluestore的元数据是以KEY-VALUE的形式保存到RockDB里的，而RockDB又不能直接操作裸盘，为此，bluestore实现了一个BlueRocksEnv，继承自EnvWrapper，来为RocksDB提供底层文件系统的抽象接口支持；</p></li><li><p>为了对接BlueRocksEnv，Bluestore自己实现了一个简洁的文件系统BlueFS，只实现RocksDB Env所需要的接口，在系统启动挂在这个文件系统的时候将所有的元数据都加载到内存中，BluesFS的数据和日志文件都通过BlockDevice保存到底层的裸设备上；</p></li><li><p>BlueFS和BlueStore可以共享裸设备，也可以分别指定不同的设备，比如为了获得更好的性能Bluestore可以采用 SATA SSD 盘，BlueFS采用 NVMe SSD 盘。</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>pravega blog - pravega状态同步器</title>
      <link href="/2019/03/02/pravega-blog-exploring-state-synchronizer/"/>
      <url>/2019/03/02/pravega-blog-exploring-state-synchronizer/</url>
      
        <content type="html"><![CDATA[<p>Pravega允许使用状态同步器在集群中分布的多个协作进程中以一致的方式共享状态。本文详细介绍了如何使用State Synchronizer[1] 在分布式应用程序中构建和维护一致性。</p><h2 id="状态同步器"><a href="#状态同步器" class="headerlink" title="状态同步器"></a>状态同步器</h2><p>在分布式系统中，经常需要跨应用程序的多个实例共享状态。如果此信息位于数据路径上，则通常会通过适合应用程序的任何数据存储区。通常，我们会根据应用程序的要求仔细选择数据存储区。</p><p>当我们拥有需要由多个进程使用的状态时，例如架构注册表或与应用程序数据无关的集群成员资格，需要考虑替代存储选项，因为要求可能完全不同。元数据通常不能完全适合数据路径的模式或一致性模型。因此，拥有不同的存储解决方案通常是有意义, 有时，这一点的重要性被低估并作为事后的想法实施。</p><p>在Pravega中，当Reader Group用于读取事件时，我们遇到了类似的问题。在以前的文章中讨论的缩放，而不是读者如何协调会员和主机拥有什么样的数据。这是一个棘手的问题，所以我们需要提供一次语义。</p><p>我们开发了一个新模型：正在运行的应用程序的所有实例在内存中都具有相同的对象。它包含的数据完全由用户定义。它是一个普通的Java对象，除了它不是被普通方法修改，它就像一个状态机一样：每种可能的修改方法都有一个单独的类。这些类在运行时是可序列化的和确定的。该对象由State Synchronizer包装，它将确保所有主机以相同的顺序对其对象应用相同的更新。这样，对象在任何地方都保持相同。</p><p>这为现有解决方案无法很好处理的大量不同用例打开了大门。</p><h2 id="现有解决方案"><a href="#现有解决方案" class="headerlink" title="现有解决方案"></a>现有解决方案</h2><p>成员和领导者选举的常用解决方案是使用Apache ZooKeeper[1]。ZooKeeper适用于需要保持一致的共享状态。ZooKeeper几乎在每个数据中心的某个地方运行。</p><p>ZooKeeper的用户可以选择部署多个集合并在它们之间传播应用程序。这样做可以让我们提高整体容量，但不能以细粒度的方式。为了提高资源效率，有必要在同一个集合上执行多个任务，甚至可能跨越多个应用程序。一旦它们达到整体的容量，就不可能增加它或在其他地方迁移任务。</p><p>有许多存储系统在其API中提供了强大的一致性，并且内部依赖ZooKeeper来保持其内部元数据的一致性。这是一种常见模式，可以利用一个一致性点来创建另一个点。Pravega遵循这种模式。它在Segment [3] 上提供了强大的一致性，这是通过使用Apache BookKeeper [4] 提供的写屏障来保证的，而后者又使用ZooKeeper作为其元数据。</p><p>State Synchronizer更进一步，提供了一个抽象，其中Java对象可以在多台机器上保持一致，以便组中的所有成员即使在修改时也能看到相同的对象。</p><p>使用状态同步器，我们将更新存储在可以任意长的日志中，并确保始终存储和复制日志。应用程序逻辑负责了解更新并应用它们，从而将服务从执行部分中释放出来，使整个方法具有高度可扩展性。因此，Zookeeper是复制状态机的特定实现; State Synchronizer为实现任意复制状态机提供了基础。</p><p>Pravega使用状态同步器将数据与强一致性保证同步。具体来说，我们使用它来协调读者群中读者的行为，例如，跨读者分配流段。</p><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>Pravega的工作原理是将数据存储在第1层存储中，缓冲数据一段时间，然后将数据移动到第2层以进行长期存档。（参见 Pravega Internals博客）。然而，与大多数系统不同，它与（或甚至可以写入的系统）竞争，它提供了强大的一致性。在大多数系统中，一致性最终由ZooKeeper [14]锚定，即使它从未在数据路径（甚至大多数元数据路径）中使用。</p><p>这是可能的，因为一旦存在强一致性，就可以利用它来创建一个也提供一致性的更大系统。在State Synchronizer的情况下，它使用的事实是，在任何给定时间只有一个Pravega服务器可以更新Segment。因此，它可以在Segment上使用原子比较和设置操作来构建更高级别的抽象，同时保持较大应用程序的一致性。</p><p>可以跨各种进程使用State Synchronizer API [5]来对该对象执行更新。状态同步器确保对该对象的最新版本执行更新的每个进程。因此，对象在一个队列中协调，并且每个人在同一对象上看到相同的更新序列。</p><p>作为示例用例，在Pravega中，我们需要在读者组中协调读者的位置[6]。</p><p>可以将一组读取器组合在一起，以便可以并行读取流中的事件集。这组读者称为读者组。Pravega保证流中的每个事件都由读者组中的一个读取器读取。</p><p>有来自阅读器的地图列表段，并在这些段存储的偏移量。我们可以执行各种类型的更新：更新段的位置，在段拆分或合并 [7] 时用其后续替换段，或者通过将细分重新分配到不同的读取器来重新平衡。这些更新中的每一个仅在某些情况下才有意义。（读取器无法更新它不拥有的段的位置。只有在接收段的读取器处于联机状态时，重新平衡才有意义。）因此，虽然更新速率和数据不是很大，但数据需要保持一致。由于许多主机可以更新数据，因此没有任何明确的“所有者”。这使得这是使用状态同步器的完美案例（这就是我们的工作）。</p><h2 id="State-Synchronizer如何工作？"><a href="#State-Synchronizer如何工作？" class="headerlink" title="State Synchronizer如何工作？"></a>State Synchronizer如何工作？</h2><p>我们的想法是使用Stream来保持共享状态的一系列更改。并允许各种应用程序使用Pravega Java客户端库（如下图所示）以一致的方式同时读取和写入共享状态。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/blog-state_syn_fig1.png" alt="状态同步器的高级视图"></p><p>为了使用它，我们创建了一个普通的Java Object，它封装了我们想要跟踪的数据。对于该对象的每个可能的更新，我们编写一个类，该applyTo 方法接受该状态对象的实例并返回具有更新的状态对象。（更新操作可以是修改或生成新对象。）然后我们提供一个可以序列化和反序列化这些更新对象的类。然后使用状态同步器接口   [8]，我们可以从我们车队中的任何主机更新我们的状态对象，并保证所有主机他们将以相同的顺序看到相同的更新。（幕后所有更新写入Pravega，并Pravega保证它们的顺序）。假设该applyTo 方法是确定性的，因为所有主机都将到达相同的State对象。</p><p>由于状态完全由用户定义，因此应用程序可以执行以下任何操作：</p><ul><li>跟踪主机会员资格</li><li>做领导选举</li><li>存储配置</li><li>用于协调更复杂的过程。</li><li>或者如上所述，跟踪进度和工作分配。</li></ul><p><strong> 但它如何保证一致性？所有两台主机都可以尝试同时写入更新。</strong></p><p>这是通过使更新的附加条件有条理地使用乐观并发来完成的。在内部，状态同步器正在跟踪读取的数据量。当新的更新到达时，它会根据数据的长度递增计数器。然后，当请求更新时，它会序列化更新并将其作为条件追加发送到Pravega。</p><p>对于服务器，请求如下所示：</p><blockquote><blockquote><p>“ 当且仅当<countertotal> 是已写入此流的所有数据的长度总和时，才附加此数据。”</countertotal></p></blockquote></blockquote><p>在服务器端，服务器将比较数据的长度与客户端提供的值。如果客户端值匹配，则附加数据。否则，将向调用者返回错误。当状态同步器出现此错误时，它可以读取它不知道的新更新并重新运行其逻辑以查看是否应再次尝试更新。</p><p>通过跟踪客户端上的长度以及服务器更新可以在没有争用的情况下尽快从Pravega写入和读取数据来执行，即，一次只有一个客户端正在更新。因为状态同步器使用乐观并发进行更新，所以只有在合理的情况下使用它才合适。如果许多主机争用并发更新，性能会下降。但是，无论吞吐量降低，它都将继续提供一致的结果，并始终取得进展。一般来说，虽然最好避免争用并保持小状态。</p><h2 id="使用状态同步器"><a href="#使用状态同步器" class="headerlink" title="使用状态同步器"></a>使用状态同步器</h2><p>作为State Synchronizer如何使用的一个例子，当我们希望ReaderGroup中的所有读者都同意谁在读什么数据时。我们定义了一个包含我们想要跟踪的信息的数据结构。然后我们可以定义我们想要从中读取的任何方法。（就像任何其他对象一样）。对于每一个方式，数据可以被更新（AddNewReader，RemoveReader，ReassignSegment等），我们创建实现对应的类Update接口。该接口具有单个方法applyTo，该方法提供要更新的状态对象。保证传递给该applyTo 方法的对象将已应用所有先前编写的更新。</p><p>为了检测主机是否存活，我们可以创建一个成员资格跟踪器对象。它可以保留每个主机最后一次听到的时间戳。如果主机在足够长的时间内没有心跳，则可以宣告主机已经死亡。在这种情况下，我们会这样定义更新的对象AddNewHost，Heartbeat，DeclareDead，等。</p><p>我们已经创建了一些预先制作的示例，这些示例应该有助于查看：</p><ul><li>协调通用Map对象的内容 [9]。</li><li>实施领导人选举 [10]。</li></ul><p>领导者选举示例将允许许多主机加入一个组，并且一个将作为领导者被通知。Callbacks用于在失去领导力时通知它。</p><h2 id="保持状态尺寸尽量小"><a href="#保持状态尺寸尽量小" class="headerlink" title="保持状态尺寸尽量小"></a>保持状态尺寸尽量小</h2><p>状态和序列化更新很小时，状态同步器的效果最佳。状态对象需要保存在内存中，并且需要重新读取更新以重建对象。为了防止应用程序意外泄露，Pravega对状态对象施加了1MB的限制。</p><p>状态也应该毫不含糊。包含配置参数是一个好主意，这些参数指示如何在状态对象本身中解释状态对象中的数据。在成员资格跟踪器示例中，我们用于跟踪成员是否仍然是集合的一部分的超时应该是状态的一部分。这可以确保所有主机都同意数据的含义。</p><p>扩展的自然方式是使用多个不同的对象。与像Zookeeper这样的系统不同，其中所有东西都在同一个整体中，你可以拥有任意数量的状态同步器，每个都是独立的。因此，如果多个数据不相关或彼此原子级不一致，最好将它们置于不同的状态同步器之后。此外，请记住，可以使用URL或ID来引用外部数据。</p><p>另一个最佳实践是简化我们的更新。该UpdateGenerator函数可以返回多个更新。如果是，那么它们将被原子地附加。（意思是他们要么全部进入，要么都没有，并且他们之间不会有任何其他更新）。因此，为简单起见，将复杂操作分解为多个更新可能会有所帮助。这允许我们的更新对象保持小而简单。</p><h2 id="要记住的事情"><a href="#要记住的事情" class="headerlink" title="要记住的事情"></a>要记住的事情</h2><h3 id="UpdateGenerators"><a href="#UpdateGenerators" class="headerlink" title="UpdateGenerators"></a>UpdateGenerators</h3><p>在客户端，以下是要更新的签名：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs undefined">void updateState(UpdateGenerator&lt;StateT&gt; updateGenerator);<br></code></pre></td></tr></table></figure><p>这有时非常有用。例如，当我们管理读者组的状态时，如果我们执行更新以重新平衡读者，我们的初始尝试可能会失败，但随后查看新状态，我们可能会认为毕竟不需要重新平衡。下面是一个简化的示例，其中被管理的状态是一组值：应用程序传递的UpdateGenerator,是一个函数，它接受当前状态并返回应该应用的更新，而不是直接传递更新。这不会修改状态对象。相反，建议的更新有条件地附加到支持段。因此，应用更新可能会由于其他主机同时写入状态而失败。在这种情况下，更新生成简单地再次与新的状态对象调用（在UpdateGenerator可以多次调用）。</p><p>这有时非常有用。例如，当我们管理ReaderGroup的状态时，如果我们执行更新以重新平衡读者，我们的初始尝试可能会失败，但随后查看新状态，我们可能会认为毕竟不需要重新平衡。下面是一个简化示例，其中所管理的状态是一组值：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>public void add(T value) &#123;<br>    stateSynchronizer.updateState((set, updates) -&gt; &#123;<br>        if (!set.impl.contains(value)) &#123;<br>            updates.add(new AddToSet&lt;&gt;(value));<br>        &#125;<br>    &#125;);<br>&#125;<br></code></pre></td></tr></table></figure><p>这里函数使用传入的状态对象来检查要添加的项是否已经存在。<br>重要的是要注意，在更新方法期间不应该调用更新状态对象之外的东西的函数。为了解决这种情况，我们添加了另一个API：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>&lt;ReturnT&gt; ReturnT updateState(UpdateGeneratorFunction&lt;StateT,ReturnT&gt; updateGenerator);<br></code></pre></td></tr></table></figure><p>此签名类似于UpdateState调用，但具有额外的优点，即UpdateGenerator可以返回结果。最终调用的结果将UpdateGenerator返回给调用者。如果需要采取措施来响应执行的更新，这将非常有用。</p><p>例如，当我们向读者组添加新读者时，我们执行以下操作：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>void initializeReader(long initialAllocationDelay) &#123;<br>    boolean alreadyAdded = sync.updateState((state, updates) -&gt; &#123;<br>        if (state.getSegments(readerId) == null) &#123;<br>            updates.add(new AddReader(readerId));<br>            return false;<br>        &#125; else &#123;<br>            return true;<br>        &#125;<br>    &#125;);<br>...<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="FetchUpdates"><a href="#FetchUpdates" class="headerlink" title="FetchUpdates"></a>FetchUpdates</h3><p>要获得最新信息，我们需要致电fetchUpdates()[11]。updateState()[12] 也在内部调用这种方法。只有在调用这两个方法之一时，状态对象才会更改。这使得很容易推断出对状态对象的更改。</p><p>它是一种反模式，fetchUpdates()后跟无条件更新。因为状态对象可以由另一个主机同时更新导致竞争条件，所以应始终使用依赖于状态的更新updateState()。</p><h3 id="无条件更新"><a href="#无条件更新" class="headerlink" title="无条件更新"></a>无条件更新</h3><p>无条件更新将始终将更新对象置于Pravega Stream上，无论之前的更新是什么。无条件更新的优点是避免了争用。但是，这并不意味着我们完全放弃了一致性。更新仍然运行该applyTo方法，并应用所有以前的更新。（就像条件更新一样）。因此，完全可以无条件地写入更新，但是然后查看applyTo方法内部的状态决定不需要做任何事情。在这种情况下，更新将在Stream中，并且所有主机都将应用更新，但这样做将不起作用。</p><p>例如，在集合的情况下，上述add方法可以更简单地实现为：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>public void add(T value) &#123;<br>    stateSynchronizer.updateStateUnconditionally(<br>        new AddToSet&lt;&gt;(value));<br>&#125;<br></code></pre></td></tr></table></figure><p>假设这AddToSet.applyTo  是幂等的。（在一组情况下应该是这样）。</p><h3 id="线程安全"><a href="#线程安全" class="headerlink" title="线程安全"></a>线程安全</h3><p>State Synchronizer接口上的所有方法都是线程安全的。在同步器上或在读取状态之前调用方法时不需要锁定，因为线程安全性将在内部进行管理。但是，如果一个线程update并行调用，则另一个线程正在读取状态对象，并且更新会修改对象（而不是返回新的状态对象）。然后可能会有关于阅读的竞赛。这可以通过以下任何一种方式避免：</p><ol><li>使用单个线程来管理状态对象。</li><li>让update函数返回一个新对象，而不是修改现有对象。</li><li>在状态对象的方法中使用同步。</li></ol><p>（在这种情况下，值得知道update函数在调用时在状态对象本身上同步applyTo）</p><h3 id="压缩数据"><a href="#压缩数据" class="headerlink" title="压缩数据"></a>压缩数据</h3><p>随着更新被连续写入Pravega，存储的数据量随着时间的推移而增长。为了防止数据存储的无限增长，可以通过压缩和删除旧状态更新来偶尔压缩数据 [13]，以便只有最新版本的状态保留在后备流中。这是使用以下方法完成的：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>void compact(Function&lt;StateT,InitialUpdate&lt;StateT&gt;&gt; compactor);<br></code></pre></td></tr></table></figure><p>这允许以更紧凑的形式重写现有的状态对象。压缩状态与正常更新类似地写入，从提供的函数返回的压缩状态被写入流。一旦它被删除之前写入所有更新。从而用包含当前值的单个更新替换更新历史。</p><h3 id="何时压缩？"><a href="#何时压缩？" class="headerlink" title="何时压缩？"></a>何时压缩？</h3><p>压缩并不比等效大小的更新昂贵。因此，可以在更新列表变得非常大的任何时候执行压缩。通常，这是通过维持计数器并在N次更新之后压缩状态来执行的。任何副本都可以执行压缩，但它们不应该过于频繁地尝试，因为它可能会浪费空间。一种简单的方法是包括自状态中最后一次压缩以来更新次数的计数器。无法在同一操作中执行压缩和更新。它们必须在两个单独的调用中完成。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/blog-state_syn_fig2.png" alt="执行压缩"></p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>看看GitHub中的State Synchronizer，它是一个有趣且独特的工具。Pravega在内部使用State Synchronizer来管理分布在整个网络中的Reader Groups和Readers 的状态。</p><h2 id="致谢"><a href="#致谢" class="headerlink" title="致谢"></a>致谢</h2><p>特别感谢Srikanth Satya和Flavio Junqueira帮助完成了这篇文章。</p><h2 id="作者"><a href="#作者" class="headerlink" title="作者"></a>作者</h2><p>Tom Kaitchuck是Pravega项目的原始开发人员之一，目前是戴尔雇用的核心贡献者。他拥有瓦尔帕莱索大学的学士学位。汤姆是一位热心的开源软件开发人员，之前曾在谷歌和亚马逊担任高级软件开发人员。Tom的兴趣包括分布式系统，异步通信，并发，扩展系统，一致性模型。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li><a href="http://pravega.io/docs/latest/state-synchronizer/" target="_blank" rel="noopener">http://pravega.io/docs/latest/state-synchronizer/</a></li><li><a href="https://zookeeper.apache.org/" target="_blank" rel="noopener">https://zookeeper.apache.org/</a></li><li><a href="http://pravega.io/docs/latest/pravega-concepts/#stream-segments" target="_blank" rel="noopener">http://pravega.io/docs/latest/pravega-concepts/#stream-segments</a></li><li><a href="https://bookkeeper.apache.org/" target="_blank" rel="noopener">https://bookkeeper.apache.org/</a></li><li><a href="https://github.com/pravega/pravega/blob/master/client/src/main/java/io/pravega/client/state/StateSynchronizer.java" target="_blank" rel="noopener">https://github.com/pravega/pravega/blob/master/client/src/main/java/io/pravega/client/state/StateSynchronizer.java</a></li><li><a href="http://pravega.io/docs/latest/reader-group-design/" target="_blank" rel="noopener">http://pravega.io/docs/latest/reader-group-design/</a></li><li><a href="http://pravega.io/docs/latest/pravega-concepts/#autoscaling-the-number-of-stream-segments-can-vary-over-time" target="_blank" rel="noopener">http://pravega.io/docs/latest/pravega-concepts/#autoscaling-the-number-of-stream-segments-can-vary-over-time</a></li><li><a href="https://github.com/pravega/pravega/blob/master/client/src/main/java/io/pravega/client/state/StateSynchronizer.java" target="_blank" rel="noopener">https://github.com/pravega/pravega/blob/master/client/src/main/java/io/pravega/client/state/StateSynchronizer.java</a></li><li><a href="https://github.com/pravega/pravega-samples/blob/master/pravega-client-examples/src/main/java/io/pravega/example/statesynchronizer/SharedMap.java" target="_blank" rel="noopener">https://github.com/pravega/pravega-samples/blob/master/pravega-client-examples/src/main/java/io/pravega/example/statesynchronizer/SharedMap.java</a></li><li><a href="https://github.com/pravega/pravega-leaderElection" target="_blank" rel="noopener">https://github.com/pravega/pravega-leaderElection</a></li><li><a href="https://github.com/pravega/pravega/blob/3f5b65084ae17e74c8ef8e6a40e78e61fa98737b/client/src/main/java/io/pravega/client/state/StateSynchronizer.java#L51" target="_blank" rel="noopener">https://github.com/pravega/pravega/blob/3f5b65084ae17e74c8ef8e6a40e78e61fa98737b/client/src/main/java/io/pravega/client/state/StateSynchronizer.java#L51</a></li><li><a href="https://github.com/pravega/pravega/blob/3f5b65084ae17e74c8ef8e6a40e78e61fa98737b/client/src/main/java/io/pravega/client/state/StateSynchronizer.java#L105" target="_blank" rel="noopener">https://github.com/pravega/pravega/blob/3f5b65084ae17e74c8ef8e6a40e78e61fa98737b/client/src/main/java/io/pravega/client/state/StateSynchronizer.java#L105</a></li><li><a href="http://pravega.io/docs/latest/state-synchronizer/#delete-operations" target="_blank" rel="noopener">http://pravega.io/docs/latest/state-synchronizer/#delete-operations</a></li><li><a href="https://fpj.me/2016/02/10/note-on-fencing-and-distributed-locks/" target="_blank" rel="noopener">https://fpj.me/2016/02/10/note-on-fencing-and-distributed-locks/</a></li></ol><h2 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h2><p><a href="http://blog.pravega.io/2019/02/15/exploring-state-synchronizer/" target="_blank" rel="noopener">http://blog.pravega.io/2019/02/15/exploring-state-synchronizer/</a></p>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>新公司一年里程碑</title>
      <link href="/2019/02/11/person-emc-one-year/"/>
      <url>/2019/02/11/person-emc-one-year/</url>
      
        <content type="html"><![CDATA[<p>2018年2月12日到2019年2月11日，刚好满一年，不知不觉间居然写了35770行代码，</p><p>2018-02-12 ~ 2019-02-11， 刚好入职EMC满一年，里程碑两件：</p><p>1，个人代码量突破3万5千行，排列第一；</p><p>2，专利公司内部通过且美国专利局审核中2个。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/person/emc-201902-codeline.png" alt="codeline"></p><div align="left"> </div>]]></content>
      
      
      <categories>
          
          <category> person </category>
          
      </categories>
      
      
        <tags>
            
            <tag> person </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>重构大数据平台的存储栈</title>
      <link href="/2019/01/25/pravega-arch-refactor-bigdata-storage-stack/"/>
      <url>/2019/01/25/pravega-arch-refactor-bigdata-storage-stack/</url>
      
        <content type="html"><![CDATA[<h2 id="当前大数据处理平台存在的问题"><a href="#当前大数据处理平台存在的问题" class="headerlink" title="当前大数据处理平台存在的问题"></a><font color="#FF8C00">当前大数据处理平台存在的问题</font></h2><p>如图1是目前大数据处理平台最常见的Lambda架构，它的优势在于实时处理与批处理统一，但是它的缺点也很明显：</p><ol><li>实时处理一条路径，批处理另外一条路径，不同的路径采用了不同的计算组件，这就增加了系统的复杂度；</li><li>数据存储多组件化、多份化，如下图，同样的数据会被存储在ElasticSearch 里、S3对象存储系统里、Kafka里、HDFS里以及Cassandra里，而且考虑到数据的可靠性，数据还都是多份冗余的，这就极大的增加了用户的存储成本；</li><li>系统里组件太多太复杂，也增加了用户的运维成本。</li></ol><div align="center"> <p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/pravega-infoq-arch-lambda.png" alt="lambda架构"></p><p>​图1.  Lambda架构</p><div align="left"> <p>因此，为了解决Lambda架构的以上三大缺点，流式架构被提出。在流式架构里，流计算一般选用<strong>Flink</strong>作为计算组件，那么对于存储来说又意味着什么呢？为了<strong>降低系统复杂度、减少用户的存储成本与运维成本</strong>，我们推出了<font color="#FF0000"> <strong>流存储</strong></font>，目的之一就是为了重构Lambda架构里的存储栈，这样流式架构就可以由<font color="#FF0000"><strong>”流计算+流存储“</strong></font>组成。</p><h2 id="第4种存储类型-流存储"><a href="#第4种存储类型-流存储" class="headerlink" title="第4种存储类型 - 流存储 "></a><font color="#FF8C00">第4种存储类型 - 流存储 </font></h2><p>首先，流式大数据处理平台里的数据一般被称之为“流数据”，流数据在百度百科里是这样被定义的：</p><blockquote><p>流数据是一组顺序、大量、快速、连续到达的数据序列，一般情况下，数据流可被视为一个随时间延续而无限增长的动态数据集合。应用于网络监控、传感器网络、航空航天、气象测控和金融服务等领域。</p></blockquote><p>那么目前又有哪种存储系统最适合用于<strong>“流数据”</strong>呢？正如当前技术条件下最适合“流数据”计算的是类似Flink这样的流计算应用，最适合“流数据”存储的应当是流存储系统。</p><p>如图2所示，从<font color="#FF0000"> <strong>存储的视角</strong></font>来说，每种类型的数据都有其原生的属性和需求，对应有最佳的适用场景以及最合适的存储系统。</p><div align="center"> <p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/pravega-infoq-storage-type.png" alt="存储类型"></p><p>​                                                                       图2.  4大存储类型</p><div align="left"> <p>简单来说就是传统数据库这类对于IOPS要求高的业务需要块存储系统。文件共享场景下需要在用户间共享文件进行读写操作，因此适合采用分布式文件存储系统。而互联网业务文件以及图片、视频等适合采用对象存储系统。</p><p>流数据存储具有性能要求高、严格次序保证、连续而又无限、大规模租户隔离等特点，而目前市面上又没有这样一个专门针对流数据进行设计的存储系统。因此，为了满足业务需求、平衡商业成本与技术成本，也为了给流数据提供最佳最合适的存储系统，分布式流存储Pravega被推出。</p><div align="center"> <p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/pravega-infoq-arch-6.png" alt="I/O路径隔离"></p><p>​                                                                       图3.  日志结构</p><div align="left"> <p>如图3所示：在Pravega里，日志是作为共享存储原语而存在的。Pravega被推出的目的之一就是为了<font color="#FF0000"> <strong>重构Lambda架构里的存储栈：流批统一、降低存储成本以及运维成本。</strong></font> 一般数据的批处理对应于处理历史数据，因此Pravega支持高吞吐量的追赶读；数据的流处理对应于处理实时数据，因此Pravega又支持低时延的尾部读取以及写入；同时Pravega通过分层存储以及资源自动伸缩降低了用户的存储成本以及运维成本。</p><h2 id="Pravega关键架构"><a href="#Pravega关键架构" class="headerlink" title="Pravega关键架构"></a><font color="#FF8C00">Pravega关键架构</font></h2><h3 id="架构目标"><a href="#架构目标" class="headerlink" title="架构目标"></a><font color="#00CED1">架构目标</font></h3><ul><li>持久化：在客户端确认写入前，数据被复制并且写入磁盘；</li><li>严格的顺序保证以及恰好一次语义：支持追赶读、尾部读以及从中间任意位置读，支持事务</li><li>轻量级：一个流就如同一个文件，可以在单集群里创建千万量级起的流；</li><li>可弹性：可基于负载和吞吐量智能地动态扩展或者收缩流；</li><li>无限性：存储空间大小不受单个节点的容量限制；</li><li>高性能：写入延迟低于10ms，吞吐量仅受网络带宽限制，读模式（例如：追赶读）不影响写性能;</li></ul><h3 id="逻辑架构"><a href="#逻辑架构" class="headerlink" title=" 逻辑架构"></a><font color="#00CED1"> 逻辑架构</font></h3><blockquote><p>”技术在某种程度上一定是来自此前已有技术的新的组合“  – 《技术的本质》，布莱恩·阿瑟</p></blockquote><p>Pravega为连续而又无限的数据提供了一种新的存储原语 - 流存储，然而Pravega也并不是凭空发明出来的，它是以前成熟技术与新技术的组合，例如Pravega的 范围、流、段、事件就跟Kafka的主题、分区、段、消息对应，而一层存储又用了Bookkeeper，协调器用了Zookeeper等，如图4 ：Pravega的逻辑架构。</p><div align="center"> <p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/pravega-infoq-arch.png" alt="逻辑架构图"></p><p>​                                                                       图4.  逻辑架构</p><div align="left"> <ol><li>Pravega提供了一个用Java编写的客户端库，抽象出了流协议层接口，用于支持客户端应用，例如Flink、Spark以及一些检索系统等；</li><li>Pravega实现了一个流数据抽象层，用于事件流和字节流的抽象；</li><li>Pravega遵循软件定义存储的设计规则，其控制面与数据面分离，控制实例组成控制面，实现了检索流信息、监控集群、收集相关指标等功能，同时为了实现高可用，通常有多个（建议至少3个）控制实例同时对外提供服务；</li><li>Pravega采用Zookeeper作为集群中的协调组件；</li><li>Pravega的第1层存储系统由bookkeeper实现，第2层存储系统由开源的HDFS、Ceph、GlusterFS、Swift或者商业存储产品组成。</li></ol><h3 id="流批统一-降低系统复杂度"><a href="#流批统一-降低系统复杂度" class="headerlink" title="流批统一 - 降低系统复杂度"></a><font color="#00CED1">流批统一 - 降低系统复杂度</font></h3><p>通过使用Pravega，实现了流批统一的大数据处理架构，重构了大数据处理平台的存储栈，有效降低了系统复杂度.</p><h3 id="存储分层-降低存储成本"><a href="#存储分层-降低存储成本" class="headerlink" title="存储分层 - 降低存储成本"></a><font color="#00CED1">存储分层 - 降低存储成本</font></h3><p>如图4所示，在Pravega里，底层存储系统由两部分组成：第1层为低时延存储层，主要关注性能，用于存储热点数据，由bookkeeper实现，保证了存储系统的低时延、高性能。第2层为长期存储层，主要关注低成本、高吞吐量以及高可扩展性，提供数据的长期存储，由开源的或者商业的存储产品组成。随着数据的老化，第1层中的数据将自动分层流入第2层。通过这种方式，冷热数据分离有效降低了数据存储成本。</p><h3 id="资源自动缩放-减少运维成本"><a href="#资源自动缩放-减少运维成本" class="headerlink" title="资源自动缩放 - 减少运维成本"></a><font color="#00CED1">资源自动缩放 - 减少运维成本</font></h3><p>在Pravega里，当流中的负载上升或下降时，流中段的数量会随着负载自动增长或收缩，此特性被称之为“自动缩放”，该特性无需人工干预自动完成，有效减少了系统的运维成本。当创建流时，可以使用缩放策略配置流，该策略确定流如何响应其负载变化，目前支持三种策略：1）固定，流段的数量不随负载而变化；2）基于写入的字节数，当每秒写入流的数据字节数增量超过某个目标速率时，流段的数量增加，相应的如果它低于某个流速时，流段数量减少；3）基于事件的个数，与基于字节数的扩展策略类似，不同之处在于它使用事件的个数而不是字节数。</p><h2 id="Pravega的一些关键概念与特性"><a href="#Pravega的一些关键概念与特性" class="headerlink" title="Pravega的一些关键概念与特性"></a><font color="#FF8C00">Pravega的一些关键概念与特性</font></h2><p>本章节将简要介绍一些Pravega的关键特性。</p><font color="#00CED1"><strong>范围（scope）：</strong></font>在Pravega里，范围是流的命名空间，例如可以把一台机器命名为一个范围，也可以把一个无人车命名为一个范围，还可以把整个工厂命名为一个范围。<br><br><font color="#00CED1"><strong>流（stream）：</strong></font>在同一个范围内流具有命名唯一性，所有流的名称在同一个范围内都是唯一的。在pravega里数据被组织到流中的，流是一种可持久化、可伸缩、仅附加、字节大小无限制的序列，具有高性能和强一致性的特性。<br><br><font color="#00CED1"><strong>段（segment）：</strong></font>流由段组成，段是流的分片。<br><br><font color="#00CED1"><strong>事件（event）：</strong></font> 段由事件组成，事件存储在段里，事件是流中的可以表示为一组字节的任何事物。例如：来自温度传感器的读数，它包含少量的字节且由时间戳，度量标识符和温度值组成。另外事件也可以是与用户点击网站或APP相关联的日志数据等。<br><br><font color="#00CED1"><strong>写客户端（writers）：</strong></font>写客户端是一个可以创建事件并将事件写入流中的应用，所有的事件数据都可以通过附加到流的尾部来写入。<br><br><font color="#00CED1"><strong>读客户端（readers）：</strong></font>读客户端是一个可以从流中读取事件的应用，读客户端可以从流中的任何一点读取，比如头部、尾部、中间任何一点。<br><br><font color="#00CED1"><strong>读者组（readerGroups）：</strong></font>读者组由读客户端组成，读者组本质上是为了实现同一个组内读客户端的平衡以及不同组的扇出。同一个读者组内的读客户端可以一起并行读取给定的一组流段内的事件，比如一个读客户端对应一个段。不同的应用可以定义不同的读者组实现扇出，比如定义一个Flink读者组，再定义一个检索读者组，这样二者互不影响，互不干涉，可以优雅而又和谐地一起读取同一个流段内的事件。<br><br><font color="#00CED1"><strong>顺序保证：</strong></font>流是由段组成的，写入流的事件被写入单个段，在同一个段内的事件具有顺序性。对于读客户端来说，可以分配多个可并行读取的段，从多个段读取的也许是交错的事件，但在同一个段内读取的数据是有严格有序的。<br><br><font color="#00CED1"><strong>检查点：</strong></font>Pravega为应用提供了在读者组上初始化检查点的功能，使用检查点的意图是通过使用检查点事件来确保每个读客户端能保存原来的使用状态。<br><br><font color="#00CED1"><strong>事务：</strong></font> Pravega提供了事务功能，事务是写客户端可以“批处理”一堆事件并将它们作为一个处理单元原子性地提交到流中。这一堆事件要么所有都处理成功，要么所有都处理失败。在提交事务之前，发布到事务中的事件永远不会被读客户端看到。<br><br><font color="#00CED1"><strong>状态同步器：</strong></font> Pravega也提供了在分布式计算环境中作为协调器的功能，类似Zookeeper、ETCD这样的提供分布式共识和领导者选举能力。这样的组件在Pravega里被称作“状态同步器”。状态同步器为在集群中运行的多个进程之间的共享状态提供同步机制，使用户可以轻松地构建高级服务，从而使用户更加的容易构建分布式应用。<br><br><font color="#00CED1"><strong>恰好一次：</strong></font> Pravega确保每个事件只被处理一次，即使客户端、服务器或网络出现故障也能保证精确的处理顺序。<br><br><font color="#00CED1"><strong>性能：</strong></font> Pravega的延迟目标为毫秒级(&lt;10ms)；<br><br><font color="#00CED1"><strong>永久保留：</strong></font> Pravega将流的抽象与实际数据存储分离，这使得Pravega可以透明地将数据从低延迟、持久的存储层移到云存储服务层。<br><br><font color="#00CED1"><strong>高效存储：</strong></font> Pravega统一了流（有序）数据和批量（并行）数据的访问，可以将批量和实时应用程序结合起来而无需为流式计算流水线（比如Flink）的每个步骤复制数据从而有效的提高了数据的存储效率。<br><br><br><br>## <font color="#FF8C00">与kafka对比</font><p>前面我们已经提到过Pravega是从<font color="#FF0000"> <strong>存储的视角</strong></font>来看待流数据，而Kafka本身的定位是消息系统而不是存储系统，它是从<font color="#FF0000"> <strong>消息的视角</strong></font>来看待流数据。消息系统与存储系统的定位是不同的，简单来说，消息系统是消息的传输系统，关注的是数据传输与生产消费的过程。而存储系统除了关注存储用的物理媒介，数据的持久化、安全、可靠性、一致性、隔离等都是它的原生属性，它关注数据的生产、传输、存放、访问等整个数据的生命周期。</p><p>这里我们把Pravega与Kafka做了对比，大体在功能上的差异如下表所示。功能上的差异也只是说明各个产品针对的业务场景不同，看待数据的视角不同，并不是说明这个产品不好，另外每个产品自身也在演进，因此本对比仅供参考。</p><table><thead><tr><th>名称</th><th style="text-align:center">Kafka 2.1.0</th><th style="text-align:right">Pravega GA</th></tr></thead><tbody><tr><td>自动扩容缩容</td><td style="text-align:center">部分支持</td><td style="text-align:right">支持</td></tr><tr><td>完全不丢数据</td><td style="text-align:center">不支持</td><td style="text-align:right">支持</td></tr><tr><td>多协议可入</td><td style="text-align:center">支持</td><td style="text-align:right">支持</td></tr><tr><td>无限个流</td><td style="text-align:center">不支持</td><td style="text-align:right">支持</td></tr><tr><td>事务</td><td style="text-align:center">支持</td><td style="text-align:right">支持</td></tr><tr><td>恰好一次</td><td style="text-align:center">支持</td><td style="text-align:right">支持</td></tr><tr><td>顺序保证</td><td style="text-align:center">支持</td><td style="text-align:right">支持</td></tr><tr><td>兼容Kafka API</td><td style="text-align:center">支持</td><td style="text-align:right">支持</td></tr><tr><td>数据链接与汇聚</td><td style="text-align:center">支持</td><td style="text-align:right">部分支持</td></tr><tr><td>多种二层存储支持（ECS,HDFS,S3,etc）</td><td style="text-align:center">不支持</td><td style="text-align:right">支持</td></tr><tr><td>安全与加密</td><td style="text-align:center">支持</td><td style="text-align:right">支持</td></tr><tr><td>无限多租户</td><td style="text-align:center">不支持</td><td style="text-align:right">部分支持</td></tr><tr><td>服务质量保证</td><td style="text-align:center">部分支持</td><td style="text-align:right">部分支持</td></tr><tr><td>流计算应用集成</td><td style="text-align:center">支持</td><td style="text-align:right">支持</td></tr><tr><td>数据治理</td><td style="text-align:center">不支持</td><td style="text-align:right">支持</td></tr></tbody></table><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a><font color="#FF8C00">总结</font></h2><p>本文讲述了推出分布式流存储Pravega的原因，介绍了一些Pravega的关键架构以及关键特性，另外还与Kafka做了简要对比。有关Pravega的更多详细信息，请参阅官方网站以及关注我们的后续文章。另作者能力有限，如有不足之处欢迎留言批评指正。</p><h2 id="问题思考"><a href="#问题思考" class="headerlink" title="问题思考"></a><font color="#FF8C00">问题思考</font></h2><p>最后给大家留一个问题：<font color="#00CED1"><strong>一般来说从开源项目到商业产品还是有一段距离的（注意这里的用词：开源的“项目”，商业的“产品”），那么对于设计开发人员来说应该如何弥补这段距离，从而使得开源项目产品化？</strong></font> </p></div></div></div></div></div></div></div></div>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>分布式流存储 - 架构、自动缩放、IO隔离与事务</title>
      <link href="/2019/01/25/pravega-arch-IO-transaction-autoscaling/"/>
      <url>/2019/01/25/pravega-arch-IO-transaction-autoscaling/</url>
      
        <content type="html"><![CDATA[<h2 id="Pravega架构"><a href="#Pravega架构" class="headerlink" title=" Pravega架构  "></a><font color="#FF8C00"> Pravega架构  </font></h2><blockquote><p> ”技术在某种程度上一定是来自此前已有技术的新的组合“  – 《技术的本质》，布莱恩·阿瑟</p></blockquote><p>Pravega为连续而又无限的数据提供了一种新的存储原语 - 流存储，然而Pravega也并不是凭空发明出来的，它是以前成熟技术与新技术的组合，例如Pravega的 范围、流、段、事件就跟Kafka的主题、分区、段、消息对应，而一层存储又用了Bookkeeper，协调器用了Zookeeper等。</p><h3 id="设计原则与目标"><a href="#设计原则与目标" class="headerlink" title=" 设计原则与目标"></a><font color="#00CED1"> 设计原则与目标</font></h3><ul><li><p>持久化：在客户端确认写入前，数据被复制并且写入磁盘；</p></li><li><p>保序：段内严格保序；</p></li><li><p>恰好一次：支持恰好一次语义；</p></li><li><p>轻量级：一个流就如同一个文件，可以在单集群里创建千万量级起的流；</p></li><li><p>可弹性：可基于负载和吞吐量智能地动态扩展或者收缩流；</p></li><li><p>无限性：存储空间大小不受单个节点的容量限制；</p></li><li><p>高性能：写入延迟低于10ms，吞吐量仅受网络带宽限制，读模式（例如：追赶读）不影响写性能;</p></li></ul><h3 id="Pravega设计创新"><a href="#Pravega设计创新" class="headerlink" title="Pravega设计创新"></a><font color="#00CED1">Pravega设计创新</font></h3><ol><li><p>支持“无限流”分层</p></li><li><p>零接触动态缩放</p><ul><li><p>根据负载和SLO自动调整读/写并行度</p></li><li><p>没有服务中断</p></li><li>无需手动重新配置客户端</li><li>无需手动重新配置服务资源</li></ul></li><li><p>智能工作负载分配</p><ul><li>无需为峰值负载过度配置服务器</li></ul></li><li><p>I / O路径隔离</p><ul><li>支持尾部写入</li><li>支持尾部读</li><li>支持追赶读</li></ul></li><li><p>支持“恰好一次”事务</p></li></ol><h3 id="逻辑架构"><a href="#逻辑架构" class="headerlink" title="  逻辑架构"></a><font color="#00CED1">  逻辑架构</font></h3><p>下图为Pravega的逻辑架构图：</p><p><div align="center"><br><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/pravega-infoq-arch.png" alt="逻辑架构图"></div></p><div align="left"> <ol><li>首先，Pravega提供了一个用Java编写的客户端库，抽象出了流协议层接口，用于支持客户端应用，例如Flink、Spark以及一些检索系统等；</li><li>其次，Pravega实现了一个流数据抽象层，用于事件流和字节流的抽象；</li><li>再者，从整体架构上来讲Pravega符合软件定义存储的设计规则，其控制面与数据面分离，数据面的集合统称为段存储层，控制实例组成控制面，实现了检索流信息、监控集群、收集相关指标等功能，同时为了实现高可用，通常有多个（建议至少3个）控制实例同时对外提供服务。 </li><li>Pravega采用Zookeeper作为集群中的协调组件。 </li><li>Pravega的存储系统由两部分组成：第1层为短期存储层，主要关注性能，用于存储热点数据，由bookkeeper实现，保证了存储系统的低时延、高性能。第2层为长期存储层，主要关注成本，提供数据的持久性以及长期存储，由开源的或者商业的存储产品组成。第1层保留热点数据，随着第1层中数据的老化，数据将自动分层流入第2层。</li></ol><h3 id="数据架构"><a href="#数据架构" class="headerlink" title=" 数据架构"></a><font color="#00CED1"> 数据架构</font></h3><p>下图展示了Pravega的数据架构图以及数据流分层：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/pravega-infoq-data-path.png" alt="数据架构图"></p><ol><li>Pravega客户端可以通过调用控制器接口管理流的创建、删除和缩放以及进行事务管理：启动事务、创建事务、跟踪事务状态；</li><li>所有的数据对读来说都是透明的，客户端的读写操作直接与段存储（数据面）进行交互，而不通过控制器；</li><li>段存储里有缓存组件保证了读写的高性能，热点数据放在bookkeeper里作为一层存储；</li><li>数据老化后会自动流转到长期存储（例如：对象存储系统，文件存储系统，HDFS等）里以便降低存储成本；</li></ol><h3 id="关键子功能-零接触缩放"><a href="#关键子功能-零接触缩放" class="headerlink" title="关键子功能 - 零接触缩放"></a><font color="#00CED1">关键子功能 - 零接触缩放</font></h3><h4 id="零接触缩放：段的动态拆分与合并"><a href="#零接触缩放：段的动态拆分与合并" class="headerlink" title="零接触缩放：段的动态拆分与合并"></a>零接触缩放：段的动态拆分与合并</h4><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/pravega-infoq-arch-2.png" alt="段的拆分与合并"></p><p>如上图所示，1）拆分：在t1时刻系统负载加大，段0被拆分成段1和段2，同时段0封装不再写入；t2时刻系统负载继续加大，段2被拆分成段3与段4，同时段2被封装不再写入；t3时刻系统负载又继续加大，段1被拆分成段5和段6，同时段1被封装不再写入；2）合并：t4时刻系统负载降低，段6与段3被合并成段7，同时段6与段3被封装不再写入。而且所有的这些行为都是Pravega里自动完成的无需人工干预。</p><h4 id="零接触缩放：写并行-与Kafka比较"><a href="#零接触缩放：写并行-与Kafka比较" class="headerlink" title="零接触缩放：写并行 - 与Kafka比较"></a>零接触缩放：写并行 - 与Kafka比较</h4><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/pravega-infoq-arch-3.png" alt="写并行"></p><p>当并行写入的时候：</p><ol><li><p>在Pravega里流段的数量会根据负载和服务质量目标而动态变化，并且段的拆分与合并都是自动进行的无需人工干预，同时拆分或合并流段是，写客户端的配置是静态不变的；</p></li><li><p>在Kafka里主题分区数（写并行性）是静态的，添加或删除分区时需要手动配置服务并且当分区数更改时，必须手动更新生产者配置。</p></li></ol><h4 id="零接触缩放：读并行-与Kafka比较"><a href="#零接触缩放：读并行-与Kafka比较" class="headerlink" title="零接触缩放：读并行 - 与Kafka比较"></a>零接触缩放：读并行 - 与Kafka比较</h4><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/pravega-infoq-arch-4.png" alt="读并行"></p><p>并行读取时：</p><ol><li>在Pravega里，当拆分或者合并流段时，读客户端通过流协议获得通知从而使得读并行与流段缩放保持同步；</li><li>在Kafka里，当分区数更改时，必须手动更改使用者配置。</li></ol><h4 id="关键子功能-智能工作负载分配"><a href="#关键子功能-智能工作负载分配" class="headerlink" title="关键子功能 - 智能工作负载分配 "></a><font color="#00CED1">关键子功能 - 智能工作负载分配 </font></h4><h4 id="智能工作负载分配-与Kafka比较"><a href="#智能工作负载分配-与Kafka比较" class="headerlink" title="智能工作负载分配 - 与Kafka比较"></a>智能工作负载分配 - 与Kafka比较</h4><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/pravega-infoq-arch-5.png" alt="智能工作负载分配"></p><p>在Pravega里，热点段会自动拆分，子段在整个集群中重新分配缓解热点，同时最大限度地利用集群的可用IOPS能力；而在Kafka里没有减轻“热点”分区的机制，其强制部署并且过度配置资源以获得处理其“峰值负载”的能力。</p><h3 id="关键子功能-I-O路径隔离"><a href="#关键子功能-I-O路径隔离" class="headerlink" title="关键子功能 - I/O路径隔离"></a><font color="#00CED1">关键子功能 - I/O路径隔离</font></h3><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/pravega-infoq-arch-6.png" alt="I/O路径隔离"></p><p>流存储的基础数据结构为仅附加写入的日志结构。考虑到高吞吐量，Pravega支持追赶读，同时为了保证低时延，Pravega还支持尾部读取以及尾部写入，从而进行了IO路径的隔离。</p><h3 id="关键子功能-事务"><a href="#关键子功能-事务" class="headerlink" title="关键子功能 - 事务"></a><font color="#00CED1">关键子功能 - 事务</font></h3><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/pravega-infoq-arch-7.png" alt="智能工作负载分配"></p><p>Pravega提供了事务功能，事务是写客户端可以“批处理”一堆事件并将它们作为一个处理单元原子性地提交到流中。这一堆事件要么所有都处理成功，要么所有都处理失败。在提交事务之前，发布到事务中的事件永远不会被读客户端看到。如上图所示，第一步，先将一堆事件封装在一个事务里；第二步，提交这个事务。这个事务里所有的事件要么全部都处理成功要么全部都处理失败。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a><font color="#FF8C00">总结</font></h2><p>本文分析了物联网场景下的数据存储商业现状以及技术现状，为平衡商业成本与技术成本推出了分布式流存储系统Pravega，同时本文还介绍了流存储的特殊需求点以及与Kafka做了简要对比，此外还介绍了一些Pravega的关键架构以及一些关键特性。有关Pravega的更多详细信息，请参阅官方网站。另作者能力有限，如有不足之处欢迎留言批评指正。</p></div>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>pravega blog - 原生的流存储解决方案</title>
      <link href="/2018/11/25/pravega-blog-i-have-a-stream/"/>
      <url>/2018/11/25/pravega-blog-i-have-a-stream/</url>
      
        <content type="html"><![CDATA[<h2 id="现阶段的Pravega"><a href="#现阶段的Pravega" class="headerlink" title="现阶段的Pravega"></a>现阶段的Pravega</h2><p>流处理在数据分析领域备受关注，其原因相当明显：在短时间内就能够对连续生成的数据产生洞察力，而不是等待它在批处理中累积和处理。从摄取到结果的低延迟是流处理技术向其各种应用程序领域提供的关键优势之一。在某些情况下，低延迟不仅是可取的，而且对于保证正确行为的绝对必要条件。在物联网中等待数小时处理火警或煤气泄漏事件是没有意义的。</p><p>处理流数据的典型应用程序具有一些核心组件。它有一个生产事件、消息、数据样本的源，这些事件的大小通常很小，从几百字节到几千字节。源不必是单个元素，它可以是多个传感器、移动终端、用户或服务器。该数据最终被送入流处理器，该处理器对其进行处理并产生中间或最终输出。最终输出可以具有各种形式，通常被持久存储在一些数据存储中以供消费（例如，针对数据集的查询）。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/praveg-blog-ihaveastream-1.png" alt="用于处理事件的典型管道的概要视图"></p><p>这种通用架构的存储分为两部分：摄取和输出。用于摄取的存储组件将数据的生成与处理解耦，解耦源和处理很重要，因为不同的应用程序需要处理相同的数据，但是以不同的速度处理数据。对于这些应用程序中的一些，要求它们对最近的数据做出快速反应，这要求存储组件从摄取到服务的存储组件上有低延迟的要求。对存储的写入通常很小，例如，来自传感器和应用程序的小样本事件单独读取写入的项目。</p><p>当从存储组件读取连续生成的数据时，随着应用程序顺序读取项目，存在强大的空间组件。然而，除了这个空间维度之外，还存在时间维度，现有系统并未完全强调这一点。应用程序可能希望出于各种原因在不同时间处理相同的数据，例如，在修复BUG之后，加入新数据和历史数据时，或者仅在稍后处理大量累积数据时。提供此功能的存储组件在摄取后不久消耗连续生成的数据，以及随后高吞吐量地消费连续生成的数据，以进行历史处理。</p><p>Pravega是一个存储系统，具有一个流的概念。Pravega使应用程序能够连续摄取数据并按顺序（遵循摄取顺序）或批量处理（并行读取数据，而不必遵循流顺序）处理此类数据流。Pravega为流处理提供了许多非常理想的功能：低延迟、流弹性、无限流以及事务。</p><p>Pravega的核心是一个简单而强大的概念：段。段是仅附加字节序列; 它们可以通过多种方式组成，以形成流并启用强大的功能，例如事务和流缩放。Pravega最终是一个带有控制平面的段的数据存储，该控制平面代表应用程序跟踪和操作这些段以形成流。</p><p>在这篇文章中，我们将解释Pravega的一些核心概念以及我们如何认为它将改变我们处理流数据的方式。第一个早期alpha版本为：Pravega 0.1。这个早期版本包含一些令人兴奋的功能：</p><ul><li><p>持久写入：  Pravega的附加在被确认之前是持久的，就是这样; 没有可配置的选项来放松持久性。我们选择了这条路径，因为我们想要提供的其他一些属性需要强持久性，例如订单和一次。有了这个选择，Pravega开发人员面临的挑战就是在满足预期性能的同时满足这种保证。谁知道 - 我们将来也许需要放宽这个限制，但目前我们会坚持这一点。</p></li><li><p>流缩放：流缩放是一项令人印象深刻的功能，它可以根据写入流量自动增长和收缩。当然，我们也允许用户手动缩放，但看Pravega为您做自动伸缩会更舒服。</p></li><li><p>事务： 流写入器可以通过开始事务并附加在该事务的上下文中，以原子方式附加到Pravega流。只有在事务提交的情况下，才会在事务上下文中附加的数据变为可见。</p></li><li><p>状态同步器：状态同步器将日志复制与状态复制解耦。它允许在Pravega段之上实现任何复制状态机。例如，可以在Pravega段存储之上实施领导者选举或组成员资格。</p></li></ul><p>在下一版本中还会出现更多令人兴奋的功能，例如启用下游动态扩展和数据保留的信令。开源参与人员的贡献也是非常受欢迎的，因为它是我们在Pravega周围建立社区的战略和努力的一部分。我们主网站上提供了如何使用Pravega的指导。</p><h2 id="在Pravega之前的流数据处理"><a href="#在Pravega之前的流数据处理" class="headerlink" title="在Pravega之前的流数据处理"></a>在Pravega之前的流数据处理</h2><p>在大数据繁荣的早期阶段，当MapReduce成为热点时，主要目标是使用通常包含数千台服务器的集群快速处理大量数据集。在一个或多个大数据集上运行的这种计算通常被称为批处理作业。批处理作业使各种应用程序能够从原始数据中获得洞察力，这对于在线Web领域的许多成长型公司来说非常重要。例如，在Yahoo!这样的公司中，很多早期的Hadoop工作已经发生，有很多生产工作用于网络搜索、定向广告、推荐和其他应用程序。</p><p>对于大型数据集的批处理作业通常在最佳情况下具有几分钟的完成时间，根据作业的大小和复杂性而达到多个小时。如此长的延迟对于许多应用程序来说并不理想，很快我们开始观察到处理数据的愿望，而不是等待积累大块然后才处理数据。例如，在Web上进行目标广告时，不希望等待数小时或数天来获得对数据的任何洞察。对于需要向用户执行推荐的任何系统都是如此。使用最新数据至关重要，但与此同时，即使推荐中最小程度的不准确也可能最终导致用户离开。在这里，我们观察到低延迟流处理的兴起，并开始揭开其挑战。我们将其称为流处理，因为传入的数据基本上是事件、消息或样本的连续流。</p><p>许多对数据分析感兴趣的公司已经部署了大型Hadoop集群，他们并不一定愿意放弃MapReduce模型。为了解决延迟限制，一些应用程序开始使用微批处理方法：不是等待收集大量数据，而是在较短时间内累积的较小块上运行作业。使用微批次的想法并不一定是坏事，事实上，它确实使应用程序能够在更短的时间内获得洞察力。</p><p>微批处理在当时是一个很好的调用，但它是有限的。校准微批次的大小不一定是微不足道的，从摄取到输出的等待时间通常为几分钟。低于此水平是很困难的，因为单独开始工作需要几秒钟。作为对无法以较低延迟处理数据的反应，最初尝试开发处理数据流的系统。用于流处理的Web空间中的公司出现的几个早期系统是S4 [1]和Apache Storm [2]。S4实际上早于Storm出现，但Storm变得越来越流行，它仍然被广泛使用。其他系统也遵循：Apache Spark [3]通过微批处理支持流; Apache Flink [4]从根本上统一了批处理和流处理，不需要微批处理; Heron [5]是一个流处理引擎，旨在与Storm兼容。最近，Apache Samza [6]和Kafka Streams被开发用于利用Apache Kafka [7]来实现高效的流处理。<br>所有这些系统的共同点之一是它们需要一些捕获数据的方法。直接从源中提取数据是一个坏主意，至少有几个原因：</p><ol><li>处理传入数据的多个应用程序可能共享数据，每个应用程序可能有自己的处理速度和频率。</li><li>耦合源和应用程序通常是错误的，因为源通常具有另一个主要角色，即不为后端应用程序提供服务。例如，Web服务<br>器在应用程序中的中心目的是与最终用户交互，而不是可靠地缓冲数据，例如在后端运行的推荐应用程序。</li></ol><p>由于这些原因，数据的摄取通常通过分布式文件系统（例如，HDFS）在批处理时发生，或者通过临时缓冲用于流处理的输入事件、消息或样本的一些消息传递基底发生。对数据感兴趣的应用程序可以在任何需要的时间使用它，并且它希望以任何频率消耗它，仅受为传入数据设置的保留策略的约束。</p><p>Pravega认为，成功的流处理应用程序能够有效地提取和提供数据至关重要。不过，Pravega偏离了传统的消息传递系统，可以通过几种方式提取数据。Pravega旨在成为流的存储解决方案。应用程序将数据摄取到Pravega中，并且这样的流可以在其长度上无限制并且存储任意长时间。在流Pravega具有弹性：流的摄取能力可以随着时间的推移自动增长和收缩。它的API目标流应用程序，因此，它借用了空间中成功系统的许多概念，如Apache Kafka [7]。例如，Pravega使应用程序能够以仅附加方式编写事件，并按照它们被附加的顺序读取这些事件。</p><p>在下一节中，我们将介绍Pravega的一些核心概念  ，重点介绍我们的第一个alpha版本中的功能：Pravega 0.1.0。</p><h2 id="流和段"><a href="#流和段" class="headerlink" title="流和段"></a>流和段</h2><p>Pravega向应用程序公开的核心抽象是流。客户端可以将数据写入流并从同一流中读取数据。考虑在线应用程序的用户或某些物联网应用程序中的传感器事件生成的事件，以便写入要从Pravega流中读取的数据。我们将这两种类型的客户区分开来，分别称它们为  writer 和 reader。</p><p>Writer将数据附加到Pravega流。writer可以选择在附加到流时提供路由密钥。Pravega使用键将附加映射到 形成流的一个段。该段是形成流的基本单元，当writer将数据附加到流时，它实际上是附加到段。具有包括多个可打开以便附加的段的流对于并行性是需要的。更多的段打开意味着更高的写入容量，因为writer可以并行追加到段。</p><p>流可以具有任意数量的段打开，使得可以根据路由密钥对这些段中的任何段执行附加。Pravega的一个重要特征是流的段数不一定是固定的，并且开放段的数量可以根据负载而变化，我们将此功能称为缩放。当给定的段变热时，我们将键范围分成多个新段。当多个邻居段变冷时，我们反转该过程并合并键范围。</p><p>下图说明了由于缩放而对流的更改：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/praveg-blog-ihaveastream-2.png" alt="流的片段如何随着时间的推移随着流缩放而演变"></p><p>轴是时间（x轴）和路由键范围（y轴）。流以单个段开始（S1）。在时间t1，流向上扩展并且段S1分裂成段S2  和S3。在时间t2，它再次向上扩展，并且段S2分裂成S4和S5。请注意，S3没有任何反应。在时间t3，段S4和S5 合并到段S6中。</p><p>为了实现流缩放，Pravega具有密封段的概念。密封至关重要，以确保一旦有新的段附加，段就不会再发生任何追加。防止对已拆分或合并的段进行进一步写入对于保证使用相同键的追加顺序非常重要。例如，假设我们最初有一个流，其中单个段S1的范围为[0,1）。在某个时间T，我们将该段分成两个新的段S2、S3，其范围为：[0,0.5），[0.5,1]。如果稍后将 某些密钥k附加到S2的数据的应用程序能够将数据  附加到S1使用相同的密钥k，然后我们违反了顺序，因为逻辑上来自S1的所有数据都已附加在S2中的数据之前。</p><p>密封对交易也至关重要。Pravega允许writer以事务方式附加到流。要以事务方式编写，writer会开始一个事务并定期附加到流。一旦完成写入，它就会提交事务。在内部，在单独的事务段中附加事务。这些段只是常规段，但在提交之前它们不会作为任何流的一部分公开。当事务提交时，事务段被密封，并且它们被合并回主流段。此时，交易数据对于读者而言变得可见。如果事务中止，则仅丢弃事务段，并且它们根本不可见。重要的是要强调，当事务未定时，其数据与主段的数据分开。</p><p>利用这种实现事务的方法，流段中不存在正在进行的事务的干扰。为了论证，我们直接写入流段而不是创建事务段。在这种情况下，我们将至少通过以下几种方式为读者创造一个问题：</p><ol><li>当事务保持打开时，读取器不能提供来自打开事务的段数据，并且事务可以任意长时间地提交或中止。</li><li>在事务中止的情况下，流段仍包含来自中止事务的数据。段仅被附加，不能真正从段的中间消除数据。</li></ol><p>对事务的这种观察增强了我们基于能够实现这些特性的段的灵活方案的地位</p><h2 id="下一步是什么？"><a href="#下一步是什么？" class="headerlink" title="下一步是什么？"></a>下一步是什么？</h2><p>Pravega功能非常丰富。这篇文章刚刚介绍了Pravega所做的和提供的内容。在以后的文章中，我们将深入讨论特定主题：reader和writerAPI，Pravega体系结构，分段存储、控制器、使用修改后的流复制状态和部署Pravega。</p><p>我们目前正在研究即将发布的0.2版本。0.2的大多数功能已经合并，我们主要致力于稳定。如果您有兴趣提供贡献和帮助，我们一定会欢迎您加入我们的社区。</p><h3 id="About-the-Author"><a href="#About-the-Author" class="headerlink" title="About the Author:"></a>About the Author:</h3><p>Flavio Junqueira leads the Pravega team at Dell EMC. He holds a PhD in computer science from the University of California, San Diego and is interested in various aspects of distributed systems, including distributed algorithms, concurrency, and scalability. Previously, Flavio held a software engineer position with Confluent and research positions with Yahoo! Research and Microsoft Research. Flavio has contributed to a few important open-source projects. Most of his current contributions are to the Pravega open-source project, and previously he contributed and started Apache projects such as Apache ZooKeeper and Apache BookKeeper. Flavio coauthored the O’Reilly ZooKeeper: Distributed process coordination book.</p><p>原文: <a href="http://blog.pravega.io/2017/12/14/i-have-a-stream/" target="_blank" rel="noopener">http://blog.pravega.io/2017/12/14/i-have-a-stream/</a></p>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>pravega blog - streams in 与 streams out</title>
      <link href="/2018/11/17/pravega-blog-streams-in-and-out/"/>
      <url>/2018/11/17/pravega-blog-streams-in-and-out/</url>
      
        <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>读和写是Pravega提供的最基本的功能。应用程序通过写入一个或多个Pravega流来摄取数据，并通过从一个或多个流中读取数据来使用数据。但是，要使用Pravega正确实现应用程序，开发人员必须了解一些核心的写入和读取的附加功能。例如，写入可以是事务性的，reader可以被Group织成Group。</p><p>在本文中，我们将介绍开发人员在使用Pravega开发应用程序时必须注意的一些基本概念和功能，重点是读和写。我们鼓励reader在“开发Pravega应用程序”部分中另外查看Pravega文档站点，了解一些代码和更多细节。</p><h2 id="写入流"><a href="#写入流" class="headerlink" title="写入流"></a>写入流</h2><p>我们当前公开的用于编写的API使应用程序能够将事件附加到流中。事件是一个应用程序概念，应用程序可以定义事件是什么以及它代表什么。就Pravega而言，事件是字节序列，而Pravega并不试图理解事件。我们希望应用程序传递一个串行器，使  Pravega  能够接收任意类型的事件并将它们转换为字节序列。最终，  Pravega  在流段中存储字节序列，并且不知道事件类型。</p><p>存储字节序列而不是事件使得Pravega能够支持除API中的事件之外的抽象，例如，我们计划公开对读取和写入字节流的调用。当应用程序有其他包含不可变数据的大对象要存储时（例如Apache Flink中的检查点），此功能将非常有用。使用这样的API，应用程序能够直接在Pravega中存储这些对象，而不是依赖于单独的存储。<br>回想一下，Pravega流由段Group成，任何给定的流都可以在任何时间点打开许多并行段。为了将事件映射到段，应用程序会传递  路由键  以及事件本身。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/pravega-blog-streams-inout-1.png" alt="路由键到段图"></p><p>路由键是一个字符串，经过哈希处理以确定要将事件追加到哪个段。 Pravega  保证将路由密钥分配给段是一致的。请注意，由于流缩放，路由密钥到段的映射并不总是相同，但它是一致的。在两个缩放事件之间，写入具有相同路由密钥的流的所有事件都映射到同一个段。跨比例事件的分段根据缩放排序。为了使其具体化，例如示例，我们从一个区段S1向上扩展到区段S2和S3。S1的关键空间与S2和S3的关键空间重叠，但是S2和S3没有交集，所以可以简单地附加到S2和S3，但不要同时附加说S1和S2，因为具有相同路由键的事件可以转到两个不同的段。为了防止后一种情况发生，在S1被密封之前，S2和S3不会发生附加，这会在缩放事件之前和之后推广到任意数量的段。因此，一旦由于缩放事件而将段密封，则将未来事件附加到密封段的后继者，从而保留路由键顺序。</p><p>将事件写入流很简单，有两个选项：  常规 和  事务。通过常规写入，writer可以简单地触发写入事件的调用：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>// Set up a new scope and stream with a single segment (no scaling)<br>StreamManager streamManager = StreamManager.create(controllerURI);<br>StreamConfiguration streamConfig = StreamConfiguration.builder()<br>    .scope(scope).streamName(streamName)<br>    .scalingPolicy(ScalingPolicy.fixed(1))<br>    .build();<br>streamManager.createScope(scope);<br>streamManager.createStream(scope, streamName, streamConfig);<br> <br>// Create a client factory, a writer and append events<br>try(ClientFactory clientFactory = <br>      ClientFactory.withScope(scope, controllerURI) &#123;<br>    EventStreamWriter&lt;String&gt; writer = clientFactory<br>         .createEventWriter(streamName, <br>                            new JavaSerializer&lt;String&gt;(),<br>                            EventWriterConfig.builder().build()); <br>    writer.writeNext(&quot;Key 1&quot;, &quot;Hola&quot;); <br>    writer.writeNext(&quot;Key 2&quot;, &quot;Mundo!&quot;);<br>&#125;<br></code></pre></td></tr></table></figure><p>通过事务，writer开始一个事务并根据需要调用事件来进行多次调用：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>Transaction&lt;String&gt; txn = writer.beginTxn();<br>txn.writeEvent(&quot;Key 1&quot;, &quot;Hola&quot;);<br>txn.writeEvent(&quot;Key 2&quot;, &quot;Mundo!&quot;);<br>txn.commit();<br></code></pre></td></tr></table></figure><p>一旦完成，它就会提交事务，这使得事务中的写入可供读取。应用程序还可以选择中止事务，在这种情况下，作为事务的一部分编写的事件不可见。</p><p>关于writer的一些非常有趣的观点值得一提：重复和分段顺序。</p><h2 id="避免重复"><a href="#避免重复" class="headerlink" title="避免重复"></a>避免重复</h2><p>流中的重复可能是有问题的：它们通常会导致不正确的结果或不正确的行为。例如，重复可能导致实例的计数错误或状态机中的错误转换。一些应用程序对这种偏差非常敏感。</p><p>为避免重复，writer内部具有一个ID，用于确定重新连接时写入的最后一个事件。当writer有要追加的事件时，它会启动一个事件块的写入。一旦完成附加块，writer就会发送一个  块结束  命令，其中  包含写入  的事件数和  最后一个事件编号。writer附加块以便能够从批处理中受益。</p><p>段存储必须记住任何给定writerID的最后一个事件编号。否则，它无法发现重复。要记住给定writerID的最后一个事件编号，它会将writerID，事件编号对保留为该段的属性，作为处理追加请求的一部分。在writer断开连接并创建新连接的情况下，段存储将获取此属性并返回作为与客户端握手的一部分写入的最后一个事件编号。来自分段存储的响应使writer能够在其附加未完成的情况下从正确的事件中恢复。</p><p>但是，writer不会持久存在甚至暴露其writerID。如果writer崩溃并且实例化了新的writer，则新writer将使用新的writerID。尽管writer崩溃，为避免重复，我们需要将此writerID重复数据删除与事务相结合。通过事务性写入，如果写入程序在提交一批写入之前崩溃，那么它可以让事务超时并中止，在这种情况下，新写入程序可以从上一个写入程序停止的最后一个提交点恢复。</p><p>总而言之，  Pravega  通过检查与writerID相关联的事件编号以及使用事务写入来容忍writer崩溃来避免写入时的重复。在writer在事务中间崩溃的情况下，应用程序可以简单地让事务超时并中止。此类事务的部分写入不会向reader公开。</p><h2 id="段顺序"><a href="#段顺序" class="headerlink" title="段顺序"></a>段顺序</h2><p>流缩放导致流的段数随着时间而改变。流的段数的变化会导致随着时间的推移，路由关键字范围到段的映射发生变化。但是，如果映射发生变化，我们如何保证reader按照附加顺序接收具有相同路由键的事件？</p><p>为了保证具有相同路由密钥的事件的顺序，客户端与控制器一起根据它们的创建顺序读取段。例如，假设流以一个我们称为S1的段开始  。在时间  T1，段  S1  分成  S2  和  S3。因此，如缩放流的一部分，我们分离的键范围  S1  之间  S2  和  S3。为了简化讨论，让我们说我们将它分开，所以  S2  最终得到[0.0,0.5]，而  S3 以[0.5,1.0]结束。为了保证可以按附加顺序读取具有相同路由键的所有事件，我们需要确保在密封S1之前，writer不能附加到S2或S3。事实上，这正是writer的操作方式：当它发现一个段密封时，它会向控制器询问后继者。在这个例子中，当它到达S1的末尾   （表示段密封的返回代码）时，writer询问控制器并接收S2  和  S3  是后继者的响应  。下图说明了这种情况：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/pravega-blog-streams-inout-2.png" alt="读取和缩放"></p><p>在reader方，我们还必须遵循段的顺序，接下来当我们介绍reader和reader group时，我们将更详细地讨论它。</p><h2 id="从流中读取"><a href="#从流中读取" class="headerlink" title="从流中读取"></a>从流中读取</h2><p>流可以有多个段，writer可以并行追加。这种并行性不仅对于实现更高的摄取能力而且在读取和处理事件时实现并行性也很重要。</p><p>将事件附加到流时，我们可以让许多writer同时访问流的所有段。writer彼此独立，处理事件而无需进一步协调。我们也可以在读取方面有很多reader，但reader却不同。通常，事件只需要处理一次，因此一Groupreader需要协调段的工作负载分布，以便在整个Group中进行分割。</p><p>为了使reader能够有效地共享一个或多个流的工作负载，我们使用reader Group的概念  ：</p><p><strong>Reader Group</strong>：一reader Group是一Group RG 的  Pravega  reader和流S的一Group相关联，使得对于每个 ř ∈ RG，S（R）＆SubsetEqual; ⋃s∈ S C（S） 。在任何时间和任何两个不同的reader R，R ‘ ∈ RG ， S（R）∩ S（R’）是空的。</p><p>在该定义中，s（r）是分配给reader r的段的集合，并且c（s）是流的当前活动段的集合（用于读取的非密封段）。注意，这个定义并不意味着在所有的段 ⋃ 小号 ∈ 小号 C（S）在任何时间分配给一些reader。reader可能已经发布了一个片段，而其他人尚未获得该片段，或者尚未获得某些新片段。Reader Group的合约是，最终分配给⋃ 小号∈ 小号 C（S）中的任何段。因此，readerGroup不保证在任何时候 ⋃ 小号∈ 小号C（S）= ⋃ [R ∈ RG S（R） ，虽然我们保证了活性，所有 X ∈ ⋃ s∈ S C（S） ，最终x被分配到一些reader。 </p><p>每个reader都必须属于readerGroup。以下代码段说明了如何设置 reader：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>// Set up a new scope and stream with a single segment (no scaling)<br>StreamManager streamManager = StreamManager.create(controllerURI);<br>StreamConfiguration streamConfig = StreamConfiguration.builder()<br>    .scope(scope).streamName(streamName)<br>    .scalingPolicy(ScalingPolicy.fixed(1))<br>    .build();<br>streamManager.createScope(scope);<br>streamManager.createStream(scope, streamName, streamConfig);<br> <br>try (ReaderGroupManager manager =<br>              ReaderGroupManager.withScope(scope, controllerURI)) &#123;<br>    manager.createReaderGroup(readerGroup, <br>                              readerGroupConfig, <br>                              Collections.singleton(streamName));<br>&#125;<br> <br>try(ClientFactory clientFactory = <br>      ClientFactory.withScope(scope, controllerURI) &#123;<br>    EventStreamReader&lt;String&gt; reader = <br>             clientFactory.createReader(&quot;reader&quot;,<br>                                        readerGroup,<br>                                        new JavaSerializer&lt;String&gt;(),<br>                                        ReaderConfig.builder().build());<br>   while(!stop) &#123;<br>        EventRead&lt;String&gt; event = <br>                  reader.readNextEvent(READER_TIMEOUT_MS);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>将段分配给Group中的reader取决于使用我们在Pravega中称为stateSynchronizer的机制的reader的分布式协调  。stateSynchronizer使reader能够获得分布状态的一致视图，他们使用这些视图来协商Group状态的变化，  例如，分配了哪些分段以及分配给哪些分Group。我们用来确定分配的特定启发式算法很简单，但我们会对另一篇文章进行详细讨论。</p><p>reader和Group体有四个方面值得强调。</p><h2 id="段顺序-1"><a href="#段顺序-1" class="headerlink" title="段顺序"></a>段顺序</h2><p>为了保证reader在附加顺序中读取具有相同键的事件，reader遵循与writer类似的过程。当readerGroup 中的reader遇到密封段时，它会提取后继者，以便该Group可以从这些段中读取。如果后继者对应于分割密封片段的结果，那么reader可以立即开始阅读后继者。下图说明了这种情况：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/pravega-blog-streams-inout-3.png" alt="读取和缩放"></p><p>最初，流具有单个段  S1 ， 并且它最终扩展，导致S1分裂成  S2  和  S3。一旦reader 到达S1的末尾  ，它就会从控制器请求后继者，并开始从新的段中读取。</p><p>但是，如果密封段实际上与另一段合并而另一段尚未完全读取，该怎么办？让我们通过一个例子使这个方面更加具体。<br>假设我们有一个readerGroup  G，  有两个reader，  R1  和  R2。方案如下：</p><ul><li>Group  G  正在读取当前具有两个段  S1  和  S2的流。</li><li>R1  正在读取  S1，而  R2  正在读取  S2。</li><li>段合并为  S3  （S1  和  S2  是密封的，它们不接受进一步的附加）。</li><li>Reader  R1  命中S1结束   并请求其后继者。</li><li>reader  R1  回来说  S3  是S1的继承者  。</li><li>reader  R2  尚未完成  S2。</li></ul><p>如果  R1  或  R2  在R2  完成读取  S2之前   继续读取  S3，那么我们可能会违背我们在附加顺序中使用相同键读取事件的承诺。因此，为了满足我们的顺序属性，我们将  S3  置于保持状态，直到  R2标记它已完成  S2。只有这样   才能分配和读取S3。</p><p>为了协调分段的分配和顺序，我们再次依赖状态同步器。当reader获得段的后继者时，它会相应地更新状态，并且该状态将在ReaderGroup之间同步。具体到该示例，Reader  R1  将段S3添加   到未来 段的列表中  ，并且仅在完全读取S2的所有前任之后才分配段。</p><h2 id="检查点"><a href="#检查点" class="headerlink" title="检查点"></a>检查点</h2><p>我们目前不会通过reader GroupAPI向应用程序公开任何段信息。这是故意的。为了保证流的读取遵循正确的顺序，我们选择隐藏应用程序中后继者，前任和未来段的复杂性。即使应用程序没有明确地看到段，它仍然需要某种方式来确定流中在所有活动段中保持一致的点，并使应用程序从此点恢复。例如，如果应用程序想要从流中的较早点重新启动并恢复，则需要一种机制来引用此前一点。</p><p>检查点是我们提供的一种机制，使应用程序能够请求一个对象，该对象包含当前正在读取或可供读取的每个段的偏移量。检查点在内部使用状态同步器实现。一旦触发，reader就会协调生成一个不透明的检查点对象，该对象包含当前正在读取或可供读取的每个段的偏移量。</p><p>每个reader将其指定段的当前位置记录到状态一次：</p><p>1.它了解到有一个检查点在继续;<br>2.它已经发布了一个  检查点事件。</p><p>检查点事件通过reader 通知应用程序检查点正在进行中，并且应用程序应该采取任何适当的步骤（如果有的话）。例如，作为检查其状态的一部分，应用程序可能需要获取其输入的位置（  Pravega 流），为执行Reader的每个进程收集任何本地状态，并向下游刷新输出。因此，应用程序可能希望通过收集任何状态检查点信息并刷新下游的任何输出来对检查点事件作出反应，以避免重复。</p><p>如果需要，我们还利用检查点的机会重新平衡分段的分配。必须在检查点时执行此操作，以便应用程序有机会刷新任何挂起的状态更改，消息和事件，以避免任何重复。</p><h2 id="下游故障与重复"><a href="#下游故障与重复" class="headerlink" title="下游故障与重复"></a>下游故障与重复</h2><p>readerGroup使一组reader可以集中读取流。Reader Group逻辑以试图保持负载平衡的方式在Reader之间分配段。<br>一个重要的问题是当reader崩溃时会发生什么。具体来说，分配给该reader 的段会发生什么？显然，要在这些段存储取得进展，我们需要将它们重新分配给新的reader。在重新分配这些段时，我们需要从某个偏移量恢复。理想情况下，此偏移量是前一个Reader未读取的第一个偏移量。从第一个段偏移（偏移零）开始可能导致重复处理事件。如果应用程序对重复项敏感，则这是不可取的。</p><p>为了使应用程序在从Pravega读取时避免重复  ，我们执行以下操作。对于应用程序读取的每个事件，我们提供一个  位置 对象。position对象是一个可序列化的不透明对象，它包含reader当前分配的段的偏移量。此对象类似于检查点对象，但缩小为单个Reader。reader应该将此对象作为处理事件的一部分来持久化。如果Reader 崩溃，  Pravega  希望应用程序通过调用readerGroup API的方法并传递Reader 的最后一个位置对象来使Reader 脱机。此位置对象确定剩余Reader需要从指定段中的位置。</p><p>到目前为止，我们已选择将崩溃检测推送到应用程序。Reader Group API提供reader Offline调用，但它不提供任何检测崩溃的机制。因此，应用程序需要提供检测并相应地调用reader Offline。</p><p>请注意，使用位置对象背后没有任何魔力。我们要求应用程序合作：完全取决于应用程序持久保存这样的位置对象并在Reader崩溃时检索最新的位置对象。如果维护这些对象的成本很高或不合需要，那么根据所执行的处理的性质，应用程序在其输出中存在重复的风险。</p><h2 id="批读取"><a href="#批读取" class="headerlink" title="批读取"></a>批读取</h2><p>有时候应用程序想要简单地处理存储在流中的所有事件而不依赖于顺序。例如，假设应用程序想要收集流中的所有用户ID，事件中的单词，甚至执行经典的单词计数。在这种情况下，段的顺序并不重要。</p><p>对于这种情况，我们公开了一个批处理API，它使应用程序能够利用并行性并以任何顺序迭代流的各个段并使用它所需的任何程度的并行性。</p><p>要执行批量读取，应用程序会通过段请求迭代器：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>Iterator&lt;SegmentInfo&gt; segments = client.listSegments(stream);<br>SegmentInfo segmentInfo = segments.next();<br></code></pre></td></tr></table></figure><p>一旦它有了这个迭代器，它就可以继续单独遍历各个段：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>SegmentIterator&lt;T&gt; events = client.readSegment(segmentInfo.getSegment(),<br>                   deserializer);<br> <br>while (events.hasNext()) &#123;<br>    processEvent(events.next());<br>&#125;<br></code></pre></td></tr></table></figure><p>如果应用程序选择，它可以并行读取所有段。请注意，在撰写本文时，此API是实验性的，并且可能会发生变化。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>在这里，我们介绍了一些关于Pravega摄取和读的基本概念，和不是那么基本的一些概念  。这些是了解Pravega需要理解的一些主要概念 ， 基本功能易于使用和理解，但关于顺序和重复，在我们公开的属性中有一些细微差别，这对于开发人员来说是很重要的。更多的信息，我们建议读者们查看 Pravega.io网站  文档 和github上的代码库。</p><p><strong>原文</strong> ： <a href="http://blog.pravega.io/2018/02/12/streams-in-and-out-of-pravega/" target="_blank" rel="noopener">http://blog.pravega.io/2018/02/12/streams-in-and-out-of-pravega/</a></p>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>pravega blog - 流存储-重新设想流的世界</title>
      <link href="/2018/11/11/pravega-blog-storage-reimagined/"/>
      <url>/2018/11/11/pravega-blog-storage-reimagined/</url>
      
        <content type="html"><![CDATA[<p>将海量原始数据转换为有用的信息和行动所需的时间缩短为零的愿景的驱动下，流式传输看似简单：只需在数据到达时，快速地、连续且无限地处理和处理数据。</p><p>对于从工业物联网到联网汽车到实时欺诈检测等的用例，我们越来越多地寻求构建新的应用程序和客户体验，以快速响应客户的兴趣和行为，学习和适应不断变化的行为模式等。但实际情况是，我们大多数人还没有工具来处理生产级数据量、摄取率和故障弹性。因此，我们尽可能地利用定制系统在复杂性之上堆积复杂性。</p><p>复杂性是基本系统设计不匹配的症状：我们使用一个组件来完成它没有设计完成的任务，并且我们使用的机制不会从小到大进行扩展。</p><p>流式传输很难实现，因为它具有三种破坏性系统功能：</p><ul><li>能够将数据视为连续且无限的而不是有限的和静态的</li><li>能够通过与到达的数据量协调地动态扩展数据摄取、存储和处理能力来提供始终如一的快速结果的能力</li><li>即使是迟到或无序数据，也能够持续提供准确的结果处理数据</li></ul><p>在这里，它以一种好的方式变得有趣，甚至更具破坏性：事件驱动，连续和有状态数据处理的流式范例以及在许多情况下对时间的一致理解比传统的ETL&gt;Store&gt;Query， 即使对于没有实时要求的应用程序，查询方法也是如此！</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/Blog-Fig-1-1.png" alt=""></p><p>图1：流式处理的简单生命周期</p><p>流式传输迫使系统设计人员重新思考基本的计算和存储原理。作为充满激情的存储人员，我们正在通过设计一个新的存储原语（称为流，专门为流体系结构构建并在名为Pravega的新开源项目中实现）来完成我们的工作。</p><p>通过将Pravega流存储与像Apache Flink这样的有状态流处理器相结合，我们实现了一个系统，其中上图中的所有元素 - 写入器，处理器，读取器和存储 - 独立，弹性和动态可扩展，与数据到达使我们所有人都能够构建我们以前无法构建的流式应用程序，并无缝地将它们从原型扩展到生产。</p><h2 id="流式存储的要求"><a href="#流式存储的要求" class="headerlink" title="流式存储的要求"></a>流式存储的要求</h2><p>让我们看看流式系统的三个破坏性特征中的每一个，看看Pravega流如何以今天的存储无法实现的方式实现它们。</p><h3 id="将数据视为连续和无限"><a href="#将数据视为连续和无限" class="headerlink" title="将数据视为连续和无限"></a>将数据视为连续和无限</h3><p>附加到文件末尾并尾随其内容会模拟连续且无限的数据流，但文件并未针对此模式进行优化。它们也不是无限的。曾经轮换过日志文件的人都知道这一点。套接字或管道是连续数据的更好抽象，但它们不是持久化的。消息传递是连续数据的合理抽象 - 特别是像Kafka的仅附加日志 - 但它们并不是设计为无限、持久化的系统。并且它们使用信包和标题来构造数据结构，使它们不像字节序列那样通用。</p><p>将这些想法拼凑在一起，我们提出了Pravega将从数据的角度支持的特征，即连续和无限：</p><ul><li>Pravega流是一个有命名空间的、持久的、仅附加的、无限的字节序列</li><li>低延迟附加到序列的尾部并从中读取</li><li>通过序列的较老部分进行高通量追赶读取</li></ul><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/Blog-Fig-2-1.png" alt=""></p><p> 图2：在管道中使用流</p><h3 id="基于数据到达量的系统扩展"><a href="#基于数据到达量的系统扩展" class="headerlink" title="基于数据到达量的系统扩展"></a>基于数据到达量的系统扩展</h3><p>那么我们如何根据数据量弹性地、独立地缩放数据摄取、存储和数据处理？</p><p>我们通过将数据拆分为分区，并独立处理来获得并行性。例如，Hadoop通过HDFS和map-reduce实现了批处理。对于流式工作负载，我们今天要使用队列或Kafka分区。这两个选项都有同样的问题：分区会影响读者和写入者。连续处理的读/写缩放要求通常不同，并且链接它们会增加复杂性。此外，虽然可以添加队列或分区以进行扩展，但这需要手动协调地更新写入器、读取器和存储。这是很复杂，而不是动态缩放。</p><p>Pravega流，专为动态和独立扩展而设计，支持：</p><ul><li>许多写入者同时追加一个不相交的数据子集<ul><li>不相交的子集由用相同密钥写入的数据定义</li><li>为写入者分配密钥留给应用程序 </li><li>当密钥空间或编写器更改时，存储不得约束或不需要更改</li></ul></li><li>许多读者同时处理不相交的数据子集<ul><li>读取的数据分区必须独立于写入分区</li><li>读取分区必须由存储策略控制，例如将流分成足够的段以确保没有看到超过N字节/秒</li><li>每个传入数据卷的存储系统必须自动且不断地更新流中的段数</li></ul></li></ul><p>这些都是很苛刻的要求，我们来看看两种典型的分区方案。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/Blog-Fig-3-1.png" alt=""></p><p>图3：摄取率&lt;&lt;处理率</p><p>在图3中，处理时间比摄取时间更长。有一个写入器，但数据被分段用于读取：读取器＃1获取密钥k a … k c的数据，另一个获取密钥k d … k f。在图4中，处理比摄取更快，因此拓扑反转：多个写入器为写入分区密钥空间，但是一个读取器处理它。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/Blog-Fig-4-1.png" alt=""></p><p>图4：摄取率&gt;&gt;处理率</p><p>在现实生活中，我们最终介于两者之间 - 随着我们的数据源和应用程序的发展，可能会随着时间的推移而变化。虽然流将由多个段内部组成，但（a）写入者并不知道段拓扑，因为他们只知道键，以及（b）读者动态学习段拓扑 - 只需将它们指向流即可。</p><p>为了使整个系统（存储+处理）适应不断变化的数据量，Pravega不断监控流的传入数据速率，并确保存在适当数量的段以满足SLO合规性。图5显示了流的片段随时间动态变化。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/Blog-Fig-5-1.png" alt=""></p><p>图5：随时间动态缩放流段</p><p>在t 0，输入数据速率低于缩放SLO。所有数据都存储在段0中。在t 1，超过SLO。段0被密封，并且创建了段1和段2。k 0和k 1的新数据将转到段2。k 2和k 3 的新数据进入第1段。这是针对数量增加而分割的细分市场。分裂也发生在t 2和t 3。在t 4，速率减慢。段3和6被密封，并且段7被创建并将保持k 1 … k 2 的新数据。这是一个段合并以响应数量减少。</p><p>Pravega的分段缩放协议允许读者跟踪分段缩放并采取适当的措施，例如添加或删除读取器，使整个系统能够以协调的方式动态缩放。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/Blog-Fig-6-1.png" alt=""></p><p>图6：具有动态，协调的组件缩放的流式传输系统</p><h3 id="持续生成准确的结果处理数据"><a href="#持续生成准确的结果处理数据" class="headerlink" title="持续生成准确的结果处理数据"></a>持续生成准确的结果处理数据</h3><p>连续计算准确的结果意味着精确地进行一次处理，并且当关于该发生的数据被计算处理时，将事件时间——现实生活中发生的时间——与处理时间区分开。为此，我们向链式应用程序添加了一个要求，同时保留了一次将计算分成多个独立的应用程序。这是流式处理满足微服务。</p><p>与lambda架构相比，生成准确结果的流式系统可以节省大量成本，其中实时和批处理使用单独的基础架构。这不仅更简单、更便宜 - 它只是一个基础设施而不是两个 - 它简化了开发，因为您总共只需要编写一次代码而不是为每个 lambda 基础设施都编写一次。Tyler Akidau的O’Reilly博客中有一篇关于这些概念的精彩文章，名为“超越批量的世界：流式101”。</p><p>恰好一次的存储要求是明确的：流必须是持久的、有序的，一致的和事务性的。这些是关键属性，因为它们是存储系统设计中最困难的方面。如果没有重大的重新设计，您无法在以后更改它们。</p><p>持久性意味着一旦得到确认，即使面对组件故障，写入也不会丢失。持久性至关重要，因为如果数据丢失，则无法（重新）处理。大多数持久的数据并没有解决问题：要么你可以依靠存储持久性，要么你不能。不持久的系统不是记录系统，意味着数据的永久副本必须存储在其他地方 - 通常存储在对象存储或NAS等归档系统中。归档意味着ETL的应用程序代码和ETL过程的管理。这种复杂性被消除了，因为Pravega流式存储是一个持久的永久存储，您可以永久地可靠地保存您的流数据。</p><p>排序意味着读者将按照写入的顺序处理数据。对于具有密钥分区写入的流的系统，排序仅对具有相同密钥的数据有意义。在拥有数百万设备生成传感器指标的物联网系统中，sensor-ID.metric可能是关键。流保证读取密钥的数据将按其编写的顺序进行。对于许多计算（例如使用增量更新计算的聚合度量），排序是必不可少的。</p><p>一致性意味着所有读者都会看到给定密钥的相同有序数据视图 - 即使面对组件故障 - 无论是从流的尾部读取数据还是通过追加读取。与持久性一样，大多数情况并不一致：要么存储是一致的，要么是不一致的。从恰好一次的要求来看，存储一致性与区分计算层中的事件时间与处理时间同等重要。</p><p>事务性写入对于跨链接的应用程序一次完全正确是必要的。像Flink这样的有状态流处理器使用聪明的分布式检查点在单个应用程序中只有一次内部机制。跨多个应用程序精确扩展一次范围需要中间存储（在本例中为流）通过事务写入参与这些检查点方案。</p><h2 id="Pravega-Streams"><a href="#Pravega-Streams" class="headerlink" title="Pravega Streams"></a>Pravega Streams</h2><p>Pravega是一个实现流的开源分布式存储服务。流是可靠流式传输系统的基础：高性能、持久化，有弹性且无限附加的字节流，具有严格的排序和一致性。流是轻量级的。就像文件或对象一样，我们可以根据需要快速轻松地创建多个文件或对象 - 单个群集中的数百万。</p><p>通过对先前的内部日志和专有日志进行重构和外部化，流大大简化了新一代分布式中间件的开发和运行，这些中间件被重新构想为流式基础架构：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/Blog-Fig-7-1.png" alt=""></p><p> 图7：为流式世界重构堆栈</p><p>Pravega项目目前包括Pravega字节流原语以及分层摄取缓冲区和pub / sub机制，在概念上与Kafka类似，但具有性能、弹性、无限性、一致性和持久性的流特性。我们将在下一节讨论将Pravega的摄取缓冲区与Flink集成。</p><p>另外两个项目，都将通用中间件服务重新构想为流式基础设施，处于早期概念阶段：</p><ul><li>基于流的全文搜索：动态的、分布式的、实时的Lucene索引器，具有用于流数据的连续查询工具</li><li>流支持的持久数据结构：微服务原生主义者的框架，他们希望自己的微服务拥有自己的数据</li></ul><h2 id="Pravega架构"><a href="#Pravega架构" class="headerlink" title="Pravega架构"></a>Pravega架构</h2><p>Pravega的架构有三个主要组成部分。所述Pravega流服务是使用分布式软件服务执行流抽象语义，包括流控制和段存储的API，数据存储器缓存（Rocks DB）以及利用两个底层存储系统的数据放置和分层逻辑：低延迟存储Apache Bookkeeper，以及HDFS用于支持高吞吐量、大规模的存储。[此组件旨在可插拔，以支持具有适当强一致性语义的备用后备存储系统。]</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/Blog-Fig-8-1.png" alt=""></p><p> 图8：Pravega流式存储架构</p><p>Pravega的系统设计有许多创新，使其能够满足流的挑战性要求。I / O路径设计完全隔离了读写路径，从而实现了对尾部进行极低延迟的持久写入，从尾部进行低延迟读取以及从流的老的部分进行高吞吐量读取。Pravega架构的细节超出了本文的范围。更多信息可在Pravega Architecture Wiki中找到。</p><h2 id="流式存储-Apache-Flink-YEAH！"><a href="#流式存储-Apache-Flink-YEAH！" class="headerlink" title="流式存储+ Apache Flink = YEAH！"></a>流式存储+ Apache Flink = YEAH！</h2><p>让我们探索Pravega流如何与Flink集成，以实现一个动态和弹性的系统，提供快速和准确的计算结果，同时即使在数据速率变化很大的情况下也可以在恒定的时间内处理海量数据。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/Blog-Fig-9a.png" alt=""></p><p>系统的概念结构如图9所示。它包含一个典型的输入流，其中包含由一组写入者编写的原始数据，一个用于处理它的多工作者Flink应用程序，以及一个处理第一个输出的链式Flink应用程序。</p><p>这里是不同的地方：每个元素 – 写入者、输入流、读取器应用程序，输出流 - 独立，弹性和动态可伸缩，以响应数据量到达率随时间的变化。</p><p>两个集成点实现了这一点：Pravega的分段缩放驱动Flink的worker缩放，以及通过流将应用程序链接到整个系统，从而精确地保存一次。仅使用一个worker部署Flink应用程序，并根据流SLO动态缩放它。太好了！Pravega和Flink开发人员已经将流自动缩放功能整合到Flink中。</p><p>除了此之外，无限流还可以显著的简化许多操作用例。这里考虑推出一个新版本的Flink应用程序（真正的任何应用程序），首先根据历史数据对其进行测试。</p><p>图10展示了今天针对实时Flink应用程序的典型部署。信息被馈送到消息传送系统，由Flink应用程序处理，然后被转发到NOC或类似的框架以进行显示和/或动作。与此同时，ETL工作人员不断地将消息拉出并将其写入持久化的存储以进行历史访问。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/Blog-Fig-10-1.png" alt=""></p><p> 图10：测试没有流的新应用版本的复杂性</p><p>现在我们已经构建了一个新版本的应用程序“App”。准备在生产环境里对无中断部署之前，尝试针对历史数据集的新逻辑来验证正确性并确保没有回归的操作过程是什么？</p><p>首先，我们需要部署”App”来从归档而不是消息传递系统里获取其数据。因此，您的测试与生产不同：归档和消息传递之间的微妙行为差异可能会使测试不可靠。测试完成后，我们重新部署“App”以使用消息传递系统，并重新填充其缓存或从历史数据中派生的其他状态。如果一切正常，我们终于可以取代之前的版本了。结果是一个复杂的工作流程序列。复杂性意味着麻烦。</p><p>Pravega流如何改变？App’的部署与生产完全一样，因为历史数据是通过相同的流访问的- 只需回放它！消耗历史记录时，App’和App正在处理具有相同状态的相同数据。当我们确信App’很好时，请关闭App并重定向NOC。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/Blog-Fig-11-1.png" alt=""></p><p> 图11：使用流测试新的应用版本</p><h2 id="结束思考"><a href="#结束思考" class="headerlink" title="结束思考"></a>结束思考</h2><p>我们是充满激情的存储界人，我们喜欢流式的想法，我们觉得Flink这样的“原生的流式”计算非常的有意思。我们认为这个世界需要一种互补的存储技术。Pravega是我们贡献的开源流存储项目：pravega.io，我们相信它将进一步推动流式技术的发展.</p><p>请记住，当您考虑流式应用时，请将数据视为连续且无限的，而不是静态和有限的。想想企业存储的重要性，如持久性、一致性弹性、以及现在的：无限性。</p><p>另外我们鼓励您加入我们的社区！</p><blockquote><p>原文链接：<a href="http://blog.pravega.io/2017/04/09/storage-reimagined-for-a-streaming-world/" target="_blank" rel="noopener">http://blog.pravega.io/2017/04/09/storage-reimagined-for-a-streaming-world/</a></p></blockquote><blockquote><p>About the Author： Salvatore DeSimone – VP and CTO Advanced Software Division at Dell EMC</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>pravega blog - pravega的内部架构</title>
      <link href="/2018/11/02/pravega-blog-internals/"/>
      <url>/2018/11/02/pravega-blog-internals/</url>
      
        <content type="html"><![CDATA[<p>尾随数据流的一些困难归结为源和流处理器总是动态变化的。例如，如果源以非计划的方式增加其输出率，则读取系统必须能够适应这种变化。处理器下游遇到问题并努力跟上速率的变化也是如此。为了能够适应所有这些变化，用于存储流数据的系统（如Pravega）必须足够灵活，这一点至关重要。</p><p>Pravega的灵活性来自将数据流分解为段：仅附加的字节序列，这些字节序列被顺序和并行地组织成流。段支持重要的特性，例如并行读写，自动缩放和事务; 它们一开始就是按创建和维护成本低廉的理念而设计。当需要更多并行性，需要扩展或需要启动事务时，我们可以为给定流创建新的段。</p><p>Pravega中的控制面负责所有影响流的生命周期的所有操作，如创建、删除和缩放。数据面存储和服务段的数据。下图描绘了具有核心组件的高级Pravega架构。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/flavio_fig1.png" alt=" Pravega 架构图"></p><p>鉴于我们在之前的博客文章中讨论了客户端的概念，我们将在以下部分重点介绍控制器和段存储。</p><h2 id="控制器"><a href="#控制器" class="headerlink" title="控制器"></a>控制器</h2><p>控制器实现了Pravega的控制平面。它负责Pravega集群中的一些非常重要的任务，例如：</p><ol><li><p>流生命周期：管理流的创建，删除和缩放。</p></li><li><p>事务管理：它负责启动或创建事务并跟踪其状态，包括时间跟踪。</p></li></ol><h2 id="控制器服务"><a href="#控制器服务" class="headerlink" title="控制器服务"></a>控制器服务</h2><p>控制器主要负责编排所有流生命周期操作，如创建、更新、缩放和删除流。因此，控制器维护流元数据并响应客户端对流的查询。</p><p>创建和删除流是由用户请求触发的操作，但是控制器的某些操作由内部机制触发，例如缩放和保留。控制器实现工作流，使用户能够配置控制器以自动缩放流，并根据时间或大小截断流。此机制的配置基于策略，并且根据应用程序所期望的行为将策略配置为流配置的一部分。有关如何配置此类策略的示例，请参阅以下代码段：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>// Set up scaling and retention policies. <br>//<br>// In this example, the scaling policy sets the target rate to be<br>// of 10 events/second, with a scaling factor of 2, and a minimum<br>// of 2 segments.<br>//<br>// http://pravega.io/docs/latest/javadoc/javadoc/clients/io/pravega/client/stream/ScalingPolicy.html<br>//<br>// The retention policy sets it to an hour. With this policy, Pravega<br>// retains stream data for at least an hour and truncates eventually<br>// after the time has elapsed.<br>//<br>// http://pravega.io/docs/latest/javadoc/javadoc/clients/io/pravega/client/stream/RetentionPolicy.html<br>ScalingPolicy scalingPolicy = ScalingPolicy.byEventRate(10, 2, 2);<br>RetentionPolicy retentionPolicy = RetentionPolicy.byTime(Duration.ofMinutes(60);<br><br>// Configure the stream adding the policies<br>StreamConfiguration config = StreamConfiguration.builder().scope(&quot;myScope&quot;)<br>                                                          .streamName(&quot;myStream&quot;)<br>                                                          .scalingPolicy(scalingPolicy)<br>                                                          .retentionPolicy(retentionPolicy)<br>                                                          .build();<br><br>// Create scope and stream with the previously built configuration<br>StreamManager streamManager = StreamManager.create(controllerURI);<br>streamManager.createScope(&quot;myScope&quot;);<br>streamManager.createStream(&quot;myScope&quot;, &quot;myStream&quot;, config);<br></code></pre></td></tr></table></figure><h2 id="客户端交互"><a href="#客户端交互" class="headerlink" title="客户端交互"></a>客户端交互</h2><p>控制器在客户端交互中起着至关重要的作用。客户端与控制器交互以创建和删除scope和流。此交互通过Java或REST API进行。</p><p>创建和删除流是通过API调用直接触发的操作，但是对于客户端的来说，其他操作也很重要的，并且这些操作需要透明化。具体而言，客户端在其生命周期中需要与控制器交互，以了解段集以及它们所处的位置。回想一下，流执行自动缩放，因此，任何配置为自动缩放的流的段集都可以随时间改变。随着流的演进，客户端需要知道从控制器获得的这些段的拆分和合并。然而，了解当前的段集是不够的。客户端还需要知道对于给定的段，需要联系哪个段存储。控制器负责客户端和段存储之间的这种交集。</p><p>作为缩放流的一部分，控制器负责密封其部分片段。密封段是我们用来向客户端指示它需要从控制器获取新元数据的主要机制。在找到段的末尾（段密封）后，客户端从控制器请求后继段，包括联系用于新段的相应段存储所需的信息。此流程对于确保流的伸缩与应用程序无缝地互动至关重要，并且避免对应用程序的任何干扰。</p><h2 id="控制器实例"><a href="#控制器实例" class="headerlink" title="控制器实例"></a>控制器实例</h2><p>控制器服务包括许多控制器实例，这些实例当前依赖Apache ZooKeeper进行元数据协调。可以根据群集要求创建实例数。建议至少有两个实例能够容忍崩溃，并引入其他实例，既具有较高的崩溃容忍度，又能提高容量。只要有可能，控制器就会缓存ZooKeeper元数据以避免网络延迟。</p><p>随着控制器实例的数量随时间变化，系统必须能够适应对控制器集合的变化。在控制器实例崩溃或有意从系统中删除的情况下，我们实现了故障转移机制，以便其余实例接管已删除实例的工作。为了启用此类故障转移过程，控制器实例将向ZooKeeper注册并监视订阅的更改。在检测到实例已被移除时，每个控制器实例触发一组清扫任务争夺已删除实例的工作所有权。通过这种方式，我们可以自动响应控制平面中实例数量的变化。请注意，元数据是通过ZooKeeper存储和协调的，因此，控制器实例被视为无状态进程。目前正在努力将一些流元数据移出ZooKeeper fort可伸缩性。我们将在以后的文章中介绍它。</p><h2 id="事务管理"><a href="#事务管理" class="headerlink" title="事务管理"></a>事务管理</h2><p>控制器服务管理事务的生命周期。用户应用程序中的编写器请求控制器执行与事务有关的所有控制平面操作。在启动事务时，写入器需要使用控制器服务进行设置。控制器添加必要的元数据以跟踪事务的状态，并在需要更多时间才能完成的情况下将其设置为超时。</p><p>客户端针对单个流执行事务，因为Pravega当前不支持跨多个流的事务。当客户端开始事务处理时，控制器创建事务段，会为每个流段开放一个事务段。例如，假设客户端针对具有三个开放段s 1、s 2、s 3的流S启动事务。控制器创建事务TS i为每个打开的段SI，i∈{1，2，3} 。当客户端使用给定密钥k写入事件时要附加到段s i，该事件将附加到ts i。在提交事务的情况下，事务段被合并到流段上，并且事务事件变得可用于读取。</p><p>一旦写入器准备好，它就根据应用程序逻辑提交或中止事务，并且控制器负责命令段存储执行事务段的合并。它还负责更新事务相应的元数据。<br>当通过提交或中止事务来结束事务时，控制器需要确保事务的结果在确认操作后不会改变。接受提交事务并随后中止同一事务，或者反过来，是不可接受的方案。当它收到提交事务的请求时，控制器通过读取事务元数据（存储在ZooKeeper中）来检查事务的状态。如果事务仍处于打开状态，则控制器会更新元数据以反映其新状态。请注意，可以有多个控制器实例，并且元数据的更新需要以znode版本为条件，以避免因竞争条件导致的不一致。</p><p>事务元数据操作成功后，它会将事件发布到内部提交流，以便异步处理。这种流是用于内部目的的常规Pravega流。内部流的事件由提交事件处理器处理，提交事件处理器是处理流事件的控制器实例中的元素。提交事务事件包括合并事务段。在提交事件的处理被中断的情况下，例如，因为控制器实例崩溃，不同控制器流中的提交处理器可以拾取并执行它。合并操作是幂等的，并且在同一段上多次尝试时不会引起任何不一致。</p><p>同样，在事务中止的情况下，该过程类似于删除事务段。</p><p>对于同一流上的并发事务，控制器按顺序提交它们以保证两个或多个事务的事件在单个段中的排序不同。如果控制器同时合并两个事务t 1和t 2 ，那么一些段可能在t 2事件之前对t 1事件进行排序，而其他段可能具有相反的顺序。提交（和合并）的串行顺序保证满足此属性。</p><p>一个有趣的方面是在存在缩放的情况下处理事务。如果事务段和开放流段之间存在一对一映射，那么当流缩放并更改段数时会发生什么？在Pravega的原始设计中，我们选择阻止流的缩放，直到所有未完成的事务都已提交或中止。。我们有一个超时，如果事务在进行伸缩操作时调用时间过长，则会中止事务。这个超时可能导致的主要问题是应用程序花了太长时间来提交事务，即使它确实想要提交事务。这种情况在本质上存在正确性的问题，因为写入的数据是从应用程序获取的，而应用程序则指望将其公开。最近，我们添加了一项特性，使事务能够在缩放事件中“滚动”。在事务以一组给定的段开始，并且当事务提交时段的集合不同的情况下，我们就像对流的缩放一样处理它：我们密封当前的段集Σ，使事务段成为后继者，并创建一组新的后继段Σ’，使得| Σ| = | Σ’| 密钥空间的分割与Σ相同。</p><h2 id="段存储"><a href="#段存储" class="headerlink" title="段存储"></a>段存储</h2><p>段存储实现了Pravega的数据平面，并且正如名称所说的那样：它存储段。它在使分段数据持久并有效地提供服务方面发挥着关键作用。段存储与流的概念无关。控制器执行分段到流的组成。例如，当我们将一个段拆分为新段时，段存储会创建新段，但控制器有责任了解流中段的顺序。</p><p>段存储服务的一个角色是将事务段合并为流的段。控制器负责命令段存储在事务提交时合并事务段，并且段存储基于每个段执行必要的操作。</p><p>段存储有两个主存储依赖关系，我们给出了第1层和第2层的通用名称。第1层的主要目标是保证写入持久且低延迟。使写入持久意味着一旦应用程序获知写入请求成功，系统就会保证写入不会丢失，即使有错误。第1层的实现是段存储写入的仅附加数据结构。可以将其视为段存储更新的日志。</p><p>我们将附加的数据和一些其他Bookeeper数据同步记录到第1层，这些数据是我们为了正确操作服务而需要持久保存的。目前，Pravega使用Apache BookKeeper [1]来实现第1层.BookKeeper为少量数据提供了出色的写入延迟，这保证了写操作的持久性，同时为事件流提供低延迟。我们还使用了在打开BookKeeper分类帐时屏蔽旧陈述者的能力。这是BookKeeper提供的一个特性，即使存在错误的崩溃问题，也能使其一致性。</p><p>我们将数据异步迁移到第2层，一旦我们这样做，我们就会截断了来自第1层的相应数据。我们有一个第2层，原因有两个：</p><ul><li>我们设想一个可以存储大量数据的无限量数据的系统。因此，我们需要一个水平可扩展的大容量存储来容纳所有的这些数据，遵循更紧密的云存储选项。</li><li>我们需要为读取数据提供高吞吐量选项，特别是在我们需要赶上流时读取旧数据时。</li></ul><p>我们目前支持第2层的几个选项：HDFS [2]，NFS [3]和扩展S3 [4]。</p><p>在这一点上，重要的是要讨论我们预期的两种不同类型的读取，以便我们理解这种架构背后的动机。我们希望应用程序执行尾部读取和追赶或历史读取 [5]。尾部读取对应于最近写入的字节读取，正如术语所指示的那样尾随流的写入者。这样的读取器期望非常低的延迟，并且为了满足这个要求，我们保留最近写入内存的数据缓存以服务于这些读取。我们目前使用RocksDB [6]来实现这样的缓存。</p><p>下图说明了Pravega中的尾部和追赶读取。段存储服务的所有数据都来自缓存。对于尾部读取，期望它是足够新的，以便缓存命中，并且可以立即提供服务。对于历史数据，它可能是缓存未命中，其中它会引起对第2层的读取以填充缓存。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/flavio_fig2.png" alt="尾部和追赶读取"></p><p>第一层中的数据唯一地用于恢复的，并且如上所述，在缓存未命中的情况下，我们提供从缓存的读取和从第2层获取数据的服务。我们还开始实现一种不同类型的只读段存储（PDP-25）的实现。只读段存储不会缓存来自第2层的数据。这样的特性对于批处理读取量很大的设置很有用（例如，对于批处理作业），因为这种批量读取可能最终在常规段存储的情况下干扰新数据的摄取。只读段存储的工作尚未完成，在撰写本文时，客户端无法使用该功能。</p><p>段存储服务器中的工作负载在跨段容器之间进行拆分。在轻量级虚拟化环境中，这不会与容器混淆（例如， Docker容器）。段容器是Pravega的概念。它们是段的逻辑分组，并负责对这些段内的所有操作进行操作。容器是工作分配和恢复的单位; 控制器是负责在重新平衡时将容器分配给不同的段存储的元素，这是由于段存储崩溃导致新的段存储启动或重新分配。每个容器在任何时候都应该有一个所有者，我们使用围栏机制来防止僵尸进程的出现（仍然认为他们拥有它的旧所有者）。</p><p>段存储的每个实例都执行容器管理器，该管理器负责管理分配给该实例的段容器的生命周期。在重新分配容器的情况下，容器管理器需要通过关闭或引导段容器来做出反应，具体取决于段存储实例是新所有者还是容器的先前所有者。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>这篇文章介绍了Pravega内部的概要性的架构视图。它展现了控制器和段存储。它们是实现Pravega核心的两个主要组件：控制器实现控制平面，而段存储实现数据平面。正如之前的文章所讨论的那样，段抽象非常重要，可以灵活地开发kick-ass功能，以支持流作为存储原语。</p><p>未来的文章将详细介绍控制器和分段存储机制，这篇文章介绍一些概念，为即将发布的pravega的更深入的文章为读者提供背景上下文信息。</p><h3 id="About-the-Author"><a href="#About-the-Author" class="headerlink" title="About the Author"></a>About the Author</h3><p>Flavio Junqueira leads the Pravega team at Dell EMC. He holds a PhD in computer science from the University of California, San Diego and is interested in various aspects of distributed systems, including distributed algorithms, concurrency, and scalability. Previously, Flavio held a software engineer position with Confluent and research positions with Yahoo! Research and Microsoft Research. Flavio has contributed to a few important open-source projects. Most of his current contributions are to the Pravega open-source project, and previously he contributed and started Apache projects such as Apache ZooKeeper and Apache BookKeeper. Flavio coauthored the O’Reilly ZooKeeper: Distributed process coordination book.</p><h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><p>[1] Apache BookKeeper. <a href="http://bookkeeper.apache.org" target="_blank" rel="noopener">http://bookkeeper.apache.org</a><br>[2] Hadoop File System. <a href="https://hadoop.apache.org/" target="_blank" rel="noopener">https://hadoop.apache.org/</a><br>[3] R. Sandberg, D. Goldberg, S. Kleiman, D. Walsh, and B. Lyon. Design and Implementation of the Sun Network Filesystem. USENIX Conference and Exhibition, 1985.<br>[4] Extended S3. <a href="https://www.emc.com/techpubs/ecs/ecs_s3_supported_features-1.htm" target="_blank" rel="noopener">https://www.emc.com/techpubs/ecs/ecs_s3_supported_features-1.htm</a><br>[5] Leigh Stewart. Building DistributedLog: High-performance replicated log service, September 2016.<br>[6] RocksDB: A persistent key-value store for fast storage environments. <a href="https://rocksdb.org/" target="_blank" rel="noopener">https://rocksdb.org/</a><br>[7] Stephan Ewen and Flavio Junqueira, An elastic batch and stream processing stack with Pravega and Apache Flink, April 2018.</p><p>原文链接：<a href="http://blog.pravega.io/2018/10/" target="_blank" rel="noopener">http://blog.pravega.io/2018/10/</a></p>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>pravega handbook - 设计提案</title>
      <link href="/2018/10/09/pravega-pdp-design-proposals/"/>
      <url>/2018/10/09/pravega-pdp-design-proposals/</url>
      
        <content type="html"><![CDATA[<p>本文档描述了开发Pravega新特性所遵循的流程。我们的想法是在开始实现这个特性之前先提出设计方案，并与社区讨论这个设计，避免由于方案的分歧而导致的长时间的检视。流程如下：</p><h2 id="设计文档"><a href="#设计文档" class="headerlink" title="设计文档"></a>设计文档</h2><p>将设计文档编写为当前页面的子页面。页面标题应为：</p><blockquote><p>PDP-XX: 简要描述特性</p></blockquote><p>XX是我们通过递增先前提案的编号而生成的数字。第一个数字是01，希望在创建新PDP时不会有任何冲突。我们将使用PDP-XX作为标签来指代特定的设计。</p><p>该文件应包含：</p><ul><li>功能和提案的摘要（摘要）</li><li>API更改的说明（API更改）</li><li>内部变更说明（内部变更）</li><li>必要时有关向后兼容性和迁移计划的部分（兼容性和迁移）</li><li>关于解决问题的废弃方法的章节（废弃方法）</li><li>引用，例如，Github问题或pull请求（参考）</li></ul><p>如果某个部分不适用，请说“不适用”，但不要省略该部分。</p>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>pravega handbook - 开发pravega应用 - connector与readerGroup通知</title>
      <link href="/2018/10/02/pravega-working-with-connector-readergroupnotifications/"/>
      <url>/2018/10/02/pravega-working-with-connector-readergroupnotifications/</url>
      
        <content type="html"><![CDATA[<h1 id="ReaderGroup通知"><a href="#ReaderGroup通知" class="headerlink" title="ReaderGroup通知"></a>ReaderGroup通知</h1><p>ReaderGroup api支持不同类型的通知。目前，我们已经实现了两种类型，但我们计划添加更多类型。我们目前支持的类型如下：</p><h2 id="分段通知"><a href="#分段通知" class="headerlink" title="分段通知"></a>分段通知</h2><p>当ReaderGroup管理的段总数发生变化时，触发段通知。在缩放期间，可以将段拆分为多个或合并到某个其他段中，从而导致段的总数发生变化。当ReaderGroup的配置发生改变时（例如，添加或删除流时），段的总数也会发生变化。</p><p>订阅分段通知的方法如下所示</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>@Cleanup<br>ReaderGroupManager groupManager = new ReaderGroupManagerImpl(SCOPE, controller, clientFactory,<br>        connectionFactory);<br>groupManager.createReaderGroup(GROUP_NAME, ReaderGroupConfig.builder().<br>                                                            .stream(Stream.of(SCOPE, STREAM))<br>                                                            .build());<br><br>groupManager.getReaderGroup(GROUP_NAME).getSegmentNotifier(executor).registerListener(segmentNotification -&gt; &#123;<br>       int numOfReaders = segmentNotification.getNumOfReaders();<br>       int segments = segmentNotification.getNumOfSegments();<br>       if (numOfReaders &lt; segments) &#123;<br>          //Scale up number of readers based on application capacity<br>       &#125; else &#123;<br>         //More readers available time to shut down some<br>       &#125;<br>&#125;);<br></code></pre></td></tr></table></figure><p>应用程序可以使用registerListenerapi 注册一个监听器以通知SegmentNotification。这个 API 以<code>io.pravega.client.stream.notifications.Listener</code>作为参数。在这里，应用程序可以添加自定义逻辑，以根据段的数量更改在线reader的数量。例如，如果段数增加，则应用程序可能会考虑增加在线reader的数量。如果段的数量根据段通知而减少，则应用程序可能希望相应地更改该组在线reader的数量。</p><h2 id="EndOfData通知"><a href="#EndOfData通知" class="headerlink" title="EndOfData通知"></a>EndOfData通知</h2><p>当读者已读取readerGroup管理的流的所有数据时，将触发数据通知程序的结束。这对于使用批处理作业处理流数据很有用，其中应用程序想要读取密封流的数据。<br>订阅数据通知结束的方法如下所示：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>@Cleanup<br>ReaderGroupManager groupManager = new ReaderGroupManagerImpl(SCOPE, controller, clientFactory,<br>        connectionFactory);<br>groupManager.createReaderGroup(GROUP_NAME, ReaderGroupConfig.builder()<br>                                                            .stream(Stream.of(SCOPE, SEALED_STREAM))<br>                                                            .build());<br><br>groupManager.getReaderGroup(GROUP_NAME).getEndOfDataNotifier(executor).registerListener(notification -&gt; &#123;<br>      //custom action e.g: close all readers<br>&#125;);<br></code></pre></td></tr></table></figure><p>应用程序可以使用registerListener api注册一个监听器以通知EndOfDataNotification。这个api以<code>io.pravega.client.stream.notifications.Listener</code>作为参数。在这里，应用程序可以添加自定义逻辑，读取密封流的所有数据就可以调用该自定义逻辑。</p><h1 id="Pravega连接器"><a href="#Pravega连接器" class="headerlink" title="Pravega连接器"></a>Pravega连接器</h1><p>连接器允许将Pravega与不同的数据源和接收器集成。</p><h2 id="Flink连接器"><a href="#Flink连接器" class="headerlink" title="Flink连接器"></a>Flink连接器</h2><p>支持的初始连接器是Flink，它支持使用Pravega构建端到端流处理流水线。这还允许通过Flink流连接器读取和写入数据到外部数据源和接收器。</p><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><ul><li>Logstash</li><li>Hadoop连接器</li></ul><p>其他参考原文： <a href="http://pravega.io/docs/latest/connectors" target="_blank" rel="noopener">http://pravega.io/docs/latest/connectors</a></p><h1 id="Java-API参考"><a href="#Java-API参考" class="headerlink" title="Java API参考"></a>Java API参考</h1><h2 id="客户端"><a href="#客户端" class="headerlink" title="客户端"></a>客户端</h2><p>Writer是一个创建事件并将它们发布到Streams中的客户端。Reader是一个消费来自Streams的事件的客户端。我们提供了一个Java库，它为Writer和Reader应用程序实现了一个方便的API。客户端库封装了用于在Pravega客户端和Pravega服务之间传递请求和响应的有线协议。<br>Writer和Reader API</p><h1 id="Pravega控制器的API"><a href="#Pravega控制器的API" class="headerlink" title="Pravega控制器的API"></a>Pravega控制器的API</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>pravega控制器服务的管理REST API列表。</p><h2 id="版本信息"><a href="#版本信息" class="headerlink" title="版本信息"></a>版本信息</h2><p>版本：0.0.1</p><p>许可证信息</p><p>许可证：Apache 2.0 </p><p>许可证URL：http：//<a href="http://www.apache.org/licenses/LICENSE-2.0" target="_blank" rel="noopener">www.apache.org/licenses/LICENSE-2.0</a> </p><p>服务条款：null</p><p>其他参考原文： <a href="http://pravega.io/docs/latest/rest/restapis/" target="_blank" rel="noopener">http://pravega.io/docs/latest/rest/restapis/</a></p>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>pravega handbook - 开发pravega应用 - streamcuts</title>
      <link href="/2018/10/01/pravega-working-with-streamcuts/"/>
      <url>/2018/10/01/pravega-working-with-streamcuts/</url>
      
        <content type="html"><![CDATA[<p>本节介绍StreamCuts以及如何将它们与流客户端和批处理客户端一起使用。先决条件：您应该熟悉Pravega Concepts。</p><h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><p>Pravega流由一个或多个并行段形成，用于存储/读取事件。Pravega流是弹性的，这意味着并行段的数量可能随时间变化以适应波动的工作负载。也就是说，StreamCut表示流中的一致位置。它包含一组用于单个流的段和偏移对，它表示给定时间点的完整键空间。偏移量始终指向事件边界，因此没有指向不完整事件的偏移量。</p><p>表示流尾部的StreamCut（带有最新事件）是一个不断变化的流，因为事件可被连续地加入到流中，并且指向具有更新事件流的尾部的streamCuts将具有不同的值。类似地，StreamCut表示流的头部（具有最旧的事件）是不断变化的，因为流保留策略可以截断流并且StreamCut指向截断的流的头部将具有不同的值。 StreamCut.UNBOUNDED用于表示流中的这种位置，用户可以使用它来指定这个不断变化的流位置（流的头部和尾部）。</p><p>应当注意，StreamCut使用流客户端和批量客户端获得的流可以互换使用。</p><h2 id="StreamCut-with-reader"><a href="#StreamCut-with-reader" class="headerlink" title="StreamCut with reader"></a>StreamCut with reader</h2><p>ReaderGroup是一组命名的读者集合，它们并行地从给定的Stream中读取的事件。每个Reader始终与ReaderGroup相关联。StreamCut（s）可以使用以下api从ReaderGroup获得io.pravega.client.stream.ReaderGroup.getStreamCuts。此api返回一个 Map&lt;Stream, StreamCut&gt;表示ReaderGroup管理的所有流的reader的最后已知位置。</p><p>StreamCut可用于配置ReaderGroup以允许对Stream进行有界处理。StreamCutStream 的开始和/或结束可以作为ReaderGroup配置的一部分传递。以下示例显示了将StreamCuts用作</p><p>ReaderGroup配置的一部分的不同方法。</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>/*<br> * The below ReaderGroup configuration ensures that the readers belonging to<br> * the ReaderGroup read events from<br> *   - Stream &quot;s1&quot; from startStreamCut1 (representing the oldest event) upto<br>          endStreamCut1 (representing the newest event)<br> *   - Stream &quot;s2&quot; from startStreamCut2 upto the tail of the stream, this is similar to using StreamCut.UNBOUNDED<br> *        for endStreamCut.<br> *   - Stream &quot;s3&quot; from the current head of the stream upto endStreamCut2<br> *   - Stream &quot;s4&quot; from the current head of the stream upto the tail of the stream.<br> */<br>ReaderGroupConfig.builder()<br>                .stream(&quot;scope/s1&quot;, startStreamCut1, endStreamCut1)<br>                .stream(&quot;scope/s2&quot;, startStreamCut2)<br>                .stream(&quot;scope/s3&quot;, StreamCut.UNBOUNDED, endStreamCut2)<br>                .stream(&quot;scope/s4&quot;)<br>                .build();<br></code></pre></td></tr></table></figure><p>以下API可用于使用新的ReaderGroup配置重置现有ReaderGroup，而不是创建ReaderGroup。</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>/*<br> * ReaderGroup api used to reset a ReaderGroup to a newer ReaderGroup configuration.<br> */<br>io.pravega.client.stream.ReaderGroup.resetReaderGroup(ReaderGroupConfig config)<br></code></pre></td></tr></table></figure><h2 id="StreamCut-with-BatchClient"><a href="#StreamCut-with-BatchClient" class="headerlink" title="StreamCut with BatchClient"></a>StreamCut with BatchClient</h2><p>StreamCut 表示流的当前头部和当前尾部可以使用以下BatchClient API获得。</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>/*<br> * The API io.pravega.client.batch.BatchClient.getStreamInfo(Stream stream) fetches the StreamCut representing the<br> * current head and tail of the stream. StreamInfo.getHeadStreamCut() and StreamInfo.getTailStreamCut() can be<br> * used to fetch the StreamCuts.<br> */<br>CompletableFuture&lt;StreamInfo&gt; getStreamInfo(Stream stream);<br></code></pre></td></tr></table></figure><p>BatchClient可用于在给定开始和结束StreamCuts的情况下执行流的有界处理。BatchClient api io.pravega.client.batch.BatchClient.getSegments(stream, startStreamCut, endStreamCut)用于获取位于给定startStreamCut和endStreamCut之间的段。利用检索到的段信息，用户可以并行地消耗所有事件而不必遵守事件的时间排序。<br>必须注意的是，传递StreamCut.UNBOUNDED给startStreamCut和endStreamCut将分别导致使用流的当前头部和流的当前尾部。</p>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>pravega handbook - 开发pravega应用 - 事务</title>
      <link href="/2018/10/01/pravega-working-with-transactions/"/>
      <url>/2018/10/01/pravega-working-with-transactions/</url>
      
        <content type="html"><![CDATA[<h2 id="Pravega事务"><a href="#Pravega事务" class="headerlink" title="Pravega事务"></a>Pravega事务</h2><p>本文探讨了如何使用Pravega 事务以原子方式将一组事件写入Stream。<br>有关示例的说明，请参阅 Pravega Samples自述文件。</p><p>在阅读本页之前，您应该熟悉Pravega Concepts（请参阅  Pravega Concepts）。<br>Pravega事务和控制台writer和控制台reader APPs<br>我们编写了几个应用，ConsoleReader和ConsoleWriter，用于帮助说明使用Pravega读取和写入数据，特别是用于说明Pravega编程模型中的事务工具。你可以找到这些应用 在这里。</p><h2 id="ConsoleReader"><a href="#ConsoleReader" class="headerlink" title="ConsoleReader"></a>ConsoleReader</h2><p>ConsoleReader应用非常简单。它使用Pravega Java客户端库从Stream读取并将每个事件输出到控制台。它无限期运行，所以你必须终止进程才能终止程序。</p><h2 id="ConsoleWriter"><a href="#ConsoleWriter" class="headerlink" title="ConsoleWriter"></a>ConsoleWriter</h2><p>ConsoleWriter应用有点复杂。它使用Pravega Java客户端库将事件写入流，包括在Pravega事务的上下文中编写的事件。为了更轻松地操作事务，我们提供了一个基于控制台的CLI，CLI的帮助文本如下所示：</p><h3 id="ConsoleWriter帮助文本"><a href="#ConsoleWriter帮助文本" class="headerlink" title="ConsoleWriter帮助文本"></a>ConsoleWriter帮助文本</h3><p>在命令行提示符处输入以下命令之一：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>如果未输入任何命令，则将该行视为WRITE_EVENT命令的参数。<br><br>WRITE_EVENT &#123;event&#125;  - 将&#123;event&#125;写入Stream或当前的Transaction。<br>WRITE_EVENT_RK &lt;&lt; &#123;routingKey&#125; &gt;&gt;，&#123;event&#125;  - 使用&#123;routingKey&#125;将&#123;event&#125;写入Stream或当前Transaction。注意&#123;routingKey&#125;周围的&lt;&lt;和&gt;&gt;。<br>开始 - 开始交易。CLI支持一次只有一个事务。<br>GET_TXN_ID  - 输出当前交易的Id（如果交易正在运行）<br>FLUSH  - 刷新当前事务（如果事务正在运行）<br>COMMIT  - 提交事务（如果事务正在运行）<br>ABORT  - 中止事务（如果事务正在运行）<br>STATUS - 检查事务的状态（如果事务正在运行）<br>HELP - 打印出命令列表。<br>QUIT - 终止程序。<br>examples/someStream &gt;<br></code></pre></td></tr></table></figure><p>因此，编写单个事件很简单，只需键入一些文本（如果您不想，甚至不必键入WRITE_EVENT命令）。<br>但我们真的想谈谈Pravega事务，所以让我们深入研究一下。</p><h2 id="Pravega事务-1"><a href="#Pravega事务-1" class="headerlink" title="Pravega事务"></a>Pravega事务</h2><p>Pravega 事务的想法是允许应用程序准备一组可以“一次性”写入Stream的事件。这允许应用程序以原子方式“提交”一系列事件。这是通过将它们写入事务并调用commit以将它们追加到Stream来实现的。如果应用程序希望持久存储事件，并随后决定是否应将这些事件附加到Stream中，那么它可能期望这样操作。这允许应用程序控制何时对读者可见。</p><p>通过EventStreamWriter创建事务。回想一下，EventStreamWriter本身是通过ClientFactory创建的，并被构造为对Stream进行操作。因此，事务绑定到Stream。一旦创建了一个事务，它就像一个Writer。应用程序将事件写入事务，一旦确认，数据将被认为在事务中持久存在。请注意，在提交事务之前，写入事务的数据对读者来说是不可见的。除了使用路由键的writeEvent和writeEvent之外，还提供了几个特定于事务的操作：</p><table><thead><tr><th>操作</th><th>讨论</th></tr></thead><tbody><tr><td>getTxnId（）</td><td>检索事务的唯一标识符。Pravega为每个交易生成一个唯一的UUID。</td></tr><tr><td>flush()</td><td>确保所有写入都已持久化</td></tr><tr><td>ping()</td><td>延长交易的持续时间。请注意，在一定的空闲时间后，事务将自动中止。这是为了处理客户端崩溃的情况，并且不再适合持久化与事务关联的资源。</td></tr><tr><td>checkStatus()</td><td>返回交易状态。事务可以处于以下状态之一：打开，提交，提交，中止或中止。</td></tr><tr><td>commit()</td><td>将写入事务的所有事件附加到流中。要么所有的事件数据都要附加到Stream，要么都不会。</td></tr><tr><td>abort()</td><td>终止事务，将删除写入事务的数据。</td></tr></tbody></table><h2 id="使用ConsoleWriter来启动并提交事务"><a href="#使用ConsoleWriter来启动并提交事务" class="headerlink" title="使用ConsoleWriter来启动并提交事务"></a>使用ConsoleWriter来启动并提交事务</h2><p>所有事务API都反映在ConsoleWriter的CLI命令集中。<br>要开始事务，请键入BEGIN：</p><h3 id="开始事务"><a href="#开始事务" class="headerlink" title="开始事务"></a>开始事务</h3><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs undefined">examples/someStream &gt;begin<br>346d8561-3fd8-40b6-8c15-9343eeea2992 &gt;<br></code></pre></td></tr></table></figure><p>创建事务时，它返回一个事务对象，它将参数化的事务对象返回到Stream支持的Event类型。对于ConsoleWriter，Event的类型是Java String。</p><p>命令提示符将更改为显示事务的id。现在可以发出任何与事务相关的命令（GET_TXN_ID，FLUSH，PING，COMMIT，ABORT和STATUS）。请注意，BEGIN命令不起作用，因为ConsoleWriter一次只支持一个事务（这是应用的限制，而不是Pravega的限制）。当ConsoleWriter处于事务上下文时，WRITE_EVENT（请记住，如果不键入命令，ConsoleWriter假定您希望将文本写为事件），或者WRITE_EVENT_RK将被写入事务：</p><h3 id="将事件写入事务"><a href="#将事件写入事务" class="headerlink" title="将事件写入事务"></a>将事件写入事务</h3><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>346d8561-3fd8-40b6-8c15-9343eeea2992 &gt;m1<br>**** Wrote &apos;m1&apos;<br>346d8561-3fd8-40b6-8c15-9343eeea2992 &gt;m2<br>**** Wrote &apos;m2&apos;<br>346d8561-3fd8-40b6-8c15-9343eeea2992 &gt;m3<br>**** Wrote &apos;m3&apos;<br></code></pre></td></tr></table></figure><p>此时，如果您查看Stream（例如，通过调用Stream上的ConsoleReader应用程序），您将看不到写入Stream的那些事件。</p><h3 id="事件未写入流（尚未）"><a href="#事件未写入流（尚未）" class="headerlink" title="事件未写入流（尚未）"></a>事件未写入流（尚未）</h3><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>$ bin/consoleReader<br>...<br>******** Reading events from examples/someStream<br></code></pre></td></tr></table></figure><p>但是当给出COMMIT命令时，导致事务提交：</p><h3 id="提交"><a href="#提交" class="headerlink" title="提交"></a>提交</h3><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>346d8561-3fd8-40b6-8c15-9343eeea2992 &gt;commit<br>**** Transaction commit completed.<br></code></pre></td></tr></table></figure><p> 这些事件被附加到Stream，现在全部可用：<br>提交后，事件是可见的</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>******** Reading events from examples/someStream<br>&apos;m1&apos;<br>&apos;m2&apos;<br>&apos;m3&apos;<br></code></pre></td></tr></table></figure><h2 id="更多关于BeginTransaction"><a href="#更多关于BeginTransaction" class="headerlink" title="更多关于BeginTransaction"></a>更多关于BeginTransaction</h2><p>Begin 事务（beginTxn（））操作需要三个参数（ConsoleWriter选择一些合理的默认值，因此在CLI中这些是可选的）： </p><table><thead><tr><th>参数</th><th>讨论</th></tr></thead><tbody><tr><td>transactionTimeout</td><td>允许事务在Pravega自动中止之前运行的时间。这也称为“租约”。</td></tr><tr><td>maxExecutionTime</td><td>ping操作之间允许的时间量</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>pravega handbook - 开发pravega应用 - stateSynchronizer</title>
      <link href="/2018/10/01/pravega-working-with-state-synchronizer/"/>
      <url>/2018/10/01/pravega-working-with-state-synchronizer/</url>
      
        <content type="html"><![CDATA[<p>Pravega即可以作为流式存储系统，也可以作为 pub-sub消息系统，还可以将Pravega作为一种在分布式集群中共享多个进程状态的方法。<br>运行示例应用，请参阅 Pravega Samples文件。<br>在看本文之前，需要熟悉Pravega Concepts（请参考  Pravega Concepts）。特别是，对State Synchronizer 概念有所了解。</p><h2 id="共享的状态和Pravega"><a href="#共享的状态和Pravega" class="headerlink" title="共享的状态和Pravega"></a>共享的状态和Pravega</h2><p>State Synchronizer是Pravega编程模型提供的一种工具，它使得开发人员可以轻松地使用Pravega来协调进程之间的共享状态。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/state.synchronizer.png" alt=""></p><p>其思想是使用Stream来保持共享状态的变化序列，并且各种应用使用其Pravega Java客户端库以一致的方式同时读取和写入共享状态。 </p><h2 id="SharedStateMap和共享配置示例"><a href="#SharedStateMap和共享配置示例" class="headerlink" title="SharedStateMap和共享配置示例"></a>SharedStateMap和共享配置示例</h2><p>在深入了解如何使用状态同步器之前，我们先快速看一下一个使用状态同步器的简单示例 。<br>该示例使用State Synchronizer构建Java 映射数据结构的实现，称为SharedMap。我们使用该SharedMap数据结构来构建一个共享配置，该配置允许一组进程一致地读/写键/值对属性的共享配置对象。此外，作为该示例的一部分，我们提供了一个简单的基于命令行的应用程序，允许您使用SharedConfig。  </p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/state.sync.example.png" alt=""></p><p>以下是SharedConfigCLI中可用的命令菜单：<br><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs undefined">在命令行提示符处输入以下命令之一：<br><br>GET_ALL  - 打印出共享配置中的所有属性。<br>GET &#123;key&#125;  - 打印出给定键的配置属性。<br>PUT &#123;key&#125;，&#123;value&#125;  - 使用给定的键/值对更新共享配置。打印出以前的值（如果存在）。<br>PUT_IF_ABSENT &#123;key&#125;，&#123;value&#125;  - 仅在尚未定义属性的情况下，使用给定的键/值对更新共享配置。<br>REMOVE &#123;key&#125; [，&#123;currentValue&#125;]  - 从共享配置中删除给定的属性。如果给出&#123;currentValue&#125;，则仅在属性的当前值与&#123;currentValue&#125;匹配时删除。<br>REPLACE &#123;key&#125;，&#123;newValue&#125; [，&#123;currentValue&#125;]  - 更新属性的值。如果给出&#123;currentValue&#125;，则仅在属性的当前值与&#123;cuurentValue&#125;匹配时才更新。<br>CLEAR - 从共享配置中删除所有密钥。<br>REFRESH  - 强制从同步状态更新。<br>HELP - 打印出命令列表。<br>QUIT - 终止程序。<br></code></pre></td></tr></table></figure></p><p>安装Pravega-Samples并使用相同的范围和流名称启动SharedConfigCLI的两个实例。这将模拟两个不同的进程如何将SharedConfig的本地副本与一个共享状态对象进行协调。您可以按照以下步骤来了解SharedConfig的如何协调：</p><table><thead><tr><th>#</th><th>过程1</th><th>过程2</th><th>讨论</th></tr></thead><tbody><tr><td>1</td><td>GET_ALL</td><td>GET_ALL</td><td>显示两个进程都看到一个空的SharedConfig</td></tr><tr><td>2</td><td>PUT  p1, v1</td><td></td><td>进程1添加名为p1的属性</td></tr><tr><td>3</td><td>GET p1</td><td>GET p1</td><td>过程1看到属性的值v1, 进程2没有名为p1的属性。为什么？因为它没有, 使用共享状态刷新其状态</td></tr><tr><td>4</td><td></td><td>REFRESH</td><td>将进程2的状态与共享状态重新同步</td></tr><tr><td>5</td><td></td><td>GET p1</td><td>现在，流程2看到了步骤2中所做的更改流程1</td></tr><tr><td>6</td><td></td><td>REPLACE p1, newVal, v1</td><td>进程2尝试更改p1的值，但使用条件替换，这意味着仅当p1的旧值为v1（此时为此）时才应进行更改</td></tr><tr><td>7</td><td></td><td>GET p1</td><td>果然，p1的值改为newVal</td></tr><tr><td>8</td><td>REPLACE p1, anotherVal, v1</td><td></td><td>进程1尝试以与进程2在步骤6中所做的相同的方式更改p1的值。这将失败，因为共享状态中p1的值不再是v1</td></tr><tr><td>9</td><td>GET p1</td><td></td><td>步骤8中的失败替换操作导致进程1的共享状态, 副本被更新，由于步骤6，其值现在是newVal。</td></tr></tbody></table><p>您可以使用类似的序列，以探索PUT_IF_ABSENT的语义以及修改共享状态的其他操作。<br>这个想法是，只有在对最新的值进行操作时，对SharedConfig的修改才会成功。我们使用乐观并发来实现SharedConfig对象的多个消费者之间实现有效的一致性。<br>您可以同时运行多个不同的SharedConfig状态对象，每个单独的SharedConfig使用基于不同Pravega Stream的State Synchronizer对象。当然，如果使用由同一Stream支持的State Synchronizer对象启动两个应用，则两个进程会同时访问共享状态，这正是我们上面说明的情况。</p><h2 id="使用State-Synchronizer构建SharedMap"><a href="#使用State-Synchronizer构建SharedMap" class="headerlink" title="使用State Synchronizer构建SharedMap"></a>使用State Synchronizer构建SharedMap</h2><p>我们使用State Synchronizer在Pravega-Samples中构建SharedMap对象。State Synchronizer可用于构建几乎任何数据结构的共享版本。也许你的应用只需要共享一些简单的整数计数; 我们可以使用State Synchronizer来构建一个简单的共享计数器。也许您共享的数据是集群中当前运行的服务器集; 我们可以使用State Synchronizer来构建共享Set。可能性是多方面的。<br>让我们通过使用如何构建共享映射来探讨如何使用State Synchronizer构建共享对象。</p><h2 id="State-Synchronizer"><a href="#State-Synchronizer" class="headerlink" title="State Synchronizer"></a>State Synchronizer</h2><p>State Synchronizer是一种Pravega客户端，类似于EventStreamReader或EventStreamWriter。状态同步器是通过ClientFactory对象创建的。每个状态同步器在范围内都有唯一的名称。SynchronizerConfig对象用于定制StateSynchronizer的行为（尽管目前State Synchronizer上没有可配置的属性）。State Synchronizer使用Java泛型类型来允许开发人员指定类型特定的State Synchronizer。所有这些都以类似于使用EventStreamReaders和EventStreamWriters的方式进行。</p><h2 id="StateT"><a href="#StateT" class="headerlink" title="StateT"></a>StateT</h2><p>在设计使用State Synchronizer的应用时，开发人员需要决定要同步（共享）哪种类型的状态。我们共享一个map吗？一个 set ? 一个Pojo？正在共享的数据结构是什么？这定义了状态同步器的核心“类型”（状态同步器接口中的StateT泛型类型）。StateT对象可以是实现Pravega定义的Revisioned接口的任何Java对象。  Revisioned是一个简单的接口，允许Pravega确保它能够正确地比较两个不同的StateT对象。<br>在我们的示例中，SharedMap是State Synchronizer的一个应用。它定义了一个简单的Map对象，该对象表示您期望从键值对映射对象获得的典型get（key），set（key，value）等操作。它根据需要使用状态同步器的实现了  Revisioned接口，并使用简单的ConcurrentHashMap作为Map的内部实现。因此，在我们的示例中，StateT对应于SharedStateMap \&lt;K，V&gt;。</p><h2 id="UpdateT和InitialUpdateT"><a href="#UpdateT和InitialUpdateT" class="headerlink" title="UpdateT和InitialUpdateT"></a>UpdateT和InitialUpdateT</h2><p>除了StateT之外，还有另外两种需要由StateSynchronizer定义的泛型类型：Update类型和InitialUpdate类型。UpdateType表示Pravega Stream上持久存储的“delta”或更改对象。InitialUpdateType是一个特殊的更新对象，用于启动状态同步器。UpdateType和InitialUpdateType都是根据StateT定义的。<br>StateSynchronizer使用Stream上的单个Segment来将更新（更改）存储到共享状态对象的，以Initial或Update类型对象的形式进行的更改将根据更新是否与Stream中状态的最新副本相关而写入Stream。如果更新是基于旧版本的状态，则不进行更新。<br>StateSynchronizer对象本身在本地内存中保存状态的本地副本，它还保留有关该状态副本的版本元数据。可以使用getState（）操作检索本地状态。内存中的本地副本可能是过时的，应用可以使用fetchUpdates（）操作来刷新它，该操作将检索对给定版本的状态所做的所有更改。<br>应用的大多数更改都是通过updateState（）操作进行的。updateState（）操作将Function作为参数。使用最新的状态对象调用Function，并计算要应用的更新。<br>在我们的示例中，InitialUpdateT实现为：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>/**<br> * Create a Map. This is used by StateSynchronizer to initialize shared state.<br> */<br>private static class CreateState&lt;K, V&gt; implements InitialUpdate&lt;SharedStateMap&lt;K,V&gt;&gt;, Serializable &#123;<br>    private static final long serialVersionUID = 1L;<br>    private final ConcurrentHashMap&lt;K, V&gt; impl;<br><br>    public CreateState(ConcurrentHashMap&lt;K, V&gt; impl) &#123;<br>        this.impl = impl;<br>    &#125;<br><br>    @Override<br>    public SharedStateMap&lt;K, V&gt; create(String scopedStreamName, Revision revision) &#123;<br>        return new SharedStateMap&lt;K, V&gt;(scopedStreamName, impl, revision);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>在这种情况下，CreateState类用于通过创建一个新的、空的SharedStateMap对象来初始化Stream中的共享状态。您可以想象InitialUpdate的其他示例将计数器设置为1，或者将Set初始化为固定的初始成员集。<br>像“initialize”和“update”这样的函数表示为类似乎有点奇怪，但是当你考虑到它时，这是有意义的。这些更改（如初始化和更新）需要存储在Pravega中，因此它们需要的是可序列化的对象。客户端应用必须能够随时启动，计算当前状态，然后在将更改写入Stream时保持运行状态。如果我们只是在Stream中存储“最新状态值”，就不可能始终如一地提供使用乐观并发的并发更新和读取。<br>UpdateT有点棘手。不仅有一种对Map的更新，而是有各种更新：放置一个键/值对，放置一组键/值对，删除键/值对并清除所有键/值对，这些“更新类型”中的每一个都由它们自己的类表示。我们定义了一个名为StateUpdate的抽象类，所有这些“操作”更新类都从该类继承。  </p><h3 id="StateUpdate抽象类"><a href="#StateUpdate抽象类" class="headerlink" title="StateUpdate抽象类"></a>StateUpdate抽象类</h3><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>/**<br> * A base class for all updates to the shared state. This allows for several different types of updates.<br> */<br>private static abstract class StateUpdate&lt;K,V&gt; implements Update&lt;SharedStateMap&lt;K,V&gt;&gt;, Serializable &#123;<br>    private static final long serialVersionUID = 1L;<br><br>    @Override<br>    public SharedStateMap&lt;K,V&gt; applyTo(SharedStateMap&lt;K,V&gt; oldState, Revision newRevision) &#123;<br>        ConcurrentHashMap&lt;K, V&gt; newState = new ConcurrentHashMap&lt;K, V&gt;(oldState.impl);<br>        process(newState);<br>        return new SharedStateMap&lt;K,V&gt;(oldState.getScopedStreamName(), newState, newRevision);<br>    &#125;<br><br>    public abstract void process(ConcurrentHashMap&lt;K, V&gt; updatableList);<br>&#125;<br></code></pre></td></tr></table></figure><p>通过定义抽象类，我们可以用抽象StateUpdate类来定义UpdateT。抽象类实现StateSynchronizer调用的“applyTo”方法，以便将更新应用于当前状态对象并返回更新后的状态对象。实际的工作是在对旧状态的底层Map（impl）对象的副本上进行的，对impl对象和新版本的SharedState应用“特定于每个子类”的“进程”操作，使用后处理的impl作为内部状态。抽象类定义了一个process（）方法，该方法实际上需要应用任何更新的工作。此方法由表示共享映射上的Put，PutAll等操作的各种具体类实现。<br>例如，我们在SharedMap对象上实现Put（key，value）操作的方式：</p><h3 id="作为更新对象"><a href="#作为更新对象" class="headerlink" title="作为更新对象"></a>作为更新对象</h3><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>/**<br> * Add a key/value pair to the State.<br> */<br>private static class Put&lt;K,V&gt; extends StateUpdate&lt;K,V&gt; &#123;<br>    private static final long serialVersionUID = 1L;<br>    private final K key;<br>    private final V value;<br><br>    public Put(K key, V value) &#123;<br>        this.key = key;<br>        this.value = value;<br>    &#125;<br><br>    @Override<br>    public void process(ConcurrentHashMap&lt;K, V&gt; impl) &#123;<br>        impl.put(key, value);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>这里，process（）操作是向map添加键/值对，或者如果key已经存在，则更改该值。SharedMap上的每个“操作”都是根据创建StateUpdate的各个子类的实例来实现的。</p><h2 id="在SharedMap上执行操作"><a href="#在SharedMap上执行操作" class="headerlink" title="在SharedMap上执行操作"></a>在SharedMap上执行操作</h2><p>SharedMap演示了StateSynchronizer的典型操作。SharedMap提供了一个API，非常类似于Java的Map \ &lt;K，V&gt;接口。它通过操作StateSynchronizer来实现了Map操作，使用StateUpdate的各种子类来执行状态更改（写入）操作。</p><h3 id="创建-初始化"><a href="#创建-初始化" class="headerlink" title="创建/初始化"></a>创建/初始化</h3><h3 id="创建SharedMap"><a href="#创建SharedMap" class="headerlink" title="创建SharedMap"></a>创建SharedMap</h3><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>/**<br>  * Creates the shared state using a synchronizer based on the given stream name.<br>  *<br>  * @param clientFactory - the Pravega ClientFactory to use to create the StateSynchronizer.<br>  * @param streamManager - the Pravega StreamManager to use to create the Scope and the Stream used by the StateSynchronizer<br>  * @param scope - the Scope to use to create the Stream used by the StateSynchronizer.<br>  * @param name - the name of the Stream to be used by the StateSynchronizer.<br>  */<br> public SharedMap(ClientFactory clientFactory, StreamManager streamManager, String scope, String name)&#123;<br>     streamManager.createScope(scope);<br><br>     StreamConfiguration streamConfig = StreamConfiguration.builder().scope(scope).streamName(name)<br>             .scalingPolicy(ScalingPolicy.fixed(1))<br>             .build();<br><br>     streamManager.createStream(scope, name, streamConfig);<br><br>     this.stateSynchronizer = clientFactory.createStateSynchronizer(name,<br>                                             new JavaSerializer&lt;StateUpdate&lt;K,V&gt;&gt;(),<br>                                             new JavaSerializer&lt;CreateState&lt;K,V&gt;&gt;(),<br>                                             SynchronizerConfig.builder().build());<br><br>     stateSynchronizer.initialize(new CreateState&lt;K,V&gt;(new ConcurrentHashMap&lt;K,V&gt;()));<br> &#125;<br></code></pre></td></tr></table></figure><p>SharedMap对象是通过定义范围和流来创建的（几乎总是如此，范围和流可能已经存在，因此第10-16行中的步骤通常是无操作的）。StateSynchronizer对象本身使用ClientFactory以类似于创建Pravega Reader或Writer的方式在第18-21行中构造。请注意，UpdateT对象和InitialUpdateT对象可以指定单独的Java序列化程序。目前，SynchronizerConfig对象非常枯燥; StateSynchronizer上当前没有可用的配置选项。<br>StateSynchronizer提供了一个带InitialUpdate对象的初始化（）API。这在SharedMap构造函数中被调用，以确保SharedState被正确初始化。请注意，在许多情况下，SharedMap对象将在已经包含SharedMap的共享状态的流上创建。即使在这种情况下，也可以调用initialize（），因为initialize（）不会修改Stream中的共享状态。</p><h2 id="读操作"><a href="#读操作" class="headerlink" title="读操作"></a>读操作</h2><p>读操作，即不改变共享状态的操作，如get（key）containsValue（value）等，针对StateSynchronizer的本地副本工作。所有这些操作都使用getState（）检索当前本地状态，然后从该状态执行读取操作。StateSynchronizer的本地状态可能是过时的。在这些情况下，SharedMap客户端将使用refresh（）来强制StateSynchronizer使用StateSynchronizer对象上的fetchUpdates（）操作从共享状态刷新其状态。<br>请注意，这是一个设计决策，用于平衡响应性的单调性。我们可以很容易地实现读取操作，而不是在对本地状态执行读取之前总是执行刷新。如果开发人员预计将对共享状态进行频繁更新，这将是一种非常有效的策略。在我们的例子中，我们曾想象过，SharedMap会被频繁地读取，但更新相对较少，因此选择针对本地状态进行读取。</p><h2 id="写（更新）操作"><a href="#写（更新）操作" class="headerlink" title="写（更新）操作"></a>写（更新）操作</h2><p>每一个写操作都是根据我们前面讨论过的各种具体StateUpdate对象实现的。clear（）操作使用StateUpdate的Clear子类删除所有键/值对，put（）使用Put类等。<br>让我们深入了解put（）操作的实现，以更详细地讨论StateSynchronizer编程：</p><h3 id="实现put（键，值）"><a href="#实现put（键，值）" class="headerlink" title="实现put（键，值）"></a>实现put（键，值）</h3><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>/**<br> * Associates the specified value with the specified key in this map.<br> *<br> * @param key - the key at which the value should be found.<br> * @param value - the value to be entered into the map.<br> * @return - the previous value (if it existed) for the given key or null if the key did not exist before this operation.<br> */<br>public V put(K key, V value)&#123;<br>    final AtomicReference&lt;V&gt; oldValue = new AtomicReference&lt;V&gt;(null);<br>     stateSynchronizer.updateState((state, updates) -&gt; &#123;<br>        oldValue.set(state.get(key));<br>        updates.add(new Put&lt;K,V&gt;(key,value));<br>    &#125;);<br>    return oldValue.get();<br>&#125;<br></code></pre></td></tr></table></figure><p>需要注意的是，提供给StateSynchronizer的updateState（）的函数可能会被多次调用。将函数应用于旧状态的结果仅在对最新的状态修订应用时才会写入。如果存在竞争并且乐观并发检查失败，则将再次调用它。大多数时候只会有少量的调用。在某些情况下，开发人员可以选择使用fetchUpdates（）在运行updateState（）之前将StateSynchronizer与流中的最新共享状态副本同步。这是优化预期更新的频率与您希望更新效率之间的权衡的问题。如果您期望进行大量更新，请在调用updateState（）之前调用fetchUpdates（）。在我们的例子中，我们没有期望进行很多更新，因此每次调用put()时，都可能处理函数的几个调用。</p><h2 id="删除操作"><a href="#删除操作" class="headerlink" title="删除操作"></a>删除操作</h2><p>我们选择实现删除（删除）操作以利用StateSynchronizer的compact（）功能。我们有一个策略，在每5个删除操作之后，并且在每次clear（）操作之后，我们都会进行compact()操作。现在，我们可以选择在每5次更新操作后执行compact（）操作，但是我们希望隔离使用compact（）仅删除操作的说明。<br>您可以将compact（）视为StateSynchronizer中的“垃圾收集”形式。在将一定数量的更改写入SharedState之后，将新的初始状态（所有更改的累积表示）写入Stream可能是有效的。这样，可以忽略比compact()操作更旧的数据，并最终从Stream中删除。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/ss.compact.png" alt=""></p><p>作为compact（）操作的结果，新的初始状态（Initial2）被写入流。现在，来自Change3及更旧版本的所有数据不再相关，可以从Stream中回收垃圾。</p>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>pravega handbook - 开发pravega应用 - Basic reader and writer</title>
      <link href="/2018/10/01/pravega-working-with-reader-and-writer/"/>
      <url>/2018/10/01/pravega-working-with-reader-and-writer/</url>
      
        <content type="html"><![CDATA[<p>本文讲述如何构建简单的Pravega应用程序。最简单的Pravega应用程序使用Pravega Reader读取Pravega Stream或写入Pravega Stream的Pravega Writer。两个简单的例子都可以在Pravega Samples <code>“hello world”</code> 中找到。这些示例提供了一个非常基本的例子，说明Java应用程序如何使用Pravega Java Client Library来访问Pravega功能。</p><p>有关运行示例的说明，请参阅Pravega Samples自述文件。在阅读本页之前，您应该熟悉Pravega Concepts（请参阅Pravega Concepts）。</p><h2 id="HelloWorldWriter"><a href="#HelloWorldWriter" class="headerlink" title="HelloWorldWriter"></a>HelloWorldWriter</h2><p>HelloWorldWriter应用是使用EventStreamWriter将事件写入Pravega的简单演示。<br>首先看一下HelloWorldWriter示例应用，代码的关键部分在run（）方法中：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>public void run(String routingKey, String message) &#123;<br>    StreamManager streamManager = StreamManager.create(controllerURI);<br><br>    final boolean scopeCreation = streamManager.createScope(scope);<br>    StreamConfiguration streamConfig = StreamConfiguration.builder()<br>            .scalingPolicy(ScalingPolicy.fixed(1))<br>            .build();<br>    final boolean streamCreation = streamManager.createStream(scope, streamName, streamConfig);<br><br>    try (ClientFactory clientFactory = ClientFactory.withScope(scope, controllerURI);<br>         EventStreamWriter&lt;String&gt; writer = clientFactory.createEventWriter(streamName,<br>                                                          new JavaSerializer&lt;String&gt;(),<br>                                                   EventWriterConfig.builder().build())) &#123;<br><br>         System.out.format(&quot;Writing message: &apos;%s&apos; with routing-key: &apos;%s&apos; to stream &apos;%s / %s&apos;%n&quot;,<br>                message, routingKey, scope, streamName);<br>         final CompletableFuture&lt;Void&gt; writeFuture = writer.writeEvent(routingKey, message);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>run（）方法的目的是创建一个Stream（第2-9行）并将给定的Event输出到该Stream（第10-18行）。</p><h2 id="创建流和StreamManager接口"><a href="#创建流和StreamManager接口" class="headerlink" title="创建流和StreamManager接口"></a>创建流和StreamManager接口</h2><p>Stream是在Scope的上下文中创建的; Scope充当命名空间机制，以便可以为不同的目的对不同的Streams集进行分类。例如，对于每个应用程序都有可能有一个单独的作用域。可以选择创建一组Scopes，一个scope对应于一个组织中的一个部门。在多租户环境中，每个租户可能有一个单独的Scope。作为开发人员，我可以选择我需要的任何分类方案，并使用Scope概念在该分类方案中组织我的Streams。</p><p>通过StreamManager接口创建和操作Scopes和Streams到Pravega控制器。您需要为集群中的任何Pravega Controller实例提供URI才能创建StreamManager对象。这在第2行中显示。</p><p>在HelloWorld示例应用的设置中，在启动示例应用时，controllerURI被配置为命令行参数。对于Pravega的“单节点”部署，Controller正在侦听localhost，端口9090。</p><p>StreamManager提供对Pravega中与Scopes和Streams相关的各种控制平面功能的访问：</p><table><thead><tr><th>方法</th><th>参数</th><th>讨论</th></tr></thead><tbody><tr><td>(static) create</td><td>(URI controller)</td><td>给定Pravega集群中某个Pravega Controller实例的URI，创建一个Stream Manager对象。</td></tr><tr><td>createScope</td><td>（String scopeName）</td><td>创建具有给定名称的Scope。如果创建了Scope，则返回true;如果Scope已存在，则返回false。即使Scope已经存在，您也可以调用此方法，它不会对任何内容造成任何伤害。</td></tr><tr><td>deleteScope</td><td>（String scopeName）</td><td>删除具有给定名称的范围。如果删除范围，则返回true，否则返回false。请注意，如果Scope包含Streams，则deleteScope操作将失败并出现异常。如果删除不存在的Scope，则该方法将成功并返回false。</td></tr><tr><td>createStream</td><td>（String scopeName，String streamName，StreamConfiguration config）</td><td>在给定范围内创建流。请注意，范围名称和流名称都受以下模式限制：[a-zA-Z0-9] +（即仅字母和数字，没有标点符号）,另请注意：Scope必须存在，如果在不存在的作用域中创建Stream，则抛出异常。StreamConfiguration使用构建器模式构建.如果创建了Stream，则返回true;如果Stream已存在，则返回false。即使Stream已经存在，您也可以调用此方法，它不会损害任何内容。</td></tr><tr><td>updateStream</td><td>（String scopeName，String streamName，StreamConfiguration config）</td><td>交换Stream的配置。请注意，Stream必须已存在，如果更新不存在的流，则会引发异常。如果Stream已更改，则返回true</td></tr><tr><td>sealStream</td><td>（String scopeName，String streamName）</td><td>防止对Stream进行任何进一步写入,注意Stream必须已经存在，如果密封不存在的流，则抛出异常。如果Stream成功密封，则返回true</td></tr><tr><td>deleteStream</td><td>（String scopeName，String streamName）</td><td>从Pravega中删除Stream并恢复该Stream使用的所有资源,请注意，Stream必须已存在，如果删除不存在的流，则会引发异常。如果删除了流，则返回true。</td></tr></tbody></table><p>在代码中的第3行完成之后，我们已经建立Scope，然后我们可以继续在第5-8行创建Stream。 </p><p>StreamManager需要3个输入来创建Stream，Scope的名称，Stream的名称和StreamConfiguration。最有趣的任务是创建StreamConfiguration。</p><p>与Pravega中的许多对象一样，Stream使用配置对象，允许开发人员控制Stream的各种行为。Pravega中的所有配置对象都使用builder模式进行构造。实际上有两个与流相关的重要配置项：保留策略和扩展策略。 </p><p>保留策略允许开发人员控制数据在删除之前保存在Stream中的时间。他/她可以指定数据应保留一段时间（对于强制执行某些保留期的法规遵从性这样的情况是理想的）或保留数据直到消耗了一定数量的字节。目前，保留政策尚未完全实施。默认情况下，RetentionPolicy设置为“无限制”，意味着数据不会从Stream中删除。</p><p>缩放策略允许开发人员配置Stream以利用Pravega自动缩放功能的方式。在第6行中，我们使用固定策略，这意味着Stream配置了给定数量的流段，并且不会改变。其他选项是按每秒给定数量的事件或每秒给定的千字节数进行缩放。在这两个策略中，开发人员指定目标速率，缩放因子和最小段数。目标速率是直接的，如果摄取率在一段时间内超过一定数量的事件或几千字节的数据，Pravega将尝试向流添加新的流段。如果速率在一段持续的时间内降至该阈值以下，Pravega将尝试合并相邻的流段。缩放因子是缩放策略上的一个设置，用于确定在超过目标速率（事件或千字节）时应添加的流段数。最小段数是设置要保持的最小读取并行度的因素; 例如，如果此值设置为3，则流上始终会有3个Stream Segments可用。目前，此属性仅在创建流时有效; 在未来的某个时刻，更新流将允许使用此因子来更改现有流上的最小读取并行度。例如，如果此值设置为3，则流上始终会有3个Stream Segments可用。目前，此属性仅在创建流时有效; 在未来的某个时刻，更新流将允许使用此因子来更改现有流上的最小读取并行度。</p><p>一旦创建StreamConfiguration对象后，创建Stream是直接的（第8行）。在创建Stream之后，我们都准备开始向Stream写入Event。</p><h2 id="使用EventWriter编写事件"><a href="#使用EventWriter编写事件" class="headerlink" title="使用EventWriter编写事件"></a>使用EventWriter编写事件</h2><p>应用程序使用EventStreamWriter对象将事件写入Stream。创建EventStreamWriter的关键对象是ClientFactory。ClientFactory用于创建Readers，Writers和其他类型的Pravega Client对象，例如State Synchronizer（请参阅  使用Pravega：状态同步器）。</p><p>第10行显示了ClientFactory的创建。ClientFactory是在Scope的上下文中创建的，因为ClientFactory创建的所有Readers，Writers和其他客户端都是在该Scope的上下文中创建的。ClientFactory还需要一个Pravega控制器的URI，就像StreamManager一样。</p><p>因为ClientFactory及其创建的对象消耗Pravega的资源，所以在try-with-resources语句中创建这些对象。由于ClientFactory及其创建的对象都实现了Autocloseable，因此try-with-resources方法可确保无论应用程序如何结束，Pravega资源都将以正确的顺序正确关闭。<br>现在我们有了ClientFactory，我们可以用它来创建一个Writer。在创建Writer之前，开发人员需要了解一些事项：</p><ol><li>要写入的Stream的名称是什么？注意：在创建ClientFactory时已经确定了Scope</li><li>什么类型的Event对象将被写入Stream？</li><li>什么序列化器将用于将Event对象转换为字节？回想一下，Pravega只知道字节序列，它对Java对象一无所知。</li><li>Writer是否需要配置任何特殊行为？</li></ol><p>在我们的例子中，第11-13行显示了所有这些决定。此Writer写入在HelloWorldWriter对象本身的配置中指定的Stream（默认情况下，流在“示例”Scope中命名为“helloStream”）。Writer将Java String对象作为Events处理，并使用内置的Java序列化程序进行Strings。<br>EventWriterConfig允许开发人员指定诸如在放弃之前尝试重试请求的次数以及相关的指数返回设置。在连接失败或Pravega组件中断可能暂时阻止请求成功的情况下，Pravega会小心重试请求，因此应用程序逻辑不需要处理间歇性群集故障。在我们的例子中，我们在第13行中采用了EventWriterConfig的默认设置。</p><p>现在我们可以将事件写入Stream，如第17行所示.EventStreamWriter提供了一个writeEvent（）操作，它使用给定的路由键将给定的非null Event对象写入Stream，以确定它应该出现在哪个Stream Segment上。Pravega中的许多操作，例如writeEvent（），都是异步的，并返回某种Future对象。如果应用程序需要确保将事件持久地写入Pravega并可供读者使用，那么它可以在继续之前等待Future。在我们简单的“hello world”的例子中，我们不必等待。</p><p>EventStreamWriter也可用于开始事务。我们在其他地方更详细地介绍事务事务（使用Pravega：事务）。<br>这就是写事件的原因。现在让我们来看看如何使用Pravega读取事件。</p><h2 id="HelloWorldReader"><a href="#HelloWorldReader" class="headerlink" title="HelloWorldReader"></a>HelloWorldReader</h2><p>HelloWorldReader是使用EventStreamReader的简单演示。应用只是从给定的Stream读取事件，并将这些事件的字符串表示形式打印到控制台上。<br>就像HelloWorldWriter示例一样，HelloWorldReader应用的关键部分是在run（）方法中：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>public void run() &#123;<br>   StreamManager streamManager = StreamManager.create(controllerURI);<br><br>   final boolean scopeIsNew = streamManager.createScope(scope);<br>   StreamConfiguration streamConfig = StreamConfiguration.builder()<br>           .scalingPolicy(ScalingPolicy.fixed(1))<br>           .build();<br>   final boolean streamIsNew = streamManager.createStream(scope, streamName, streamConfig);<br><br>   final String readerGroup = UUID.randomUUID().toString().replace(&quot;-&quot;, &quot;&quot;);<br>   final ReaderGroupConfig readerGroupConfig = ReaderGroupConfig.builder()<br>                                                                .stream(Stream.of(scope, streamName))<br>                                                                .build();<br>   try (ReaderGroupManager readerGroupManager = ReaderGroupManager.withScope(scope, controllerURI)) &#123;<br>       readerGroupManager.createReaderGroup(readerGroup, readerGroupConfig);<br>   &#125;<br><br>   try (ClientFactory clientFactory = ClientFactory.withScope(scope, controllerURI);<br>        EventStreamReader&lt;String&gt; reader = clientFactory.createReader(&quot;reader&quot;,<br>                                                                      readerGroup,<br>                                                     new JavaSerializer&lt;String&gt;(),<br>                                                  ReaderConfig.builder().build())) &#123;<br>        System.out.format(&quot;Reading all the events from %s/%s%n&quot;, scope, streamName);<br>        EventRead&lt;String&gt; event = null;<br>        do &#123;<br>           try &#123;<br>               event = reader.readNextEvent(READER_TIMEOUT_MS);<br>               if (event.getEvent() != null) &#123;<br>                   System.out.format(&quot;Read event &apos;%s&apos;%n&quot;, event.getEvent());<br>               &#125;<br>           &#125; catch (ReinitializationRequiredException e) &#123;<br>               //There are certain circumstances where the reader needs to be reinitialized<br>               e.printStackTrace();<br>           &#125;<br>       &#125; while (event.getEvent() != null);<br>       System.out.format(&quot;No more events from %s/%s%n&quot;, scope, streamName);<br>   &#125;<br></code></pre></td></tr></table></figure><p>第2-8行设置了Scope和Stream，就像在HelloWorldWriter应用中一样。第10-15行设置ReaderGroup作为创建EventStreamReader并使用它从Stream读取事件的先决条件（第17-36行）。</p><h2 id="ReaderGroup基础"><a href="#ReaderGroup基础" class="headerlink" title="ReaderGroup基础"></a>ReaderGroup基础</h2><p>Pravega中的任何读者都属于某些ReaderGroup。ReaderGroup是一个或多个读取器的分组，它们并行使用Stream。在创建Reader之前，我们需要创建一个ReaderGroup（或者知道现有ReaderGroup的名称）。此应用仅使用ReaderGroup的基础知识。</p><p>第10-15行显示了基本的ReaderGroup创建。ReaderGroup对象是从ReaderGroupManager对象创建的。反过来，ReaderGroupManager对象是在给定的Scope上创建的，其中包含一个Pravega控制器的URI，就像创建ClientFactory一样。在第14行创建了ReaderGroupManager对象。请注意，创建也在try-with-resources语句中，以确保正确清理ReaderGroupManager。ReaderGroupManager允许开发人员按名称创建，删除和检索ReaderGroup对象。</p><p>要创建ReaderGroup，开发人员需要ReaderGroup的名称，该组件包含一组或多个要读取的Streams。  </p><p>ReaderGroup的名称可能对应用程序有意义，例如“WebClickStreamReaders”。在我们的例子中，在第10行，我们有一个简单的UUID作为名称（注意修改UUID字符串以删除“ - ”字符，因为ReaderGroup名称只能包含字母和数字）。如果您有多个读者并行阅读并且每个阅读器都在一个单独的过程中，那么为ReaderGroup提供一个可读的名称会很有帮助。在我们的例子中，我们有一个Reader，单独读取，因此UUID是一种安全的方式来命名ReaderGroup。由于ReaderGroup是通过ReaderGroupManager创建的，并且由于ReaderGroupManager是在Scope的上下文中创建的，因此我们可以安全地得出结论，ReaderGroup名称由该Scope命名。  </p><p>ReaderGroupConfig现在没有太多行为。开发人员指定Stream，它应该是ReaderGroup的一部分及其下限和上限。在我们的例子中，在第11行，我们从Stream的开头开始。其他配置项（例如指定检查点等）是可通过ReaderGroupConfig获得的选项。但就目前而言，我们保持简单。<br>ReaderGroup可以配置为从多个Streams读取这一事实很有意思。想象一下，我收集了来自工厂车间的传感器数据流，每台机器都有自己的传感器数据流。我可以构建每个Stream使用ReaderGroup的应用，以便应用可以从一台机器中获取数据。我可以构建其他使用ReaderGroup配置为从所有Streams读取的应用。在我们的例子中，在第14行，ReaderGroup只读取一个Stream。</p><p>您可以多次使用相同的参数调用createReaderGroup（），它不会造成任何损害，并且每次最初创建后都会返回相同的ReaderGroup。<br>请注意，在其他情况下，如果开发人员知道要使用的ReaderGroup的名称并且知道它已经创建，则他/她可以使用ReaderGroupManager上的getReaderGroup（）来按名称检索ReaderGroup对象。</p><p>所以在代码的这一点上，我们设置了Scope和Stream，我们创建了ReaderGroup，现在我们需要创建一个Reader并开始阅读Events。</p><h2 id="使用EventStreamReader读取事件"><a href="#使用EventStreamReader读取事件" class="headerlink" title="使用EventStreamReader读取事件"></a>使用EventStreamReader读取事件</h2><p>第17-36行显示了设置EventStreamReader并使用该EventStreamReader读取事件的示例。</p><p>首先，我们在第17行创建一个ClientFactory，就像我们在HelloWorldWriter应用中一样。  </p><p>然后我们使用ClientFactory创建一个EventStreamReader对象。开发人员需要创建Reader的四件事：读者的名称，它应该是readerGroup的一部分，Stream上预期的对象类型，用于将存储在Pravega中的字节转换为事件的序列化器对象和ReaderConfig。第18-21行显示了EventStreamReader的创建。Reader的名称可以是任何有效的Pravega名称（数字和字母）。当然，阅读器的名称在Scope中是命名空间。我们在上一节讨论了ReaderGroup的创建。与EventStreamWriter一样，EventStreamReader使用Java泛型类型来允许开发人员指定类型安全的Reader。在我们的例子中，我们从流中读取字符串并使用标准的Java String Serializer将从流中读取的字节转换为String对象。最后，创建了ReaderConfig，但目前没有与Reader关联的配置项，因此空的ReaderConfig只是一个占位符，因为Pravega演变为在读者上包含配置项。</p><p>请注意，您不能多次创建相同的Reader。基本上你需要调用createReader（）它会尝试将Reader添加到ReaderGroup。如果ReaderGroup已包含具有该名称的Reader，则会引发异常。</p><p>现在我们已经创建了一个EventStreamReader，我们可以开始使用它来从流中读取事件。这是在第26行完成的。readNextEvent（）操作返回Stream上可用的下一个Event，或者如果没有这样的Event，则阻塞指定的超时时间。如果在超时期限到期且没有可用于读取的事件之后，则返回null。这就是为什么在第27行进行空检查（以避免向控制台打印出虚假的“null”事件消息）。它也用作第34行循环的终止。请注意，Event本身包含在EventRead对象中。</p><p>值得注意的是，readNextEvent（）可能会抛出异常（在第30-33行中处理）。如果ReaderGroup中的Readers需要重置为检查点或者ReaderGroup本身已被更改并且因此读取的Streams集已被更改，则会处理此异常。</p><p>就是这样了。简单的HelloWorldReader循环，从Stream读取事件，直到不再有更多事件，然后应用程序终止。</p><h2 id="批量读取"><a href="#批量读取" class="headerlink" title="批量读取"></a>批量读取</h2><p>对于想要执行历史流数据批量读取的应用程序，BatchClient提供了执行此操作的方法。它允许列出流中的所有段，并读取其数据。<br>当以这种方式读取数据时，不是加入自动分区数据的读取器组，而是公开流的底层结构，由应用程序决定如何处理它。因此，以这种方式读取的事件不需要按顺序读取。</p><p>显然，这个API并不适用于所有应用，主要优点是它允许与批处理框架（如MapReduce）进行低级集成。</p><p>作为一个例子来遍历流中所有的段：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>//将null传递给fromStreamCut和toStreamCut将导致分别使用当前流的开始和流的当前结束。<br>//Passing null to fromStreamCut and toStreamCut will result in using the current start of stream and the current end of stream respectively.<br>Iterator&lt;SegmentRange&gt; segments = client.listSegments(stream, null, null).getIterator();<br>SegmentRange segmentInfo = segments.next();<br></code></pre></td></tr></table></figure><p>或者从段中读取事件：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>SegmentIterator&lt;T&gt; events = client.readSegment(segmentInfo, deserializer);<br>while (events.hasNext()) &#123;<br>    processEvent(events.next());<br>&#125;<br></code></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>flink handbook - Flink分布式运行时</title>
      <link href="/2018/09/26/flink-concepts-distributed-runtime/"/>
      <url>/2018/09/26/flink-concepts-distributed-runtime/</url>
      
        <content type="html"><![CDATA[<h2 id="任务和算子链"><a href="#任务和算子链" class="headerlink" title="任务和算子链"></a>任务和算子链</h2><p>对于分布式执行，Flink将算子子任务链接到任务中。每个任务由一个线程执行。将算子链接到任务中是一项有用的优化：它可以减少线程到线程切换和缓冲的开销，并在降低延迟的同时提高整体吞吐量。可以配置链接行为; 有关详细信息，请参阅链接文档。</p><p>下图中的示例数据流由五个子任务执行，因此具有五个并行线程。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/flink/tasks_chains.svg" alt="算子链接到任务"></p><h2 id="作业管理器，任务管理器，客户端"><a href="#作业管理器，任务管理器，客户端" class="headerlink" title="作业管理器，任务管理器，客户端"></a>作业管理器，任务管理器，客户端</h2><p>Flink运行时包含两种类型的进程：</p><ul><li>JobManagers（也称为主作业）协调分布式执行。他们调度任务，协调检查点，协调故障恢复等。</li></ul><p>总是至少有一个Job Manager。高可用性配置将具有多个JobManagers，其中一个始终是领导者，其他人则是备用者。</p><ul><li>TaskManagers（也叫工作者）执行数据流的任务（或者更具体地说，子任务），并且缓冲和交换数据流。</li></ul><p>必须至少有一个TaskManager。</p><p>JobManagers和TaskManagers可以通过多种方式启动：直接作为独立集群、在容器中、或由YARN或Mesos等资源框架管理。TaskManagers连接到JobManagers，宣布它们自己是可用，并被分配工作。</p><p>客户端不是运行时和程序执行的一部分，而是被用来准备和发送的数据流的JobManager。之后，客户端可以断开连接或保持连接以接收进度报告。客户端既可以作为触发执行的Java / Scala程序的一部分运行，也可以在命令行进程中运行./bin/flink run …。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/flink/processes.svg" alt="执行Flink数据流所涉及的过程"></p><h2 id="任务槽和资源"><a href="#任务槽和资源" class="headerlink" title="任务槽和资源"></a>任务槽和资源</h2><p>每个worker（TaskManager）都是一个JVM进程，可以在不同的线程中执行一个或多个子任务。为了控制worker接受的任务数量，worker有所谓的任务槽（至少一个）。</p><p>每个任务槽代表TaskManager的固定资源子集。例如，具有三个插槽的TaskManager将其托管内存的1/3专用于每个插槽。对资源进行分隔意味着子任务不会与来自其他作业的子任务竞争托管内存，而是具有一定数量的保留托管内存。请注意，此处不会发生CPU隔离; 当前插槽只分离任务的托管内存。</p><p>通过调整任务槽的数量，用户可以定义子任务如何相互隔离。每个TaskManager有一个插槽意味着每个任务组在一个单独的JVM中运行（例如，可以在一个单独的容器中启动）。拥有多个插槽意味着更多子任务共享同一个JVM。同一JVM中的任务共享TCP连接（通过多路复用）和心跳消息。它们还可以共享数据集和数据结构，从而减少每任务开销。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/flink/tasks_slots.svg" alt="具有任务槽和任务的TaskManager"></p><p>默认情况下，Flink允许子任务共享插槽，即使它们是不同任务的子任务，只要它们来自同一个作业。结果是一个槽可以容纳整个作业的管道。允许此插槽共享有两个主要好处：</p><p>Flink集群需要与作业中使用的最高并行度一样多的任务槽。无需计算程序总共包含多少任务（具有不同的并行性）。</p><p>更容易获得更好的资源利用率。如果没有插槽共享，非密集型源/ map（）子任务将阻止与资源密集型窗口子任务一样多的资源。通过插槽共享，将示例中的基本并行性从2增加到6可以充分利用插槽资源，同时确保繁重的子任务在TaskManagers之间公平分配。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/flink/slot_sharing.svg" alt="具有共享任务槽的TaskManagers"></p><p>API还包括可用于防止不期望的插槽共享的资源组机制。</p><p>根据经验，一个好的默认任务槽数就是CPU核心数。使用超线程，每个插槽然后需要2个或更多硬件线程上下文。</p><h2 id="状态后端"><a href="#状态后端" class="headerlink" title="状态后端"></a>状态后端</h2><p>存储键/值索引的确切数据结构取决于所选的状态后端。一个状态后端将数据存储在内存中的哈希映射中，另一个状态后端使用RocksDB作为键/值存储。除了定义保存状态的数据结构之外，状态后端还实现逻辑以获取键/值状态的时间点快照，并将该快照存储为检查点的一部分逻辑。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/flink/checkpoints.svg" alt="检查点和快照"></p><h2 id="保存点"><a href="#保存点" class="headerlink" title="保存点"></a>保存点</h2><p>用Data Stream API编写的程序可以从保存点恢复执行。保存点允许更新程序和Flink群集，而不会丢失任何状态。</p><p>保存点是手动触发的检查点，它将程序的快照写入状态后端。他们依赖于常规的检查点机制。在执行期间，程序会周期性地在工作节点上创建快照并生成检查点。对于恢复，仅需要最后完成的检查点，并且一旦新的检查点完成，就可以安全地丢弃旧的检查点。</p><p>保存点与这些定期检查点类似，不同之处在于它们由用户触发，并且在完成较新的检查点时不会自动过期。可以从命令行或通过REST API取消作业时创建保存点。</p>]]></content>
      
      
      <categories>
          
          <category> flink </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flink </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>flink handbook - flink数据流编程模型</title>
      <link href="/2018/09/26/flink-concepts-programming-model/"/>
      <url>/2018/09/26/flink-concepts-programming-model/</url>
      
        <content type="html"><![CDATA[<h2 id="抽象层次"><a href="#抽象层次" class="headerlink" title="抽象层次"></a>抽象层次</h2><p>Flink提供不同级别的抽象来开发流/批处理应用程序。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/flink/levels_of_abstraction.svg" alt="抽象层次"></p><ul><li><p>最低级抽象只提供有状态流。它通过Process Function嵌入到DataStream API中。它允许用户自由处理来自一个或多个流的事件，并使用一致的容错状态。此外，用户可以注册事件时间和处理时间回调，允许程序实现复杂的计算。</p></li><li><p>实际上，大多数应用不需要上述低级抽象，而是针对Core API编程， 如DataStream API（有界/无界流）和DataSet API （有界数据集）。这些流动的API提供了用于数据处理的通用构建块，例如各种形式的用户指定的转换，连接，聚合，窗口，状态等。在这些API中处理的数据类型在相应的编程语言中表示为类。</p></li></ul><p>低级Process Function与DataStream API集成，因此只能对某些操作进行低级抽象。DataSet API提供的有限数据集的其他原语，如循环/迭代。</p><ul><li>Table API是以表为中心的声明性DSL，其可以是动态地改变的表（表示流时）。Table API遵循（扩展）关系模型：表附加了一个模式（类似于在关系数据库中的表），API提供了类似的操作，如选择，项目，连接，分组依据，聚合等。Table API程序以声明方式定义应该执行的逻辑操作，而不是准确指定 操作代码的外观。虽然Table API可以通过各种类型的用户定义函数进行扩展，但它的表现力不如Core API，但使用更简洁（编写的代码更少）。此外，Table API程序还会通过优化程序，在执行之前应用优化规则。</li></ul><p>可以在表和DataStream / DataSet之间无缝转换，允许程序混合Table API以及DataStream 和DataSet API。</p><ul><li>Flink提供的最高级抽象是SQL。这种抽象在语义和表达方面类似于Table API，但是将程序表示为SQL查询表达式。在SQL抽象与 Table API紧密地相互作用，和SQL查询可以在Table API中定义的表上执行。</li></ul><h2 id="程序和数据流"><a href="#程序和数据流" class="headerlink" title="程序和数据流"></a>程序和数据流</h2><p>Flink程序的基本构建块是流和转换。（请注意，Flink的DataSet API中使用的DataSet也是内部流 - 稍后会详细介绍。）从概念上讲，流是（可能永无止境的）数据记录流，而转换是将一个或多个流作为输入，并产生一个或多个流输出的结果。</p><p>执行时，Flink程序映射到流数据流，由流和转换运算符组成。每个数据流都以一个或多个源开头，并以一个或多个接收器结束。数据流类似于任意有向无环图 （DAG）。尽管通过迭代结构允许特殊形式的循环 ，但为了简单起见，我们将在大多数情况下对此进行掩饰。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/flink/program_dataflow.svg" alt="DataStream程序及其数据流"></p><p>通常，程序中的转换与数据流中的运算符之间存在一对一的对应关系。但是，有时一个转换可能包含多个转换运算符。</p><p>源流和接收器记录在流连接器和批处理连接器文档中。DataStream运算符和DataSet转换中记录了转换。</p><h2 id="并行数据流"><a href="#并行数据流" class="headerlink" title="并行数据流"></a>并行数据流</h2><p>Flink中的程序本质上是并行和分布式的。在执行期间，流具有一个或多个流分区，并且每个运算符具有一个或多个运算符子任务。运算符子任务彼此独立，并且可以在不同的线程中执行，并且可能在不同的机器或容器上执行。</p><p>运算符子任务的数量是该特定运算符的并行度。流的并行性始终是其生成运算符的并行性。同一程序的不同运算符可能具有不同的并行级别。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/flink/parallel_dataflow.svg" alt="并行数据流"></p><p>流可以以一对一（或转发）模式或以重新分发模式在两个算子之间传输数据：</p><ul><li><p>一对一流（例如，在上图中的Source和map（）算子之间）保留元素的分区和排序。这意味着map（）算子的subtask [1] 将以与Source算子的subtask [1]生成的顺序相同的顺序看到相同的元素。</p></li><li><p>重新分配流（在上面的map（）和keyBy / window之间，以及 keyBy / window和Sink之间）重新分配流。每个算子子任务将数据发送到不同的目标子任务，具体取决于所选的转换。实例是 keyBy（） （其通过散列密钥重新分区），广播（） ，或重新平衡（） （其重新分区随机地）。在重新分配交换中，元素之间的排序仅保留在每对发送和接收子任务中（例如，map（）的子任务[1] 和子任务[2]keyBy / window）。因此，在此示例中，保留了每个密钥内的排序，但并行性确实引入了关于不同密钥的聚合结果到达接收器的顺序的非确定性。</p></li></ul><p>有关配置和控制并行性的详细信息，请参阅并行执行的文档。</p><h2 id="视窗"><a href="#视窗" class="headerlink" title="视窗"></a>视窗</h2><p>聚合事件（例如，计数，总和）在流上的工作方式与批处理方式不同。例如，不可能计算流中的所有元素，因为流通常是无限的（无界）。相反，流上的聚合（计数，总和等）由窗口限定，例如“在最后5分钟内计数”或“最后100个元素的总和”。</p><p>Windows可以是时间驱动的（例如：每30秒）或数据驱动（例如：每100个元素）。一个典型地区分不同类型的窗口，例如翻滚窗口（没有重叠）， 滑动窗口（具有重叠）和会话窗口（由不活动的间隙打断）。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/flink/windows.svg" alt="时间和计数Windows"></p><p>更多窗口示例可以在此博客文章中找到。更多详细信息在窗口文档中。</p><h2 id="时间"><a href="#时间" class="headerlink" title="时间"></a>时间</h2><p>当在流程序中引用时间（例如定义窗口）时，可以参考不同的时间概念：</p><ul><li><p>事件时间是创建事件的时间。它通常由事件中的时间戳描述，例如由生产传感器或生产服务附加。Flink通过时间戳分配器访问事件时间戳。</p></li><li><p>摄取时间是事件在源操作员处输入Flink数据流的时间。</p></li><li><p>处理时间是执行基于时间的操作的每个算子的本地时间。</p></li></ul><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/flink/event_ingestion_processing_time.svg" alt="事件时间，摄取时间和处理时间"></p><p>有关如何处理时间的更多详细信息，请参阅<a href="https://ci.apache.org/projects/flink/flink-docs-master/dev/event_time.html" target="_blank" rel="noopener">事件时间文档</a>。</p><h2 id="有状态的操作"><a href="#有状态的操作" class="headerlink" title="有状态的操作"></a>有状态的操作</h2><p>虽然数据流中的许多操作只是一次查看一个单独的事件（例如事件解析器），但某些操作会记住多个事件（例如窗口操作符）的信息。这些操作称为有状态。</p><p>状态操作的状态保持在可以被认为是嵌入式键/值存储的状态中。状态被分区并严格地与有状态算子读取的流一起分发。因此，只有在keyBy（）函数之后才能在键控流上访问键/值状态，并且限制为与当前事件的键相关联的值。对齐流和状态的密钥可确保所有状态更新都是本地操作，从而保证一致性而无需事务开销。此对齐还允许Flink重新分配状态并透明地调整流分区。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/flink/state_partitioning.svg" alt="状态和分区"></p><p>有关更多信息，请参阅有关状态的文档。</p><h2 id="容错检查点"><a href="#容错检查点" class="headerlink" title="容错检查点"></a>容错检查点</h2><p>Flink使用流重放和检查点的组合实现容错。检查点与每个输入流中的特定点以及每个算子的对应状态相关。通过恢复算子的状态并从检查点重放事件，可以从检查点恢复流数据流，同时保持一致性（恰好一次处理语义）。</p><p>检查点间隔是在执行期间用恢复时间（需要重放的事件的数量）来折衷容错开销的手段。</p><p><a href="https://ci.apache.org/projects/flink/flink-docs-master/internals/stream_checkpointing.html" target="_blank" rel="noopener">容错内部</a>的描述提供了有关Flink如何管理检查点和相关主题的更多信息。有关启用和配置检查点的详细信息，请参阅检查点API文档。</p><h2 id="批处理流"><a href="#批处理流" class="headerlink" title="批处理流"></a>批处理流</h2><p>Flink执行<a href="https://ci.apache.org/projects/flink/flink-docs-master/dev/batch/index.html" target="_blank" rel="noopener">批处理程序</a>作为流程序的特殊情况，其中流是有界的（有限数量的元素）。数据集做为数据流在内部处理。因此，上述概念以适用于流程序相同的方式应用于批处理程序，只是少数例外：</p><ul><li><p><a href="https://ci.apache.org/projects/flink/flink-docs-master/dev/batch/fault_tolerance.html" target="_blank" rel="noopener">批处理程序的容错</a>不使用检查点。而是通过完全重放流来恢复。这是可能的，因为输入是有界的。这会使成本更多高，但却使常规处理更便宜，因为它避免了检查点。</p></li><li><p>DataSet API中的有状态操作使用简化的内存/核外数据结构，而不是键/值索引。</p></li><li><p>DataSet API引入了特殊的同步（基于超前的）迭代，这在有界流上是可行的。有关详细信息，请查看<a href="https://ci.apache.org/projects/flink/flink-docs-master/dev/batch/iterations.html" target="_blank" rel="noopener">迭代文档</a>。</p></li></ul><h2 id="下一步"><a href="#下一步" class="headerlink" title="下一步"></a>下一步</h2><p>Flink的Distributed Runtime。</p>]]></content>
      
      
      <categories>
          
          <category> flink </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flink </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Flink handbook - Apache Flink的文档</title>
      <link href="/2018/09/24/flink-apache-flink-home/"/>
      <url>/2018/09/24/flink-apache-flink-home/</url>
      
        <content type="html"><![CDATA[<h2 id="Apache-Flink文档"><a href="#Apache-Flink文档" class="headerlink" title="Apache Flink文档"></a>Apache Flink文档</h2><p>本文档适用于Apache Flink master版。</p><p>Apache Flink是一个用于分布式流和批处理数据处理的开源平台。Flink的核心是流数据流引擎，为数据流上的分布式计算提供数据分发，通信和容错。Flink在流引擎之上构建批处理，涵盖原生的迭代支持，受管理的内存和程序优化。</p><h2 id="第一步"><a href="#第一步" class="headerlink" title="第一步"></a>第一步</h2><p><strong>概念：</strong>从Flink的<a href="https://ci.apache.org/projects/flink/flink-docs-master/concepts/programming-model.html" target="_blank" rel="noopener">数据流编程模型</a>和<a href="https://ci.apache.org/projects/flink/flink-docs-master/concepts/runtime.html" target="_blank" rel="noopener">分布式运行时环境</a>的基本概念开始。这将有助于您了解文档的其他部分，包括配置和编程指南。我们建议您先阅读这部分内容。</p><p><strong>教程：</strong></p><ul><li><a href="https://ci.apache.org/projects/flink/flink-docs-master/tutorials/datastream_api.html" target="_blank" rel="noopener">实现并运行DataStream应用</a></li><li><a href="https://ci.apache.org/projects/flink/flink-docs-master/tutorials/local_setup.html" target="_blank" rel="noopener">配置本地Flink群集</a></li></ul><p><strong>编程指南：</strong>您可以阅读我们关于<a href="https://ci.apache.org/projects/flink/flink-docs-master/dev/api_concepts.html" target="_blank" rel="noopener">基本API概念</a>和<a href="https://ci.apache.org/projects/flink/flink-docs-master/dev/datastream_api.html" target="_blank" rel="noopener">DataStream API</a>或<a href="https://ci.apache.org/projects/flink/flink-docs-master/dev/batch/index.html" target="_blank" rel="noopener">DataSet API</a>的指南，以了解如何编写您的第一个Flink程序。</p><h2 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h2><p>在将Flink作业投入生产之前，请阅读<a href="https://ci.apache.org/projects/flink/flink-docs-master/ops/production_ready.html" target="_blank" rel="noopener">生产准备清单</a>。</p><h2 id="发行说明"><a href="#发行说明" class="headerlink" title="发行说明"></a>发行说明</h2><p>发行说明涵盖了Flink版本之间的重要更改。如果您计划将Flink升级到更高版本，请仔细阅读这些说明。</p><ul><li><a href="https://ci.apache.org/projects/flink/flink-docs-master/release-notes/flink-1.6.html" target="_blank" rel="noopener">Flink 1.6发行说明</a></li><li><a href="https://ci.apache.org/projects/flink/flink-docs-master/release-notes/flink-1.5.html" target="_blank" rel="noopener">Flink 1.5的发行说明</a></li></ul><h2 id="外部资源"><a href="#外部资源" class="headerlink" title="外部资源"></a>外部资源</h2><ul><li><p>Flink Forward：<a href="http://flink-forward.org/" target="_blank" rel="noopener">Flink Forward网站</a>和<a href="https://www.youtube.com/channel/UCY8_lgiZLZErZPF47a2hXMA" target="_blank" rel="noopener">YouTube</a>上提供了以往会议的讲座。<a href="http://2016.flink-forward.org/kb_sessions/robust-stream-processing-with-apache-flink/" target="_blank" rel="noopener">使用Apache Flink进行可靠的流处理</a>，那这些资料是一个很好的起点。</p></li><li><p>培训：data Artisans的<a href="http://training.data-artisans.com/" target="_blank" rel="noopener">培训材料</a>包括幻灯片，练习和示例。</p></li><li><p>博客：<a href="https://flink.apache.org/blog/" target="_blank" rel="noopener">Apache Flink</a>和<a href="https://data-artisans.com/blog/" target="_blank" rel="noopener">data Artisans</a>博客会比较频繁的发布flink相关的、深入的技术文章。</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> flink </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flink </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Flink handbook - flink常见问题</title>
      <link href="/2018/09/24/flink-faq/"/>
      <url>/2018/09/24/flink-faq/</url>
      
        <content type="html"><![CDATA[<p>关于Flink项目，一般会经常被问到以下问题。</p><h2 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h2><h2 id="Apache-Flink仅用于（近）实时处理用例吗？"><a href="#Apache-Flink仅用于（近）实时处理用例吗？" class="headerlink" title="Apache Flink仅用于（近）实时处理用例吗？"></a>Apache Flink仅用于（近）实时处理用例吗？</h2><p>Flink是一个非常通用的系统，用于数据处理和数据驱动的应用程序，数据流作为核心构建块。这些数据流可以是实时数据流,也可以是存储的历史数据流。例如，在Flink的视图中，文件是存储的字节流。因此，Flink支持实时数据处理和应用，以及批处理应用。</p><p>流可以是无界的（没有结束，事件不断发生）或受限制（流有开始和结束）。例如，来自消息队列的Twitter馈送或事件流通常是无界流，而来自文件的字节流是有界流。</p><h2 id="如果一切都是流，为什么Flink中有DataStream和DataSet-API？"><a href="#如果一切都是流，为什么Flink中有DataStream和DataSet-API？" class="headerlink" title="如果一切都是流，为什么Flink中有DataStream和DataSet API？"></a>如果一切都是流，为什么Flink中有DataStream和DataSet API？</h2><p>有界流通常比无界流更有效。在（近）实时处理无限事件流需要系统能够立即对事件起作用并产生中间结果（通常具有低延迟）。处理有界流通常不需要产生低延迟结果，因为无论如何数据都是旧的（相对而言）。这允许Flink以简单且更有效的方式处理数据。</p><p>DataStream API通过支持低延时的结果和对事件和时间（包括事件时间）灵活反应的模型捕获无界流和有界流的连续处理，</p><p>DataSet API具有加快有界数据流的处理的技术。将来，社区计划将这些优化与DataStream API中的技术相结合。</p><h2 id="Flink如何与Hadoop堆栈相关？"><a href="#Flink如何与Hadoop堆栈相关？" class="headerlink" title="Flink如何与Hadoop堆栈相关？"></a>Flink如何与Hadoop堆栈相关？</h2><p>Flink独立于Apache Hadoop，并且在没有任何Hadoop依赖性的情况下运行。</p><p>但是，Flink与许多Hadoop组件集成得非常好，例如HDFS，YARN或HBase。与这些组件一起运行时，Flink可以使用HDFS读取数据，或写入结果和检查点/快照。Flink可以通过YARN轻松部署，并与YARN和HDFS Kerberos安全模块集成。</p><h2 id="Flink运行的其他堆栈是什么？"><a href="#Flink运行的其他堆栈是什么？" class="headerlink" title="Flink运行的其他堆栈是什么？"></a>Flink运行的其他堆栈是什么？</h2><p>Flink可以在Kubernetes，Mesos， Docker上运行 ，甚至作为独立服务运行。</p><h2 id="使用Flink有哪些先决条件？"><a href="#使用Flink有哪些先决条件？" class="headerlink" title="使用Flink有哪些先决条件？"></a>使用Flink有哪些先决条件？</h2><p>您需要Java 8来运行Flink作业/应用。<br>Scala API（可选）依赖于Scala 2.11。<br>Apache ZooKeeper需要高度可用且没有单点故障的设置。<br>对于可以从故障中恢复的高可用流处理设置，Flink需要某种形式的分布式存储用于检查点（HDFS / S3 / NFS / SAN / GFS / Kosmos / Ceph / …）。</p><h2 id="Flink支持多大的规模？"><a href="#Flink支持多大的规模？" class="headerlink" title="Flink支持多大的规模？"></a>Flink支持多大的规模？</h2><p>用户在非常小的设置（少于5个节点）和1000个节点以及状态的TB上运行Flink作业。</p><h2 id="Flink是否仅限于内存数据集？"><a href="#Flink是否仅限于内存数据集？" class="headerlink" title="Flink是否仅限于内存数据集？"></a>Flink是否仅限于内存数据集？</h2><p>对于DataStream API，Flink支持大于内存的状态来配置RocksDB状态后端。</p><p>对于DataSet API，所有操作（delta迭代除外）都可以扩展到主内存之外。</p><h2 id="常见错误消息"><a href="#常见错误消息" class="headerlink" title="常见错误消息"></a>常见错误消息</h2><p>“ 获得帮助”页面上列出了常见错误消息。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1].<a href="https://flink.apache.org/faq.html" target="_blank" rel="noopener">https://flink.apache.org/faq.html</a></p>]]></content>
      
      
      <categories>
          
          <category> flink </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flink </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Flink handbook - flink用例</title>
      <link href="/2018/09/23/flink-use-cases/"/>
      <url>/2018/09/23/flink-use-cases/</url>
      
        <content type="html"><![CDATA[<h2 id="用例"><a href="#用例" class="headerlink" title="用例"></a>用例</h2><p>Apache Flink因其丰富的功能集而成为开发和运行多种不同类型应用程序的绝佳选择。Flink的功能包括对流和批处理的支持，复杂的状态管理，事件时间处理语义以及状态的恰好一次一致性保证。此外，Flink可以部署在各种资源管理集群（如YARN，Apache Mesos和Kubernetes）上，也可以部署为裸机硬件上的单个群集。Flink配置为高可用性，没有单点故障。Flink已经被证明可以扩展到数千个核心和万亿字节的应用状态，提供高吞吐量和低延迟，并为世界上一些最苛刻的流处理应用程序提供支持。</p><p>下面，我们将探讨由Flink提供支持的最常见类型的应用程序，并指出实际示例。</p><ul><li>事件驱动的应用</li><li>数据分析应用</li><li>数据管道应用</li></ul><h2 id="事件驱动的应用"><a href="#事件驱动的应用" class="headerlink" title="事件驱动的应用"></a>事件驱动的应用</h2><h3 id="什么是事件驱动的应用？"><a href="#什么是事件驱动的应用？" class="headerlink" title="什么是事件驱动的应用？"></a>什么是事件驱动的应用？</h3><p>事件驱动的应用程序是一个有状态的应用程序，它从一个或多个事件流中提取事件，并通过触发计算，状态更新或外部操作对传入事件做出响应。</p><p>事件驱动的应用程序是传统应用程序设计的演变，具有分离的计算和数据存储层。在传统应用的体系结构中，应用从远程事务数据库中读取数据并将数据持久化到远程事务数据库。</p><p>相比之下，事件驱动的应用程序基于有状态流处理应用程序。在这种设计中，数据和计算是共同定位的，这产生了本地（内存或磁盘）数据访问。通过定期将检查点写入远程持久存储来实现容错。下图描绘了传统应用程序体系结构和事件驱动应用程序之间的差异。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/flink%2Fusecases-eventdrivenapps.png" alt=""></p><h3 id="事件驱动的应用有哪些优点？"><a href="#事件驱动的应用有哪些优点？" class="headerlink" title="事件驱动的应用有哪些优点？"></a>事件驱动的应用有哪些优点？</h3><p>事件驱动的应用程序不是查询远程数据库，而是在本地访问其数据，从而在吞吐量和延迟方面发挥更好的性能。远程持久存储的定期检查点可以异步和递增完成。因此，检查点对常规事件处理的影响非常小。但是，事件驱动的应用程序设计提供的不仅仅是本地数据访问。在分层体系结构中，多个应用程序共享同一数据库是很常见的。因此，需要协调数据库的任何更改，例如由于应用程序更新或扩展服务而更改数据布局。由于每个事件驱动的应用程序都负责自己的数据，因此对数据表示的更改或扩展应用程序需要较少的协调。</p><h3 id="Flink如何支持事件驱动的应用？"><a href="#Flink如何支持事件驱动的应用？" class="headerlink" title="Flink如何支持事件驱动的应用？"></a>Flink如何支持事件驱动的应用？</h3><p>事件驱动应用程序的限制由流处理器处理时间和状态的程度来定义。Flink的许多杰出功能都围绕着这些概念。Flink提供了一组丰富的状态原语，可以管理非常大的数据量（最多几TB），并且具有恰好一次的一致性保证。此外，Flink支持事件时间，高度可定制的窗口逻辑，以及通过ProcessFunction实现高级业务逻辑提供的细粒度时间控制。此外，Flink还提供了一个用于复杂事件处理（CEP）的库，用于检测数据流中的模式。</p><p>但是，Flink针对事件驱动应用程序的突出特点是保存点功能。保存点是一致的状态图像，可用作兼容应用程序的起点。给定保存点，可以更新应用程序或调整其规模，或者可以启动应用程序的多个版本以进行A / B测试。</p><h3 id="什么是典型的事件驱动应用？"><a href="#什么是典型的事件驱动应用？" class="headerlink" title="什么是典型的事件驱动应用？"></a>什么是典型的事件驱动应用？</h3><ul><li>欺诈识别</li><li>异常检测</li><li>基于规则的警报</li><li>业务流程监控</li><li>Web应用程序（社交网络）</li></ul><h2 id="数据分析应用"><a href="#数据分析应用" class="headerlink" title="数据分析应用"></a>数据分析应用</h2><h3 id="什么是数据分析应用？"><a href="#什么是数据分析应用？" class="headerlink" title="什么是数据分析应用？"></a>什么是数据分析应用？</h3><p>分析工作从原始数据中提取信息和洞察力。传统上，分析是在有记录事件的有界数据集上作为批查询或应用程序来执行的。为了将最新数据合并到分析结果中，必须将其添加到分析的数据集中，并重新运行查询或应用程序。结果将写入存储系统或作为报告发出。</p><p>借助先进的流处理引擎，还可以实时地执行分析。流式查询或应用程序不是读取有限数据集，而是摄取实时事件流，并在消耗事件时不断生成和更新结果。结果要么写入外部数据库，要么保持为内部状态。仪表板应用程序可以从外部数据库读取最新结果或直接查询应用程序的内部状态。</p><p>Apache Flink支持流式和批量分析应用程序，如下图所示。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/flink%2Fusecases-analytics.png" alt=""></p><h3 id="流式分析应用有哪些优势？"><a href="#流式分析应用有哪些优势？" class="headerlink" title="流式分析应用有哪些优势？"></a>流式分析应用有哪些优势？</h3><p>与批量分析相比，连续流分析的优势不仅限于因消除定期导入和查询执行而从事件到洞察的低得多的延迟。与批量查询相比，流式查询不必处理输入数据中的人为边界，这些边界是由定期导入和输入的有界性质引起的。</p><p>另一方面是更简单的应用程序架构。批量分析管道由若干独立组件组成，以周期性地调度数据提取和查询执行。可靠地操作这样的管道并非易事，因为一个组件的故障会影响管道的后续步骤。相比之下，在像Flink这样的复杂流处理器上运行的流分析应用程序包含从数据摄取到连续结果计算的所有步骤。因此，它可以依赖于引擎的故障恢复机制。</p><h3 id="Flink如何支持数据分析应用？"><a href="#Flink如何支持数据分析应用？" class="headerlink" title="Flink如何支持数据分析应用？"></a>Flink如何支持数据分析应用？</h3><p>Flink为连续流式传输和批量分析提供了非常好的支持。具体来说，它具有符合ANSI标准的SQL接口，具有用于批处理和流式查询的统一语义。无论是在记录事件的静态数据集上还是在实时事件流上运行，SQL查询都会计算相同的结果。对用户定义函数的丰富支持可确保在SQL查询中执行自定义代码。如果需要更多的自定义逻辑，Flink的DataStream API或DataSet API提供更多的低级控制。此外，Flink的Gelly库为批量数据集上的大规模和高性能图形分析提供算法和构建块。</p><h3 id="什么是典型的数据分析应用？"><a href="#什么是典型的数据分析应用？" class="headerlink" title="什么是典型的数据分析应用？"></a>什么是典型的数据分析应用？</h3><ul><li>电信网络的质量监控</li><li>分析移动应用程序中的产品更新和实验评估</li><li>对消费者技术中的实时数据进行特别分析</li><li>大规模图分析</li></ul><h2 id="数据管道应用"><a href="#数据管道应用" class="headerlink" title="数据管道应用"></a>数据管道应用</h2><h3 id="什么是数据管道？"><a href="#什么是数据管道？" class="headerlink" title="什么是数据管道？"></a>什么是数据管道？</h3><p>提取 - 转换 - 加载（ETL）是在存储系统之间转换和移动数据的常用方法。通常会定期触发ETL作业，以便将数据从事务数据库系统复制到分析数据库或数据仓库。</p><p>数据管道与ETL作业具有相似的用途。它们可以转换和丰富数据，并可以将数据从一个存储系统移动到另一个存储系统 但是，它们以连续流模式运行，而不是周期性地触发。因此，他们能够从连续生成数据的源中读取记录，并以低延迟将其移动到目的地。例如，数据管道可能会监视文件系统目录中的新文件并将其数据写入事件日志。另一个应用程序可能会将事件流实现到数据库，或者逐步构建和优化搜索索引。</p><p>下图描述了定期ETL作业和连续数据管道之间的差异。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/flink%2Fusecases-datapipelines.png" alt=""></p><h3 id="数据管道有哪些优势？"><a href="#数据管道有哪些优势？" class="headerlink" title="数据管道有哪些优势？"></a>数据管道有哪些优势？</h3><p>连续数据流水线优于周期性ETL作业的显著优势是减少了将数据移动到目的地的延迟。此外，数据管道更加通用，可用于更多用例，因为它们能够连续消耗和发送数据。</p><h3 id="Flink如何支持数据管道？"><a href="#Flink如何支持数据管道？" class="headerlink" title="Flink如何支持数据管道？"></a>Flink如何支持数据管道？</h3><p>Flink的SQL接口（或表API）可以解决许多常见的数据转换或丰富任务，并支持用户定义的函数。通过使用更通用的DataStream API，可以实现具有更高级要求的数据管道。Flink为各种存储系统（如Kafka，Kinesis，Elasticsearch和JDBC数据库系统）提供了丰富的连接器。它还具有连续的文件系统源，用于监视以时间分区方式写入文件的目录和接收器。</p><h3 id="什么是典型的数据管道应用？"><a href="#什么是典型的数据管道应用？" class="headerlink" title="什么是典型的数据管道应用？"></a>什么是典型的数据管道应用？</h3><ul><li>电子商务中的实时搜索索引构建</li><li>电子商务中持续的ETL</li></ul><h2 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h2><p>[1].<a href="https://flink.apache.org/usecases.html" target="_blank" rel="noopener">https://flink.apache.org/usecases.html</a></p>]]></content>
      
      
      <categories>
          
          <category> flink </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flink </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Flink handbook - 什么是Apache Flink？</title>
      <link href="/2018/09/23/flink-what-is-apache-flink/"/>
      <url>/2018/09/23/flink-what-is-apache-flink/</url>
      
        <content type="html"><![CDATA[<p>Apache Flink是一个框架和分布式处理引擎，用于对无界和有界数据流进行有状态计算。Flink设计为在所有常见的集群环境中运行，以内存速度和任何规模执行计算。</p><p>在这里，我们解释了Flink架构的重要方面。</p><h2 id="无界和有界数据的处理"><a href="#无界和有界数据的处理" class="headerlink" title="无界和有界数据的处理"></a>无界和有界数据的处理</h2><p>任何类型的数据都是作为事件流产生的。信用卡交易，传感器测量，机器日志或网站或移动应用程序上的用户交互，所有这些数据都作为流生成。</p><p>数据可以作为无界或有界流处理。</p><ol><li><p><strong>无界流</strong> 有一个开始，但没有定义的结束。它们不会终止并提供其生成的数据。无界流必须持续处理，即必须在摄取事件后立即处理事件。不可能等待所有的输入数据都到达，因为输入是无界的，并且在任何时间点都不会结束。处理无界数据通常要求以特定顺序（例如事件发生的顺序）摄取事件，以便能够推断结果的完整性。</p></li><li><p><strong>有界流</strong>具有定义的开始和结束。可以在执行任何计算之前，通过摄取所有数据来处理有界流。有界数据集是可以被排序的，因此处理有界流不需要有序摄取。有界流的处理也称为批处理。</p></li></ol><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/flink%2Fbounded-unbounded.png" alt=""></p><p><strong>Apache Flink擅长处理无界和有界数据集</strong>。精确控制时间和状态使Flink的运行时能够在无界流上运行任何类型的应用程序。有界流由算法和数据结构在内部处理，这些算法和数据结构专门针对固定大小的数据集而设计，从而发挥出性能优势。</p><h2 id="随处部署应用"><a href="#随处部署应用" class="headerlink" title="随处部署应用"></a>随处部署应用</h2><p>Apache Flink是一个分布式系统，需要计算资源才能执行的应用程序。Flink可以与所有常见的集群资源管理器（如Hadoop YARN，Apache Mesos和Kubernetes）集成，但也可以设置为独立的集群运行。</p><p>Flink旨在很好地适用于之前列出的每个资源管理器，这是通过特定于资源管理器的部署模式实现的，这些模式允许Flink以其惯用的方式与每个资源管理器进行交互。</p><p>部署Flink应用程序时，Flink会根据应用程序配置的并行性自动识别所需资源，并从资源管理器里申请它们。如果发生故障，Flink会通过申请新资源来替换发生故障的容器。所有提交或控制应用程序的通信都是通过REST调用来进行，这简化了Flink在许多环境中的集成。</p><h2 id="以任何规模运行应用"><a href="#以任何规模运行应用" class="headerlink" title="以任何规模运行应用"></a>以任何规模运行应用</h2><p>Flink旨在以任何规模运行有状态的流应用，应用程序可以并行化为数千个在集群中分布和同时执行的任务。因此，应用程序可以利用几乎无限量的CPU、主内存、磁盘和网络IO。而且，Flink可以轻松维护数据量非常大的应用状态。其异步和增量检查点算法确保对处理的延迟影响最小，同时保证恰好一次状态的一致性。</p><p>用户报告了在其生产环境中运行的Flink集群的规模，这样的规模有点令人印象深刻，例如</p><ul><li>应用程序每天处理数万亿个事件，</li><li>应用程序维护多个TB的状态，以及</li><li>应用程序在数千个内核的运行。</li></ul><h2 id="内存的性能优势"><a href="#内存的性能优势" class="headerlink" title="内存的性能优势"></a>内存的性能优势</h2><p>有状态Flink应用针对本地状态的访问进行了优化。任务状态始终保留在内存中，或者，如果状态大小超过可用内存，则保存在可高效访问的磁盘上的数据结构中。因此，任务通过访问本地（通常是内存中）状态来执行所有计算，从而产生非常低的处理延迟。Flink通过定期并且异步地把本地状态打检查点并持久化到存储设备来保证在出现故障时的恰好一次状态的一致性。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/flink%2Flocal-state.png" alt=""></p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1].<a href="https://flink.apache.org/flink-architecture.html" target="_blank" rel="noopener">https://flink.apache.org/flink-architecture.html</a></p>]]></content>
      
      
      <categories>
          
          <category> flink </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flink </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>微服务-微服务解惑</title>
      <link href="/2018/09/23/distributed-microservice-weifuwunaxieshier/"/>
      <url>/2018/09/23/distributed-microservice-weifuwunaxieshier/</url>
      
        <content type="html"><![CDATA[<h2 id="微服务解惑"><a href="#微服务解惑" class="headerlink" title="微服务解惑"></a>微服务解惑</h2><h3 id="微服务与容器"><a href="#微服务与容器" class="headerlink" title="微服务与容器"></a>微服务与容器</h3><p>微服务又指的是在传统应用架构的基础上，按照业务能力将系统拆分成多个服务，每个服务都是一个独立的应用，对外提供一些列的公共服务API，服务之间以轻量的方式互相调用。<br>微服务里的每个服务都是一个组件，通过编排组合从而达到独立、解耦、组件化、易维护、可复用、可替换、高可用的设计原则。微服务后，自动化部署以及运维是比较头疼的事，容器技术解决了这个问题。</p><ul><li>好的架构需要考虑后面的扩展以及修改</li><li>好的架构是解耦的，需改一个地方不会影响另外一个地方</li><li>好的架构是轻便灵活的，一个应用最好只解决一个问题，而不是叠加功能</li></ul><h3 id="微服务的标签"><a href="#微服务的标签" class="headerlink" title="微服务的标签"></a>微服务的标签</h3><ul><li>单一职责</li><li>微</li><li>面向服务</li><li>自治</li><li>易扩展</li><li>流程化</li></ul><h3 id="微服务的不足"><a href="#微服务的不足" class="headerlink" title="微服务的不足"></a>微服务的不足</h3><ul><li>时效性·服务间的调用延时可能导致系统相应慢的问题</li><li>一致性·微服务在保证一致性上需要做更多的工作</li></ul><h3 id="微服务的价值"><a href="#微服务的价值" class="headerlink" title="微服务的价值"></a>微服务的价值</h3><ul><li>资源价值，资源不足是自动扩容，资源过量时自动缩容；</li><li>业务价值，工作量、人员数量、交付质量、交付周期；</li><li>技术价值，技术是为业务来服务的（个人标注：技术也是业务的一部分而不只是为业务而服务）</li><li>用户价值，用户体验好，服务上线快</li><li>未来价值，技术不成为业务的瓶颈</li></ul><h3 id="微服务的小目标"><a href="#微服务的小目标" class="headerlink" title="微服务的小目标"></a>微服务的小目标</h3><ul><li>持续交付</li><li>业务敏捷</li><li>独立演进</li><li>高可用</li><li>高性能</li></ul><h3 id="微服务的拆与不拆"><a href="#微服务的拆与不拆" class="headerlink" title="微服务的拆与不拆"></a>微服务的拆与不拆</h3><p>依据：数据模型、业务模型、关键指标，粒度平衡，边界合理</p><h3 id="DevOPS"><a href="#DevOPS" class="headerlink" title="DevOPS"></a>DevOPS</h3><p>开发与运维是一个整体，devops是一种思维方式，微服务与devops是天生一对</p><h3 id="SpringCloud特点"><a href="#SpringCloud特点" class="headerlink" title="SpringCloud特点"></a>SpringCloud特点</h3><ul><li>功能齐全</li><li>标准化</li><li>简单方便</li><li>按需取用</li><li>轻量</li><li>易扩展、易维护</li><li>可复用性</li></ul><h3 id="分布式系统组件及操作"><a href="#分布式系统组件及操作" class="headerlink" title="分布式系统组件及操作"></a>分布式系统组件及操作</h3><p>配置管理（Spring cloud config）、服务发现/调用(Feign)、断路器、智能路由（ZUUL）、微代理、控制总线、一次性Token、全局锁、决策竞选、分布式会话、集群状态。</p><p>注册中心(Eureka)、负载均衡(Ribbon)、断路器（Hystrix）、服务追踪（Sleuth，zipkin）、权限（string security）、接口可视化（Swagger）。</p><p>以上内容为《微服务那些事儿》读书笔记。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1]. 微服务那些事儿，纪晓峰著</p>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>打造“流原生”式大数据处理平台</title>
      <link href="/2018/09/22/distributed-streaming-native-platform/"/>
      <url>/2018/09/22/distributed-streaming-native-platform/</url>
      
        <content type="html"><![CDATA[<h1 id="开篇-马斯克们的Hyperloop"><a href="#开篇-马斯克们的Hyperloop" class="headerlink" title="开篇,马斯克们的Hyperloop"></a>开篇,马斯克们的Hyperloop</h1><p>我们先来看张图，下图上部分是现在的高铁，它是跑在露天的轨道上的，下图是Elon Musk’s 在正吹的<a href="https://hyperloop-one.com" target="_blank" rel="noopener">hyperloop</a>，类似于跑在真空管道里的未来高铁。相比跑在露天轨道里的高铁，跑真空管道里的高铁好处多了：快，节能，安全，比飞机便宜。。。<br>技术是可以自己进化的，相信类似hyperloop的”高铁+真空管道”的模式就是未来的一种交通出行方式。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/streaming%2Fstreaming-native-platform-0.jpg" alt="hyperloop"></p><p>那么HYPERLOOP跟本文又有什么关系呢？ 是不是有点扯远了？其实本文讲的就是类似给高铁加上真空管道的活，二者本质上是相同的。</p><h2 id="管道-Unix-Linux的设计哲学"><a href="#管道-Unix-Linux的设计哲学" class="headerlink" title="管道,Unix/Linux的设计哲学"></a>管道,Unix/Linux的设计哲学</h2><p>在Linux或者Unix系统里,有时候我们为了查询某个信息，会输入类似如下的命令行：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs undefined">#cat *.log | grep –v ‘pipeline’ | sort –nr | head –n 10 | tail -5 | awk ‘&#123;print $2&#125;’ | wc –l  &gt; /dev/stdout<br></code></pre></td></tr></table></figure><p>这个命令行通过“|”来分隔多个命令，前面命令的输出是紧接着的后面命令的输入，命令之间通过“|”彼此相连，并且一个命令只做一件事情。这里的“|”就是管道，把一个程序的输出和另一个程序的输入连起来的一根管子。</p><p>在Unix/Linux里存在这样的管道命令设计哲学：</p><ul><li>程序是个过滤器</li><li>一个程序只做一件事并且做到最好</li><li>一个程序的输入是另外一个程序的输出</li></ul><p>下图体现了这样的管道设计哲学，应用之间通过管道相连相互作用：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/streaming%2Fstreaming-native-platform-1.PNG" alt="Uniux/linux pipeline"></p><p>管道所要解决的问题是：<code>高内聚，低耦合</code>。它以一种“链”的方式将这些程序组合起来，让这些程序组成一条工作流，而每个程序又只作一件事情，给定输入，经过各个程序的先后处理，最终得到输出结果，如下图所示：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/streaming%2Fstreaming-native-platform-2.PNG" alt="Uniux/linux pipeline"></p><p>Unix/Linux在<code>&quot;每个程序只做一件事并且做好，每个程序的输出是对另一个程序的输入，可组合性&quot;</code>方面是做的非常成功的。但是，UNIX/Linux也存在一些局限性，比如：<code>&quot;仅单机，只支持一对一通信，无容错，仅字节流,数据处理能力有限等&quot;</code>。意思是说 linux/unix的这些管道命令只能在一台机器上跑，没有分布式，并且只能支持一个命令和另外一个命令之间的一对一的输入输出，无法一对多或多对一；无容错，假如管道坏了数据就出错不能恢复；只支持字节流，不支持数据格式的多样性；处理的数据量有限。</p><p>因此，我们希望可以找到一个数据处理解决方案，这个方案在保留这些Unix/linux管道的设计哲学优点的同时还能克服其缺点。 幸运的是，我们通过Flink+Pravega打造的第三代“流原生”(stream native)式的大数据处理平台实现了这种设计思想。</p><h2 id="流原生-第三代大数据处理平台"><a href="#流原生-第三代大数据处理平台" class="headerlink" title="流原生,第三代大数据处理平台"></a>流原生,第三代大数据处理平台</h2><p>下图体现了“流原生”(stream native)式的设计哲学，Flink是“流原生”的计算，Pravega是“流原生”的存储管道，Flink + pravega 是“流原生”的大数据处理平台。数据从pravega管道输入经过map算子计算，输出中间计算结果到pravega的管道里，数据又从pravega的管道里读入到filter算子里，再经过计算，中间结果放到了pravega管道里，再最后的计算结果经过聚合算子的计算放到了目的地的pravega的管道里。这个过程体现了算子编排和管道式编程的设计哲学。在这里pravega起了大数据处理平台里的管道的作用。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/streaming%2Fstreaming-native-platform-3.PNG" alt="Stream processing pipeline"></p><p>在Unix/Linux中，系统提供管道和命令，用于从一个进程到另一个进程获取字节流。</p><p>在“流原生”处理平台上，Flink提供流处理服务，pravega提供流存储服务，数据源自pravega，被Flink算子们处理后输出到pravega，这是一种将事件从一个流处理作业转移到另一个流处理作业的机制。 Flink和Pravega 所遵循的流处理平台设计哲学是：</p><ul><li>每个算子都只做一件事，并且做到最好</li><li>每个算子的输出是另一个算子的输入</li><li>可组合</li><li>流式传输：数据是动态的，算子是静态的</li><li>算子可编排</li><li>Pravega是最好的Flink搭档</li><li>分布式，扩展到多台机器</li><li>可进化的编码/解码</li></ul><p>当前的流式处理平台一般是 Flink 加传统的存储类型，这种是”半流原生“式的大数据处理平台，计算是原生的流计算而存储却不是原生的流存储。<br>而Pravega就是专门给Flink们设计的原生流存储，它的数据传输方式类似于“管道”，不同于传统的块存储，文件存储以及对象存储，它是一个”管道式流存储“。</p><p>通过Flink + Pravega的组合可以实现 “流原生”(stream native)式的第三代大数据处理平台，未来已来。。。。。</p><h2 id="思考题"><a href="#思考题" class="headerlink" title="思考题"></a>思考题</h2><p>最后给大家留个思考题，“流原生”(stream native)的概念有了，Flink + Pravega 也有了，而且二者的代码都是开源的（flink.apache.org, pravega.io），那么怎么把这些开源的东西产品化？ 或者这个问题太伤脑筋，我们换个简单的问题：“今天中午吃什么？”</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a>作者简介</h2><p>常平，毕业于中国科学技术大学，获硕士研究生学历学位，10年+ 存储、布式系统、云计算以及大数据经验，曾就职于Marvell、AMD等，现就职于EMC，资深首席工程师，主要负责流式大数据处理平台的架构设计、编码及产品交付等。</p>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>算命先生的阴阳五行学说与码农们的分布式系统设计理论</title>
      <link href="/2018/09/22/distributed-tradeoff/"/>
      <url>/2018/09/22/distributed-tradeoff/</url>
      
        <content type="html"><![CDATA[<h2 id="阴阳五行"><a href="#阴阳五行" class="headerlink" title="阴阳五行"></a>阴阳五行</h2><p>一说到阴阳五行就容易让人想到大街上的算命先生，然而阴阳五行学说却是中国古代解释世间万物的起源和多样性的哲学理论依据，是中国古代朴素的唯物论和自发的辩证法思想。</p><p>中国古代哲学的核心思想之一用“老子”的话来说就是：</p><blockquote><p>“道生一、一生二、二生三、三生万物，万物负阴而抱阳，冲气以为和。”。</p></blockquote><p>而五行学说讲的是:<code>“金 木 水 火 土”</code>这五行,五行相生又相克。<code>木头烧火——木生火；火烧木头成灰——火生土，土长期聚在一起生石头、石头里炼金——土生金，金销水——金生水，水又生土。</code>,<code>水克火，火克金，金克木，木克土，土克水。</code></p><p>但是如下图,五行虽然相生相克但都是为“和”字而服务的，即平衡：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed%2Fdistributed-tradeoff-1.PNG" alt="五行"></p><p>解读开来就是：</p><p><code>“天道生阴阳，阴阳成五行，五行变化成万物，而万物的存在方式和相互关系一直在追求一种“和谐”。</code>“道”在阴阳的相互作用下，产生五行，五行之间相互作用产生世间万物的无穷变化，并且阴阳之间对立消长，五行之间相生相克，自此万物得以和谐发展。借助于阴阳五行的核心要素以及由此而生的非核心要素关系把宇宙看成一个统一的整体，这样的整体：<code>循环平衡、相生相克、有刚有柔、和谐统一</code>。</p><p>那么这些玄乎的哲学理论跟码农又有什么关系呢？对于本人这么个靠技术混饭吃卖身又卖艺的码农来说，这实在太重要，归纳成一个字就是”和”，对应到技术实现体系里就是一个理念 ”权衡“，英文叫<code>tradeoff</code>。<code>“tradeoff”</code>这词实在是太妙了，啥都可以往上套，比如你十一准备到哪旅游啦，中午到哪吃饭啦，买哪里的房子啦，准备追哪个姑娘做老婆啦…….，都需要 <code>tradeoff</code>。技术如此人生又何尝不如是。</p><h2 id="分布式系统"><a href="#分布式系统" class="headerlink" title="分布式系统"></a>分布式系统</h2><p>通常来讲设计分布式系统的时候需要考虑的最重要的<code>核心要素</code>有五个，这里不是说其他要素就不重要，这是指经过<code>tradeoff</code>过的五个最重要的核心要素，如下图：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed%2Fdistributed-tradeoff-2.PNG" alt="分布式系统要素"></p><ol><li><p><code>Capacity</code>，容量，其实这个词翻译成”能力“会更合适，指的是分布式系统里的CPU，内存，硬盘，网络，文件描述符，socket连接数，老板的预期，开发周期，成本预算之类的限制条件,以下所有的要素都受 “容量”的限制，这是前提条件，就比如一辆车最多能跑多快，一个人最多能跳多高都是受自身“容量/能力”的限制的；</p></li><li><p><code>Performant</code>, performance + conformant, performant这词也是造的，指的是合适的性能，分布式系统的IOPS，TPS, QPS，Latency,Jitter之类的性能指标要求，性能受限于容量，性能同时又影响了可靠性以及可用性；</p></li><li><p><code>Availability</code>，可用性，可用性通常指的是产品或服务在随机时间内调用时处于可服务状态的概率，通常被定义为正常运行时间除以总时间（正常运行时间加停机时间），比如 5个9，6个9，还有个厂家都喜欢的号称的9个9之类的，可用性受容量的限制同时也受可伸缩性的影响，可用性又影响了性能；</p></li><li><p><code>Reliability</code>，可靠性，一般指的是出保证不出故障的概率，比如，企业级产品 5个9是保底，可测试性和可维护性通常被定义为可靠性当中的一部分，可伸缩性影响了可靠性，而可靠性又影响了可用性，同时性能又影响了可靠性，可靠性也影响着性能。</p></li><li><p><code>Scalability</code>，可伸缩性，这里很容易跟“可扩展性”混淆，可伸缩性可以指的是集群处理越来越多或越来越少的工作的能力，或者是为了适应这种增长或减少而扩大或缩小其能力的能力。可伸缩性影响了可用性，也影响了性能与可靠性，受限于容量。</p></li></ol><p>当然还有另外一些由此而衍生的非核心要素，就不多做详细解释了，比如：</p><ul><li>Testability，可测试性</li><li>Security，安全性</li><li>Observability，可观测性</li><li>Predictability，可预测性</li><li>Extensibility，可扩展性</li><li>Maintainability，可维护性</li><li>Serviceability， 可服务性</li></ul><p>这些非核心要素虽然是非核心但是也不是说就不重要，是<code>开源产品与商业产品</code>差异的关键，关键在如何<code>tradeoff</code>。</p><h2 id="阴阳五行与分布式系统"><a href="#阴阳五行与分布式系统" class="headerlink" title="阴阳五行与分布式系统"></a>阴阳五行与分布式系统</h2><p>将阴阳五行理论与分布式系统设计理论结合起来解读就是：</p><p><code>分布式系统里的“道”就是“产品”，“阴阳“ 就是 ”功能“ 与 “非功能”，五行就是 ”容量、性能、可用性、可伸缩性以及可靠性“，阴阳五行衍生的一些其他关系对应分布式系统五要素衍生的一些其他要素。</code></p><p>用人话来讲就是 开发产品的时候需要考虑功能与非功能两个方面，而要保证产品质量又需要考虑”容量、性能、可用性、可伸缩性以及可靠性“这些核心要素，但是也不能忽略由此而生的一些非核心要素。</p><p>那么从这些理论到产品又需要怎么做才能落地呢？ 那自然是需要 <code>懂得如何把从这些概念性的、功能的、非功能的、这些核心的、非核心的要素进行设计实现成代码</code>，这就涉及到 “术”的层面了，“道”的层面可以通过看书看论文获得，而<code>“术”</code>的获得除了自身努力还得靠机会，而且每个人的悟性还不一样，这些个”术“以后有空慢慢讲。</p><h2 id="思考题"><a href="#思考题" class="headerlink" title="思考题"></a>思考题</h2><p>最后给大家留一个思考题： 前面提过老子曰：<code>”道生一、一生二、二生三、三生万物，万物负阴而抱阳，冲气以为和。“</code>， 三之后就是万物，为什么不是 五、不是六、不是七之类的呢？为什么三之后就是万物了？</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a>作者简介</h2><p>常平，毕业于中国科学技术大学，获硕士研究生学历学位，10年+ 存储、布式系统、云计算以及大数据经验，曾就职于Marvell、AMD等，现就职于EMC，资深首席工程师，主要负责流式大数据处理平台的架构设计、编码及产品交付等。</p><hr><h4 id="注："><a href="#注：" class="headerlink" title="注："></a>注：</h4><ol><li>这个用五行解释分布式系统的观点，以前在一个业内微信群里提出并且聊过，所以这个解读的方式为本人原创非COPY.</li><li>个人愚钝，悟性有限，欢迎拍砖，砖多了我就拿回去砌墙。</li></ol><h3 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h3><p>[1]. <a href="https://baike.sogou.com/v7556185.htm" target="_blank" rel="noopener">https://baike.sogou.com/v7556185.htm</a></p>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>应该在同一个Kafka主题中放入几种事件类型吗？</title>
      <link href="/2018/09/21/pravega-streaming-put-several-event-types-kafka-topic/"/>
      <url>/2018/09/21/pravega-streaming-put-several-event-types-kafka-topic/</url>
      
        <content type="html"><![CDATA[<p>如果您采用Apache Kafka等流平台，有个很重要的问题是：将使用哪些主题？特别是，如果要将一堆不同的事件作为消息发布到Kafka，是将它们放在同一主题中，还是将它们拆分为不同的主题？</p><p>主题最重要的功能是允许使用者指定它想要使用的消息子集。在一个极端情况下，所有数据都放在一个主题中可不是一个好主意，因为这意味着消费者无法选择感兴趣的事件 - 给他们的只会是所有的内容。在另一个极端，拥有数百万个不同的主题也不是一个好事，因为Kafka中的每个主题都会消耗资源消耗，因此拥有大量的主题就会对性能不利。</p><p>实际上，从性能的角度来看，重要的是分区数量。但由于Kafka中的每个主题至少有一个分区，如果你有n个主题，那么就不可避免地至少有n个分区。不久之前，[Jun Rao撰写了一篇博文]，解释了拥有多个分区的成本（端到端延迟，文件描述符，内存开销，故障后的恢复时间）。根据经验，如果您关注延迟问题，您应该关注每个代理节点上的（数量级）数百个主题分区。如果每个节点有数万个甚至数千个分区，则延迟会受到影响。</p><p>该性能参数给设计主题的结构提供了一些指导：如果您发现自己有数千个主题，那么将一些细粒度，低吞吐量的主题合并到粗粒度主题中是明智之举，从而减少分区的扩散。</p><p>然而，性能问题并不是结束。在我看来，更重要的是您的主题结构的数据完整性和数据建模方面。我们将在本文的其余部分讨论这些内容。</p><h2 id="主题-相同类型的事件的集合？"><a href="#主题-相同类型的事件的集合？" class="headerlink" title="主题=相同类型的事件的集合？"></a>主题=相同类型的事件的集合？</h2><p>常见的想法（根据我所拥有的几个对话，并根据邮件列表）似乎是：将同类型的所有事件放在同一主题中，并针对不同的事件类型使用不同的主题。这种思路让人联想到关系数据库，其中表是具有相同类型（即同一组列）的记录的集合，因此我们在关系表和Kafka主题之间进行类比。</p><p>该<a href="https://www.confluent.io/confluent-schema-registry/" target="_blank" rel="noopener">融合模式的注册表</a>本质上强化了这种模式，因为它鼓励你在主题中的所有消息使用相同的Avro模式。该模式可以在保持兼容性的同时进化（例如，通过添加可选字段），但最终所有消息都必须符合某种记录类型。在我们介绍了更多背景之后，我们将在后面的帖子中再次讨论这个问题。</p><p>对于某些类型的流数据（例如记录的活动事件），要求同一主题中的所有消息都符合相同的模式是有意义的。但是，有些人正在使用Kafka来实现更多类似数据库的目的，例如事件溯源，或者在微服务之间交换数据。在这种情况下，我相信，它定义一个主题为一组具有相同模式的消息并不重要。更重要的是Kafka维护主题分区内的消息排序。</p><p>想象一下，您有一些事物（比如客户），并且该事物可能发生许多不同的事情：创建客户，客户更改地址，客户向其帐户添加新信用卡，客户进行客户支持查询，客户支付发票，客户关闭其帐户。</p><p>这些事件的顺序很重要。例如，我们期望在客户做任何动作之前创建客户，并且我们也期望在客户关闭其帐户之后不再发生任何其他事情。使用Kafka时，您可以通过将它们全部放在同一个分区中来保留这些事件的顺序。在此示例中，您将使用客户ID作为分区键，然后将所有这些不同的事件放在同一主题中。它们必须位于同一主题中，因为不同的主题意味着不同的分区，并且不会跨分区保留排序。</p><h2 id="排序问题"><a href="#排序问题" class="headerlink" title="排序问题"></a>排序问题</h2><p>如果你没有使用（比方说）不同的主题<code>customerCreated</code>，<code>customerAddressChanged</code>和<code>customerInvoicePaid</code>事件，然后这些议题的消费者可能会看到荒谬的事件顺序。例如，消费者可能会看到不存在的客户的地址更改（因为尚未创建，因为相应的<code>customerCreate</code>事件已被延迟）。</p><p>如果消费者暂停一段时间（可能是维护或部署新版本），则重新排序的风险尤其高。当消费者停止时，事件将继续发布，并且这些事件将存储在Kafka代理的选定主题分区中。当消费者再次启动时，它会消耗来自其所有输入分区的积压事件。如果消费者只有一个输入，那就没问题了：挂起的事件只是按照它们存储的顺序依次处理。但是，如果消费者有几个输入主题，它将选择输入主题以按任意顺序读取。它可以在读取另一个输入主题上的积压之前从一个输入主题读取所有挂起事件，或者它可以以某种方式交错输入。</p><p>因此，如果你把<code>customerCreated</code>，<code>customerAddressChanged</code>以及<code>customerInvoicePaid</code>事件在三个独立的主题，消费者可能会看到所有的<code>customerAddressChanged</code>事件，它看到任何之前<code>customerCreated</code>的事件。因此，消费者可能会看到一个<code>customerAddressChanged</code>客户的事件，根据其对世界的看法，尚未创建。</p><p>您可能想要为每条消息附加时间戳，并将其用于事件排序。如果要将事件导入数据仓库，您可以在事后对事件进行排序，这可能就可以了。但是在流进程中，时间戳是不够的：如果你得到一个具有特定时间戳的事件，你不知道你是否仍然需要等待一个时间戳较低的先前事件，或者所有之前的事件是否已到达而你是’准备好处理这个事件。依靠时钟同步通常会导致噩梦;</p><h2 id="何时分割主题，何时结合？"><a href="#何时分割主题，何时结合？" class="headerlink" title="何时分割主题，何时结合？"></a>何时分割主题，何时结合？</h2><p>鉴于这种背景，我将提出一些经验法则来帮助您确定在同一主题中放入哪些内容，以及将哪些内容拆分为单独的主题：</p><ol><li><p>最重要的规则是，  任何需要保持固定顺序的事件必须放在同一主题中（并且它们也必须使用相同的分区键）。最常见的是，如果事件的顺序与同一事物有关，则事件的顺序很重要。因此，根据经验，我们可以说关于同一事物的所有事件都需要在同一主题中。如果您使用事件排序方法进行数据建模，事件的排序尤为重要。这里，聚合对象的状态是通过以特定顺序重放它们来从事件日志中导出的。因此，即使可能存在许多不同的事件类型，定义聚合的所有事件也必须在同一主题中。</p></li><li><p>当您有关于不同事物的事件时，它们应该是相同的主题还是不同的主题？我想说，如果一个事物依赖于另一个事物（例如，一个地址属于一个客户），或者如果它们经常需要在一起，那么它们也可能会出现在同一个主题中。另一方面，如果它们不相关并由不同的团队管理，则最好将它们放在单独的主题中。它还取决于事件的吞吐量：如果一个事物类型具有比另一个事物类型高得多的事件，它们是更好地分成单独的主题，以避免压倒性的消费者只想要具有低写入吞吐量的事物（参见第4点）。但是，几个都具有低事件率的事物可以很容易地合并。</p></li><li><p>如果一个事件涉及多个事物怎么办？例如，购买涉及产品和客户，并且从一个帐户到另一个帐户的转移涉及至少那两个帐户。我建议最初将事件记录为单个原子消息，而不是将其分成几个消息。主题，最好以完全按照您收到的方式记录事件，并尽可能采用原始形式。您可以随后使用流处理器拆分复合事件 - 但如果您过早地将其拆分，则重建原始事件要困难得多。更好的是，您可以为初始事件提供唯一ID（例如UUID）; 以后，当您将原始事件拆分为每个涉及的事物的一个事件时，您可以将该ID转发，从而使每个事件的起源都可追溯。</p></li><li><p>查看消费者需要订阅的主题数量。如果几个消费者都阅读了一组特定的主题，这表明可能应该将这些主题组合在一起。如果将细粒度的主题组合成粗粒度的主题，一些消费者可能会收到他们需要忽略的不需要的事件。这不是什么大问题：消费来自Kafka的消息非常便宜，所以即使消费者最终忽略了一半的事件，这种过度消费的成本可能也不大。只有当消费者需要忽略绝大多数消息（例如99.9％是不需要的）时，我才建议从高容量流中分割低容量事件流。</p></li><li><p>Kafka Streams状态存储（KTable）的更改日志主题应与所有其他主题分开。在这种情况下，主题由Kafka Streams流程管理，不应与其他任何内容共享。</p></li><li><p>最后，如果上述规则都没有告诉您是否将某些事件放在同一主题或不同主题中，该怎么办？然后，通过将相同类型的事件放在同一主题中，通过所有方法将它们按事件类型分组。但是，我认为这条规则是最不重要的。</p></li></ol><h2 id="模式管理"><a href="#模式管理" class="headerlink" title="模式管理"></a>模式管理</h2><p>如果您使用的是数据编码（如JSON），而没有静态定义的模式，则可以轻松地将许多不同的事件类型放在同一主题中。但是，如果您使用的是基于模式的编码（如Avro），则需要更多地考虑在单个主题中处理多个事件类型。</p><p>如上所述，基于Avro的<code>Kafka Confluent Schema Registry</code>目前依赖于每个主题都有一个模式的假设（或者更确切地说，一个模式用于密钥，一个模式用于消息的值）。您可以注册新版本的模式，注册表会检查模式更改是向前还是向后兼容。这个设计的一个好处是，您可以让不同的生产者和消费者同时使用不同的模式版本，并且它们仍然保持彼此兼容。</p><p>更确切地说，当Confluent的Avro序列化程序在注册表中注册模式时，它会在主题名称下注册。默认情况下，该主题<code>&lt;topic&gt;-key</code>用于消息键和<code>&lt;topic&gt;-value</code>消息值。然后，模式注册表检查在特定主题下注册的所有模式的相互兼容性。</p><p>我最近对<a href="https://github.com/confluentinc/schema-registry/pull/680" target="_blank" rel="noopener">Avro序列化程序进行了修补</a>，使兼容性检查更加灵活。该补丁添加了两个新的配置选项:(<code>key.subject.name.strategy</code>定义如何构造消息键的主题名称），以及<code>value.subject.name.strategy</code>（如何构造消息值的主题名称）。选项可以采用以下值之一：</p><ul><li><p><code>io.confluent.kafka.serializers.subject.TopicNameStrategy</code>（默认值）：消息键的主题名称是<code>&lt;topic&gt;-key</code>，<code>&lt;topic&gt;-value</code>对于消息值。这意味着主题中所有消息的模式必须相互兼容。</p></li><li><p><code>io.confluent.kafka.serializers.subject.RecordNameStrategy</code>：主题名称是邮件的Avro记录类型的完全限定名称。因此，模式注册表会检查特定记录类型的兼容性，而不考虑主题。此设置允许同一主题中的任意数量的不同事件类型。</p></li><li><p><code>io.confluent.kafka.serializers.subject.TopicRecordNameStrategy</code>：主题名称是<code>&lt;topic&gt;-&lt;type&gt;</code>，<code>&lt;topic&gt;Kafka</code>主题名称在哪里，并且<type>是邮件的Avro记录类型的完全限定名称。此设置还允许同一主题中的任意数量的事件类型，并进一步将兼容性检查限制为仅当前主题。</type></p></li></ul><p>使用此新功能，可以轻松，干净地将特定事物的所有不同事件放在同一主题中。现在，可以根据上述条件自由选择主题的粒度，而不仅限于每个主题的单个事件类型。</p><h2 id="原文："><a href="#原文：" class="headerlink" title="原文："></a>原文：</h2><p>[1] <a href="https://www.confluent.io/blog/put-several-event-types-kafka-topic/" target="_blank" rel="noopener">https://www.confluent.io/blog/put-several-event-types-kafka-topic/</a>, Martin KleppmannMartin Kleppmann</p>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Pravega handbook - 控制器服务之三</title>
      <link href="/2018/09/20/pravega-controller-service-3/"/>
      <url>/2018/09/20/pravega-controller-service-3/</url>
      
        <content type="html"><![CDATA[<h2 id="角色和责任"><a href="#角色和责任" class="headerlink" title="角色和责任"></a>角色和责任</h2><h3 id="流操作"><a href="#流操作" class="headerlink" title="流操作"></a>流操作</h3><p>控制器是所有流相关元数据的真实存储。Pravega客户端（EventStreamReaders和EventStreamWriters）与控制器一起确保流不变量在流上工作时得到满足和尊重。控制器维护流的元数据，包括段的整个历史。访问流的客户端需要联系控制器以获取有关段的信息。<br>客户端查询控制器以了解如何导航流。为此，控制器公开适当的API以获取活动段，后继者，前驱者和段信息以及Uris。这些查询使用存储和通过流存储接口访问元数据来提供这些查询服务。<br>Controller还提供了修改流的状态和行为的工作流程。这些工作流程包括创建，缩放，截断，更新，密封和删除。这些工作流程既可以通过直接API调用，也可以通过后台策略管理器（自动调整和保留）调用。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega%2FRequestProcessing.png" alt="RequestProcessing"><br>请求处理流程</p><h2 id="创建流"><a href="#创建流" class="headerlink" title="创建流"></a>创建流</h2><p>创建流是作为任务框架上的任务来实现的。创建流工作流首先创建流状态设置为CREATING * 的初始流元数据。在此之后，它标识应该拥有的段容器并为此流创建段并同时调用create-segment。完成所有创建段后，创建流任务完成，从而将流移动到ACTIVE状态。所有故障都会以指数退避重试几次。但是，如果它无法完成任何步骤，则流将保持在CREATING状态。</p><h2 id="更新流"><a href="#更新流" class="headerlink" title="更新流"></a>更新流</h2><p>更新流被实现为序列化请求处理程序/并发事件处理器框架上的任务。更新流由显式API调用来调用到控制器中。它首先将更新请求事件发布到请求流中。之后，它尝试创建临时更新属性。如果它无法创建临时更新属性，则请求失败，并且会通知调用方由于与另一个正在进行的更新冲突而无法更新流。</p><p>事件由请求事件处理器选择。处理开始时，更新流任务期望找到要存在的临时更新流属性。如果找不到该属性，则通过将事件推回到内存中队列中来延迟更新处理，直到它认为事件已过期为止。如果在此期间找到要更新的属性，则在到期之前，处理该事件并执行更新流操作。现在处理开始，它首先将状态设置为UPDATING。在此之后，在元数据存储中更新流配置，然后通知段存储关于流的所有活动段关于策略的改变。现在状态重置为ACTIVE。</p><h3 id="缩放流"><a href="#缩放流" class="headerlink" title="缩放流"></a>缩放流</h3><p>可以通过显式API调用（称为手动缩放）调用缩放，也可以基于缩放策略自动执行缩放（称为自动缩放）。我们首先编写事件，然后通过为要创建的所需段创建新条目来更新段表。此步骤是幂等的，并确保如果正在进行现有的缩放操作，则此启动新的缩放的尝试失败。处理的开始类似于更新流中遵循的机制。如果更新元数据，则事件处理并继续执行任务。如果元数据未在期望的时间范围内更新，则事件被丢弃。</p><p>一旦缩放处理开始，它首先设置流状态SCALING。然后在段存储中创建新段。在成功创建新段之后，它使用对应于新时期的部分记录更新历史表，该新时期包含按比例显示的段列表。每个新的时期创建还创建新的根历元节点，在该节点下，来自该时期的所有事务的元数据驻留在该节点上。因此，当执行比例时，将存在与旧时期对应的节点，并且现在还将存在用于新时期的根节点。从这一点开始创建的任何事务都将针对新时期进行。现在，工作流尝试通过机会性地尝试删除旧时期来完成缩放。当且仅当其名下没有事务时，可以删除旧时期。一旦我们确定旧时期没有事务，我们就可以继续密封旧的段并完成规模。成功密封旧段后，历史表中的部分记录现已完成，从而完成了缩放工作流程。状态现在重置为ACTIVE。</p><h3 id="截断流"><a href="#截断流" class="headerlink" title="截断流"></a>截断流</h3><p>Truncate遵循类似的机制进行更新，并具有用于截断的临时流属性，用于为截断流提供输入。一旦截断工作流标识它可以继续，它首先将状态设置为TRUNCATING。然后截断工作流查看请求的流截断，并检查它是否大于或等于现有截断点，然后它才是截断的有效输入并且工作流程开始。截断工作流接受请求的流截断，并计算要作为此截断请求的一部分删除的所有段。然后它调用相应的段存储来删除已识别的段。删除后，我们称在截止流中截断的流中描述的截断段，如流截断中所述。在此之后，截断记录将使用新的截断点和已删除的段进行更新。状态重置为ACTIVE。</p><h2 id="密封流"><a href="#密封流" class="headerlink" title="密封流"></a>密封流</h2><p>可以通过对控制器的显式API调用来请求密封流。它首先将密封流事件发布到请求流中，然后尝试将流的状态设置为SEALING。如果事件被挑选并且没有找到流处于期望状态，则它通过将其重新发布在内存队列的后面来推迟密封流处理。一旦流被设置为密封状态，流的所有活动段都通过调用段存储来密封。在此之后，流在流元数据中被标记为SEALED。</p><h3 id="删除流"><a href="#删除流" class="headerlink" title="删除流"></a>删除流</h3><p>可以通过对控制器的显式API调用来请求删除流。请求首先验证流是否处于SEALED状态。只有密封的流才能被删除，并在请求流中发布这样的事件。当事件被处理，它会再次验证流状态，然后通过调用段存储来继续从一开始就删除属于该流的所有段。成功删除所有段后，将清除与此流对应的流元数据。</p><h2 id="流策略管理器"><a href="#流策略管理器" class="headerlink" title="流策略管理器"></a>流策略管理器</h2><p>如前所述，控制器负责执行的用户定义策略有两种类型，即自动缩放和自动保留。Controller不仅仅是流策略的存储，而是主动为其流实施这些用户定义的策略。</p><h3 id="缩放基础架构"><a href="#缩放基础架构" class="headerlink" title="缩放基础架构"></a>缩放基础架构</h3><p>缩放基础架构与段存储一起构建。当控制器在段存储中创建新段时，它会将用户定义的缩放策略传递给段存储。然后，段存储监视所述段的流量，并且如果违反了从策略确定的某些阈值，则向控制器报告。Controller通过在专用内部流中发布的事件接收这些通知。可以为段接收两种类型的流量报告。第一种类型标识是否应该按比例放大（拆分）段，第二种类型标识是否应按比例缩小段。对于符合条件进行缩放的段，控制器会立即在请求流中发布段缩放请求，以便处理请求事件处理器。但是，为了缩小规模，控制器需要等待至少两个相邻的段，才有资格进行缩小。为此，它只是在元数据存储中将该段标记为冷。如果有相邻的段标记为冷，控制器会将它们合并，并发布缩小请求。然后，在请求事件处理器上异步执行缩放处理请求。</p><h3 id="保留基础设施"><a href="#保留基础设施" class="headerlink" title="保留基础设施"></a>保留基础设施</h3><p>保留策略定义了应为给定流保留多少数据。这可以定义为基于时间或基于大小的。为了应用此策略，控制器定期收集流的流截断，并且如果策略指定，则有机会地对先前收集的流截断执行截断。由于这是需要为已定义保留策略的所有流执行的定期后台工作，因此迫切需要在所有可用的控制器实例之间公平地分配此工作负载。为实现这一点，我们依赖于将流转储到预定义集中，并在控制器实例之间分发这些集。这是通过使用zookeeper来存储此分发来完成的。在引导期间，每个控制器实例都尝试获取存储桶的所有权。拥有控制器监视桶下的所有流以保留机会。在每个周期里，控制器收集新的流截断并将其添加到所述流的保留集中。发布此消息后，它会查找存储在保留集中的候选流截断，这些流截断可以根据定义的保留策略进行截断。例如，在基于时间的保留中，选择早于指定保留期的最新流截断作为截断点。</p><h2 id="事务管理器"><a href="#事务管理器" class="headerlink" title="事务管理器"></a>事务管理器</h2><p>控制器扮演的另一个重要角色是事务管理器。它负责创建，提交和中止事务。由于控制器是我们集群中的核心大脑和机构，并且是关于流的真实的持有者，因此writer请求控制器执行关于事务的所有控制平面动作。从创建事务到提交或中止事务的时间起，控制器在为事务提供保证方面发挥着积极作用。控制器跟踪每个事务的指定超时，如果超时超过，它会自动中止事务。</p><p>控制器负责确保事务和潜在的并行规模操作相互配合，确保所有承诺都得到尊重和执行。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega%2FTransactionManagement.png" alt="TransactionManagement"></p><p>事务管理图</p><p>客户端调用控制器进程来创建，ping提交或中止事务。这些请求中的每一个都在控制器上接收并由Transaction Utility模块处理，该模块实现用于处理每个请求的业务逻辑。</p><h3 id="创建事务"><a href="#创建事务" class="headerlink" title="创建事务"></a>创建事务</h3><p>writer与Controller交互以创建新事务。Controller Service将创建事务请求传递给事务工具Utility模块。模块中的create transaction函数执行以下步骤以创建事务：1。为事务生成唯一的UUID。2.它从元数据存储中获取流的当前活动的一组段，并从历史中获取其对应的时期标识符。3.它使用元数据存储接口在zookeeper中创建新的事务记录。4.然后，它请求段存储创建特定的事务段，这些段本质上链接到父活动段。<br>在创建事务时，控制器确保在我们尝试创建相应的事务段时不会密封父段。并且在事务的生命周期中，如果缩放开始，它应该等待旧时期事务在缩放之前完成，以便从旧时期密封段。</p><h3 id="提交事务"><a href="#提交事务" class="headerlink" title="提交事务"></a>提交事务</h3><p>在收到提交事务的请求后，Controller Service将请求传递给Transaction Utility模块。该模块首先尝试通过元数据存储来标记事务特定元数据记录中的提交事务。在此之后，它在内部提交流中发布提交事件。提交事务工作流在提交事件处理器上实现，从而异步处理。提交事务工作流检查提交事务的是否合格，如果为true，则执行提交工作流，无限期重试，直到成功为止。如果事务不符合提交条件（通常在旧时期仍处于活动状态时在新时期上创建事务时发生），则此类事件将重新发布到内部流中以便稍后选取。</p><p>成功提交事务后，事务的记录将从其时期根下被删除。然后，如果存在一个正在进行的缩放，则它呼叫尝试完成正在进行的缩放。试图完成缩放取决于删除旧时期的能力，当且仅当没有针对所述时期的未完成的活动事务时才能删除（有关更多细节，请参阅缩放工作流程）。</p><h3 id="中止事务"><a href="#中止事务" class="headerlink" title="中止事务"></a>中止事务</h3><p>可以通过应用程序明确请求中止，类似于提交。但是，如果事务超时，则也可以自动启动中止。控制器跟踪系统中每个事务的超时，并且每当超时过去时，或者在显式用户请求时，事务实用程序模块在其各自元数据中将事务标记为中止。在此之后，事件被中止事件处理器处理，并立即尝试中止事务。中止事务没有排序要求，因此它同时并跨流执行。</p><p>与提交一样，一旦事务中止，其节点将从其时期根目录中删除，如果存在持续的缩放，则尝试完成缩放流。</p><h3 id="Ping事务"><a href="#Ping事务" class="headerlink" title="Ping事务"></a>Ping事务</h3><p>由于控制器对于正在写入事务中的段的数据没有对数据路径的可见性，因此控制器不知道是否正在主动处理事务，并且如果超时过去，它可能会尝试中止事务。为了使应用程序能够控制事务的命运，控制器公开API以允许应用程序更新事务超时期限。这种机制称为ping，只要应用程序ping事务，控制器就会为各自的事务重置其计时器。</p><h3 id="事务超时管理"><a href="#事务超时管理" class="headerlink" title="事务超时管理"></a>事务超时管理</h3><p>控制器跟踪每个事务的超时。这是作为定时轮服务实现的。创建后，每个事务都会在创建它的控制器上注册到计时器服务中。可以在不同的控制器实例上接收事务的后续ping，并且基于通过zookeeper实现的所有权机制将定时器管理转移到最新的控制器实例。超时到期后，将尝试自动中止，如果能够成功将事务状态设置为中止，则启动中止工作流。</p><p>控制器监视超时的每个事务都会添加到此进程索引中。如果此类控制器实例失败或崩溃，则其他控制器实例将收到节点失败通知，并尝试从失败的实例中扫描所有未完成的事务，并从该点开始监视其超时。</p><h2 id="段容器到主机映射"><a href="#段容器到主机映射" class="headerlink" title="段容器到主机映射"></a>段容器到主机映射</h2><p>Controller还负责将段容器分配给段存储节点。维护此映射的责任落在单个控制器实例上，该实例是通过使用zookeeper的领导者选举选择的。当段存储节点被添加到/从集群中移除时，该领导控制器监视段存储节点的生命周期，并且跨可用的段存储节点执行段容器的重新分配。此分发映射存储在专用ZNode中。每个段存储周期性地轮询此znode以查找更改，如果找到更改，它将关闭并放弃它不再拥有的容器，并尝试获取分配给它的容器的所有权。</p><p><a href="http://pravega.io/docs/latest/controller-service/#controllerClusterListener" target="_blank" rel="noopener">这里</a>已经讨论了有关实现的细节，特别是关于如何存储和管理元数据的细节。</p>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Pravega handbook - 控制器服务之二</title>
      <link href="/2018/09/20/pravega-controller-service-2/"/>
      <url>/2018/09/20/pravega-controller-service-2/</url>
      
        <content type="html"><![CDATA[<h2 id="流元数据"><a href="#流元数据" class="headerlink" title="流元数据"></a>流元数据</h2><p>客户端需要有关哪些段构成流的信息以开始其处理，并且他们从控制器存储在流存储中的时期信息中获取它。读取器客户端通常从流的头部开始，但它也可以选择从任意有趣的位置开始访问流。另一方面，writer总是附加到流的尾部。<br>客户端需要能够有效地查询和查找在以下三种场景中的任何一个段。为了启用这些查询，流存储提供API调用来获取这些段的初始集合、在特定时间获取段以及获取段的当前集合。</p><p>如前所述，流可以从一组段（epoch）转换到构成流的另一组段。如果至少一个段被密封，并且被一个或多个精确覆盖密封段的密钥空间的段替换，则流从一个时期移动到另一个时期。当客户在流上工作时，他们可能会遇到密封段的末端，因此需要找到新的段才能继续前进。为了使客户端能够查询下一个段，流存储库通过控制器服务公开有效查询，以查找任意段的直接后继和前驱。</p><p>为了启用上述服务查询，我们需要有效地存储这些段转换的时间序列，并将它们与时间进行索引。我们在一组表中存储有关流段的当前和历史状态的信息，这些表被设计为旨在针对上述查询进行优化。除了特定于段的元数据记录之外，流的当前状态包括此后描述的其他元数据类型。</p><h2 id="表"><a href="#表" class="headerlink" title="表"></a>表</h2><p>为了有效地存储和查询段信息，我们将段数据拆分为三个仅附加表，即段表，历史表和索引表。</p><ul><li><p>段表<br>segment-info：segmentid，time，keySpace-start，keySpace-end<br>控制器将段表存储在仅附加表中，第 i 行对应于段id i的元数据。值得注意的是，段表中的每一行都是固定大小的。当添加新的段时，它们将按严格增加的顺序分配新的段ID。因此，该表非常有效地创建新段并使用O（1）处理来查询段信息响应方面非常有效。</p></li><li><p>历史表<br>epoch：时间，历史中的片段列表<br>历史表在从一个时期过渡到另一个时期时存储一系列活动段。历史表中的每一行都存储一个epoch，该epoch捕获一组逻辑上一致的（如前面定义的）段，这些段组成流，并且在该epoch的生命周期内是有效的。此表旨在优化查询以查找在任意时间形成流的段集。有三种最常用的场景，我们希望有效地知道形成流的段集 - 初始的段集，当前的段和段的任意时间段。前两个查询在O（1）时间内非常有效地回答，因为它们对应于表中的第一行和最后一行。由于表中的行是按时间的增加顺序排序的，并且捕获了流段集变化的时间序列，因此我们可以很容易地执行二进制搜索来查找在任何任意时间对应于段集的行。</p></li></ul><ul><li>索引表<br>index：⟨time，offset-in-history-table⟩<br>由于历史行的长度是可变的，因此我们为索引表中的时间戳索引历史记录行。这使我们能够浏览历史表并执行二分查找以有效地回答查询以在任意时间获得段集。我们还对历史表执行二分查找以确定任何给定段的后继。</li></ul><h2 id="流配置"><a href="#流配置" class="headerlink" title="流配置"></a>流配置</h2><p>Znode，其中流配置被序列化并持久化。流配置包含需要强制实施的流策略。缩放策略和保留策略由应用程序在创建流时提供，并由控制器通过监视流中数据的速率和大小来强制执行。缩放策略描述了是否以及何时根据流中的传入流量条件自动缩放。该策略支持两种风格 -每秒事件的速率的流量和每秒的字节速率的流量。应用程序通过缩放策略将它们所需的流量指定到每个段，并选择所提供的值来计算确定何时缩放给定流的阈值。保留策略描述了需要保留到此流的pravega集群中的数据量。我们支持基于时间和基于大小的保留策略，其中应用程序可以选择是否希望通过选择适当的策略并提供其所需值来按大小或时间保留流中的数据。</p><h2 id="流状态"><a href="#流状态" class="headerlink" title="流状态"></a>流状态</h2><p>Znode捕获流的状态。它是一个枚举，包含来自创建，活动，更新，缩放，截断，密封和密封流的值。一旦激活，流在执行特定操作和活动之间转换，直到它被密封。转换映射在State 类中定义 ，允许和禁止各种状态转换。流状态描述了流的当前状态。它基于在流上执行的动作从ACTIVE转换到相应的动作。例如，在缩放期间，流的状态从ACTIVE转换为SCALING一旦缩放完成，它就会转换回ACTIVE。流状态用作屏障，以确保在任何时间点仅对给定流执行一种类型的操作。仅允许某些状态转换，并在状态转换对象中进行描述。只允许合法的状态转换，任何不允许转换的尝试都会导致适当的异常。</p><h2 id="截断记录"><a href="#截断记录" class="headerlink" title="截断记录"></a>截断记录</h2><p>这对应于最后用于截断给定流的流截断。所有流段查询都会叠加截断记录并返回严格大于或等于截断记录中的流截断的段。</p><h2 id="密封段记录"><a href="#密封段记录" class="headerlink" title="密封段记录"></a>密封段记录</h2><p>由于段表仅附加，因此在密封段时我们需要保留的任何其他信息都存储在密封段记录中。目前，它简单地包含了段号到其密封大小的映射。</p><h2 id="与事务相关的元数据记录："><a href="#与事务相关的元数据记录：" class="headerlink" title="与事务相关的元数据记录："></a>与事务相关的元数据记录：</h2><h3 id="活动事务"><a href="#活动事务" class="headerlink" title="活动事务"></a>活动事务</h3><p>每个新事务都是在此Znode下创建的。这将与每个事务相对应的元数据存储为ActiveTransactionRecord。事务完成后，将在全局完成事务znode节点下创建一个新节点，并从流特定活动事务节点下删除该节点。</p><h3 id="完成事务"><a href="#完成事务" class="headerlink" title="完成事务"></a>完成事务</h3><p>完成后，所有流的所有已完成事务都将在此单个znode下移动（通过提交或中止路径）。随后，我们可以根据我们认为合适的任何收集方案定期回收这些值。不过在这一点上，我们此时尚未实施任何计划。</p><h2 id="流存储缓存"><a href="#流存储缓存" class="headerlink" title="流存储缓存"></a>流存储缓存</h2><p>由于同一个控制器实例可以处理给定流的多个并发请求，因此每次通过查询zookeeper来读取该值是不合理的。因此，我们引入了每个流存储维护的内存缓存。它缓存每个流的检索元数据，使得缓存中每个流最多有一个数据副本。我们有两个内存缓存 - a）存储中多个流对象的缓存，b）流对象中流的缓存属性。</p><p>我们引入了操作上下文的概念，并且在任何新操作开始时创建了新的操作上下文。新操作上下文的创建使流的高速缓存实体无效，并且每当请求时都从存储中懒惰地检索每个实体。如果在操作过程中更新了值，则该值在缓存中再次无效，以便流上的其他并发读取/更新操作获取其后续步骤的新值。<br>流桶</p><p>为了启用某些场景，我们可能需要我们的后台工作人员定期处理群集中的每个流，以对它们执行某些特定操作。我们引入了一个桶的概念，以便在所有可用的控制器实例中分发此定期后台工作。为此，我们将每个流散列到一个预定义的存储桶中，然后在可用的控制器实例之间分配存储桶。<br>群集的桶数是群集生命周期的固定（可配置）值。<br>控制器实例将系统中的所有可用流映射到桶中，并在它们之间分配桶，以便所有长时间运行的后台工作可以在多个控制器实例之间均匀分布。每个桶对应于zookeeper中的唯一Znode。完全限定范围流名称用于计算散列以将流分配给桶。所有控制器实例在启动时都会尝试获取存储桶的所有权。在故障转移时，所有权都会转移，因为幸存的节点竞争以获取孤立桶的所有权。拥有存储桶的控制器实例负责与存储桶下所有节点相对应的所有长时间运行的调度后台工作。目前，这需要运行周期性工作流来捕获每个流的流截断（称为保留集）。</p><h2 id="保留集"><a href="#保留集" class="headerlink" title="保留集"></a>保留集</h2><p>每个流的一个保留集存储在相应的桶/流Znode下。当我们定期计算流截断时，我们会在此Znode下保留它们。在执行某些自动截断时，将从此集中清除不再有效的流截断。</p><h2 id="控制器群集Listener"><a href="#控制器群集Listener" class="headerlink" title="控制器群集Listener"></a>控制器群集Listener</h2><p>Pravega 集群中的每个节点都在集群Znode下作为短暂节点注册。这包括控制器和段存储节点。每个控制器实例在集群Znode上注册监视，以侦听集群更改通知。这些通知是关于节点添加和删除的。</p><p>一个控制器实例承担所有控制器实例的领导。此领导者控制器实例负责处理段存储节点更改通知。根据拓扑结构的变化，控制器实例会定期将段容器重新平衡为段存储节点映射。</p><p>所有控制器实例都侦听控制器节点更改通知。每个控制器实例都有多个子组件，用于实现故障转移 - 清除程序接口。目前有三个组件实现故障转移清除程序接口，即 TaskSweeper，EventProcessors和TransactionSweeper。每当识别出控制器实例已从群集中删除时，群集侦听器将调用所有已注册的故障转移清除程序，以便乐观地尝试清除先前由故障控制器主机拥有的所有孤儿工作。</p><h3 id="主机存储"><a href="#主机存储" class="headerlink" title="主机存储"></a>主机存储</h3><p>主机存储接口用于将Segment Container存储到Segment Store节点映射。它公开了像getHostForSegment这样的API，它计算了段ID的一致哈希值来计算所有者Segment Container。然后基于容器 - 主机映射，它将适当的URL返回给调用者。</p><h2 id="后台工作者"><a href="#后台工作者" class="headerlink" title="后台工作者"></a>后台工作者</h2><p>控制器进程有两种不同的机制/框架来处理后台工作。这些后台工作通常需要多个步骤和更新特定元数据根实体下的元数据，以及与一个或多个段存储的潜在交互。</p><p>首先，我们从一个简单的任务框架开始，该框架允许运行对给定资源（通常是流）拥有独占权的任务，并允许任务从一个控制器实例故障转移到另一个控制器实例。然而，这个模型限制了它的范围和锁定语义，并且没有固有的任务排序概念，因为多个任务可以竞争地同时获取资源上的工作权限（锁定），并且其中任何一个都可以成功。</p><p>为了克服这个限制，我们提出了一种新基础架构，称为Event Processor。事件处理器是经典的自己的狗食自己吃。它使用pravega流建造。这为我们提供了一个简洁的机制，以确保互斥和有序的处理。</p><h3 id="任务框架"><a href="#任务框架" class="headerlink" title="任务框架"></a>任务框架</h3><p>任务框架被设计为在每个资源上运行独占的后台处理， 以便在控制器实例失败的情况下，工作可以轻松地转移到另一个控制器实例并完成。框架本身并不保证幂等处理，并且如果需要，任务的作者必须处理它。任务模型被定义为只在给定资源上专门工作，这意味着没有其他任务可以在同一资源上并发运行。这是通过在zookeeper上实现的持久分布式锁实现的。任务的故障转移是通过遵循索引给定进程正在执行的工作的索引方案来实现的。因此，如果一个流程失败，另一个流程将扫描所有未完成的工作并尝试将所有权转移给自己。注意：控制器进程失败时，多个幸存的控制器进程可以同时尝试扫描孤立的任务。它们中的每一个都将在其主机索引中索引任务，但只有其中一个能够成功获取对资源的锁定，从而获得处理任务的权限。执行任务的参数被序列化并存储在资源下。</p><p>目前，我们仅将任务框架用于创建流任务。所有其他后台处理都是使用事件处理器框架完成的。</p><h2 id="事件处理器框架"><a href="#事件处理器框架" class="headerlink" title="事件处理器框架"></a>事件处理器框架</h2><p>事件处理器框架是后台工作子系统，它从内部流中读取事件并对其进行处理，因此称为事件处理器。我们系统中的所有事件处理器至少 提供一次 处理保证。并且在其基本风格方面，该框架还提供强大的顺序保证。但我们也有不同的事件处理器子类型，允许并发处理。</p><p>我们为不同类型的工作创建不同的事件处理器。目前，我们的系统中有三个不同的事件处理器，用于提交事务，中止事务和处理流特定请求，如扩展更新密封等。每个控制器实例都有一个每种类型的事件处理器。事件处理器框架允许为每个事件处理器创建多个读取器。跨控制器实例的特定事件处理器的所有读者共享相同的读取器组，这保证了跨控制器实例的互斥分配工作。每个读者都获得一个专用线程，在该线程中，它读取事件，调用其处理并在完成处理后更新其检查点。事件被发布在事件处理器特定的流中，并且基于使用作用域流名称作为路由密钥被路由到特定的段。</p><p>我们有两种类型的事件处理器，一种执行串行处理，这基本上意味着它会读取一个事件并启动它的处理，并等待它完成后再继续进行下一个事件。这为处理过程提供了强有力的顺序保证。处理完每个事件后的检查点。提交事务是使用事件处理器的这种基本风格实现的。处理这些事件的并行度上限为内容流中段数，下限为读者取器数量的限制。来自不同流的多个事件可以在同一段中出现，并且由于我们执行串行处理，串行处理的缺点是处理停顿或来自一个流的事件泛滥会对不相关流的延迟产生不利影响。</p><p>为了克服这些缺点，我们设计了Concurrent Event Processor作为串行事件处理器的叠加。顾名思义，并发事件处理器允许我们同时处理多个事件。这里读者线程读取一个事件，调度它的异步处理并返回读取下一个事件。在任何时间点同时处理的事件数量都有上限，并且当某个事件的处理完成时，允许获取更新的事件。这里的检查点方案变得更加复杂，因为我们希望保证至少一次处理。</p><p>但是，随着并发处理，顺序保证会被破坏。但是，重要的是要注意，我们只需要顺序保证来处理来自流而不是跨流的事件提供顺序保证。为了满足排序保证，我们将Concurrent Event Processor与Serialized Request Handler重叠，后者将来自内存队列中相同流的事件排队并按顺序处理它们。</p><p>提交事务处理是在专用串行事件处理器上实现的，因为我们需要提交顺序的强力保证，同时确保提交不会干扰流上其他类型请求的处理。</p><p>中止事务处理是在专用并发事件处理器上实现的，该处理器同时对来自跨流的事务执行中止处理。</p><p>对流的所有其他请求都在序列化请求处理程序上实现，该处理程序确保在任何给定时间正在处理每个流的一个请求，并且在请求处理期间存在排序保证。但是，它允许来自跨流的并发请求同时进行。实现缩放，截断，密封，更新和删除流等工作流程，以便在请求事件处理器上进行处理。</p>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Pravega handbook - 控制器服务之一</title>
      <link href="/2018/09/20/pravega-controller-service-1/"/>
      <url>/2018/09/20/pravega-controller-service-1/</url>
      
        <content type="html"><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>控制器服务是Pravega的核心组件，用于实现控制平面。它充当集群中执行的各种操作的中央协调器和管理器，主要分为两类：</p><ol><li>流管理</li><li>集群管理</li></ol><p>控制器服务，此后简称为控制器，负责提供<a href="http://pravega.io/docs/latest/pravega-concepts/#streams" target="_blank" rel="noopener">流</a>的抽象，这是Pravega向应用程序公开的主要抽象。流包括一个或多个<a href="http://pravega.io/docs/latest/pravega-concepts/#stream-segments" target="_blank" rel="noopener">段</a>。每个段都是仅附加数据结构，用于存储字节序列。一个段本身与其他段的存在无关，并且不知道它与其对等段的逻辑关系。拥有和管理这些段的段存储没有任何流的概念。流是由Controller概念化的逻辑视图通过组合动态变化的一组段来满足一组预定义的逻辑不变量。控制器提供流抽象并协调流上的所有生命周期操作，同时确保抽象保持一致。</p><p>控制器在流的生命周期中起着核心作用：创建，修改，<a href="http://pravega.io/docs/latest/pravega-concepts/#autoscalingthenumber-of-stream-segments-can-vary-over-time" target="_blank" rel="noopener">缩放</a>和删除。它通过维护每个流的元数据并在必要时对段执行必要的操作来完成这些操作。例如，作为流生命周期的一部分，可以创建新的段并密封现有的段。控制器决定何时执行这些操作，使得流继续可用并且对访问它们的客户端是一致的。</p><h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><p>控制器服务由一个或多个无状态工作节点实例组成。每个新的控制器实例都可以独立启动，并成为pravega集群的一部分，它只需要指向相同的Apache Zookeeper。对于高可用性，建议是每个群集具有不止一个控制器服务实例。</p><p>每个控制器实例都能够独立工作，并使用一个共享的持久存储作为控制器服务所拥有和管理的所属状态的真实来源。目前使用Apache ZooKeeper作为持久存储来保存所有的元数据。每个实例包括各种子系统，其负责对不同类别的元数据执行特定操作。这些子系统包括不同的API端点，元数据存储句柄，策略管理器和后台工作程序。</p><p>控制器暴露两个端点，这些端点可用于与控制器服务交互。第一个端口用于为pravega客户端提供编程访问，并使用gRPC实现为RPC。另一个端点用于管理操作，并作为REST端点实现。</p><h2 id="流管理"><a href="#流管理" class="headerlink" title="流管理"></a>流管理</h2><p>控制器拥有并管理流的概念，并负责维护每个流的元数据和生命周期。具体而言，它负责创建，更新，缩放，截断，密封和删除流。<br>流管理可以大致分为三类：</p><ol><li><p>流抽象<br>流可以被视为一系列动态变化的段集，其中流从一组一致的段转换到下一个。Controller是创建和管理此流抽象的地方。控制器决定流何时以及如何从一种状态转换到另一种状态，并负责执行这些转换，同时保持流的状态一致且可用。这些转换是受控制器强制执行的用户定义策略的支配。因此，作为流管理的一部分，控制器还会执行策略管理器的角色，以实现保留和缩放等策略。</p></li><li><p>自动策略管理<br>控制器负责通过主动监视流的状态来存储和实施用户定义的流策略。目前，我们有两个用户可以定义的策略，即<a href="https://github.com/pravega/pravega/blob/master/client/src/main/java/io/pravega/client/stream/ScalingPolicy.java" target="_blank" rel="noopener">缩放策略</a>和 <a href="https://github.com/pravega/pravega/blob/master/client/src/main/java/io/pravega/client/stream/RetentionPolicy.java" target="_blank" rel="noopener">保留策略</a>。缩放策略描述了流是否以及在何种情况下应自动缩放其段数。保留策略描述了有关在流中保留多少数据的策略。</p></li><li><p><a href="http://pravega.io/docs/latest/pravega-concepts/#transactions" target="_blank" rel="noopener">事务</a>管理<br>实现事务需要操作段。对于每个事务，Pravega创建一组事务段，这些事务段稍后在提交时合并到流段上或在中止时丢弃。控制器执行事务管理器的角色，负责在给定流上创建和提交事务。在创建事务时，控制器还跟踪事务超时并中止超时已过期的事务。事务管理的细节可以在文档的后面找到。</p></li></ol><h2 id="集群管理"><a href="#集群管理" class="headerlink" title="集群管理"></a>集群管理</h2><p>控制器负责管理段存储集群。控制器管理段存储节点的生命周期，因为它们被添加到群集/从群集中删除，并在可用的段存储节点上执行段容器的重新分发。</p><h2 id="系统图"><a href="#系统图" class="headerlink" title="系统图"></a>系统图</h2><p>下图显示了控制器进程的主要组件。我们接下来将详细讨论该图表的元素。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega%2FControllerSystemDiagram.png" alt="ControllerSystemDiagram"></p><p>控制器流程图</p><h1 id="组件"><a href="#组件" class="headerlink" title="组件"></a>组件</h1><h3 id="服务端点"><a href="#服务端点" class="headerlink" title="服务端点"></a>服务端点</h3><p>控制器公开了两个端口：客户端控制器API和管理API。客户端控制器通信被实现为RPC，RPC公开API以执行所有与流相关的控制平面操作。除此控制器外，还公开了一个作为REST实现的管理API集。</p><p>每个端点都对Controller Service后端子系统执行适当的调用，该控制器服务子系统 具有对控制器拥有和管理的实体进行各种创建，读取，更新和删除（CRUD）操作的实际实现。</p><h3 id="GRPC"><a href="#GRPC" class="headerlink" title="GRPC"></a>GRPC</h3><p>客户端控制器通信端点实现为gRPC 接口。完整的API列表可以在<a href="https://github.com/pravega/pravega/blob/master/shared/controller-api/src/main/proto/Controller.proto" target="_blank" rel="noopener">此处</a>找到 。这暴露了Pravega客户端（读者，写者和流管理器）使用的API，并启用了流管理。此API启用的请求包括创建，修改和删除流。底层gRPC框架提供同步和异步编程模型。我们在客户端控制器交互中使用异步模型，以便客户端线程不会阻止来自服务器的响应。</p><p>为了能够附加和读取来自流，writer和reader的数据，查询控制器以在使用流时获得活动的段集，后继段和前置段。对于事务，客户端使用特定的API调用来请求控制器创建和提交事务。</p><h3 id="REST"><a href="#REST" class="headerlink" title="REST"></a>REST</h3><p>对于管理，控制器实现并公开REST接口。这包括用于流管理的API调用以及主要处理范围创建和删除的其他管理API。我们使用swagger来描述我们的REST API。<a href="https://github.com/pravega/pravega/tree/master/shared/controller-api/src/main/swagger" target="_blank" rel="noopener">这里</a>可以找到swagger的yaml文件。</p><h3 id="控制器服务"><a href="#控制器服务" class="headerlink" title="控制器服务"></a>控制器服务</h3><p>Controller服务是控制器端点（gRPC和REST）后面的后端层。提供控制器API调用所需的所有业务逻辑都在此处实现。该层包含所有其他子系统的句柄，如各种存储实现（流存储，主机存储和检查点存储）和后台处理框架（任务框架，事件处理器框架）。存储是提供对Controller管理的各种类型元数据的访问的接口。后台处理框架用于执行异步处理，该异步处理通常实现涉及元数据更新和对分段存储的请求的工作流。</p><h3 id="流元数据存储"><a href="#流元数据存储" class="headerlink" title="流元数据存储"></a>流元数据存储</h3><p>流是动态改变的段序列，其中路由键空间的区域映射到开放段。随着流的段的集合发生变化，路由密钥空间到段的映射也会发生变化。<br>如果1）映射到集合中的段的关键空间区域的并集覆盖整个密钥空间，则该组段是一致的。2）密钥空间区域之间没有重叠。例如，假设集合S = { S 1，S 2，S 3 }，使得： - 区域[0,0.3]映射到区段S 1 - 区域[0.3,0.6]映射到区段S 2 - 区域[0.6 ，1.0）映射到段S 3<br>S是一致的段集。</p><p>随着时间的推移，流会经历转换。流以初始的段集合开始，这些初始段集合在创建时由流配置确定，并且随着对流执行缩放操作时转换为新的段集。在任何给定时间点构成流的每一段被认为属于一个时期。因此，流以初始时期开始，该初始时期是时期0，并且在每次转换时，它在其时期中向前移动以描述流中的段的生成的变化。</p><p>控制器维护流存储关于构成给定流的所有时期以及它们如何转换的信息。该存储旨在优化存储和查询与段及其相互关系相关的信息。<br>除了时期信息之外，它还保留了一些额外的元数据，例如状态及其策略以及流上的持续事务。</p><p>控制器的各种子组件通过定义良好的接口访问每个流的存储元数据 。我们目前有两个具体的流存储接口实现：内存和zookeeper支持的存储。两者共享一个公共的基础实现，该实现依赖于流对象，为所有特定于流的元数据提供特定于存储类型的实现。流存储的基本实现创建并缓存这些流对象。</p><p>流对象实现存储/流接口。具体的流实现特定于存储类型的，并负责实现存储特定的方法，以提供一致性和正确性。我们有一个提供乐观并发的所有存储类型的通用基础实现。此基类封装了针对支持Compare和Swap（CAS）的所有具体存储的流存储查询的逻辑。我们目前使用zookeeper作为我们的底层存储，它也支持CAS。我们在流特定的znodes（ZooKeeper数据节点）下以分层方式存储所有流元数据。</p><p>对于基于ZooKeeper的存储，我们将元数据组织到不同的组中，以支持针对此元数据的各种查询。所有特定于流的元数据都存储在作用域/流根节点下。针对该元数据的查询包括（但不限于）查询在不同时间点形成流的段集，段特定信息，段前驱和后继。有关流元数据存储公开的API的详细信息，请参阅流元数据接口。</p>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Flink handbook - flink集群与部署之kubernetes篇</title>
      <link href="/2018/09/20/flink-deployment-kubernetes/"/>
      <url>/2018/09/20/flink-deployment-kubernetes/</url>
      
        <content type="html"><![CDATA[<p>本页介绍如何在Kubernetes上部署Flink作业和会话群集。</p><h2 id="设置Kubernetes"><a href="#设置Kubernetes" class="headerlink" title="设置Kubernetes"></a>设置Kubernetes</h2><p>请参照<a href="https://kubernetes.io/docs/setup/" target="_blank" rel="noopener">Kubernetes的设置指南</a>来部署Kubernetes集群。如果您想在本地运行Kubernetes，我们建议使用<a href="https://kubernetes.io/docs/setup/minikube/" target="_blank" rel="noopener">MiniKube</a>来部署集群。</p><blockquote><p>注意：如果使用MiniKube，请确保<code>minikube ssh &#39;sudo ip link set docker0 promisc on&#39;</code>在部署Flink群集之前执行。否则，Flink组件无法通过Kubernetes服务自行引用。</p></blockquote><h2 id="Kubernetes上的Flink会话群集"><a href="#Kubernetes上的Flink会话群集" class="headerlink" title="Kubernetes上的Flink会话群集"></a>Kubernetes上的Flink会话群集</h2><p>Flink会话群集作为长期运行的Kubernetes部署来执行，请注意，可以在会话群集上运行多个Flink作业。在部署了集群之后，每个作业都需要提交到群集。</p><p>一个基本的部署在Kubernetes上的Flink会话群集一般会有三个组件：</p><ul><li>一个运行JobManager的deployment或job</li><li>一个TaskManagers池 deployment</li><li>一个公开JobManager的REST和UI端口的service</li></ul><h2 id="在Kubernetes上部署Flink会话群集"><a href="#在Kubernetes上部署Flink会话群集" class="headerlink" title="在Kubernetes上部署Flink会话群集"></a>在Kubernetes上部署Flink会话群集</h2><p>使用会话群集的资源定义，采用kubectl命令启动群集：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs undefined">kubectl create -f jobmanager-service.yaml<br>kubectl create -f jobmanager-deployment.yaml<br>kubectl create -f taskmanager-deployment.yaml<br></code></pre></td></tr></table></figure><p>然后，您可以通过kubectl proxy按以下方式访问Flink UI ：</p><p>第一步，保证kubectl proxy在终端中运行</p><p>第二步，在浏览器里输入 <code>http://localhost:8001/api/v1/namespaces/default/services/flink-jobmanager:ui/proxy</code></p><p>如果要终止Flink会话群集，可以使用如下命令：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs undefined">kubectl delete -f jobmanager-deployment.yaml<br>kubectl delete -f taskmanager-deployment.yaml<br>kubectl delete -f jobmanager-service.yaml<br></code></pre></td></tr></table></figure><h2 id="Kubernetes上的Flink作业集群"><a href="#Kubernetes上的Flink作业集群" class="headerlink" title="Kubernetes上的Flink作业集群"></a>Kubernetes上的Flink作业集群</h2><p>Flink作业集群是运行单个作业的专用集群，这项作业是打包在flink镜像里的，因此，不需要提交额外的作业对象，步骤如下：</p><h3 id="创建特定于作业的镜像"><a href="#创建特定于作业的镜像" class="headerlink" title="创建特定于作业的镜像"></a>创建特定于作业的镜像</h3><p>Flink作业集群镜像需要包含启动集群的作业的用户代码jar。因此，需要为每个作业构建专用的容器镜像。请按照这些<a href="https://github.com/apache/flink/blob/master/flink-container/docker/README.md" target="_blank" rel="noopener">说明</a>构建Docker镜像。</p><h3 id="在Kubernetes上部署Flink作业集群"><a href="#在Kubernetes上部署Flink作业集群" class="headerlink" title="在Kubernetes上部署Flink作业集群"></a>在Kubernetes上部署Flink作业集群</h3><p>要在Kubernetes上部署作业集群，请按照这些<a href="https://github.com/apache/flink/blob/master/flink-container/kubernetes/README.md#deploy-flink-job-cluster" target="_blank" rel="noopener">说明</a>进行操作。</p><h2 id="高级群集部署"><a href="#高级群集部署" class="headerlink" title="高级群集部署"></a>高级群集部署</h2><p>GitHub上提供了早期版本的<a href="https://github.com/docker-flink/examples" target="_blank" rel="noopener">Flink Helm chart</a>。</p><h1 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h1><h2 id="会话群集资源定义"><a href="#会话群集资源定义" class="headerlink" title="会话群集资源定义"></a>会话群集资源定义</h2><p>部署使用的最新镜像 <code>flink:latest</code> 可在<a href="https://hub.docker.com/r/_/flink/" target="_blank" rel="noopener">Docker Hub</a>上找到。该镜像是用这个工具 <code>https://github.com/docker-flink/docker-flink</code> 构建的</p><p>jobmanager-deployment.yaml</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs undefined">&quot;<br>apiVersion: extensions/v1beta1<br>kind: Deployment<br>metadata:<br>  name: flink-jobmanager<br>spec:<br>  replicas: 1<br>  template:<br>    metadata:<br>      labels:<br>        app: flink<br>        component: jobmanager<br>    spec:<br>      containers:<br>      - name: jobmanager<br>        image: flink:latest<br>        args:<br>        - jobmanager<br>        ports:<br>        - containerPort: 6123<br>          name: rpc<br>        - containerPort: 6124<br>          name: blob<br>        - containerPort: 6125<br>          name: query<br>        - containerPort: 8081<br>          name: ui<br>        env:<br>        - name: JOB_MANAGER_RPC_ADDRESS<br>          value: flink-jobmanager<br>&quot;<br></code></pre></td></tr></table></figure><p>taskmanager-deployment.yaml</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs undefined">&quot;<br>apiVersion: extensions/v1beta1<br>kind: Deployment<br>metadata:<br>  name: flink-taskmanager<br>spec:<br>  replicas: 2<br>  template:<br>    metadata:<br>      labels:<br>        app: flink<br>        component: taskmanager<br>    spec:<br>      containers:<br>      - name: taskmanager<br>        image: flink:latest<br>        args:<br>        - taskmanager<br>        ports:<br>        - containerPort: 6121<br>          name: data<br>        - containerPort: 6122<br>          name: rpc<br>        - containerPort: 6125<br>          name: query<br>        env:<br>        - name: JOB_MANAGER_RPC_ADDRESS<br>          value: flink-jobmanager<br>&quot;<br></code></pre></td></tr></table></figure><p>jobmanager-service.yaml</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs undefined">&quot;<br>apiVersion: v1<br>kind: Service<br>metadata:<br>  name: flink-jobmanager<br>spec:<br>  ports:<br>  - name: rpc<br>    port: 6123<br>  - name: blob<br>    port: 6124<br>  - name: query<br>    port: 6125<br>  - name: ui<br>    port: 8081<br>  selector:<br>    app: flink<br>    component: jobmanager<br>&quot;<br></code></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> flink </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flink </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Flink handbook - flink 集群与部署之docker篇</title>
      <link href="/2018/09/20/flink-deployment-docker/"/>
      <url>/2018/09/20/flink-deployment-docker/</url>
      
        <content type="html"><![CDATA[<h2 id="作者标注"><a href="#作者标注" class="headerlink" title="作者标注"></a>作者标注</h2><p>经过验证， 到当前版本为止 flink-1.7 snapshot，构建 flink docker镜像需要采用这个flink docker 构建工具 <code>https://github.com/docker-flink/docker-flink</code>，按照<a href="https://github.com/apache/flink/tree/master/flink-container" target="_blank" rel="noopener">flink官方代码库</a>里的构建出来的flink镜像有些功能不能用，比如 flink-standalone模式，report metrics等。</p><h2 id="Docker设置"><a href="#Docker设置" class="headerlink" title="Docker设置"></a>Docker设置</h2><p>Docker Hub上有关于Apache Flink的Docker镜像，可用于部署flink群集。Flink镜像库还包含用于创建容器映像以部署flink工作集群的一些工具以及说明。</p><h2 id="Flink-session群集"><a href="#Flink-session群集" class="headerlink" title="Flink session群集"></a>Flink session群集</h2><p>Flink会话群集可用于运行多个业务。在部署后，每个业务都需要提交到集群才能跑起来。</p><h2 id="Docker镜像"><a href="#Docker镜像" class="headerlink" title="Docker镜像"></a>Docker镜像</h2><p>该<a href="https://hub.docker.com/_/flink/" target="_blank" rel="noopener">Flink镜像库</a>托管在docker hub，提供了flink1.2.1以及之后的版本镜像。</p><p>注意： Docker镜像是由个人提供的社区项目，它们并不是Apache Flink PMC的官方版本（作者标注：所以需要用这个个人的<a href="https://github.com/docker-flink/docker-flink" target="_blank" rel="noopener">构建工具</a>，而不是官方代码库里的构建工具）。</p><h2 id="Flink作业集群"><a href="#Flink作业集群" class="headerlink" title="Flink作业集群"></a>Flink作业集群</h2><p>Flink作业集群是运行单个作业的专用集群，这是镜像内容的一部分，因此，不需要额外的工作。</p><h2 id="Docker镜像-1"><a href="#Docker镜像-1" class="headerlink" title="Docker镜像"></a>Docker镜像</h2><p>Flink作业集群镜像需要包含启动集群的作业的用户代码jar。因此，需要为每个作业构建专用的容器镜像。该flink-container模块包含一个build.sh脚本，可用于创建此类镜像。有关详细信息，请参阅<a href="https://github.com/apache/flink/blob/master/flink-container/docker/README.md" target="_blank" rel="noopener">说明</a>。（作者注：这个是官方的构建方式，试过有问题，比如跑 flink-standalone再 report metrics）</p><h2 id="Flink与Docker-Compose"><a href="#Flink与Docker-Compose" class="headerlink" title="Flink与Docker Compose"></a>Flink与Docker Compose</h2><p>Docker Compose是一种很方便的用于在本地启动一组Flink Docker容器的方式。</p><p>GitHub上提供了<a href="https://github.com/docker-flink/examples/blob/master/docker-compose.yml" target="_blank" rel="noopener">集群部署实例</a>和<a href="https://github.com/apache/flink/blob/master/flink-container/docker/docker-compose.yml" target="_blank" rel="noopener">作业群集示例</a>的配置文件。</p><h2 id="用法"><a href="#用法" class="headerlink" title="用法"></a>用法</h2><p>启动集群</p><p><code>$docker-compose up</code></p><p>以deamon的方式启动集群</p><p> <code>$docker-compose up -d</code></p><p>集群扩展 N 个 TaskManagers</p><p><code>$docker-compose scale taskmanager=&lt;N&gt;</code></p><p>销毁集群</p><p><code>$docker-compose kill</code></p><p>当拉起一个Flink群集后，您可以访问 <code>http：// localhost：8081</code>的Web UI ，在界面里您还可以将作业提交到群集。</p><p>如果要通过命令行将作业提交到会话群集，必须将JAR复制到JobManager容器里并从那里执行作业。</p><p>例如：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs undefined">$ JOBMANAGER_CONTAINER=$(docker ps --filter name=jobmanager --format=&#123;&#123;.ID&#125;&#125;)<br>$ docker cp path/to/jar &quot;$JOBMANAGER_CONTAINER&quot;:/job.jar<br>$ docker exec -t -i &quot;$JOBMANAGER_CONTAINER&quot; flink run /job.jar<br></code></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> flink </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flink </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>pravega handbook - 段容器</title>
      <link href="/2018/09/19/pravega-segment-containers/"/>
      <url>/2018/09/19/pravega-segment-containers/</url>
      
        <content type="html"><![CDATA[<h2 id="Pravega集群中的段容器"><a href="#Pravega集群中的段容器" class="headerlink" title="Pravega集群中的段容器"></a>Pravega集群中的段容器</h2><p>本文档描述了我们如何管理Pravega集群中Segment Containers生命周期的高级设计。</p><h2 id="平衡段容器"><a href="#平衡段容器" class="headerlink" title="平衡段容器"></a>平衡段容器</h2><h2 id="段容器"><a href="#段容器" class="headerlink" title="段容器"></a>段容器</h2><p>在本文档中，我们将段容器称为容器。对于给定的部署，容器的总数是固定的。每个容器只能由一个Pravega主机拥有，并且群集中的所有容器都应该在任何时刻都是运行着的。</p><h2 id="Pravega主机"><a href="#Pravega主机" class="headerlink" title="Pravega主机"></a>Pravega主机</h2><p>pravega主机是pravega服务的一个实例，它拥有并执行一组容器。</p><h2 id="检测活动的Pravega主机"><a href="#检测活动的Pravega主机" class="headerlink" title="检测活动的Pravega主机"></a>检测活动的Pravega主机</h2><p>启动时每个pravega主机都会使用临时节点向Zookeeper注册。只要zookeeper从Pravega主机接收到适当的心跳，临时的节点就会出现在zookeeper中。我们依靠这些临时的节点来检测哪些pravega主机当前在群集中是活动的。</p><h2 id="监控Pravega集群"><a href="#监控Pravega集群" class="headerlink" title="监控Pravega集群"></a>监控Pravega集群</h2><p>每个Pravega Controller都运行一项服务，监控zookeeper上的临时节点并检测集群中所有活动的pravega主机。在检测到对集群成员资格的任何更改时，我们会验证所有容器并将其重新映射到可用的pravega主机集。此信息以原子方式保存在HostStore中。它存储为单个blob，并包含主机拥有的主机到容器集的映射。</p><p>我们使用zookeeper来确保只有一个pravega控制器监视集群，以避免多个同时写入HostStore的写入器。这将避免竞争条件，并允许状态更快地收敛。</p><h2 id="再平衡频率"><a href="#再平衡频率" class="headerlink" title="再平衡频率"></a>再平衡频率</h2><p>当从群集中添加或删除pravega主机时，会发生容器所有权的重新平衡。由于这是一项代价高昂的操作，我们需要防止经常这样做。目前，我们确保在任何2次重新平衡操作之间保持配置的最小时间间隔。在最坏的情况下，这将按比例增加在集群中执行所有权更改所花费的时间。</p><h2 id="所有权变更通知"><a href="#所有权变更通知" class="headerlink" title="所有权变更通知"></a>所有权变更通知</h2><p>每个pravega主机都有一个长期运行的Segment Manager服务。这会不断轮询/监视HostStore，以便对容器所有权进行任何更改。在检测到自身的所有权变更（由map中的主机密钥标识）时，段管理器会相应地触发添加和删除容器。</p><h2 id="确保容器在另一台主机上启动之前在一台主机上停止"><a href="#确保容器在另一台主机上启动之前在一台主机上停止" class="headerlink" title="确保容器在另一台主机上启动之前在一台主机上停止"></a>确保容器在另一台主机上启动之前在一台主机上停止</h2><p>我们目前计划在Pravega主机上使用保守超时，以确保容器在另一个节点上停止之前不会启动。这需要进一步检阅/讨论。</p><h2 id="检测和处理容器启动-停止故障"><a href="#检测和处理容器启动-停止故障" class="headerlink" title="检测和处理容器启动/停止故障"></a>检测和处理容器启动/停止故障</h2><p>任何容器启动/停止故障都被视为本地故障，我们希望Pravega主机尽可能在本地处理这些情况。Pravega Controller控制器不需要通过在不同主机上运行来纠正这一点。这需要进一步检阅/讨论。</p>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>pravega handbook - wire protocol</title>
      <link href="/2018/09/19/pravega-wire-protocol/"/>
      <url>/2018/09/19/pravega-wire-protocol/</url>
      
        <content type="html"><![CDATA[<h2 id="流服务线协议"><a href="#流服务线协议" class="headerlink" title="流服务线协议"></a>流服务线协议</h2><p>本页描述了为流服务提出的有线协议。有关服务的描述，请参阅父页面。</p><h2 id="协议"><a href="#协议" class="headerlink" title="协议"></a>协议</h2><p>数据通过线路以独立的“消息”发送，这些消息是“请求”（从客户端到服务器的消息）或“回复”（响应请求并返回到客户端）。</p><p>所有请求和回复都有一个带有两个字段的8字节头，（所有数据都以BigEndian格式写入）：1。消息类型 -​​ 一个整数（4个字节）标识消息类型，这决定了后面的字段。（注意，协议可以通过添加新类型来扩展）2。长度 - 无符号整数4个字节（消息应该&lt;2 ^ 24，但高位保持为零）。此点前面的数据字节数是此消息的一部分。（可能为零，表示没有数据）</p><p>字段的其余部分是特定于消息类型。下面列出了一些重要信息。</p><h1 id="一般信息"><a href="#一般信息" class="headerlink" title="一般信息"></a>一般信息</h1><h2 id="部分消息-请求-应答"><a href="#部分消息-请求-应答" class="headerlink" title="部分消息 - 请求/应答"></a>部分消息 - 请求/应答</h2><ol><li>开始/中间/结尾 - 枚举（1个字节）</li><li>数据部分消息是通过线路发送时被分解的消息。（出于任何原因）。通过按依次读取部分消息并将它们组合成一个整体来重建整个消息。在完成上一个部分消息之前尝试启动新的部分消息是无效的。</li></ol><h2 id="KeepAlive-请求-回复"><a href="#KeepAlive-请求-回复" class="headerlink" title="KeepAlive - 请求/回复"></a>KeepAlive - 请求/回复</h2><ol><li>数据 - 消息长度的未解释数据。（通常为0字节）</li></ol><h1 id="读取"><a href="#读取" class="headerlink" title="读取"></a>读取</h1><h2 id="读段-请求"><a href="#读段-请求" class="headerlink" title="读段 - 请求"></a>读段 - 请求</h2><ol><li>要读取的段 - 字符串（2字节长度，后跟Java的修改后的UTF-8的多个字节）</li><li>读取偏移量 - 长（8个字节）</li><li>建议的回复长度 - int（4字节）<ul><li>这是客户端想要的数据量。他们不一定会获得那么多。</li></ul></li></ol><h2 id="段读-回复"><a href="#段读-回复" class="headerlink" title="段读 - 回复"></a>段读 - 回复</h2><ol><li>读取的段 - 字符串（长度为2个字节，后跟Java的修改后的UTF-8的多个字节）</li><li>从中读取的偏移量 - 长（8个字节）</li><li>在Tail - 布尔值（1位）</li><li>在EndOfSegment - （1位）</li><li>数据 - 二进制（消息中的剩余长度）</li></ol><p>客户端请求以特定偏移量从特定流中读取，然后以SegmentRead消息的形式接收一个或多个应答。这些包含他们请求的数据（假设它存在）。在合适的答复中，服务器可能决定给客户端提供比其要求更多或更少的数据。</p><h2 id="追加"><a href="#追加" class="headerlink" title="追加"></a>追加</h2><h2 id="设置追加-请求"><a href="#设置追加-请求" class="headerlink" title="设置追加 - 请求"></a>设置追加 - 请求</h2><ol><li>ConnectionId - UUID（16字节）标识此appender。</li><li>要追加的段。 - 字符串（长度为2个字节，后跟Java的Modified UTF-8的多个字节）</li></ol><h2 id="追加设置-答复"><a href="#追加设置-答复" class="headerlink" title="追加设置 - 答复"></a>追加设置 - 答复</h2><ol><li>可以附加到的段。 - 字符串（长度为2个字节，后跟Java的Modified UTF-8的多个字节）</li><li>ConnectionId - UUID（16字节）标识请求的appender。</li><li>ConnectionOffsetAckLevel - Long（8字节）此connectionId在此段上接收和存储的最后一个偏移量（如果是新的话，则为0）</li></ol><h2 id="BeginAppendBlock-请求"><a href="#BeginAppendBlock-请求" class="headerlink" title="BeginAppendBlock - 请求"></a>BeginAppendBlock - 请求</h2><p>仅在SetupAppend成功完成后才有效。</p><ol><li>ConnectionId - UUID（16字节）</li><li>ConnectionOffset - Long（8字节）到目前为止通过此连接写入此段的数据</li><li>EndAppendBlock消息之前的数据长度 - 整数（4个字节） </li></ol><h2 id="EndAppendBlock-请求"><a href="#EndAppendBlock-请求" class="headerlink" title="EndAppendBlock-请求"></a>EndAppendBlock-请求</h2><ol><li>ConnectionId - UUID（16字节）</li><li>ConnectionOffset - Long（8字节）到目前为止通过此连接写入的数据</li><li>块长度 - （4个字节）写入的块的总大小。（注意，这可能多于或少于BeginAppendBlock和此消息之间的字节数）</li></ol><h2 id="事件-请求"><a href="#事件-请求" class="headerlink" title="事件 - 请求"></a>事件 - 请求</h2><p>仅在块内有效</p><ol><li>数据</li></ol><h2 id="数据附加-答复"><a href="#数据附加-答复" class="headerlink" title="数据附加 - 答复"></a>数据附加 - 答复</h2><ol><li>ConnectionId - UUID（16字节）</li><li>ConnectionOffsetAckLevel - 长（8字节）此连接之前所有数据成功存储在此段上的最高偏移量</li></ol><h3 id="追加客户段时"><a href="#追加客户段时" class="headerlink" title="追加客户段时"></a>追加客户段时</h3><ol><li>建立与其认为正确的主机的连接。</li><li>发送安装追加请求。</li><li>等待追加设置回复。</li></ol><p>然后它可以1.发送BeginEventBlock请求2.发送尽可能多的消息以适应块3.发送EndEventBlock请求</p><p>在发生这种情况时，服务器将定期向其发送DataAppended回复acking消息。请注意，给定的TCP连接可以有多个“追加”设置。这允许客户端在生成多个段时共享连接。</p><p>客户端可以通过在其BeginAppendBlock消息中指定一个较大的值来优化其附加，因为块内的事件不需要单独处理。</p><p>EndEventBlock消息指定追加块的大小而不是BeginAppendBlock消息。这意味着不需要事先知道块中数据的大小。如果客户端正在生成小消息流，这将非常有用。它可以开始一个块，写入许多消息，然后当它结束块时，它可以在EndAppendBlock消息之后写入部分消息，然后是剩余的部分消息。这样可以避免在块中的所有消息上都有标题，而不必在其进程中将它们缓冲在ram中。</p>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>pravega handbook - 数据面段存储服务之三</title>
      <link href="/2018/09/18/pravega-segment-store-service-3/"/>
      <url>/2018/09/18/pravega-segment-store-service-3/</url>
      
        <content type="html"><![CDATA[<h2 id="与Controller集成"><a href="#与Controller集成" class="headerlink" title="与Controller集成"></a>与Controller集成</h2><p>关于如何将段容器映射到主机以及使用什么规则从一个迁移到另一个的实际方法超出了本文的范围。这里，我们只描述段存储服务如何与控制器交互，以及它如何基于外部事件管理段容器的生命周期。</p><h2 id="段容器管理"><a href="#段容器管理" class="headerlink" title="段容器管理"></a>段容器管理</h2><p>Segment Store Service的每个实例都需要Segment Container Manager。此组件的作用是管理分配给该节点（服务）的Segment Containers的生命周期。它履行以下职责：</p><ul><li>连接到Controller服务端客户端（即，仅处理Segment Container事件的客户端，而不是Streams的管理，并侦听与其自身实例相关的所有与Container相关的更改。</li><li>当它收到需要为特定Container Id启动Segment Container的通知时，它会启动引导此类对象的过程。在操作完成且没有错误之前，它不会通知请求客户端成功。</li><li>当它收到需要停止特定Container Id的Segment Container的通知时，它会启动关闭它的过程。在操作完成且没有错误之前，它不会通知请求客户端成功。</li><li>如果Segment Container意外关闭（无论是在Start期间还是在正常操作期间），它将不会尝试在本地重新启动它; 相反，它会通知控制器这个事实。</li></ul><h2 id="存储抽象"><a href="#存储抽象" class="headerlink" title="存储抽象"></a>存储抽象</h2><p>段存储不是专门针对TIER-1或TiR-2的实现而设计的。相反，所有这些组件都已经抽象出来并定义得很好，可以针对任何标准文件系统（Tier-2）或仅追加日志系统（Tier-1）实现。</p><p>第1层存储的可能候选者：</p><ul><li>Apache BookKeeper（首选，适配器完全实现为Pravega的一部分）</li><li>非持久性，非复制性解决方案：</li><li>内存中（只部署单个节点——Pravega成为二级存储的易失性缓冲区；在进程崩溃或系统重新启动的情况下，数据丢失是不可避免的和不可恢复的）。<ul><li>这仅用于单元测试。</li></ul></li><li>本地文件系统（仅单节点部署——Pravega成为二级存储的半持久缓冲区；在完全节点失败的情况下，数据丢失是不可避免的和不可恢复的）</li></ul><p>二级存储的可能候选者：</p><ul><li>HDFS（可实施）</li><li>扩展S3（可实现）</li><li>NFS（通用FileSystem）（可用实现）</li><li>内存中（单节点部署——有限的用途；在进程崩溃或系统重新启动的情况下，数据丢失是不可避免的和不可恢复的）<ul><li>这仅用于单元测试。</li></ul></li></ul><p>关于Tier-2 Truncation的注释：</p><ul><li><p>Segment Store支持在特定偏移量处的Segment截断，这意味着，一旦该请求完成，那么在该偏移量以下的偏移量将不可用于读取。<br>上面这只是一个元数据更新操作，但是这也需要由Tier-2支持，以便从其中物理删除截断的数据。</p></li><li><p>如果Tier-2实现从具有偏移量保存的文件开始就不支持截断（即，在偏移50处截断长度为100的段，则删除偏移0..49，但是偏移量50-99可用并且没有向下移动），然后Segment Store在通用的Tier-2实现之上提供了一个包装器，它可以做到这一点.</p></li><li><p>所述RollingStorage tier-2 分割segment成多个段组块并暴露它们作为一个单一的段到上层。已截断的段块将自动删除。这不是一个非常精确的应用程序（因为它在很大程度上依赖于规定粒度的翻转策略），但对于那些真正的第2层实现不提供我们需要的功能的情况，它是一个实用的解决方案。</p></li></ul><h2 id="数据流"><a href="#数据流" class="headerlink" title="数据流"></a>数据流</h2><p>以下是Pravega Segment Store Service中数据流动的几个示例。</p><h2 id="追加"><a href="#追加" class="headerlink" title="追加"></a>追加</h2><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega%2FSegment.Store.Appends.png" alt="Segment.Store.Appends"></p><p>上图描绘了这些步骤（注意步骤编号可能不匹配，但顺序相同）：</p><ol><li>Segment Store接收带有params的附加请求：Segment Name，Payload和AttributeUpdates。</li><li>Segment Store确定给定Segment的ContainerId，并验证Segment Container是否在本地注册。如果不是，则返回适当的错误代码。</li><li>Segment Store将请求委托给相应的Segment Container实例。<ul><li>Segment Container验证Segment是否属于Segment Container并且Segment实际存在。如果不是，则返回适当的错误代码。<ul><li>在此过程中，它还会获得现有的段ID或分配新段（通过使用段映射器组件）。</li></ul></li><li>Segment Container StreamSegmentAppendOperation使用输入数据创建a 并将其发送到Durable Log。</li></ul></li></ol><ol start="4"><li><p>持久日志采用追加操作并根据持久日志部分中描述的算法对其进行处理:</p><ul><li>将其放入其操作队列中。</li><li>操作处理器从队列中拉出所有操作。</li><li>操作处理器使用数据框构建器来构建具有其操作的数据框架。</li><li>Data Frame Builder将数据帧异步写入持久数据日志。</li><li>完成后，以下内容并行完成：<ul><li>元数据已更新。</li><li>操作被添加到内存操作日志和读取索引中。</li><li>触发操作的呼叫被激活。</li></ul></li><li>上述过程是异步的，这意味着操作处理器将具有多个未受控制的数据帧（未示出）。它将跟踪每一个的变化并根据需要应用或回滚。<br>此过程适用于Segment Store支持的每个操作。所有修改操作都通过操作处理器并具有类似的路径。</li></ul></li></ol><h2 id="读取"><a href="#读取" class="headerlink" title="读取"></a>读取</h2><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega%2FSegment.Store.Reads.png" alt="Segment.Store.Reads"></p><p>上图描绘了这些步骤（注意步骤编号可能不匹配，但顺序相同):</p><ol><li>段存储接收带有参数的读取请求：段名称，读取偏移量，最大长度。<ul><li>Segment Store确定给定Segment的ContainerId，并验证它是否是给定Segment Container的 Leader 。如果不是，则返回适当的错误代码。</li><li>Segment Store将请求委托给Segment Container实例。</li></ul></li><li><p>Segment Container验证Segment是否属于该Container并且它实际存在。如果没有，它会向客户端返回适当的错误代码。</p><ul><li>在此过程中，它还会获得现有的段ID或分配新段（通过使用段映射器组件）。</li></ul></li><li><p>段容器将请求委托给其读取索引，该索引按照“ 读取索引”部分中的描述处理读取，方法是从存储中发出读取（对于不在缓存中的数据），并根据需要查询/更新缓存。</p></li></ol><h2 id="与Tier-2（存储写入器）同步"><a href="#与Tier-2（存储写入器）同步" class="headerlink" title="与Tier-2（存储写入器）同步"></a>与Tier-2（存储写入器）同步</h2><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega%2FSegment.Store.SyncTier2.png" alt="Segment.Store.SyncTier2"></p><p>上图描绘了这些步骤（注意步骤编号可能不匹配，但顺序相同）：</p><ol><li>该存储写入的主循环是子组件触发所有这些操作</li><li>从持久日志中读取下一个操作（在每个循环之间，Writer会记住上次处理的操作的序列号是什么）</li><li>处理所有操作，并将其添加到内部段聚合器（每个段一个聚合器）</li><li>符合条件的段聚合器被刷新到存储（资格取决于每个聚合器中收集的数据量，以及是否有排队的Seal，Merge或Truncate操作）<ul><li>每次遇到Append操作时，可能需要访问Read Index以获取追加的内容</li></ul></li><li>在对storage的每次成功修改（写入/密封/连接/截断）之后，都会更新Container Metadata以反映更改。</li><li>该持久日志被截断（如果符合条件）。</li></ol><h2 id="容器启动（正常-恢复）"><a href="#容器启动（正常-恢复）" class="headerlink" title="容器启动（正常/恢复）"></a>容器启动（正常/恢复）</h2><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega%2FSegment.Store.Recovery.png" alt="Segment.Store.Recovery"></p><p>上图描绘了这些步骤（注意步骤编号可能不匹配，但顺序相同）：</p><ol><li>容器管理器接收在该段存储服务的这个实例中启动容器的请求。<ul><li>它创建，注册和启动Container。</li></ul></li><li>该容器启动持久日志组件。</li><li>持久日志启动恢复过程（由Recovery Executor协调）。</li><li>Recovery Executor从持久数据日志中读取所有数据帧。</li><li>读取数据帧中的反序列化操作将添加到“ 内存操作日志”中。</li><li>所述容器的元数据是由的方式更新操作元数据更新器（同运算处理器内使用的）。</li><li>该读取索引填充了那些适用于IT运营的内容。</li><li>该容器启动存储写入器。<ul><li>该存储写入的主循环开始从处理操作持久化日志，以及在第一次遇到一个新的segment时，它将其内容（和元数据）与存储中存在的实际情况调和。</li></ul></li><li>在Durable Log和Storage Writer都启动后，Container已准备好开始接受新的外部请求。</li></ol>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>pravega handbook - 数据面段存储服务之二</title>
      <link href="/2018/09/18/pravega-segment-store-service-2/"/>
      <url>/2018/09/18/pravega-segment-store-service-2/</url>
      
        <content type="html"><![CDATA[<h2 id="日志操作"><a href="#日志操作" class="headerlink" title="日志操作"></a>日志操作</h2><p>一个日志操作是在可持久化的日志里序列化的基本单元。它本身并不代表一个动作，而是几个可序列化操作的基础（我们可以序列化多种类型的操作，而不仅仅是Appends）。每个操作都是外部操作（表示更改段）或内部触发（如元数据维护操作）的结果。<br>每个日志操作都具有以下元素： <code>- SequenceNumber</code>：分配给此条目的唯一序列号（请参阅容器元数据下的更多信息）。</p><p>这些是各种类型的日志操作：</p><ul><li>存储操作表示需要应用于底下第2层存储的操作：</li><li>StreamSegmentAppendOperation：表示对特定段的附加。</li><li>CachedStreamSegmentAppendOperation：与StreamSegmentAppendOperation相同，但这是供内部使用的（它不是具有实际的数据有效负载，而是指向缓存中可以从中检索数据的位置）。</li><li>StreamSegmentSealOperation：处理后，它会在内存中的元数据中设置一个标记，以便不再接收附加内容。当Storage Writer处理它时，它会在第2层存储中将Segment标记为只读。</li><li>StreamSegmentTruncateOperation：截断特定偏移处的段。这会导致segment的StartOffset发生变化。</li><li>MergeTransactionOperation：表示要将事务合并到其父段中。</li><li>元数据操作是指示容器元数据更改的辅助操作。它们可能是外部操作的结果（我们之前收到了一个我们从未知道的段的请求，因此我们必须为其分配一个唯一的ID）或者对整个元数据进行快照（这有助于恢复和清理第1层）存储）。元数据操作的目的是减少故障转移恢复所需的时间（如果需要）：</li><li>StreamSegmentMapOperation：将Id映射到段名称。</li><li>TransactionMapOperation：将Id映射到事务及其父段。</li><li>UpdateAttributesOperation：更新segment上的任何属性。</li><li>MetadataCheckpoint包括元数据的整个快照。这在恢复期间非常有用 - 它包含到目前为止的所有元数据，这是之后所有操作的基础。</li></ul><h2 id="可持久化日志"><a href="#可持久化日志" class="headerlink" title="可持久化日志"></a>可持久化日志</h2><p>该可持久化日志是处理所有操作日志的核心组成部分。所有操作（由Container创建）都会添加到持久日志中，该日志按照接收顺序处理它们。它由一些其他组件组成，在不影响数据完整性的情况下，所有这些组件的唯一目标都是致力于尽快处理所有输入操作。</p><p>可持久化日志中的信息流:</p><ol><li>所有收到的操作都被添加到操作队列中 （调用方接收一个当操作持久地完成时将完成的未来）</li><li>该运算处理器选取目前在队列中可用的所有操作（如果队列为空，则等到至少一个操作被添加）。</li><li><p>所述操作处理器运行作为一个连续的环（在后台线程中），并且具有四个主要阶段。</p><ul><li>从操作队列中出列所有未完成的操作（如上所述）</li><li>预处理操作（验证它们是否正确并且不会导致意外行为，分配偏移量（如果需要），分配序列号等）</li><li>写操作的数据帧生成器，其序列化和包装的操作数据帧。数据框完成后（完整或不再需要添加操作），数据框构建器将数据框发送到_可持久化的数据日志。请注意，操作可能跨越多个DataFrame - 目标是通过尽可能大的写入（但也考虑到每次写入可能有最大大小限制）来充分利用持久数据日志吞吐量容量。</li></ul></li></ol><ol start="4"><li><p>当持久数据日志中的DataFrame持久存在时，操作处理器会对迄今为止完全写入的所有操作进行后处理（将它们添加到内存中结构，更新索引等）并完成与它们相关的未来。</p></li><li><p>Operation Processor异步工作，因为它在开始另一个数据帧并将其发送到持久数据日志之前不等待写入特定的数据帧。因此，多个DataFrame可能正在运行（但是以特定的顺序），并且操作处理器依赖于持久数据日志中的某些排序保证（如果特定DataFrame被攻击，那么在此之前的所有DataFrame也以正确的顺序被成功提交）。</p><ul><li>操作处理器不执行任何写入限制（将其留给持久数据日志实现），但它控制发送给它的数据帧的大小。</li></ul></li></ol><h2 id="截断"><a href="#截断" class="headerlink" title="截断"></a>截断</h2><p>根据提供的配置，Durable Log会自动添加一种特殊的操作，命名为MetadataCheckpointOperation。此操作在由操作处理器处理时，收集整个Container Metadata的快照，并将其序列化为Durable Data Log。此特殊操作标记一个截断点 - 日志操作流中的一个位置，我们可以在其中发出截断操作。非常重要的是，在每次截断之后，在日志中找到的第一个操作是一个 MetadataCheckpointOperation，因为没有先前的操作来重建元数据，这是能够处理后续操作的唯一方法。</p><p>注意：不应将持久数据日志（第1层）截断与段截断相混淆。它们用于不同的目的，适用于不同的目标。</p><h2 id="操作处理器"><a href="#操作处理器" class="headerlink" title="操作处理器"></a>操作处理器</h2><p>操作处理器是处理日志输入操作的可持久化的日志的子组件。其目的是基于每个操作的内容来验证、持久化和更新元数据和其他内部结构。<br>操作元数据更新器</p><p>操作元数据更新器是持久日志的子组件，负责基于元数据的当前状态验证操作，以及在成功提交操作之后更新元数据。在内部，它有各种机制来应对失败，并且它可以回滚失败情况下的某些变化。</p><h2 id="持久数据日志"><a href="#持久数据日志" class="headerlink" title="持久数据日志"></a>持久数据日志</h2><p>持久数据日志是一个外部组件的抽象层，提供仅附加语义。它是一个向日志提供非常快速附加的系统，它保证了写入数据的持久性和一致性。读取性能不是一个很重要的因素，因为我们不直接从该组件读取数据 - 我们只在需要恢复持久日志的内容时才从该组件读取日志数据。</p><p>如上所述，日志操作被序列化为数据框架（如果需要的话，单个操作能够跨越多个这样的框架），然后这些数据框架被序列化为持久数据日志的条目。这仅用作故障安全，并且我们只需要在需要执行恢复时才需要读回这些框架（在这种情况下，我们需要按照接收它们的相同顺序反序列化它们中包含的所有日志操作）。</p><h2 id="内存操作日志"><a href="#内存操作日志" class="headerlink" title="内存操作日志"></a>内存操作日志</h2><p>内存中操作日志包含提交（和复制）的日志操作，其顺序与添加到持久数据日志的顺序完全相同。虽然持久数据日志包含一系列数据帧（其中包含操作的序列化），但是内存日志包含实际的操作，这些操作可以在整个持久日志（以及存储写入器）中使用。</p><p>内存日志本质上是在接收操作时命令的日志操作链。我们总是在一端添加，然后从另一端移除。当我们截断持久数据日志时，内存日志也被截断在同一位置。</p><h2 id="读取索引"><a href="#读取索引" class="headerlink" title="读取索引"></a>读取索引</h2><p>读取索引有助于段容器在任意偏移量下执行从流读取。虽然耐用日志按照接收的顺序记录（并且只能重放）数据，但是Read Index可以以随机方式访问数据。读取索引由多个片段读取索引（每个活片段之一）构成。</p><p>段读取索引是一种数据结构，用于提供从内存的读取，以及从第2层存储中提取数据，并在数据尚未可用时提供未来读取（尾部读取）。当接收到读取请求时，段读取索引返回一个读取迭代器，只要读取请求参数尚未满足，该迭代器将返回数据。迭代器要么从存储器中取出立即可用的数据，要么从第2层存储器中请求数据（并将其带到存储器中），要么如果到达段当前末端，返回Future并在添加新数据时完成（从而提供尾随或未来读取）。</p><p>段读索引的核心是条目的排序索引（由它们的起始偏移量索引），用于在需要时定位所请求的数据。索引本身由定制的平衡二进制搜索树（更确切地说，是AVL树）实现，其目标是最小化内存使用而不牺牲插入或访问性能。条目本身不包含数据，而是一些少量的元数据，这些元数据用于定位缓存中的数据并确定使用模式（对缓存撤出很有好处）。</p><h2 id="高速缓存"><a href="#高速缓存" class="headerlink" title="高速缓存"></a>高速缓存</h2><p>缓存是一个组件，其中所有数据（无论是从新添加的还是从第二存储中提取的）都被存储。它是一个完全由读取索引管理的密钥值存储。</p><p>缓存被定义为抽象层，并且有两个实现：</p><ul><li>内存实现（通过哈希图）。目前只用于单元测试。</li><li>内存与磁盘混合，由ROCKSDB提供支持。这是首选的（默认的）实现，因为它不受可用堆空间或机器RAM的限制，其性能与内存大小成正比。</li></ul><h2 id="存储写入"><a href="#存储写入" class="headerlink" title="存储写入"></a>存储写入</h2><p>Pravega绝不是数据的最终安放位置，也不是存储服务。Tier-2 Storage是我们希望数据长期存在的地方而Pravega仅用于存储非常短的尾部（使用第1层存储），足够快速追加并将它们聚合成更大的块以便提交给第2层存储。为了执行此操作，它需要另一个组件（存储写入），该组件按照接收顺序从持久日志中读取数据，对其进行聚合，并将其发送到第2层存储。</p><p>就像持久日志一样，每个段容器都有一个存储写入器。每个写入器从内存操作日志中读取日志操作（通过持久日志中的read()方法公开），按照它们被处理的顺序。它通过它的序列号来跟踪最后一个读项目。此状态不被持久化，并且在恢复时，它可以从可用的持久日志的开始开始。</p><p>Storage Writer可以处理任何存储操作（附加，密封，合并），并且由于Pravega是在第2层中修改此类数据的唯一参与者，因此它可以不受约束地应用它们。它有几种机制可以检测和恢复可能的数据丢失或外部参与者同时修改数据。</p>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>pravega handbook - 数据面段存储服务之一</title>
      <link href="/2018/09/18/pravega-segment-store-service-1/"/>
      <url>/2018/09/18/pravega-segment-store-service-1/</url>
      
        <content type="html"><![CDATA[<p>Pravega Segment Store Service是Pravega的核心子系统，它提供了创建，删除和修改/访问其内容的功能，是管理流段的主要入口。Pravega客户端与Pravega stream controller互动以确定需要使用哪些段（对于流），流控制面和客户端一起处理段存储服务从而操作这些流段。<br>Segment Store Service背后的基本思想是，它将输入的数据缓存在一个非常快速且持久化的append only介质（第1层存储）中，并将其与高吞吐量（但不一定是低延迟）存储系统（第2层存储）同步，同时将多个小流段合并到大的流段里。</p><p>Pravega Segment Store Service可提供以下保证：</p><ul><li>流段长度不受限制，仅具有附加语义，但支持任意偏移读取</li><li>无论底层第2层存储系统的性能如何，执行小型附加时都不会降低吞吐量</li><li>多个并发写入到同一个段</li><li>在单个写入的上下文中保证顺序，但是来自多个并发写入的附加数据行为将按照接收它们的顺序来添加（附加是原子的而不交错其内容）。</li><li>并发写入和读取段，写入和读取之间的延迟相对较低。</li></ul><h2 id="术语"><a href="#术语" class="headerlink" title="术语"></a>术语</h2><p>在本文档的其余部分中，我们将使用以下术语：</p><ul><li>流段或段：连续的字节序列。类似于没有大小限制的文件。这是Stream的一部分，限制是暂时的并且是横向的（根据key值）。Streams的 范围 和如何将Stream Segments映射到此Streams超出了本文档需要阐述的内容。</li><li>第2层存储或永久存储：数据的最终存储位置。</li><li>第1层存储：快速附加存储，用于在将数据刷到第2层存储之前持久缓冲输入的append only数据。</li><li>缓存：键值本地缓存，不期望持久性。</li><li>Pravega Segment Store服务或Segment Store：本文档描述的服务。</li><li>事务：与段相关的一系列附加操作，如果持久化，它将在段中构成连续的字节范围。这用于摄取非常大的记录或用于累积可能或可能不会持久存储到段中的数据（但其如何使用以后才能确定）。</li></ul><p>请注意，在Pravega级别，事务适用于整个流。在本文档中，事务适用于单个段。</p><h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><p>段储存由以下几部分组成：</p><ul><li>Pravega Node：运行Pravega进程的主机。</li><li>流段容器（或段容器）：流段的逻辑分组。Segments到Containers的映射是确定性的，不需要任何持久存储; 段通过hash函数（基于段的名称）映射到容器。</li><li>持久数据日志适配器（或DurableDataLog）：第1层存储的抽象层。</li><li>存储适配器：第2层存储的抽象层。</li><li>缓存：用于追加数据缓存的抽象层。</li><li>Streaming Client：可用于与Pravega Segment Store通信的API。</li><li>Segment Container Manager：可用于确定Pravega节点上Segment Containers生命周期的组件。该组件用于启动或停止Segment Containers， 而这些段容器是基于外部协调服务（例如Pravega控制器）的。</li></ul><p>首先段存储通过将数据写入快速存储（最好是SSD）上的日志层（持久数据日志），并在数据被持久存储后立即返回给客户端。随后，这些写入的数据被合并成更大的数据块并在后台刷新到第2层存储。已经确认（并且在第1层中）但尚未在第2层中的附加数据存储在缓存中（除了第1层）。一旦将此类数据写入第2层存储，它可能会也可能不会保留在缓存中，具体取决于许多因素，例如缓存利用率/压力和访问模式。<br>有关上述每个组件的更多详细信息，请参阅“ 组件”部分（下面）。</p><h2 id="系统图"><a href="#系统图" class="headerlink" title="系统图"></a>系统图</h2><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega%2FSegment.Store.Components.png" alt="Segment.Store.Components"></p><p>在此图中，我们显示了Segment Store的主要组件（为简单起见，仅描绘了一个Segment Container）。显示所有Container组件和它们之间的主要链接（它们如何相互交互）。所述容器的元数据组件未示出。<br>更详细的图表可以在数据流部分（下面）中找到。</p><h1 id="组件"><a href="#组件" class="headerlink" title="组件"></a>组件</h1><h2 id="段容器"><a href="#段容器" class="headerlink" title="段容器"></a>段容器</h2><p>段容器是段的逻辑组，负责跨越这些段的所有操作。Segment Container由多个子组件组成：</p><ul><li>段容器元数据：一组段的元数据，用于描述每个段的当前状态（第2层中的数据量，第1层中的数量，是否密封等），以及关于每个容器的其他错误信息。</li><li>可持久化日志：Container将其接收的每个操作都写入此日志，并仅在日志显示已被接受且持久化存储时才返回。</li><li>读索引：可从中读取数据的内存索引。Container将所有读取请求委托给它，它负责从当前所在的任何位置（Cache，Tier-1 Storage或Tier-2 Storage）获取数据。</li><li>缓存：用于存储仅在第1层（尚未存在于第2层）中的附加数据，以及支持读取的数据块。</li><li>Storage Writer：处理持久日志操作并将它们应用于第2层存储（按接收顺序）。此组件也是将多个操作合并在一起的组件，以获得更好的后端吞吐量。</li></ul><h2 id="段容器元数据"><a href="#段容器元数据" class="headerlink" title="段容器元数据"></a>段容器元数据</h2><p>段容器元数据对其组件的良好运行和同步至关重要。此元数据在所有组件之间共享，它分为两个级别：容器范围的元数据和每个段的元数据。每个服务都有不同的用途，如下所述。<br>容器元数据<br>每个Segment Container都需要保存一些影响容器内所有操作的通用元数据：</p><ul><li>操作序列号：持久日志分配的最大序列号。每次通过持久日志接收并成功处理新操作时，此数字都会递增（其值永远不会减少或以其他方式回滚，即使操作未能保存）。</li><li>操作序列号保证严格单调递增（没有两个操作具有相同的值，并且操作将始终具有比之前的所有操作更大的序列号）。</li><li>Epoch：每次成功恢复（Container Start）时会增加的数字。该值可以持续递增并作为恢复的一部分进行存储，并且可以用于许多场景（例如作为HDFS的第2层防护，HDFS不能为此提供良好的原生保护机制）。</li><li>活动段元数据：有关每个活动段的信息（请参阅下一节）。如果Segment最近有活动（读取或写入）并且当前已加载到内存中，则它处于活动状态。如果这个段有一段时间内未使用，或者当前有太多个段处于活动状态，那么通过将段的元数据刷新到第2层存储并且将段的元数据从内存中淘汰，从而可以使得这个段变为非活动状态。</li><li>第1层元数据：在该点之前的所有操作已经持久存储到第2层，可用于准确截断第1层存储日志的各种信息。</li><li>检查点：通过将容器元数据的整个快照（包括活动段）序列化到第1层存储来定期对容器元数据打检查点。检查点充当第1层的截断点，这意味着它包含通过之前所有已处理的操作对Container进行的所有更新，因此我们不再需要这些操作来重建元数据。如果我们在Checkpoint上截断Tier-1，那么我们可以使用来自Tier-2和此Checkpoint的信息来重建先前元数据中的内容，而不依赖于Tier-1中之前的任何操作。</li></ul><h2 id="段元数据"><a href="#段元数据" class="headerlink" title="段元数据"></a>段元数据</h2><p>每个段容器都需要保留每个段的元数据，用于在处理每个段的操作时跟踪每个段的状态。元数据可以是易失性的（可以在恢复时完全重建），并且包含当前正在使用的每个段的以下属性：</p><ul><li>Name 段的名称。</li><li>Id：内部分配的唯一段ID。这用于指代Segments，它比段的名称更受欢迎。此ID在段的生命周期内是不会改变的，这意味着即使段变为非活动状态，将来重新激活也会将其映射到相同的Id。</li><li>StartOffset（也称为TruncationOffset）：可用于读取的数据的最低偏移量。非截断段的Start Offset将等于0，而后续Truncate操作将增加（但永不减少）此数字。</li><li>StorageLength：第2层存储中存在的数据的最高偏移量。</li><li>Length：第1层存储中已提交数据的最高偏移量。</li><li>LastModified：上次处理（和确认）附加的时间戳。</li><li>IsSealed：segment是否已关闭追加数据（此值可能尚未应用于Tier-2存储）。</li><li>IsSealedInStorage：Segment是否已关闭追加数据（并且这已在第2层存储中保留）。</li><li>IsMerged：此段是否已合并到另一个段中（但尚未在第2层存储中保留）。这仅适用于事务。一旦合并持续到第2层，事务段就不再存在（因此IsDeleted将成为现实）。</li><li>IsDeleted：segment是否被删除或最近是否已合并到另一个segment中。这仅适用于最近删除的segment，而不适用于从未存在过的segment。<br>对于任何segment，以下内容  始终为true：</li><li>StorageLength &lt;= Length</li><li>StartOffset &lt;= Length</li></ul>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>pravega handbook - reader groups设计</title>
      <link href="/2018/09/17/pravega-reader-groups/"/>
      <url>/2018/09/17/pravega-reader-groups/</url>
      
        <content type="html"><![CDATA[<h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h2><p>可以将一组读者组合在一起，以便可以并行读取流中的事件集。读者群组称为读者群。Pravega保证流中的每个事件都由读者组中的一个读者读取。<br>ReaderGroup中的每个Reader都分配了零个或多个段。分配给Segment的Reader是ReaderGroup中唯一一个从该Segment读取事件的Reader,这是Pravega向读者提供事件传递的顺序保证的基本机制,读者将按照他们发布到segment中的顺序接收事件。<br>这种机制存在以下几个挑战：</p><ul><li>如何维护ReaderGroup中哪个Reader的映射分配哪个Segment </li><li>如何在Segments拆分和合并时管理上述映射 </li><li>如何在将读者添加到ReaderGroup </li><li>当读者通过显式操作离开ReaderGroup或reader因网络中断或Reader进程失败而变得不可用时，如何管理上述映射</li></ul><p>为了解决这些问题，我们可以使用[[StateSynchronizer | StateSynchronizer-design]]使读者能够相互协调。</p><h2 id="如何使用一致的复制状态来解决问题"><a href="#如何使用一致的复制状态来解决问题" class="headerlink" title="如何使用一致的复制状态来解决问题"></a>如何使用一致的复制状态来解决问题</h2><p>每个reader中都创建了表示ReaderGroup元数据的一致复制状态对象,此ReaderGroup元数据包括：</p><ul><li>在线读者的映射表，他们拥有的segment可以接管的segment中的位置列表。</li><li>每次ReaderGroup中的读者更改时，都可以更新状态。</li><li>类似地，每当其中一个读者开始从一个新段读取时，它就可以更新复制状态。</li></ul><p>这允许所有读者了解ReaderGroup中的所有其他读者以及他们拥有的哪些片段。</p><p>假设这样的信息：</p><ul><li><p>新读者可以知道哪些片段可读取,（因为无状态）处理合并的段变得容易，因为到达其合并前段的末尾的最后一个读者知道它可以自由地获得新段的所有权。</p></li><li><p>读者可以看到他们的相对负载以及他们相对于他们小组中其他读者的进展情况，并且如果事情失衡，他们可以决定转移segment。</p></li><li><p>这允许读者直接采取行动，以确保所有事件都被读取，而无需一些外部跟踪器。</p></li></ul><h2 id="ReaderGroup的API"><a href="#ReaderGroup的API" class="headerlink" title="ReaderGroup的API"></a>ReaderGroup的API</h2><p>可以将用于管理ReaderGroup的外部API添加到StreamManager对象。它们包括：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs undefined">ReaderGroup createReaderGroup（String name，Stream stream，ReaderGroupConfig config）;<br>ReaderGroup getReaderGroup（String name，Stream stream）;<br>void deleteReaderGroup（ReaderGroup group）;<br></code></pre></td></tr></table></figure><p>创建ReaderGroup时，它会创建一个由读者共享的[[StateSynchronizer | StateSynchronizer-design]]。要加入ReaderGroup，读者只需在其配置中指定它：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs undefined">ReaderConfig cc = new ReaderConfig（props）;<br>Reader &lt;T&gt; reader = a_stream.createReader（“my_reader_id”，“my_reader_group”，cc）;<br></code></pre></td></tr></table></figure><p>当读者加入组时，他们使用状态来确定要读取的segment。当他们关闭时，他们会更新状态，以便其他读者可以接管他们的segment。</p><h2 id="故障检测器"><a href="#故障检测器" class="headerlink" title="故障检测器"></a>故障检测器</h2><p>我们仍然需要某种心跳机制来判断读者是否还在线。问题大大简化，因为它不需要生成集群视图或管理任何状态。该组件只需要检测失败并调用<code>void readerOffline(String readerId, Position lastPosition);</code>ReaderGroup上的api</p><p>为保持一致性，故障检测器不应将仍在处理事件的主机声明为死机，这样做可能会违反恰好一次处理保证。</p><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><h2 id="新读者"><a href="#新读者" class="headerlink" title="新读者"></a>新读者</h2><ol><li>当读者加入组时，其在线状态将添加到共享状态</li><li>其他读者会收到共享状态的更新。</li><li>当具有超过平均段数的读者看到新读者时，它可以通过将该段的位置写入共享状态来放弃段。</li><li>新的读者可以通过记录它在共享状态下执行此操作来接管一个段。</li><li>新读者可以从它从所拾取的段的共享状态读取的位置开始读取。</li><li>多个读者之间没有同时上线的比赛，因为只有其中一个可以成功声明任何给定片段的所有权。</li></ol><h2 id="合并段"><a href="#合并段" class="headerlink" title="合并段"></a>合并段</h2><ol><li>当读者到达其片段的末尾时，它会将此信息记录在共享状态中。</li><li>当所有合并在一起的段完成后，读者可以声明对以下段的所有权。</li></ol><p>关于拥有者是谁，因为它存储在共享状态中没有歧义。不存在遗忘某个段的风险，因为任何读者都可以通过查看共享状态并声明它们来查看哪些段可用。</p><h2 id="读者离线"><a href="#读者离线" class="headerlink" title="读者离线"></a>读者离线</h2><ol><li>当读者离线时，readerOffline（）方法将由读者本身在正常关闭（在close方法内部）或通过活动检测器调用。在任何一种情况下，读者的最后位置都会被传入。</li><li>最后一个位置写入状态。</li><li>其他读者在更新本地状态时会看到这一点。</li><li>他们中的任何一个都可以通过记录他们在状态对象中的意图来决定接管旧读者所拥有的一个或多个片段。</li><li>状态更新后，新读者将被视为该segment受众群的所有者，并可随意阅读。</li></ol><h2 id="如果读者没有及时了解会发生什么"><a href="#如果读者没有及时了解会发生什么" class="headerlink" title="如果读者没有及时了解会发生什么"></a>如果读者没有及时了解会发生什么</h2><p>具有过期状态的读者可以从其现有段中读取而不受干扰。唯一的缺点是，如果有可用的话，它们不会给另一个读者带来负担。但是，因为他们必须写入共享状态才能从他们尚未拥有的任何段开始读取，所以他们必须在转移到新段之前获取最新信息。</p><h2 id="可用性和延迟的影响"><a href="#可用性和延迟的影响" class="headerlink" title="可用性和延迟的影响"></a>可用性和延迟的影响</h2><p>读取和更新状态对象可以与读取并行发生，因此可能没有可见的延迟影响。如果Pravega以包含ReaderGroup信息的段落下并且保持离线足够长时间以使读者耗尽其现有段中的所有事件的方式失败，则流将无法读取。当然，如果Pravega以这种方式失败，那么至少某些部分流也会受到直接影响，并且无法读取任何事件。这种故障模式将表现为读者的延迟，类似于他们到达流尾部时会发生的情况。</p><p>这比使用外部系统来管理这种协调更为可取，因为这需要添加可能以不同方式失败的新组件，而不是进一步依赖我们需要高度可用的小组。在网络分区的情况下，这尤其值得注意。如果网络被分开，与Pravega服务器位于分区同一侧的任何reader都可以继续工作。如果我们要利用外部服务，那么该服务可能被切断，即使他们可以与Pravega交互，读者也可能无法取得进展。</p>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>分布式系统中DHT算法改进</title>
      <link href="/2018/09/16/distributed-dht-update/"/>
      <url>/2018/09/16/distributed-dht-update/</url>
      
        <content type="html"><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>通常，分布式存储系统以及分布式缓存系统习惯采用分布式哈希（DHT）算法来实现数据的分区分配（路由）以及负载均衡，普通的分布式hash算法通过增添虚拟节点，对物理的热点区间进行划分，将负载分配至其他节点，从而达到负载均衡的状态，但是这并不能保证集群的负载就一定很是的均衡。</p><p>而一种改进过的一致性Hash算法，即带边界因子的一致性Hash算法，其严格控制每个节点的负载从而能获得更好的负载均衡效果[1][2]。</p><h2 id="普通的DHT算法"><a href="#普通的DHT算法" class="headerlink" title="普通的DHT算法"></a>普通的DHT算法</h2><p>假设有8个Object，通过下图的DHT算法:</p><ol><li>object 0,1,2映射到了虚拟节点vNode0 ： object 0,1,2 –&gt; vNode0</li><li>Object 3,4,5 映射到了vNode1：object 3,4,5 –&gt; vNode1</li><li>Object 6映射到 vNode2：object 6 –&gt; vNode2</li><li>Object 7映射到 vNodeN：object 7 –&gt; vNodeN</li></ol><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed%2Fdistributed-DHT-1.png" alt="distributed-DHT-1"></p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed%2Fdistributed-DHT-2.png" alt="distributed-DHT-2"></p><p>很明显，Vnode0和vNode1 都落了三个 object，而 vNode2和vNodeN 都只落了 1个Object，这里的DHT算法负债均衡因子并不是很好。</p><h2 id="带负载边界因子的DHT算法"><a href="#带负载边界因子的DHT算法" class="headerlink" title="带负载边界因子的DHT算法"></a>带负载边界因子的DHT算法</h2><p>假设有8个Object，通过如下图的DHT with bounded loads算法:</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed%2Fdistributed-DHT-3.png" alt="distributed-DHT-3"></p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed%2Fdistributed-DHT-4.png" alt="distributed-DHT-4"></p><p>第一轮映射：</p><ol><li>object 0,1,2 需要映射到了虚拟节点vNode0，但是vNode0的权重因子是 2，因此只完成了 object 0,1 –&gt; vNode0， object 2不能映射到节点 vNode0；</li><li>Object 3,4,5 需要映射到了虚拟节点vNode1：但是vNode1的权重因子是 2，因此只完成了 object 3,4 –&gt; vNode1， object 5不能映射到节点 vNode1；</li><li>Object 6映射到 vNode2：object 6 –&gt; vNode2</li><li>Object 7映射到 vNodeN：object 7 –&gt; vNodeN</li></ol><p>第二轮映射：</p><ol><li>Object 2 映射到 vNode1，但是vNode1权重因子=0， 不能被接收，继续往下一个节点走，发现vNode2 权重因子是2,还剩权重因子1，可以被映射，因此 object 2–&gt;vNode2</li><li>Object 5 映射到 vNode2，但是vNode2现在的权重因子=0， 不能被接收，继续往下一个节点走，发现vNodeN 权重因子是2,还剩权重因子1，可以被映射，因此 object 5–&gt;vNodeN</li></ol><p>最终的映射结果是:</p><ol><li>object 0,1映射到了虚拟节点vNode0 ： object 0,1 –&gt; vNode0</li><li>Object 3,4 映射到了vNode1：object 3,4 –&gt; vNode1</li><li>Object 2,6映射到 vNode2：object 2,6 –&gt; vNode2</li><li>Object 5,7映射到 vNodeN：object 5,7 –&gt; vNodeN</li></ol><p>很明显，Vnode0，vNode1，vNode2, vNodeN 每个节点都分到2个 object，<br>显然带负载边界因子的DHT算法负债均衡比普通的DHT算法来的好。</p><p>这些节点的负载因子可以从IO，CPU，MEM，Disk，Network等输入因子计算出来。</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a>作者简介</h2><p>常平，毕业于中国科学技术大学，获硕士研究生学历学位，10年+ 存储、布式系统、云计算以及大数据经验，曾就职于Marvell、AMD等，现就职于EMC，资深首席工程师，主要负责流式大数据处理平台的架构设计、编码及产品交付等。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1] <a href="https://research.googleblog.com/2017/04/consistent-hashing-with-bounded-loads.html" target="_blank" rel="noopener">https://research.googleblog.com/2017/04/consistent-hashing-with-bounded-loads.html</a></p><p>[2] <a href="https://medium.com/vimeo-engineering-blog/improving-load-balancing-with-a-new-consistent-hashing-algorithm-9f1bd75709ed" target="_blank" rel="noopener">https://medium.com/vimeo-engineering-blog/improving-load-balancing-with-a-new-consistent-hashing-algorithm-9f1bd75709ed</a></p>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>是时候把分布式系统的理论指导从CAP升级到PACELC</title>
      <link href="/2018/09/16/distributed-cap-pacelc/"/>
      <url>/2018/09/16/distributed-cap-pacelc/</url>
      
        <content type="html"><![CDATA[<h2 id="从-CAP到-PACELC"><a href="#从-CAP到-PACELC" class="headerlink" title="从 CAP到 PACELC"></a>从 CAP到 PACELC</h2><p>CAP理论是当前分布式系统设计的理论指导，而PACELC理论是CAP理论的扩展，分布式系统设计的理论依据是时候从CAP理论扩展为PACELC理论, PACELC在wiki上的定义是:</p><blockquote><p>It states that in case of network partitioning (P) in a distributed computer system, one has to choose between availability (A) and consistency (C) (as per the CAP theorem), but else (E), even when the system is running normally in the absence of partitions, one has to choose between latency (L) and consistency (C).</p></blockquote><p>简单来说这里的意思就是：</p><blockquote><p>如果有分区partition (P)，系统就必须在availability 和consistency (A and C)之间取得平衡; 否则else (E) 当系统运行在无分区情况下,系统需要在 latency (L) 和 consistency (C)之间取得平衡</p></blockquote><p>CAP理论认为以下三者不能同时满足：</p><ul><li><p>一致性(Consistency): 所有的节点在同一时刻看到同样的数据。</p></li><li><p>可用性(Availability):  节点失效不会影响系统的读写。</p></li><li><p>分区容忍性(Partition Tolerance): 系统能支持网络分区，即使分区之间的消息丢失系统也正常工作。</p></li></ul><p>根据业务场景的不同，不同的分布式系统会根据自身业务的需求在CAP三者中进行权衡， CAP理论的意义是一种在分布式系统设计时权衡的因素，而非绝对的三者必舍其一，并且在CAP理论中是没有提到系统的时延（Latency）的，而访问时延（Latency）却是很重要的可用性(Availability)因素。</p><p>因此重新定义一个新的模型PACELC，添加了系统中的Latency，如下图：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed%2Fcap-pacelc.png" alt="cap-pacelc"></p><p>当前分布式系统设计指导理论应当用PACELC理论替代CAP理论，理由如下：</p><ol><li><p>PACELC更能满足实际操作中分布式系统的工作场景是更好的工程实现策略；</p></li><li><p>当partition (P)存在的场景下，需要在availability 和consistency (A and C)之间获得权衡，当时实际上分布式系统中绝大多数时间里partition (P)是不存在的，那么就需要在latency (L) 和 consistency (C)之间取得权衡。</p></li><li><p>availability在不存在partition (P)的场景下跟 latency关联,在partition (P)时跟reliable指标关联。</p></li><li><p>PACELC 可以在 latency vs consistency之间获得平衡</p></li><li><p>CAP 理论忽略了 一致性和时延之间的权衡</p></li></ol><p>PACELC建立在CAP之上，二者都描述了在一致性(Consistency)，可用性(Availability)和分区容忍性(Partition Tolerance)之间的限制和权衡。而PACELC更进一步描述了即使在没有Partition的场景下，也存在Latency和Consistency之间的权衡，从而为分布式系统的Consistency模型提供了一个更为完整的理论依据。</p><p>要保证系统的高可用（high availability）那么就必须复制数据，而分布式系统进行数据复制复制，就会出现在Consistency和Latency之间做个权衡的要求。</p><p>举个栗子，如下图所示，</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed%2Fconsistency-latency.png" alt="consistency-latency"></p><ol><li><p>在强一致性复制场景下，需要三副本都下盘才能返回ok给client端，Master向 Slave 复制数据，Latancy的限制是 20ms，有时候，slave 2 硬盘或网络出现故障，Master 往 Slave 复制数据的时延超过 20ms了，这个时候如果还一致等待 slave 2 返回结果再notify 给client就会出现性能和时延抖动，而且这种抖动是经常发生的长尾效应。</p></li><li><p>依据PACELC理论，我们可以在 consistency和Latency之间做个权衡，比如 slave 2 节点的时延超过 20ms了，就不等待slave 2 返回，master 和 slave 1 返回结果给client即可，如果 slave 2 出现 超时的 次数超过 5次那么就认为 这个节点可能出现故障，打个故障标签，进行后续的处理。</p></li></ol><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a>作者简介</h2><p>常平，毕业于中国科学技术大学，获硕士研究生学历学位，10年+ 存储、布式系统、云计算以及大数据经验，曾就职于Marvell、AMD等，现就职于EMC，资深首席工程师，主要负责流式大数据处理平台的架构设计、编码及产品交付等。</p><h3 id="参考文献："><a href="#参考文献：" class="headerlink" title="参考文献："></a>参考文献：</h3><p>[1] <a href="https://en.wikipedia.org/wiki/PACELC_theorem" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/PACELC_theorem</a></p><p>[2] CAP理论与分布式系统设计，S先生</p>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>pravega handbook - stateSynchronizer</title>
      <link href="/2018/09/16/pravega-statesynchronizer/"/>
      <url>/2018/09/16/pravega-statesynchronizer/</url>
      
        <content type="html"><![CDATA[<h2 id="StateSynchronizer的设计"><a href="#StateSynchronizer的设计" class="headerlink" title="StateSynchronizer的设计"></a>StateSynchronizer的设计</h2><p>StateSynchronizer提供了一种方法，通过这种方法可以支持多个进程同时对一份数据进行写入和读取，并且使用了一种乐观检查的方法来保证数据的一致性。</p><p>这项工作保证每个进程都有一份数据的副本。所有的数据更新都是通过StateSynchronizer写入，它将这些数据附加到Pravega的段里。通过从段里消费数据来跟踪数据的最新变化，并且使用了有条件追加数据的方法提供了一致性保证。<br>这样可确保更新的过程只有在有最新数据时才可以继续执行更新。最后，为了防止段数据无节制地增长，我们使用了一种重写最新数据的简单方法，并截断旧数据，以便可以删除它。</p><p>当大多数更新与存储的总数据大小相比较小时，此模型运行良好，因为它们可以写成小的增量。与任何乐观并发系统一样，当众多进程都试图同时尝试更新相同的信息时，工作状态最差。</p><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>这里有一个同步集合内容的具体示例，此外我们还有一个示例，即同步一组主机的成员资格。</p><p>想象一下，许多进程同时共享一个映射表的场景。这可以通过StateSynchronizer创建来完成，这将有助于协调对映射表的更改。每个客户端在内存中都有自己的一份映射表副本，可以通过将映射表生成器传递给StateSynchronizer来更新。每次尝试更新时，更新都会先记录到段中。除非传递给进程的映射表与已记录到段中的映射表一致，否则更新将失败。如果发生这种情况，则使用最新状态调用生成器以再次尝试。因此，更新的顺序由它们写入段的顺序定义。</p><h2 id="如何实现"><a href="#如何实现" class="headerlink" title="如何实现"></a>如何实现</h2><p>为此，我们使用了Pravega Segment Store Service的两个功能。</p><h3 id="条件追加"><a href="#条件追加" class="headerlink" title="条件追加"></a>条件追加</h3><p>附加方法可以指定追加期望的偏移量，如果追加数据失败，则不执行任何操作而是返回失败给客户端。</p><h3 id="截断段"><a href="#截断段" class="headerlink" title="截断段"></a>截断段</h3><p>截断段删除给定偏移之前的所有数据（此操作不会影响现有偏移量），对于低于此值的偏移量的任何读取都将失败，并且在此偏移下的任何数据都可以删除。</p>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>pravega handbook - 常见问题</title>
      <link href="/2018/09/16/pravega-faq/"/>
      <url>/2018/09/16/pravega-faq/</url>
      
        <content type="html"><![CDATA[<h2 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h2><p><strong>什么是Pravega？</strong> Pravega是一个开源存储原语，为连续和无界数据实现Streams。</p><p><strong>“Pravega”是什么意思？</strong> “Pravega”是梵文中的一句话，指的是“速度快”的意思。</p><p><strong>Pravega与Kafka和Kinesis等系统类似吗？</strong> Pravega是以企业级存储为目标从头开始构建的流存储系统，支持恰好一次性，持久化等功能.Pravega是一个理想的流存储系统，专门用于流式数据的存储，比如来自实时应用的数据和物联网数据。</p><p><strong>我怎样才能参与这个开源系统？</strong> 开源加速了颠覆性创新。当Pravega创建时，毫无疑问，将它作为开源是有道理的。我们欢迎经验丰富的新开发人员的贡献。查看Github中的代码。有关如何参与的更多细节可以在这里找到。</p><p><strong>我该如何开始使用pravega？</strong>有关更多信息，请阅读入门指南，并访问一些示例应用程序的sample-apps repo。</p><p><strong>如果遇到问题，我在哪里可以获得帮助？</strong> 不要犹豫！如果您需要任何帮助，请联系邮件列表上的开发人员和社区。有关详细信息，请参阅加入社区。</p><p><strong>Pravega支持恰好一次语义吗？</strong> 绝对的支持。有关Pravega如何支持语义的讨论，请参阅主要功能。</p><p><strong>Pravega如何与Apache Flink等流处理器配合使用？</strong> Pravega的很多功能特性使其成为流处理器的理想选择。首先，通过flink connector, Pravega支持开箱即用。更加重要的是，Pravega支持恰好一次语义，使得开发精确的流处理应用变得更加容易。恰好一次语义，持久化和事务的这些特性的组合使得Pravega成为了Flink很好的合作伙伴，通过pravega可以提供端到端的一致性和恰好一次的语义。</p><p><strong>如何在流处理器和Flink之间进行自动缩放？</strong> 自动缩放是Pravega的一项基本功能，其流中的段数根据数据的摄取率的变化而变化。如果负载更高，速度更快，Pravega会通过添加段来增加流的容量。当数据速率或系统负载下降时，Pravega可以减少流的容量。当Pravega扩展和缩小流的容量时，如Flink的应用程序可以观察到此变化并且通过添加或减少使用流的作业实例的数量来响应。有关自动缩放的更多讨论，请参阅主要功能中的“Auto Scaling”部分。</p><p><strong>Pravega提供哪些一致性保证？</strong> Pravega提供了几项保证。持久化 - 一旦客户端确认数据，Pravega保证这个数据是受到保护的。排序 - 具有相同路由密钥的事件将始终按其编写顺序读取。恰好一次 - 写给Pravega的数据不会重复。</p><p><strong>为什么支持一致性和持久化对Pravega等存储系统如此重要？</strong> 主要是因为它使构建应用更容易。一致性和持久性是支持恰好一次语义的关键。如果没有恰好一次语义，就很难构建容错性应用程序，以确保一致性产生准确的结果。有关一致性和持久性保证的讨论，请参阅主要功能 .Pravega支持恰好一次的语义。</p><p><strong>Pravega支持事务吗？</strong> 是的。Pravega API允许应用程序在流上创建事务并将数据写入事务。数据被持久存储，就像写入Pravega的任何其他数据一样。当应用程序选择时，它可以提交或中止事务。提交事务时，事务中的数据将原子地附加到流中。有关Pravega事务支持的更多详细信息，请参见此处。</p><p><strong>Pravega是否支持跨不同路由键的事务？</strong> 是的。Pravega的事务本身就是一个流; 它可以有1个或多个段，写入事务的数据被放入与数据路由键关联的段中。提交事务时，事务数据将附加到流中的相应段。</p><p><strong>我是否需要安装HDFS才能使用Pravega？</strong> 是的。通常，您将为Pravega部署HDFS以用作其第2层存储。但是，对于简单的测试/开发环境，Pravega的所谓standAlone版本实现了自己的模拟HDFS。有关详细信息，请参阅Running Pravega指南。</p><p><strong>Pravega支持哪些第2层存储系统？</strong> Pravega旨在支持各种类型的第2层存储系统。目前，我们已将HDFS作为第2层存储。</p><p><strong>Pravega提供了哪些分布式计算原语？</strong> Pravega提供了一个名为StateSynchronizer的API结构。使用StateSynchronizer，开发人员可以使用Pravega在多个进程之间构建同步共享状态。此原语可用于构建各种分布式计算解决方案，如共享配置，领导者选举等。有关详细信息，请参阅主要功能中的“分布式计算原语”部分。</p><p><strong>Pravega推荐什么硬件配置？</strong> 对比控制面，数据面Segment Store 的要求更高，最少需要1GB内存和2核CPU，存储10GB起。控制面资源消耗少点，推荐的配置是1 CPU和0.5 GB内存起。</p>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Pravega handbook - 关键特性二</title>
      <link href="/2018/09/16/pravega-key-features-2/"/>
      <url>/2018/09/16/pravega-key-features-2/</url>
      
        <content type="html"><![CDATA[<h2 id="自动缩放"><a href="#自动缩放" class="headerlink" title="自动缩放"></a>自动缩放</h2><p>与静态分区的系统不同，Pravega可以动态扩展单个数据流以适应数据摄取率的变化。</p><p>想象一下物联网的应用场景，数百万台设备为数千个数据流提供这些设备的相关信息。</p><p>想象一下Flink作业的管道，它处理这些流以从所有原始IoT数据中获取业务价值：预测设备故障，优化通过这些设备的服务交付，或在与这些设备交互时定制客户的体验。如果没有组件能够随着数据速率增加和减少的情况下自动伸缩的情况下，大规模地构建这样的应用程序是很困难的。</p><p>使用Pravega，可以轻松地弹性地和独立地扩展数据的摄取，存储和处理 - 协调数据管道中每个组件的扩展。</p><p>Pravega对自动缩放的支持始于Streams被划分为StreamSegments的想法。流可以具有一个或多个流段; 回想一下，Stream Segment是Stream的一个分区，与一系列路由密钥相关联。</p><p>写入Stream的任何数据都将写入与数据路由密钥关联的Stream Segment。写入者使用应用程序有意义的路由密钥，如customer-id，timestamp，machine-id等，以确保将类似数据组合在一起。 </p><p>流段是Pravega Streams中基本的并行度单位，具有多个流段的流可以支持更多的数据并行写入; 多个写入者将数据写入不同的流段，可能涉及群集中的所有Pravega服务器。在Reader端，Stream Segments的数量表示可能的最大读取并行度。如果Stream具有N个流段，则具有N个读取器的ReaderGroup可以并行地从流中消费数据。增加Stream Segments的数量，可以增加ReaderGroup中的Readers数量，以增加处理来自该Stream的数据的规模。当然，如果Stream Segments的数量减少，那么可以相应地减少读取器的数量。</p><p>Stream可以配置为更多数据写入Stream，那么就增加StreamSegments的数量，在数据量下降时就缩小segments规模。我们将此配置称为Stream的服务级别目标或SLO。Pravega监控输入到Stream的数据速率，并使用SLO从流中添加或删除流段。通过拆分流段来增加流段的数量。通过合并两个流段来减少流段的数量。请参阅  AutoScaling：有关Pravega如何管理StreamSegments的更多详细信息，Stream Segments的数量可能会随时间变化。</p><p>协调Pravega中Streams的自动缩放和应用程序缩小（在工作中）。这一点是可以实现的。使用Pravega提供的元数据，应用程序可以配置其应用程序组件的扩展; 例如，驱动Flink作业的实例数。或者，您可以使用Cloud Foundry，Mesos / Marathon，Kubernetes或Docker堆栈等软件来部署应用程序的新实例，以响应Pravega级别增加的并行性，或者减少Pravega规模以响应速率降低时终止实例数据的摄取。</p><h2 id="分布式计算原语"><a href="#分布式计算原语" class="headerlink" title="分布式计算原语"></a>分布式计算原语</h2><p>Pravega非常适合分布式应用，例如微服务; 它可以用作数据存储机制，用于微服务之间的消息传递和其他分布式计算服务，例如领导者选举。</p><p>State Synchronizer是Pravega API的一部分，它是在集群中以一致性和乐观并发性共享状态的基础。状态同步器基于Pravega中的基本条件写操作，因此只有当数据出现在Stream中的给定位置时才会写入数据。如果条件写入操作不满足条件，则失败。</p><p>因此，状态同步器是一种强大的同步原语，可用于群集中的共享状态，成员资格管理，领导者选举和其他分布式计算方案。</p><h2 id="写效率"><a href="#写效率" class="headerlink" title="写效率"></a>写效率</h2><p>Pravega写入延迟大约为毫秒级，无缝扩展以处理来自数千个并发客户端的高吞吐量读取和写入，使其成为物联网和其他时间敏感型应用的理想选择。</p><p>流是轻量级的，Pravega可以支持数百万个流，这可以避免静态配置流和需要预先分配少量固定数量的流以及管理或限制流资源。</p><p>Pravega中的写操作的时延是很低的，可以做到在10ms以下返回结果返回给Writer。此外，优化写入可以使的I / O吞吐量只受到网络带宽的限制; 持久性机制不是瓶颈。Pravega使用Apache BookKeeper来持久化所有写操作。BookKeeper可以非常有效地保留和保护数据。由于数据在写入操作被Writer确认之前受到保护，因此数据始终是持久的。正如我们在下面讨论的那样，数据持久性是存储原语的基本特征。为了进一步提高效率，对BookKeeper的写入通常涉及来自多个流段的数据，因此将数据保存到磁盘的成本可以通过多次写入操作来分摊。Pravega避免了持久化数据与性能的权衡问题。</p><p>读取也很有效，读取器可以在Stream的尾部或Stream历史的任何部分读取Stream。与一些基于日志的系统不同，它使用相同类型的存储进行尾部读写以及读取历史数据，而Pravega使用两种类型的存储。Stream的尾部位于所谓的第1层存储中。如上所述，写入由Apache BookKeeper实现。尾部读取由Pravega管理的内存缓存提供。事实上，BookKeeper仅在故障恢复方案中提供读取功能，Pravega Server已经崩溃并且正在恢复。BookKeeper的这种使用正是它的设计目标：快速写入，偶尔读取。Stream的历史部分在所谓的第2层存储中，针对具有高吞吐量的低成本存储进行了优化。Pravega使用高效的内存预读缓存，也获利于Streams通常以大的连续块读取的场景，并且HDFS非常适合那些大型，高吞吐量的读取。值得注意的是，尾部读取不会影响写入的性能。</p><h2 id="无限保留"><a href="#无限保留" class="headerlink" title="无限保留"></a>无限保留</h2><p>Streams中的数据可以在应用程序需要时保留，受限于可用数据量，这在第2层中使用云存储是无限制的.Pravega提供了一个方便的API来访问实时和历史数据。使用Pravega，可以有效地处理批量和实时应用程序; 另一个原因是Pravega是Kappa架构的优秀存储原语。</p><p>如果保留旧数据有价值，为什么不保留它？例如，在机器学习示例中，您可能希望定期更改模型并针对尽可能多的历史数据训练模型的新版本，以产生更准确的模型预测能力。使用Pravega自动分层，保留大量历史数据不会影响尾部读写的性能。</p><p>流的大小不受单个服务器的存储容量限制，而是仅受存储群集或云提供商的存储容量的限制。随着存储成本的降低，删除数据的经济动机也随之消失</p><h2 id="存储效率"><a href="#存储效率" class="headerlink" title="存储效率"></a>存储效率</h2><p>使用Pravega构建数据处理管道，结合批处理，实时和其他应用程序，而无需为管道的每个步骤复制数据。</p><p>考虑以下数据处理环境，它结合了使用Spark，Flink和/或Storm的实时处理; Haddoop批量; 某种基于Lucene的搜索机制，如弹性搜索全文搜索; 也许一个（或几个）NoSQL数据库支持微服务应用程序。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega%2Fpipeline.separate.replicas.png" alt="pipeline.separate.replicas"></p><p>使用传统方法，每个系统将单独摄取和复制一组源数据，例如来自IoT应用的传感器数据。您最终将获得pub / sub系统中受保护数据的3个副本，HDFS中的3个副本，Lucene中的3个副本，NoSQL数据库中的3个副本。当我们考虑以千兆字节为单位测量源数据时，由中间件类别分隔的数据复制成本变得非常昂贵。</p><p>考虑使用Pravega和适用于Pravega存储的中间件的相同管道：</p><p> <img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega%2Fpipeline.single.source.png" alt="pipeline.single.source"></p><p>使用Pravega，数据在一个地方被摄取和保护; Pravega为整个管道提供单一的事实来源。此外，由于大量数据存储在使用擦除编码的第2层中以有效地保护数据，因此数据的存储成本大大降低。</p><h2 id="持久化"><a href="#持久化" class="headerlink" title="持久化"></a>持久化</h2><p>使用Pravega，您无需在性能，持久化和一致性之间达成妥协。Pravega提供持久的流数据存储，具有强大的一致性、顺序保证和出色的性能。</p><p>持久化是基本的存储原始要求。可能丢失数据的存储不是可靠的存储，基于这种存储的系统不能满足生产要求。</p><p>一旦确认写入操作，即使发生故障，数据也不会丢失。这是因为Pravega总是在写入操作返回到Writer之前将数据保存在受保护的持久存储中。</p><p>使用Pravega，Stream中的数据受到保护。可以将Stream视为记录系统，就像处理存储在数据库或文件中的数据一样。</p><h2 id="事务支持"><a href="#事务支持" class="headerlink" title="事务支持"></a>事务支持</h2><p>开发人员使用Pravega Transaction来确保将一组事件原子地写入流中。</p><p>Pravega事务是Pravega的Writer API的一部分。数据可以直接通过API写入Stream，或者应用程序可以通过Transaction写入数据。使用事务，Writer可以立即保留数据，然后决定是将数据附加到Stream还是放弃。</p><p>使用事务，仅在提交事务时才将数据写入Stream。提交事务时，写入事务的所有数据都以原子方式附加到Stream。由于事务的实现方式与Stream Segments相同，因此写入事务的数据与直接写入Stream的数据一样耐用。如果放弃了事务（例如，如果Writer崩溃），则中止事务并丢弃所有数据。当然，如果出现表明Writer应该丢弃数据的情况，应用程序可以选择通过API中止事务。</p><p>事务是将Flink工作链接在一起的关键。当Flink作业使用Pravega作为接收器时，它可以开始一个Transaction，如果它成功完成处理，则提交Transaction，将数据写入其基于Pravega的接收器。如果作业由于某种原因失败，则事务超时并且不写入数据。重新启动作业时，接收器中没有需要管理或清理的“部分结果”。</p><p>结合事务和Pravega的其他主要功能，可以将Flink工作链接在一起，让一个工作的基于Pravega的接收器成为下游Flink工作的来源。这使得整个Flink作业管道能够恰好具有一次端到端，保证了数据处理的顺序。</p><p>当然，跨多个Streams的事务可以与事务协调，因此Flink作业可以使用2个或更多基于Pravega的接收器为下游Flink作业提供源输入。此外，应用程序逻辑可以将Pravega事务与外部数据库（如Flink的检查点存储）进行协调。</p>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Pravega handbook - 关键特性一</title>
      <link href="/2018/09/16/pravega-key-features-1/"/>
      <url>/2018/09/16/pravega-key-features-1/</url>
      
        <content type="html"><![CDATA[<p>本系列介绍了Pravega的一些关键特性。如果您已经熟悉Pravega的核心概念，那么这些概念对于理解本文会有所帮助。</p><h2 id="Pravega设计原则"><a href="#Pravega设计原则" class="headerlink" title="Pravega设计原则"></a>Pravega设计原则</h2><p>Pravega旨在支持新一代流式应用：这些应用处理大量的连续到达的数据，并且这些应用还对迟到的数据、无序到达的数据和发生故障时生成的数据进行准确的分析。有几个开源工具可以让开发人员构建这样的应用场景，例如Apache Flink，Apache Beam，Spark Streaming等。迄今为止，这些流式应用使用Apache Kafka，Apache ActiveMQ，RabbitMQ，Apache Cassandra和Apache HDFS等系统来摄取和存储数据。在pravega里，我们设想将摄取和存储这两个概念统一起来，因而pravega的工作重点是摄取和存储流数据。</p><p>Pravega从存储的角度处理流应用。它使这些流式应用能够连续不断的摄取流数据并永久地保存下来。作为分析历史数据的一部分，可以以低延迟（毫秒级）的方式访问这样的流数据，也可以提前几个月，甚至几年分析这样的历史数据。</p><p>Pravega的设计结合了使用Lambda架构构建流应用时的经验教训，也参考了大规模部署流应用时的挑战，这些应用始终以容错方式提供准确的结果。Pravega架构提供强大的持久化和一致性保证，为构建流式应用提供坚实的基础。</p><p>在Lambda架构里，开发人员使用复杂的中间件组合，其中包括批处理中间件以及Storm，Samza，Kafka等连续处理中间件。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega%2Flambda.png" alt="lambda"></p><p>在lambda体系结构中，批处理用于提供准确但可能过时的数据分析，第二条路径在摄取数据时处理数据，原则上结果是无效的，这证明了第一条路径的合理性。使用此方法，应用程序逻辑上有两个副本，因为速度层的编程模型与批处理层中使用的编程模型不同。Lambda架构很难在生产中维护和管理。因此，这种大数据处理架构一直在对用户失去吸引力。最近，一种不同类型的大数据体系结构越来越受到关注，此架构不依赖于批处理数据路径。这种架构称为Kappa架构。</p><p>Kappa架构风格是针对Lambda架构太过于复杂的一种改进，依赖于专为流式传输而设计的组件，支持更强大的语义并提供快速准确的数据分析能力，Kappa架构是一种更简单的方法：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega%2Fkappa.png" alt="kappa"></p><p>在Kappa架构里只有一个数据路径要执行，而应用程序逻辑的实现只需要维护一个，而不是两个。借助适当的工具，为需要快速而准确地处理流数据的需求而构建，使得物联网，联网汽车，金融，风险管理，在线服务等领域设计和运行大数据应用变得更加简单。通过合适的工具，可以构建这样的流水线并为需要高容量和低延迟的大数据应用提供服务。</p><p>Kappa架构里流式应用通常需要处理多个阶段，任何实用的流分析系统都必须能够以数据流水线的形式适应各阶段的组合：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega%2Fpipeline.png" alt="pipeline"></p><p>对于数据管道，重要的是要考虑端到端的保证而不是每个组件的保证。例如，一个阶段保证exactly once语义而另一个阶段又不保证，这样是不行的。Pravega的目标是实现数据管道的设计和实现，并提供端到端的强一致保证。</p><p>Pravega - 为流世界重新设想的存储</p><p>Pravega引入了一个新的存储原语，即流，可以匹配无限数据的连续处理。在Pravega中，流是一个命名的，持久的，仅附加的和无限制的字节序列。有了这个原语，以及本文档中讨论的关键特性，Pravega是Flink等流处理引擎的最佳拍档。基于Pravega的关键特性，我们认为它将成为新一代面向流的中间件的基础存储原语。</p><h1 id="让我们来看看Pravega的主要特色。"><a href="#让我们来看看Pravega的主要特色。" class="headerlink" title="让我们来看看Pravega的主要特色。"></a>让我们来看看Pravega的主要特色。</h1><h2 id="Exactly-once语义"><a href="#Exactly-once语义" class="headerlink" title="Exactly once语义"></a>Exactly once语义</h2><p>恰好一次语义，我们的意思是Pravega确保数据不会重复，并且尽管失败也不会丢失任何事件。当然，这个声明附带了许多警告，就像任何其他承诺完全一次语义的系统一样，但是我们不要在这里深挖细节。一个重要的考虑因素是，一次性语义是Pravega的自然组成部分，是pravega从零开始设计时就考虑的首要目标之一。</p><p>为了实现一次性语义，Pravega Streams具有持久性，有序性，一致性和事务性。我们在下面的单独部分讨论持久性和事务性。</p><p>通过排序，我们的意思是Reader按照写入的顺序观测数据。在Pravega中，数据是与应用定义的路由密钥一起写入的，Pravega根据路由密钥提供顺序保证。两个具有相同密钥的数据总是被Reader按照它们写入的顺序读取。Pravega的排序保证允许数据被重放（例如，当应用程序崩溃时）并且重放的结果是相同的。</p><p>通过一致性，我们的意思是所有的reader都可以看到给定路由密钥的相同有序数据视图，即使失败也是如此。“大多数一致”的系统不足以构建准确的数据处理。</p><p>提供“至少一次”语义的系统可能会出现重复。在这样的系统中，数据生产者可能在某些情况下两次写入相同的数据。在Pravega中，写入是幂等的，由于重新连接而导致的重写不会造成数据重复。请注意，我们不保证来自源的数据是否已包含重复项。源数据对Pravega是不透明，pravega不会尝试删除源数据里的重复项。</p><p>然而，我们并没有将我们的注意力限制在写的完全一次语义上。我们还提供并正在积极致力于扩展功能，这些功能可实现数据管道的端到端的一次性。强一致性保证了Praveg的数据分析引擎的语义，如Flink实现了这种端到端的保证。</p>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>pravega handbook - 相关术语</title>
      <link href="/2018/09/16/pravega-terminology/"/>
      <url>/2018/09/16/pravega-terminology/</url>
      
        <content type="html"><![CDATA[<h3 id="以下是与Pravega相关的术语表："><a href="#以下是与Pravega相关的术语表：" class="headerlink" title="以下是与Pravega相关的术语表："></a>以下是与Pravega相关的术语表：</h3><table><thead><tr><th style="text-align:left">术语</th><th style="text-align:left">定义</th></tr></thead><tbody><tr><td style="text-align:left">Pravega</td><td style="text-align:left">Pravega是一个开源存储原语，为连续和无界数据实现流式存储,Pravega是Flink最好的拍档。</td></tr><tr><td style="text-align:left">流</td><td style="text-align:left">一种可持久化，弹性，append-only，无限制的字节序列，具有良好的性能和强一致性。</td></tr><tr><td style="text-align:left"></td><td style="text-align:left">流通过名称和范围来标识。</td></tr><tr><td style="text-align:left"></td><td style="text-align:left">流由一个或多个数据流段组成。</td></tr><tr><td style="text-align:left">流段</td><td style="text-align:left">流的碎片</td></tr><tr><td style="text-align:left"></td><td style="text-align:left">流中流段的数量会随着负载和缩放策略的变化而变化</td></tr><tr><td style="text-align:left"></td><td style="text-align:left">当没有发生缩放事件时，事件写入流中，具有相同路由密钥的事件存储在同一流段中，并且这些事件全部都是有序的. 当发生缩放事件时，与事件之后使用相同路由密钥K写入的事件相比，在缩放事件之前使用给定路由密钥K写入的流段数量发生了变化，给定路由密钥K写入的事件被存储在不同的流段中。流段可与Reader Groups相结合，流段的数量是并发读取流的最大的Reader数量。</td></tr><tr><td style="text-align:left">Scope</td><td style="text-align:left">流名称的命名空间。在一个scope内的流的名称必须是独一无二的。</td></tr><tr><td style="text-align:left">事件</td><td style="text-align:left">Stream中的字节集合。 事件与路由密钥相关联。</td></tr><tr><td style="text-align:left">路由密钥</td><td style="text-align:left">用于将消息路由到Reader的事件的属性。两个具有相同路由密钥的事件将以与它们所写的完全相同的顺序被Reader所读取</td></tr><tr><td style="text-align:left">Reader</td><td style="text-align:left">从一个或多个Streams读取数据的应用程序。</td></tr><tr><td style="text-align:left">Writer</td><td style="text-align:left">将数据写入一个或多个Streams的应用程序。</td></tr><tr><td style="text-align:left">Pravega Java客户端库</td><td style="text-align:left">应用程序用于与Pravega交互的 Java库</td></tr><tr><td style="text-align:left">ReaderGroup</td><td style="text-align:left">一个或多个Reader的命名集合，它们并发读取Stream。 Pravega为Reader分配了Stream  Segments，确保一个Stream Segments至少对应一个Reader，并且保证reader之间的平衡。</td></tr><tr><td style="text-align:left">位置</td><td style="text-align:left">Stream中的偏移量，代表了Reader的恢复点。如果Reader崩溃，可以从这个位置来恢复Reader，以便从这个故障点恢复对流的持续处理。</td></tr><tr><td style="text-align:left">1层存储</td><td style="text-align:left">短期，低延迟的数据存储，可确保写入Streams的数据的持久性。 第1层的当前实现使用   Apache Bookkeeper。 第1层存储保留了Pravega中最新的流。随着第1层中的数据老化，它将从第1 层移到第2层。</td></tr><tr><td style="text-align:left">2层存储</td><td style="text-align:left">Pravega存储的一部分，基于比较便宜的磁盘介质，如HDFS，DellEMC的Isilon或DellEMC的弹性云存储。</td></tr><tr><td style="text-align:left">PravegaServer</td><td style="text-align:left">Pravega的一个组件，其实现了Pravega数据面API，用于读取和写入Streams等操作。Pravega的数据面，也称为Segment Store，由一个或多个Pravega  Server实例组成。</td></tr><tr><td style="text-align:left">Segment Store</td><td style="text-align:left">PravegaServer的集合，它们聚合形成Pravega集群的数据面。</td></tr><tr><td style="text-align:left">Controller</td><td style="text-align:left">Pravega的一个组件，其实现了Pravega控制面API，用于创建和检索有关Streams的信息。 Pravega的控制面由Zookeeper协调的一个或多个Controller实例组成。</td></tr><tr><td style="text-align:left">Auto Scaling</td><td style="text-align:left">一个Pravega概念，基于缩放策略，它允许流中流段的数量随时间的推移而改变</td></tr><tr><td style="text-align:left">缩放策略</td><td style="text-align:left">一个流的配置项，它确定一个流中流段的数量如何随着时间的改变而改变 。  缩放策略有三种，Stream在任何给定时间都有其中一种。 - 固定数量的流段- 根据写入流的每秒字节数更改流段数 - 根据写入流的每秒的事件数更改流段数</td></tr><tr><td style="text-align:left">缩放事件</td><td style="text-align:left">缩放事件有两种类型：Scale-Up Event和Scale-Down Event。一个缩放事件触发自动缩放。放大事件是一种情况，其中负载的增加导致一个或多个流段被分割，从而增加流中的流段的数量。缩小事件是负载减少导致一个或多个流段合并的情况，从而减少流中的流段数。</td></tr><tr><td style="text-align:left">事务</td><td style="text-align:left">Stream写操作的集合，以原子的方式应用于Stream。事务中的所有字节要么都成功写入Stream，要么都没写入。</td></tr><tr><td style="text-align:left">状态同步器</td><td style="text-align:left">在Pravega之上构建的抽象，使用Pravega 段来支持复制状态的实现，以支持状态转换。状态同步器允许在多个进程之间共享一段数据，具有很强的一致性和乐观的并发性</td></tr><tr><td style="text-align:left">checkpoint</td><td style="text-align:left">一种事件，表示reader group内的所有reader都要持久化它们的状态。</td></tr><tr><td style="text-align:left">StreamCut</td><td style="text-align:left">StreamCut代表了流中的一致性位置。它包含一组针对单个流的段和偏移对，这些对表示给定时间点上的完整密钥空间。偏移总是指向事件边界，因此将没有偏移指向不完整事件。</td></tr></tbody></table><a id="more"></a> ]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Pravega handbook - 基本概念四 - 架构，小结</title>
      <link href="/2018/09/16/pravega-concepts-4/"/>
      <url>/2018/09/16/pravega-concepts-4/</url>
      
        <content type="html"><![CDATA[<h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><p>下图描述了Pravega的物理结构图：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega%2Fpravega.arch.new.png" alt="pravega.arch.new"></p><p>Pravega的架构符合软件定义存储（SDS）的语义，其控制面与数据面是分开的，Pravega数据面的集合统称为Segment Store。</p><p>controller实例组构成了Pravega的控制面，提供了创建、更新和删除Streams、检索有关Streams的信息、监控Pravega集群的健康状况、收集指标等的功能。为了实现高可用，通常有多个（建议至少3个）controller实例同时提供服务。 </p><p>Segment store实现Pravega的数据面。PravegaServers提供了在Streams中读写数据的API。Pravega中的数据存储由两层组成：第1层存储，提供短期、低延迟的数据存储，保证写入Streams。第2层存储提供数据的持久性、流数据的长期存储。Pravega使用 Apache Bookkeeper  实施第1层存储，并且支持使用HDFS，戴尔EMC的Isilon或戴尔EMC的弹性云存储（ECS）来实施第2层存储。第1层存储通常在Pravega集群内运行。第2层存储通常部署在Pravega集群之外。</p><p>分层存储对于提供快速访问Stream数据的组合非常重要，但也允许Streams存储大量数据。第1层存储会保留最近的Stream数据。随着第1层存储中的数据老化，它将进入第2层存储。</p><p>Pravega使用Apache Zookeeper作为Pravega集群中组件的协调机制。 </p><p>Pravega首先被构建为数据存储原语。Pravega经过精心设计，可充分利用软件定义存储，因此Pravega中存储的数据量仅受数据中心总存储容量的限制。就像您所期望的所有存储系统一样，一旦将数据写入Pravega，数据就会被持久存储。如果没有遇到连数据中心都被毁坏的灾难，Pravega中存储的数据永远不会丢失。</p><p>Pravega提供了一个用Java编写的客户端库，用于构建客户端应用程序，例如使用Flink作为分析应用程序。Pravega Java客户端库通过自我定制的TCP协议管理应用程序与Pravega之间的交互。</p><h2 id="概念小结"><a href="#概念小结" class="headerlink" title="概念小结"></a>概念小结</h2><p>Pravega中的概念总结如下：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega%2Fputting.all.together.new.png" alt="putting.all.together.new"></p><p>Pravega的客户端是writer和reader。writer将事件写入流中。Reader读取Stream中的事件。Reader被分组到ReaderGroups中以并行读取Stream。</p><p>Controller是服务端组件，用于管理Pravega的控制面。使用ControllerAPI创建、更新和列出流。</p><p>Pravega Server是一个服务端组件，用于实现读、写和其他数据面操作。</p><p>Streams是Pravega中的基本存储原语。Streams包含一组名为Events的数据元素。事件被writer附加到Stream的“尾部”。reader可以从Stream中的任何位置读取事件。</p><p>Stream被划分为一组Stream Segments。流中的stream segments数可以随时间变化。事件基于路由码写入到一个stream segment中。对于读取Stream的任何ReaderGroup，每个Stream Segment都分配给该ReaderGroup中的一个Reader。</p><p>每个流段都存储在Tier1和Tier2存储的组合中。Segment的尾部存储在Tier1中，提供低延迟的读写操作。Segment的其余部分存储在Tier2中，提供具有水平可扩展性和低成本的高吞吐量读取访问。</p><h2 id="关于分层存储的注意事项"><a href="#关于分层存储的注意事项" class="headerlink" title="关于分层存储的注意事项"></a>关于分层存储的注意事项</h2><p>为了实现Streams的有效实现，Pravega基于分层存储模型。事件存储于低延迟/高IOPS存储（第1层存储）和更高吞吐量存储（第2层存储）中。从API的角度来看，writer和reader对分层存储模型无需知晓。</p><p>Pravega基于仅附加日志数据结构。正如所观察到的，Log中实际上有三种数据访问机制：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega%2Fanatomy.of.log.png" alt="anatomy.of.log"></p><p>所有写入活动以及大部分读取活动都发生在日志的尾部。写入被附加到日志中，并且许多客户端希望以到达日志的速度读取数据。这两种数据访问机制主要是需要低延迟 - 写入器的低延迟写入和读者对发布数据的近实时访问。</p><p>并非所有Reader都从日志的尾部读取; 一些reader想要从日志中的任意位置开始阅读。这些读取称为追赶读取。传统上访问历史数据是通过批量分析作业完成的，通常使用HDFS和Map / Reduce。但是，对于新的流应用程序，您只需访问日志即可访问历史数据和当前数据。一种方法是将所有历史数据存储在SSD中，就像我们使用尾部数据一样，但这可能会成本较高并迫使客户通过删除历史数据来节省成本。Pravega提供了一种机制，允许客户在日志的历史部分使用经济高效，高度可扩展的高吞吐量存储，这样他们就不必决定何时删除历史数据。基本上，如果存储足够便宜，为什么不保留所有的历史数据？</p><p>第1层存储用于快速持久地写入Streams，并确保从Stream的尾部读取尽可能快。第1层存储基于开源Apache BookKeeper。虽然不是必需的，但通常我们假设第1层存储通常在更快的SSD或甚至非易失性RAM上实现。</p><p>第2层存储提供高度可扩展，高吞吐量的经济高效存储。我们希望此层通常部署在机械磁盘上。Pravega异步迁移事件从第1层到第2层，以反映Stream数据的不同访问模式。第2层存储基于HDFS模型。</p>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Pravega handbook - 基本概念三 - ReaderGroup，Transactions，State Synchronizers</title>
      <link href="/2018/09/16/pravega-concepts-3/"/>
      <url>/2018/09/16/pravega-concepts-3/</url>
      
        <content type="html"><![CDATA[<h2 id="ReaderGroup以及Checkpoint"><a href="#ReaderGroup以及Checkpoint" class="headerlink" title="ReaderGroup以及Checkpoint"></a>ReaderGroup以及Checkpoint</h2><p>Pravega为应用提供了在ReaderGroup上初始化Checkpoint的功能。使用Checkpoint的意图是通过使用一种特殊事件（检查点事件）来确保每个Reader能保存原来的使用状态，ReaderGroup中的每个Reader都可以创建一个“时间点”，借助这个“时间点“可以为reader提供状态的持久化以及保证这个状态一致性的功能。检查点完成后，应用可以通过恢复checkpoint(检查点)将ReaderGroup中的所有Reader恢复成这个检查点所代表的一致状态。</p><h2 id="Transactions（事务）"><a href="#Transactions（事务）" class="headerlink" title="Transactions（事务）"></a>Transactions（事务）</h2><p>Pravega支持事务。事务的想法是，Writer可以“批处理”一堆event并将它们作为一个处理单元提交到Stream中。这在某些场景是很有用的，例如，使用Pravega作为Flink作业的接收器。Flink作业可以不断产生一些数据的处理结果，并使用事务功能来持久化累积的处理结果。当在某个时间窗口（例如）的末尾时，Flink作业可以提交事务，因此使的处理结果可用于数据的下游处理，或者在出现错误的场景下，退出事务并且放弃整个处理结果。</p><p>Pravega的事务和类似方法（例如Kafka的生产者方式批处理）之间的关键区别在于能否持久化。当事件回到Writer时，添加到事务的事件是持久的。但是，在Writer提交Transaction之前，Reader不会看到事务中的事件。事务很像流; 事务与多个流段相关联。将事件发布到事务中时，事件本身将附加到事务的流段。假设Stream有5个段，当在该流上创建事务时，那么表示该事务也有5个段。当事件发布到事务中时，它被路由到相同编号的段，就像它被发布到Stream本身一样（如果事件将被放置在“真实”流中的段3中，那么它将出现在事务的段3中）。提交事务时，每个事务的段将自动附加到实际流中的相应段。如果流被中止，则事务其所有段以及发布到事务中的所有事件都将被从Pravega中删除。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega%2Ftrx.commit.new.png" alt="trx.commit.new"></p><p>在提交事务之前，发布到事务中的事件永远不会被Reader看到。有关使用事务的更多详细信息，请参阅  使用Pravega：事务。</p><h2 id="State-Synchronizers（状态同步器）"><a href="#State-Synchronizers（状态同步器）" class="headerlink" title="State Synchronizers（状态同步器）"></a>State Synchronizers（状态同步器）</h2><p>Pravega是一个流存储; 但是Pravega也提供了在分布式计算环境中作为协调器的功能（类似zookeeper,etcd）。Pravega的State Synchronizer功能属于后一种。</p><p>状态同步器使用Pravega Stream为在集群中运行的多个进程之间共享的状态提供同步机制，从而使得更加的容易构建分布式应用。使用State Synchronizer，开发人员可以使用Pravega来读取状态，并且借助一致性和乐观锁功能对这些共享状态进行更改。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega%2Fstate.synchronizer.png" alt="state.synchronizer"></p><p>状态同步器可用于维护和保存应用的配置副本，状态同步器还可用于存储一个数据或具有数千个不同键值对的映射数据。实际上，Pravega本身就在内部使用State Synchronizer来管理分布在整个网络中的ReaderGroups和Readers的状态。</p><p>应用开发人员以类似于创建Writer的方式在Stream上创建State Synchronizer。状态同步器保留共享状态的本地副本，以便为应用提供快速访问数据的功能。对共享状态的任何修改都将通过StateSynchronizer写入Stream，以便跟踪对共享状态的所有更改。每个应用实例都使用状态同步器通过将更新提取到共享状态并修改数据的本地副本来保持最新的更改。通过状态同步器对共享状态的追加样式进行维护，保持一致性，确保仅对共享状态的最新版本进行更新。</p><p>状态同步器还支持可以“压缩”，压缩和删除旧的状态更新，以便只有最新版本的状态保留在后备流中。此功能可帮助应用开发人员确保共享状态不会未经检查。</p><p>在存储的总数据大小比较小时，状态同步器对共享状态的更新可以工作得最好，允许将这些数据写为小的增量。与任何乐观并发系统一样，当许多进程都试图同时更新同一条数据时，状态同步器并不是最佳状态。</p><p>更多有关使用状态同步器的详细信息，请参阅  使用Pravega：状态同步器。</p>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Pravega handbook - 基本概念二 - Events, Segments, AutoScaling, Ordering</title>
      <link href="/2018/09/16/pravega-concepts-2/"/>
      <url>/2018/09/16/pravega-concepts-2/</url>
      
        <content type="html"><![CDATA[<h2 id="Stream-segments"><a href="#Stream-segments" class="headerlink" title="Stream segments"></a>Stream segments</h2><p>如下图，Stream由Stream Segments组成，而流段是流的分片或分区。</p><p><img src="http://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega%2Fstream.segment.png" alt="stream.segment"></p><h2 id="Event-event组成了stream-segment"><a href="#Event-event组成了stream-segment" class="headerlink" title="Event: event组成了stream segment"></a>Event: event组成了stream segment</h2><p>Stream Segment是事件（Event）的容器，event组成了流段，event存储在stream segment里，当事件被写入流时，会进行hash计算生成一个路由码，根据这个路由码，事件会被路由到一个流段中。Pravega使用一致性哈希算法将事件分配给流段。事件路由码被哈希后会生成一个“密钥空间”。然后密钥空间会被划分为多个分区，这些分区又对应于多个流段，采用一致性哈希算法可以确定将事件分配给哪个流段。</p><h2 id="AutoScaling：流段数量可变"><a href="#AutoScaling：流段数量可变" class="headerlink" title="AutoScaling：流段数量可变"></a>AutoScaling：流段数量可变</h2><p>当了流中的I/O负载上升或下降时，Stream中stream segments的数量会随着I/O负载增长或收缩 ，我们将此特性称之为AutoScaling。</p><p>参考下图，图中体现了路由码和时间之间的关系。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega%2Fsegment.split.merge.overtime.new.png" alt="segment.split.merge.overtime.new"></p><p>流在时间t0开始，具有可配置数量的段。如果写入流的数据速率不变，则段的数量不会改变。然而，在时间t1，系统注意到摄取率的增加并且选择将段1分成两部分。我们称之为Scale-up事件。在t1之前，具有哈希到密钥空间上部的路由密钥（值0.5-0.99）的事件将被放置在段1中，而散列到密钥空间下部的值（值0-0.49）将是放置在段0中。在t1之后，段1被分成段2和段3.段1被密封，它不再接受写入。此时，具有路由密钥0.7及以上的事件被写入段3，而在0.5和0.69之间的事件将被写入段2。  </p><p>我们还在时间t2看到另一个Scale-up事件，因为段0的路由键范围被分成段5和段4.此时，段0被封闭，因此它不接受进一步的写入。</p><p>覆盖密钥空间的连续范围的段也可以合并。在时间t3，段2和段5被合并到段6中以适应流上的负载的减少。</p><p>创建Stream时，会使用Scaling Policy配置Stream，该策略确定Stream如何响应其负载变化。目前有三种扩展策略：</p><ol><li><p>固定，流段的数量不随负载而变化</p></li><li><p>基于大小，当写入流的每秒数据字节数增量超过某个目标速率时，流段的数量增加。如果它低于某个流速时，会减少流段数。</p></li><li><p>基于事件的，与基于大小的扩展策略类似，不同之处在于它使用事件数而不是字节数。</p></li></ol><h2 id="Events-Stream-Segments-and-AutoScaling"><a href="#Events-Stream-Segments-and-AutoScaling" class="headerlink" title="Events, Stream Segments and AutoScaling"></a>Events, Stream Segments and AutoScaling</h2><p>我们之前提到当一个event被写入Stream的一个段中时，有时候需要AutoScaling，Stream Segments可以被看作是基于路由密钥和时间的事件的分组。在任何给定时间，在给定值的Routing Key内发布到Stream的event都将出现在同一个Stream Segment中。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega%2Frk.segment.new.png" alt="rk.segment.new"></p><p>还值得强调的是，事件仅写入活动的流段。密封的段不接受写入。在上图中，在“现在”时，只有流段3,6和4处于活动状态，并且这三个流段覆盖了整个密钥空间。  </p><h2 id="Stream-Segments-and-ReaderGroups"><a href="#Stream-Segments-and-ReaderGroups" class="headerlink" title="Stream Segments and ReaderGroups"></a>Stream Segments and ReaderGroups</h2><p>流段对于理解ReaderGroup的工作方式非常重要。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega%2Fsegment.readergroup.png" alt="segment.readergroup"></p><p>Pravega给ReaderGroup中的每个Reader分配了零个或多个Stream Segments用于读取数据。Pravega尝试平衡每个Reader分配的Stream Segments的数量。在上图中，Reader B1从2个Stream Segments中读取，而Reader Group中的每个其他读者只有1个Stream Segment可供读取。Pravega确保每个Stream Segment都会被配置给这个Stream的ReaderGroup中的一个Reader读取。当Reader被添加到ReaderGroup或Reader崩溃并从ReaderGroup中删除时，Pravega会重新分配流段，以便在Reader之间平衡流段。</p><p>流中的流段数确定了ReaderGroup中Reader的并行度的上限 - 流段越多，我们可以使用Stream的Reader的并行集合就越多。在上图中，Stream1有4个Stream Segments。这意味着最大的有效ReaderGroup将包含4个读者。上图中名为“B”的ReaderGroup并不是最优的。如果将另外一个Reader添加到ReaderGroup，则每个Reader将有1个Stream Segment进行处理，从而最大化读取并行性。但是，ReaderGroup中的读者数量增加到4以上，至少有一个读者不会被分配一个流段。</p><p>如果上图中的Stream1经历了Scale-Down事件，将Stream Segments的数量减少到3，那么所描绘的Reader Group B将具有理想数量的Readers。</p><p>借助AutoScaling特性，Pravega开发人员无需预先使用固定的流段个数配置其Streams - Pravega可以动态确定正确的流段个数。借助此特性，Pravega Streams可以自动增长或收缩以匹配数据输入的行为。任何Stream的大小仅受Pravega集群可用的总存储容量的限制; 如果您需要更大的流，只需向群集添加更多存储空间即可。</p><p>应用程序可以响应Stream中segments数量的变化，调整ReaderGroup中的Readers数量，以便在资源允许时保持最佳读取并行度。例如，在Flink应用程序中，这很有用，允许Flink增加或减少并行处理Stream的任务的数量，因为随着时间的推移会缩放事件。</p><h2 id="顺序保证Odering-Guarantees"><a href="#顺序保证Odering-Guarantees" class="headerlink" title="顺序保证Odering Guarantees"></a>顺序保证Odering Guarantees</h2><p>流包括可以随时间变化的一组段，在键区空间区域重叠的段具有已定义的顺序。</p><p>写入流的事件将写入单个段，并且相对于该段的事件具有顺序性，段内事件的存在和位置是强一致性的。</p><p>可以为Reader分配多个并行段（来自键空间的不同部分）。从多个段读取的Reader将交错段的事件，但每个段事件的顺序关联了一个段中。具体来说，如果s是一个片段，s的事件e~1和e~2使得e~1在e~2之前， Reader读取e~1和e~2，然后Reader将在e~2之前读取e~1。</p><p>这导致以下顺序保证：</p><ol><li><p>具有相同路由密钥的事件按其编写顺序被消费。</p></li><li><p>发送到特定段的具有不同路由键的事件将始终以相同的顺序被可见，即使Reader备份并重新读取它们也是如此。</p></li><li><p>如果某个事件已经被其Writer激活或已被Reader读取，则可以保证它将在所有后续读取的同一位置继续存在，直到被删除为止。</p></li><li><p>如果有多个读者读一个流并且他们都回到任何给定点，他们将永远不会看到关于该点的任何重新排序。（永远不会发生所选点之前读取的事件现在又再次出现的情况，反之亦然。）</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Pravega handbook - 基本概念一 - Streams, Events, Writers, Readers, ReaderGroups</title>
      <link href="/2018/09/16/pravega-concepts-1/"/>
      <url>/2018/09/16/pravega-concepts-1/</url>
      
        <content type="html"><![CDATA[<p>Pravega是一个开源的流式存储系统，为连续和无界数据实现流式存储。本章节将分为一个系列讲述Pravega的一些基本概念。</p><h2 id="Streams"><a href="#Streams" class="headerlink" title="Streams"></a>Streams</h2><p>Pravega将数据组织到Streams中。Stream是一种持久，有弹性，append-only，无限制的字节序列，具有良好的性能和强大的一致性。Pravega Stream这个语义与当前很流行的面向消息的中间件（如RabbitMQ或Apache Kafka）中的“topic”类似但更灵活。</p><p>Pravega Streams是基于append-only的日志数据结构。通过使用append-only日志，Pravega可以快速将数据提取到可持久化的存储中，也可以支持流处理，工作流引擎，面向事件的应用程序，比如Flink，发布/订阅消息，NoSQL数据库（如时间序列数据库）（TSDB）等。</p><p>当开发人员在Pravega中创建Stream时，他/她会先给Stream定义一个名称，例如“IoTSensorData”或“WebApplicationLog20170330”。Stream的名称可以帮助其他开发人员了解存储在Stream中的数据类别。值得注意的是，Pravega Stream名称是在一个Scope内组织的。Scope是一个字符串，用于数据分类，它会向开发人员传达某种含义，比如“FactoryMachines”或“HRWebsitelogs”。Scope用作Stream名称的命名空间 - 所有Stream名称在Scope中都是唯一的。因此，Stream通过其Stream名称和Scope的组合唯一标识。Scope可用于按租户（在多租户环境中），按组织中的部门，按地理位置或开发人员选择的任何其他分类来命名。</p><p>Pravega的Stream大小无限制 – Pravega本身不会对Stream中可以有多少event或Stream中存储的总字节数施加以任何的限制。Pravega的设计原则是支持从几台机器的小规模到整个数据中心的大规模。</p><p>为了处理Stream中潜在的大量数据，Pravega Streams分为Stream Segments。Segment是stream中的Shard或Partition。我们稍后将在本文档中详细介绍Stream Segments。Stream Segments是一个重要的概念，但在我们深入了解Stream Segments之前，我们还需要介绍一些其他概念。</p><p>应用程序（例如从IoT传感器读取的Java程序）将数据写入Stream的尾部（前端）。应用程序（如Flink）也可以从Stream中的任何位置读取数据。多个应用程序还可以并行读写相同的Stream。弹性且可扩展地支持大量的Streams，支持大规模的数据和应用程序是Pravega的核心设计思想。在详细介绍reader和writer时，我们将会介绍应用程序如何读取和写入Streams。</p><h2 id="Event"><a href="#Event" class="headerlink" title="Event"></a>Event</h2><p>Pravega的客户端API允许应用程序根据event在Pravega中读取和写入数据。event是Stream中的一组字节。event可以像来自IoT传感器的温度读数只包含少量的字节一样简单，该传感器由时间戳，度量标识符和值组成。event可以是与用户点击网站相关联的Web日志数据，也可以是表示为一组字节的任何事物。应用程序使用标准Java序列化器和反序列化器来理解event，允许它们使用类似的技术在Pravega中读取和写入对象，以便从文件中读取和写入对象。</p><p>每个event都有一个路由码。路由码允许Pravega和应用程序开发人员推断哪些event是关联的。路由码只是开发人员用于将类似event组合在一起的字符串。路由码通常是从event中自然发生的数据派生出来的，例如“customer-id”或“machine-id”，但它也可能是一些人工字符串。路由码也可以类似于日期（按时间将event组合在一起），或者路由码可能是IoT传感器ID（按机器对event进行分组）。路由码对于定义Pravega 保证的精确读写语义非常重要，稍后我们将详细介绍。</p><h2 id="Writer-Reader-and-ReaderGroups"><a href="#Writer-Reader-and-ReaderGroups" class="headerlink" title="Writer Reader and ReaderGroups"></a>Writer Reader and ReaderGroups</h2><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega%2Fproducer.consumer.client.new.png" alt="producer.consumer.client.new"></p><p>Pravega提供了一个用Java编写的客户端库，它为Writer和Reader应用程序实现了一个方便的API。Pravega Java客户端库封装了用于Pravega客户端和Pravega之间通信的协议。</p><p>Writer是一个创建event并将其写入Stream的应用。所有数据都可以通过append到Stream的尾部（前面）来写入。</p><p>Reader是一个从Stream读取event的应用。读者可以从Stream中的任何一点读取。一些Reader从Stream的尾部读取event。这些events将会尽可能快地被发送给这些reader。一些Reader从Stream的头部读取（称为追赶读取）。应用开发人员可以控制Reader开始读取的Stream中的位置。Pravega具有Position的概念，它表示Reader当前所在的Stream中的位置。位置对象可以用作恢复机制-应用保留Reader最后成功读取的位置，如果读失败了就从这个保存的位置从新开始读。</p><p>使用这种持久化Position对象的模式，Reader被组织成ReaderGroups。ReaderGroup是一个命名的Reader集合，它们一起并行读取给定Stream的事件。当通过Pravega数据平面API创建Reader时，开发人员包含它所属的ReaderGroup的名称。我们保证发布到Stream的每个事件都被发送到ReaderGroup中的一个Reader。ReaderGroup中可能有1个Reader，也可能有多个Reader。同一个Stream可以同时被不同的ReaderGroup读取。</p><p>您可以将ReaderGroup视为“复合阅读器”或“分布式阅读器”，它允许分布式应用程序并行读取和处理流数据，以便协调的ReaderGroup可以使用大量的流数据。在ReaderGroup中，并行处理流数据的Flink是ReaderGroup的一个很好的用例。</p><p>更多关于Pravega Reader和Writer如何使用的详细信息，请参阅  使用Pravega：基本Reader和Writer章节。</p><p>我们需要更详细地讨论Reader，ReaderGroup和Streams之间的关系以及Pravega提供的顺序保证。但是，我们需要先描述一下segment是什么。</p>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>pravega handbook - 入门</title>
      <link href="/2018/09/16/pravega-usage/"/>
      <url>/2018/09/16/pravega-usage/</url>
      
        <content type="html"><![CDATA[<h2 id="Pravega入门"><a href="#Pravega入门" class="headerlink" title="Pravega入门"></a>Pravega入门</h2><p>了解Pravega最好方法就是自己动手部署一个，然后跑一把Pravega示例。</p><p>部署Pravega其实很简单，以下是步骤：</p><p>Java版本：Java 8</p><h3 id="下载Pravega"><a href="#下载Pravega" class="headerlink" title="下载Pravega"></a>下载Pravega</h3><p>可以从 <a href="https://github.com/pravega/pravega/releases" target="_blank" rel="noopener">https://github.com/pravega/pravega/releases</a> 下载Pravega编译好的发行版。如果您想自己构建Pravega，也可以自己下载代码并运行:</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs undefined">$./gradlew distribution<br></code></pre></td></tr></table></figure><p>多细节可以查看Pravega <a href="https://github.com/pravega/pravega/blob/master/README.md" target="_blank" rel="noopener">README.md</a>。</p><p>解压:</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs undefined">$ tar xfvz pravega-0.1.0.tgz<br></code></pre></td></tr></table></figure><p>然后以standalone模式运行Pravega，这种模式会在本地机器上启动Pravega的所有组件。注意：这仅用于测试/演示目的，请勿在生产环境中使用！更多内容请 <a href="http://pravega.io/docs/latest/deployment/deployment/" target="_blank" rel="noopener">查看</a></p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs undefined">$ cd pravega-0.1.0<br>$ bin / pravega-standalone<br></code></pre></td></tr></table></figure><p>执行这个命令即可拉起一个本地化的pravega 集群， 这样就可以跑pravega。</p><h3 id="Pravega“Hello-World”示例"><a href="#Pravega“Hello-World”示例" class="headerlink" title="Pravega“Hello World”示例"></a>Pravega“Hello World”示例</h3><p>Pravega为示例维护一个单独的github库：https：//github.com/pravega/pravega-samples</p><p>Pravega依赖关系会自动从maven中心拉下来。注意：示例还可以使用本地编译的Pravega。有关这方面的更多信息，请参阅<a href="https://github.com/pravega/pravega/blob/master/README.md" target="_blank" rel="noopener">README.md</a>中maven发布的注释。</p><p>下载Pravega-Samples git库</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs undefined">$ git clone https://github.com/pravega/pravega-samples<br>$ cd pravega-samples<br></code></pre></td></tr></table></figure><p>生成示例程序</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs undefined">$ ./gradlew installDist<br></code></pre></td></tr></table></figure><p>运行示例“HelloWorldWriter”，将“hello world”消息作为事件写入Pravega stream。</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs undefined">$ cd pravega-samples/standalone-examples/build/install/pravega-standalone-examples<br>$ bin/helloWorldWriter<br></code></pre></td></tr></table></figure><p>HelloWorldWriter的输出</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs undefined">...<br>Writing message: &apos;hello world&apos; with routing-key: &apos;helloRoutingKey&apos; to stream &apos;examples / helloStream&apos;<br>...<br></code></pre></td></tr></table></figure><p>若想使用不同的参数运行HelloWorldWriter，更多信息请参阅pravegs-samples中的readme.md文件</p><p>运行示例“HelloWorldReader”</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs undefined">$ cd pravega-samples/standalone-examples/build/install/pravega-standalone-examples<br>$ bin/helloWorldReader<br></code></pre></td></tr></table></figure><p>示例HelloWorldReader的输出</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs undefined">...<br>Reading all the events from examples/helloStream<br>...<br>Read event &apos;hello world&apos;<br>No more events from examples/helloStream<br>...<br></code></pre></td></tr></table></figure><p>有关HelloWorldReader的更多详细信息，请参阅pravega-samples中的readme.md文件</p>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>pravega handbook - overview</title>
      <link href="/2018/09/15/pravega-overview/"/>
      <url>/2018/09/15/pravega-overview/</url>
      
        <content type="html"><![CDATA[<p>当前的大数据处理系统无论是Lamda架构还是Kappa架构都面临一个问题，即：“计算是原生的流计算，而存储却不是原生的流存储” 。</p><p>作为存储业界首屈一指的领导者，DELL EMC的存储专家们重新思考了这一基本的数据处理和存储规则，为这一场景重新设计了一种新的存储类型，即原生的流存储，命名为”Pravega”，在梵语里是“Good Speed”的意思。</p><p>Pravega是一种流数据存储系统，其具有可持久化，弹性，数据只追加，字节序列无限制，性能良好和强一致性的特点。并且根据Apache 2.0许可证开源，DELLEMC的存储专家们相信这一颠覆性的技术应该开源出来与开源社区一起拥有与推动，Pravega相应的介绍以及代码可以从pravega.io获得。</p><h2 id="主要特性"><a href="#主要特性" class="headerlink" title="主要特性"></a>主要特性</h2><ul><li><p>正好一次 – 不管是客户端、服务端还是网络出现了故障，Pravega都能确保每个事件都只被传递和处理正好一次（exactly-once）。</p></li><li><p>自动伸缩 – 不同于静态分区系统只有固定大小的存储空间，当数据采集速率发生变化时Pravega可以根据场景自动调整空间大小以自动适应数据规模的变化。</p></li><li><p>分布式计算原语 – Pravega具有和zookeeper一样的选主功能，支持进程间传递消息，支持数据存储，非常适用于分布式计算场景。</p></li><li><p>写入效率好 – 目前Pravega 的写入时延在毫秒级，还能无缝的扩展以支持数千个客户端的同时并发读写，是IOT和其他时延敏感型应用的理想选择。</p></li><li><p>无限保存 – 数据永远都在流中采集、处理和保存，对于实时数据和历史数据使用一样的处理范式。</p></li><li><p>高效存储 – Pravega构建了一种数据处理通道，支持将批处理，实时处理以及其他应用比如数据检索，都构建在一个数据处理通道内，无需为每个处理模式都保留一份数据副本。</p></li><li><p>持久化 – Pravega保证无需在高性能，可持久化和一致性之间做权衡，在客户端确认写入操作已完成之前，Pravega将一直存留并保护数据。</p></li><li><p>支持事务 - 开发人员使用Pravega事务来确保一组事件原子性的写入流中。</p></li></ul><a id="more"></a> <h2 id="Pravega的逻辑架构"><a href="#Pravega的逻辑架构" class="headerlink" title="Pravega的逻辑架构"></a>Pravega的逻辑架构</h2><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/pravega_overview_1.jpg" alt="Pravega的逻辑架构"></p><p>计算与存储解耦，计算包括 Flink,Spark,一个自我开发的分布式检索系统。<br>存储层实现了一个流抽象层，一级高性能存储采用Bookeeper，二级冷数据存储<br>可以支持开源的HDFS，CEPH，GlusterFS，Swift，云存储等。与Kafka对比，最大区别在于Pravega是专门为流数据而生的原生的流存储。</p>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Hello World</title>
      <link href="/2018/09/13/hello-world/"/>
      <url>/2018/09/13/hello-world/</url>
      
        <content type="html"><![CDATA[<h2 id="Hello-World"><a href="#Hello-World" class="headerlink" title="Hello World"></a>Hello World</h2><p><strong>启动新的技术网站:[<a href="http://www.changping.me]">www.changping.me]</a>, [<a href="http://www.yuncunchu.org]以及微信公众号上的文章将迁移到本站。" target="_blank" rel="noopener">www.yuncunchu.org]以及微信公众号上的文章将迁移到本站。</a></strong></p>]]></content>
      
      
      
    </entry>
    
  
  
    
    <entry>
      <title></title>
      <link href="/404.html"/>
      <url>/404.html</url>
      
        <content type="html"><![CDATA[<!DOCTYPE HTML><html><head>  <meta http-equiv="content-type" content="text/html;charset=utf-8;">  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">  <meta name="robots" content="all">  <meta name="robots" content="index,follow">  <link rel="stylesheet" type="text/css" href="https://qzone.qq.com/gy/404/style/404style.css"></head><body>  <script type="text/plain" src="http://www.qq.com/404/search_children.js" charset="utf-8" homepageurl="/" homepagename="�ص��ҵ���ҳ">  </script>  <script src="https://qzone.qq.com/gy/404/data.js" charset="utf-8"></script>  <script src="https://qzone.qq.com/gy/404/page.js" charset="utf-8"></script></body></html>]]></content>
      
    </entry>
    
    <entry>
      <title>about</title>
      <link href="/about/index.html"/>
      <url>/about/index.html</url>
      
        <content type="html"><![CDATA[<h2 id="关于作者"><a href="#关于作者" class="headerlink" title="关于作者"></a>关于作者</h2><ul><li>毕业于中国科学技术大学，获硕士研究生学历学位</li><li>主要工作背景：分布式计算中间件、分布式存储中间件以及Linux内核相关工作</li><li>曾就职于Marvell、AMD等，现就职于EMC，资深首席工程师，主要负责分布式产品的架构设计、编码及产品交付</li></ul><h2 id="联系方式"><a href="#联系方式" class="headerlink" title="联系方式"></a>联系方式</h2><ul><li>Email : <a href="mailto:wu@changping.me" target="_blank" rel="noopener">wu@changping.me</a></li><li>Blog : <a href="https://www.changping.me">https://www.changping.me</a></li><li>Github : <a href="https://github.com/wuchangping" target="_blank" rel="noopener">https://github.com/wuchangping</a></li><li>微信公众号 : 分布式系统架构设计师</li></ul><h2 id="网站声明"><a href="#网站声明" class="headerlink" title="网站声明"></a>网站声明</h2><p>文章内容仅为作者愚见，与任何组织机构无关，如有错误及不足之处欢迎发信批评指正。</p><h2 id="版权声明"><a href="#版权声明" class="headerlink" title="版权声明"></a>版权声明</h2><p>非商业用途在注明作者及本网站前提下无需授权即可转载。</p><h2 id="免责声明"><a href="#免责声明" class="headerlink" title="免责声明"></a>免责声明</h2><p>文章坚持原创，且仅供技术交流及研究使用，如有不小心侵犯您的版权， 请联系：<a href="mailto:wu@changping.me" target="_blank" rel="noopener">wu@changping.me</a>，会尽快删除。</p><p>–</p>]]></content>
      
    </entry>
    
    <entry>
      <title>categories</title>
      <link href="/categories/index.html"/>
      <url>/categories/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    <entry>
      <title>tags</title>
      <link href="/tags/index.html"/>
      <url>/tags/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    <entry>
      <title>archives</title>
      <link href="/archives/index.html"/>
      <url>/archives/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
  
</search>
