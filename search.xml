<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>深度学习 - 第8篇 - 国产Ai芯片CUDA生态兼容的一些思考</title>
      <link href="/2024/07/27/ai_8/"/>
      <url>/2024/07/27/ai_8/</url>
      
        <content type="html"><![CDATA[<p>​                </p><h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a><font color="#FF8C00">1. 概述</font></h2><p>在AI芯片领域，当前阶段NVIDIA基本上可以说是处于绝对的垄断地位，除了自身产品确实够强悍之外，最厉害的地方是还能借助CUDA生态令无数的开发者、研究人员都在为他家免费打工，从而将其市值推上3万亿美元。国内AI芯片厂家只要能达到其1%的市值就是300多亿美元即2000多亿人民币，这样作为一家芯片公司相信就已经很成功了，而且当前老美对国内的各种政策利好，在这样的大势下，只要走对路线相信还是能成功的。</p><p>国内各家AI芯片厂家苦CUDA久已，要么自个实力足够强大试图重建自家的生态，要么试图全兼容或半兼容CUDA生态，但是实际上效果都不大好，用户抱怨难用的不少，急眼了来一句：“咱们能不能好好学CUDA？”。问题即是机会，国产化Ai芯片生态的构建也是个持久战问题，因此本文对国产化Ai芯片生态做了一些思考，另外存在决定意识，我所讲的都是我一家之言，不一定看的全、看的对。</p><h2 id="2-CUDA生态分析"><a href="#2-CUDA生态分析" class="headerlink" title="2. CUDA生态分析"></a><font color="#FF8C00">2. CUDA生态分析</font></h2><p>伟人告诉我们做事情之前要先调查研究，如下图所示，我们把CUDA的生态一层层从上往下拆解开来进行分析。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/aitraining/8/image-1.png" alt="image-1"></p><h3 id="2-1-应用层"><a href="#2-1-应用层" class="headerlink" title="2.1 应用层"></a>2.1 应用层</h3><p>首先是应用层，这一层是各种模型应用，是NVIDIA公司外的CUDA生态，是无数深度学习研究人员、开发者用户、客户围绕CUDA自发构建成的生态，这也是CUDA最牢靠最大的护城河，人员无数，这些应用也是离价值最近的最直接的生产力。</p><p>下面举例说明一些实际应用场景[2]：</p><ol><li><p><strong>大模型</strong>：</p><ul><li><strong>自然语言处理</strong>：如GPT-3、BERT等，用于文本生成、翻译、摘要、情感分析等。</li><li><strong>图像识别</strong>：如ResNet、Inception等，用于图像分类、目标检测、图像分割等。</li></ul></li><li><p><strong>AIGC</strong>：</p><ul><li><strong>文本生成</strong>：自动生成新闻文章、小说、诗歌等。</li><li><strong>音乐创作</strong>：AI作曲家可以创作独特的音乐旋律和和声。</li><li><strong>艺术创作</strong>：AI艺术家可以创作绘画、雕塑等艺术作品。</li></ul></li><li><p><strong>多模态</strong>：</p><ul><li><strong>视觉问答</strong>：结合视觉和语言信息，回答关于图像内容的问题。</li><li><strong>多模态情感分析</strong>：分析文本、语音和面部表情等多个模态的情感状态。</li></ul></li><li><p><strong>文生图</strong>：</p><ul><li><strong>图像生成</strong>：根据文本描述生成相应的图像，如“一个阳光明媚的海滩”。</li><li><strong>漫画生成</strong>：根据剧本自动生成漫画页面。</li></ul></li><li><p><strong>图生图</strong>：</p><ul><li><strong>风格迁移</strong>：将一种艺术风格应用到另一张图片上，如将梵高的画风应用到现代照片上。</li><li><strong>图像编辑</strong>：通过图像到图像的转换，实现图像的自动编辑和美化。</li></ul></li><li><p><strong>文生视频</strong>：</p><ul><li><strong>视频生成</strong>：根据文本描述生成视频内容，如“一个在森林中奔跑的鹿”。</li><li><strong>视频摘要</strong>：自动从长视频中提取关键片段，生成简短的视频摘要。</li></ul></li></ol><p>具体应用举例[2]：</p><ul><li><p><strong>教育</strong>：</p><ul><li>使用AIGC生成个性化学习材料和练习题。</li><li>利用多模态技术辅助语言学习，通过图像和声音增强记忆。</li></ul></li><li><p><strong>娱乐</strong>：</p><ul><li>使用文生图技术生成电影海报或游戏角色设计。</li><li>利用图生图技术进行角色形象的自动设计和风格转换。</li></ul></li><li><p><strong>医疗</strong>：</p><ul><li>利用大模型进行疾病诊断和预测，辅助医生做出更准确的判断。</li><li>使用多模态技术结合患者的医疗影像和临床数据进行综合分析。</li></ul></li><li><p><strong>电商</strong>：</p><ul><li>通过文生图技术生成商品的个性化展示图。</li><li>使用图生图技术优化商品图片，提升视觉吸引力。</li></ul></li><li><p><strong>新闻媒体</strong>：</p><ul><li>利用AIGC自动生成新闻报道和文章。</li><li>使用文生视频技术生成新闻摘要视频，快速传达信息。</li></ul></li><li><p><strong>广告</strong>：</p><ul><li>利用文生图技术生成广告创意和视觉素材。</li><li>使用图生图技术优化广告图像，提升广告效果。</li></ul></li></ul><p>这些技术的应用正在不断扩展，未来可能会有更多创新和突破，而且这些应用绝大多数都是基于CUDA的基础设施进行开发的，无数的应用，无数的开发人员构建了NVIDIA CUDA 最牢靠的护城河。</p><h3 id="2-2-框架层"><a href="#2-2-框架层" class="headerlink" title="2.2 框架层"></a>2.2 框架层</h3><p>这一层是深度学习框架，也是NVIDIA公司之外的CUDA生态，到这层就属于基础设施软件层了，这些工具主要与深度学习的训练、微调与推理框架相关，下面是它们各自的用途和特点[2]：</p><ol><li><p><strong>DeepSpeed</strong>: 这是一个由微软推出的深度学习优化库，旨在帮助研究人员和开发人员加速大规模深度学习训练。DeepSpeed 提供了多种优化技术，如模型并行、梯度累积、混合精度训练等；</p></li><li><p><strong>Megatron-LM</strong>: 这是NVIDIA推出的一个用于训练大型语言模型的库。它利用了NVIDIA的GPU和NVLink技术来加速多GPU训练，使得训练非常大的语言模型成为可能；</p></li><li><p><strong>Flash-Attention</strong>: 这是一个用于提高注意力机制效率的库，特别是在Transformer模型中。Flash-Attention 通过优化内存访问和计算流程，显著提高了注意力层的计算速度与性能；</p></li><li><p><strong>Transformer Engine</strong>: 这是一个用于构建和训练Transformer模型的框架，它提供了一套丰富的API来简化模型的构建、训练和部署过程；</p></li><li><p><strong>Apex</strong>: 这是NVIDIA推出的一个PyTorch扩展，它提供了多种用于提升PyTorch性能的工具，包括混合精度训练、分布式训练等；</p></li><li><p><strong>PyTorch</strong>: 这是一个广泛使用的开源机器学习库，特别适合于深度学习和自然语言处理。PyTorch以其易用性、灵活性和动态计算图而闻名；</p></li><li><p><strong>VLLM</strong>: vLLM是一个由加州大学伯克利分校的LMSYS组织开源的大型语言模型（LLM）高速推理框架。它旨在提供快速、易用且成本效益高的LLM服务，特别是在实时场景下，可以显著提升语言模型服务的吞吐量和内存使用效率；</p></li><li><p><strong>TensorRT-LLM</strong>: 这可能是一个结合了NVIDIA的TensorRT优化库和大型语言模型（LLM）的框架。TensorRT是一个深度学习推理引擎，它可以将训练好的模型优化为高效的推理格式，以加速在生产环境中的模型部署。如果TensorRT-LLM存在，它可能是为了在NVIDIA硬件上优化和加速大型语言模型的推理；</p></li><li><p><strong>Hugging Face:</strong> 是一个专注于自然语言处理（NLP）的开源社区和公司，提供了一系列的工具和库，以促进机器学习模型的共享和应用。包括TGI, transformers, accelerate, diffusers, peft等。</p></li></ol><p>除了目前以上这些比较主流的工具之外，而且随着技术的发展，新的工具和库可能会不断出现。这一层构成了NVIDIA CUDA 的框架与开发库护城河。</p><h3 id="2-3-CUDA-加速库与编译器层"><a href="#2-3-CUDA-加速库与编译器层" class="headerlink" title="2.3 CUDA 加速库与编译器层"></a>2.3 CUDA 加速库与编译器层</h3><p>CUDA加速库以及编译器再加上周边的辅助工具，构建成了整个NVIDIA CUDA Toolkit系统。CUDA Toolkit是NVIDIA自建闭源生态，是一个全面的开发环境，用于创建高性能、GPU加速的程序，以下是CUDA Toolkit的主要特点和功能[2]：</p><ol><li><strong>开发环境</strong>：<ul><li>CUDA Toolkit提供了一个完整的开发环境，支持在GPU加速的嵌入式系统、桌面工作站、企业数据中心、云平台和超级计算机上开发、优化和部署应用程序；</li></ul></li><li><strong>GPU加速库</strong>：<ul><li>包括cuBLAS（基本线性代数子程序的实现）、cuFFT（快速傅里叶变换库）、cuRAND（随机数生成库）、cuSOLVER（线性代数求解库）、cuSPARSE（稀疏矩阵处理库）等，这些库可以显著加速科学计算和数据处理任务；</li></ul></li><li><strong>编译器和运行时库</strong>：<ul><li>包含NVCC编译器，用于编译CUDA程序，以及运行时库，用于在不同平台上部署应用程序；</li></ul></li><li><strong>调试和优化工具</strong>：<ul><li>提供了NVIDIA Nsight Compute和NVIDIA Nsight Systems等开发工具，帮助开发者优化和提高应用程序的性能；</li></ul></li><li><strong>多GPU配置</strong>：<ul><li>内置功能支持在多GPU配置中分布计算，使得应用程序可以从单GPU工作站扩展到拥有数千GPU的云安装；</li></ul></li><li><strong>新架构支持</strong>：<ul><li>CUDA 12引入了对NVIDIA Hopper和Ada Lovelace架构的支持，包括下一代Tensor Cores、Transformer Engine、NVLink Switch、混合精度模式、第二代多实例GPU（MIG）等；</li></ul></li><li><strong>异构内存管理（HMM）</strong>：<ul><li>支持在主机内存和加速器设备之间无缝共享数据，而无需由CUDA分配或管理内存，简化了应用程序的移植和使用外部框架；</li></ul></li><li><strong>安全功能</strong>：<ul><li>支持Hopper GPU的机密计算（Confidential Computing），提供加密和身份验证功能，保护用户代码和数据；</li></ul></li><li><strong>文档和培训</strong>：<ul><li>提供详细的技术文档和培训课程，帮助开发者更好地理解和使用CUDA Toolkit。</li></ul></li></ol><p>通过这些功能，CUDA Toolkit为开发者提供了强大的工具和资源，以实现高效的GPU编程和加速计算。CUDA TOOLKIT 构成了NVIDIA GPU基础软件护城河。</p><h3 id="2-4-NVIDIA云原生软件栈"><a href="#2-4-NVIDIA云原生软件栈" class="headerlink" title="2.4 NVIDIA云原生软件栈"></a>2.4 NVIDIA云原生软件栈</h3><p>NVIDIA Cloud Native Stack 是一套软件集合，用于在 NVIDIA GPU 上运行云原生工作负载。它基于 Ubuntu、Kubernetes、Helm 以及 NVIDIA GPU 和网络运营商构建而成。以下是其主要特点和组件[2]：</p><ol><li><p><strong>平台支持</strong>：适用于各种用例和行业的应用开发和部署，包括高性能计算、对话式 AI、推荐系统等 ；</p></li><li><p><strong>灵活部署</strong>：可在裸金属服务器、Kubernetes 或虚拟化环境中运行，支持本地、云端和边缘部署，以最大化利用 GPU 资源并提高应用的便携性和可扩展性 ；</p></li><li><p><strong>AI 软件套件</strong>：NVIDIA AI Enterprise 是一个端到端的云原生 AI 软件套件，助力组织提高运营效率并解决新问题 ；</p></li><li><p><strong>容器化</strong>：NGC 目录托管了经过 NVIDIA 优化的 AI 和数据科学软件容器，简化了部署流程 ；</p></li><li><p><strong>预训练模型</strong>：NGC 目录提供预训练的 GPU 优化模型，适用于多种 AI 任务，可以按原样使用或重新训练 ；</p></li><li><p><strong>Helm 部署</strong>：实现 Kubernetes 集群上的软件部署自动化，NGC 目录提供支持 Kubernetes 的 Helm 部署 ；</p></li><li><p><strong>NVIDIA GPU Operator</strong>：一个由 NVIDIA 驱动的套件，包含容器运行时、设备插件和管理软件；</p></li><li><p><strong>Ansible Playbooks</strong>：提供自动化安装、升级、验证和卸载 NVIDIA Cloud Native Stack 的 Ansible 剧本 ；</p></li><li><p><strong>监控和存储</strong>：支持在 Cloud Native Stack 上部署 Prometheus/Grafana 和 Elastic Logging 栈进行监控，以及 Local Path 和 NFS 存储提供程序 ；</p></li><li><p><strong>版本控制</strong>：Cloud Native Stack 支持生命周期管理，允许用户升级至下一个可用版本 ；</p></li><li><p><strong>组件矩阵</strong>：详细列出了不同版本和发行日期的 Cloud Native Stack 组件，包括操作系统、容器运行时、Kubernetes、Helm、NVIDIA GPU 运营商和网络运营商等 ；</p></li><li><p><strong>NVIDIA LaunchPad</strong>：提供预先配置的环境，以便用户快速开始使用 。</p></li></ol><p>NVIDIA Cloud Native Stack 通过提供这些工具和特性，使得开发者和企业能够更容易地在云原生环境中利用 NVIDIA GPU 的强大计算能力。这一层主要还是K8S生态，工具都是开源的相对来说比较的开放，国内芯片厂家只要老老实实的参考nvidia cloud native stack 进行开发即可。</p><h2 id="3-破局策略"><a href="#3-破局策略" class="headerlink" title="3.破局策略"></a><font color="#FF8C00">3.破局策略</font></h2><h3 id="3-1-统一认识"><a href="#3-1-统一认识" class="headerlink" title="3.1 统一认识"></a>3.1 统一认识</h3><p>国产AI芯片生态上要能破局首先是要统一认识，认识是行动的指导。NVIDIA的CUDA生态链是非常的强大，但是通过以上分析可知真正的强大在应用层有无数的开发人员、研究人员在开发应用在做研究，框架层有很多的厂家在基于CUDA构建基础设施。如果剥离了这些，NVIDIA本身也只是一家普通的AI芯片公司，要破局并非不可能，因此<strong>国产AI芯片厂家要达成的认识的第一点</strong>是：<strong>国产AI芯片生态破局点在于CUDA TOOLKIT，而不是应用层与框架层。</strong></p><p>问题即是机会，事物的内部矛盾是事物发展的根本动力。首先是要解放思想承认现实，实事求是的从客观实际出发，即不走速胜论路线也不走完全不可能路线，具体问题具体分析。从以用户为中心出发，而不是以技术为中心出发是国产AI芯片生态破局的根本之道。从用户出发，也是从人性出发，违背人性的技术走不远，既然从人性出发那么就需要考虑以下三不原则：</p><p>1）不要让用户学，学CPU编程、学CUDA编程已经学的够多的了，再学真学不动；</p><p>2）不要让用户想，无脑使用最好；</p><p>3）不要让用户烦，能简单点就简单点最好；</p><p>海能够纳百川是因为它足够的低，放低用户的开发、使用门槛，用户自然而然汇聚而来，当做到使用门槛比NVIDIA的 CUDA 门槛还要低时，新的生态自然而然形成。<strong>这是国产AI芯片厂家要达成的认识的第二点。</strong></p><h3 id="3-2-生态策略"><a href="#3-2-生态策略" class="headerlink" title="3.2 生态策略"></a>3.2 生态策略</h3><p>下图是目前国内各AI芯片厂家的生态破局策略图，有完全自建生态的，有魔改框架组件的，有转换框架组件的，有基于开源开发的，下面的章节里我们一层层的解读这些策略。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/aitraining/8/image-2.png" alt="image-2"></p><h4 id="3-2-1-应用层与框架层"><a href="#3-2-1-应用层与框架层" class="headerlink" title="3.2.1 应用层与框架层"></a>3.2.1 应用层与框架层</h4><p>通过第2章的分析可知，应用层与框架层是全世界的无数开发人员、无数研究人员以及无数厂家围绕CUDA TOOLKIT 构建的生态，没有一家厂家甚至国家有能力重构这样的生态，国内想重构这个应用生态的各厂内项目基本上都已经凉凉，自己去提供开发框架试图掌握上层应用生态的也基本半死不活。</p><p>对与应用层与框架层的破局策略是不要试图去改变无数开发者，去改变无数研究人员的使用习惯，更不可能让一些厂家转而使用自己的框架，而且人家又不是傻子，在巨大的利益面前，真没几人会愿意替别人做嫁衣，任何试图改变开发者、研究人员、各个应用厂家的行为都是属于主观不符合客观。</p><p>那么对于应用层与框架层如何破局应对？ 建议是<strong>“打不过就加入”</strong>，对于存量的应用与框架，直接拉取无需做任何修改或者最多只改几行代码即可使用，遵循<strong>“不要让用户想，不要让用户烦，不要让用户学”</strong>，这样的三不原则。有些技术人员一听这个可能就会来喊一句：“这怎么可能？” ，其实只要对底层技术抽象的足够好是完全可以做到的。</p><h4 id="3-2-2-CUDA-TOOLKIT-层"><a href="#3-2-2-CUDA-TOOLKIT-层" class="headerlink" title="3.2.2 CUDA TOOLKIT 层"></a>3.2.2 CUDA TOOLKIT 层</h4><p>CUDA TOOLKIT 层是被NVIDIA牢牢掌控的一层，这一层看上去是NVIDIA最为强大的护城河，但是恰恰相反，CUDA TOOLKIT 反而是NVIDIA最为薄弱的护城河，集中一家公司的力量在一定条件下就可以完成。对于这一层目前国内AI芯片厂家有以下几个破局路线:</p><p>1，完全自建类似CUDA的生态的，构建私有的xxDNN,xxFFT,xxBLAS,xxFFT等，再自我构建开源的框架层，再继续往上构建应用开发层，算法层等，投入巨大但是效果很一般。CUDA之所以能成为生态那是一开始根本就没人看好，也没有对手，属于天时、地利、人和三合一自己长出来的。目前在国内想重建CUDA生态也要看看其他厂家愿不愿意合作，国内各家AI芯片厂都在试图构建自己的生态，对同类生态资源多多少少都有挤占，谁也不想替别人做嫁衣，而且也要面对NVIDIA用户的粘性问题，所以这一条路线基本上没太大希望，具体例子可以参考某500强大厂；</p><p>2，魔改开源框架组件的，国内ai芯片厂家走这一类路线的也不少，自己开发类似CUDA toolkit这样的工具，然后魔改开源框架组件以及各种性能加速库。这一策略如果是应用在推理芯片路线，一定程度上还是可以的，推理的复杂度远远低于训练与微调，算子只要前向算子，只要集中力量自我开发一个推理框架再遍历支持几百个模型，在有限的资源下也是没问题的。但是如果客户想用自家的推理框架而不用厂家提供的，那么新的推理框架的适配工作量还是不少的。</p><p>魔改开源组件的好处是，往上是基本上可以不动应用层，不改变应用层的用户习惯，往下是内部的各种加速库，编译器甚至芯片都可以自己玩自己的，不太需要考虑协同设计，反正都是内部问题，都能跑的起来保证项目交付。缺点是每一个版本都难以迁移，不同代际芯片的软件栈难以无缝迁移，各种版本不兼容，然后算子库也都需要重写，比如要将flash-attention, deepspeed, transformerEngine,apex, pytorch等这些基础框架在XPU上支持起来，每一代的芯片都有海量的算子要重写，对公司资源的消耗是海量的，人力投入巨大，重复的海量工作严重延误芯片推向市场的时间，所以这一条路线有点像大块头无脑秀肌肉可能适合推理芯片但是真不适合训练芯片。</p><p>3，将CUDA源代码无缝翻译为XPU代码，这一路线国内AI芯片厂家也有，看上去是比较难而正确的路线，不改变应用层，也不改变框架层，同过转换与编译工具将框架层里的cuda源代码翻译为XPU代码进而编译出XPU可执行文件。这一条策略做到了<strong>“将复杂留给自己将简单留给用户”，</strong>对用户最为友好真正做到了遵循<strong>“不要让用户想，不要让用户烦，不要让用户学”</strong>这样的三不原则。但是缺点是对AI芯片厂家要求较高，需要加速库，编译器，硬件三者协同设计，并且如果本身芯片的演进路线与NVIDIA硬件不同，那么实现与兼容起来会比较的难受。所以建议的策略是先兼容已有的、普遍的、海量存量，再以特殊情况的策略对待增量，增量毕竟对公司的资源消耗会小点，先保证存量可用，快速推向市场抢占先机，再空出资源腾出手解决增量问题，即<strong>“先立再破”</strong>。这一策略需要顶层统一思想路线，软硬件协同设计。</p><p>这一策略具体实现方案举例如下：</p><p>1）应用层</p><p>应用层尽量做到不改任何代码用户直接拉取即可使用，实在不行最多一句<code>import transfer_to_xpu</code>。</p><p>2）框架层</p><p>框架层采用monkey patching 策略完成cuda代码到xpu代码的转换，比如pytorch,megatron_lm, deepspeed, vllm, accelerate, transformers等尽量做到直接拉取即可使用，实在不行即提供transfer_to_xpu接口，供用户 <code>import transfer_to_xpu</code>完成调用。</p><p>3）算子层</p><p>算子层可以视情况提供将CUDA源代码直接编译为XPU二进制的编译工具，也可以提供对CUDA算子代码进行关键词替换或宏替换工具。</p><p>3）编程模型</p><p>遵循SISD, SIMT的编程思想，不要试图改变开发者用户的编程习惯，全面参考CUDA的线程编程模型，内存编程模型，IO编程模型以及异构执行编程模型。</p><p>4）编译器层</p><p>从人性懒惰出发，遵循SISD, SIMT的编程思想，将SISD, SIMT 代码在编译器层映射为SIMD 代码，从而提升不同代际产品算子的可移植性以及减少算子的编程学习成本。</p><p>5）硬件层</p><p>软硬件协同设计，启用SIMT+SIMD 架构支持编译器遵循SISD,SIMT的编程思想。</p><h4 id="3-2-3-GPU云原生工具"><a href="#3-2-3-GPU云原生工具" class="headerlink" title="3.2.3 GPU云原生工具"></a>3.2.3 GPU云原生工具</h4><p>这一层主要是K8S+GPU的生态，而且工具基本上也是开源的，只要遵循<strong>“不改变用户使用习惯”</strong>的原则，系统梳理全面复制即可完成GPU云原生生态兼容。</p><h2 id="4-小结"><a href="#4-小结" class="headerlink" title="4. 小结"></a><font color="#FF8C00">4. 小结</font></h2><p>“让我痛苦的，必将使我强大！”，“克服自身现有的问题，才是成长最快的方式！”，这两句话用在国产化AI芯片生态兼容上也是合适的。”路虽远行则将至，事虽难做则必成，漫漫长路必见曙光！”，AI芯片关系到国家的竞争力，也与诸位一起共勉为国争光。</p><p>日拱一卒，功不唐捐，分享是最好的学习，与其跟随不如创新，希望这个知识点对大家有用。另作者能力与认知都有限，”我讲的，可能都是错的“，欢迎大家拍砖留念。</p><h2 id="5-作者简介"><a href="#5-作者简介" class="headerlink" title="5. 作者简介"></a><font color="#FF8C00">5. 作者简介</font></h2><p>常平，为学，闻道，践行。</p><h2 id="6-参考资料"><a href="#6-参考资料" class="headerlink" title="6. 参考资料"></a><font color="#FF8C00">6. 参考资料</font></h2><p>[1] <a href="https://www.changping.me">https://www.changping.me</a></p><p>[2] <a href="https://kimi.moonshot.cn" target="_blank" rel="noopener">https://kimi.moonshot.cn</a> 生成</p><h2 id="7-版权申明"><a href="#7-版权申明" class="headerlink" title="7. 版权申明"></a><font color="#FF8C00">7. 版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>深度学习 - 第7篇 - huggingface格式大模型强转为megatron格式的掉坑点</title>
      <link href="/2024/05/23/ai_7/"/>
      <url>/2024/05/23/ai_7/</url>
      
        <content type="html"><![CDATA[<p>​                </p><h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a><font color="#FF8C00">1. 概述</font></h2><p>对大模型进行张量并行或流水并行切分是个比较麻烦的工作，有些同学觉得这个过程比较麻烦，而采用取巧的策略选择绕开这个切分工作，选用将原生的，比如从huggingface下载的权重转为megatron格式，从而快速完成该大模型的预训练、微调或推理。</p><p>殊不知这一过程是从一个小坑掉到另外一个大坑： 先抛开模型转换对用户使用体验不大好的问题，格式转换的致命问题是会在一定概率下引起模型的准确率分数下降，从而造成推理结果的不一致。模型准确率分数的下降也会造成大模型在排行榜上的排名下降，因此，一些大模型厂家是不能接受这种行为的。</p><p>将所有的大模型权重都转为megatron gpt或其他格式也是一种一刀切的行为，没有考虑到各个模型的特殊性，以普遍打特殊也是违背这个世界的运行法则的一种行为，不是早上会出问题就是晚上会出问题。这里参考megatron的官方文档说明如下。</p><h2 id="2-模型转换与微调"><a href="#2-模型转换与微调" class="headerlink" title="2. 模型转换与微调"></a><font color="#FF8C00">2. 模型转换与微调</font></h2><p>megatron里微调一个大模型基本上可以分为以下几个步骤：</p><p>1）从huggingface下载大模型的权重；</p><p>2）使用大模型转换脚本将该权重从Huggingface格式转换为megatron格式；</p><p>3）基于这个转换后的权重设置微调参数，然后开始微调；</p><p>4）最后保存微调好的权重。</p><p>以LLama-2为例，将Llama 权重从huggingface下载下来，然后采用megatron自带的Llama-2 转换器转换为megatron格式，但是需要注意的是这一过程必须正确设置大模型的张量并行大小即TP参数，如下：</p><table><thead><tr><th>模型大小</th><th>张量并行大小（TP）</th></tr></thead><tbody><tr><td>7B</td><td>1</td></tr><tr><td>13B</td><td>2</td></tr><tr><td>70B</td><td>8</td></tr></tbody></table><p>基于TP值以及Llama-2 ${TOKENIZER_MODEL}路径，在megatron根目录下执行以下转换命令可以将Llama-2 权重从Huggingface格式转换为Megatron格式：</p><figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-variable">$python</span> tools/checkpoint/convert.py \<br> --model-type GPT \<br> --loader llama2 \<br> --saver megatron \<br> --target-tensor-parallel-size <span class="hljs-variable">$&#123;TP&#125;</span> \<br> --checkpoint-type hf \<br> --load-dir <span class="hljs-variable">$&#123;HF_FORMAT_DIR&#125;</span> \<br> --save-dir <span class="hljs-variable">$&#123;MEGATRON_FORMAT_DIR&#125;</span> \<br> --tokenizer-model <span class="hljs-variable">$&#123;TOKENIZER_MODEL&#125;</span><br></code></pre></td></tr></table></figure><p>完成此转换后，可以将该权重采用megatron进行微调，微调结束后再保存该新的权重，然后这个权重就可以用于推理了。需要注意的是如果是只识别huggingface格式的推理工具则需要将该权重再转回huggingface格式才能用于推理。</p><h2 id="3-模型准确率分数说明"><a href="#3-模型准确率分数说明" class="headerlink" title="3.模型准确率分数说明"></a><font color="#FF8C00">3.模型准确率分数说明</font></h2><p>下列表格列出了原生的Llama-2与转换后的LLama-2 推理结果的准确率比较。表格里的数值是megatron格式与原生格式之间的基准测试百分误差，计算公式为：”|&lt;llama_score&gt; - &lt;megatron_score&gt;| / &lt;llama_score&gt;”。在所有测试中（每种模型大小共80个），平均误差为0.15%。</p><p>经过分析，两种模型之间基准分数的微小差异是由于实现中的小的算术差异造成的，这些差异稍微改变了数值，影响这种差异的因素包括：</p><ul><li><p>Megatron在几个地方执行批量矩阵乘法，例如在self attention 内部以及在SwiGLU中，而Llama分别执行这些操作；</p></li><li><p>Megatron在自注意力中使用torch.baddbmm，而Llama使用torch.matmul；</p></li><li><p>Megatron对旋转位置嵌入使用sin/cos实现，而Llama使用极坐标/复数实现；</p></li><li><p>Llama在初始化期间调用torch.set_default_dtype(torch.float16)，而Megatron则不调用。</p></li></ul><p>准确度分数比较说明见以下表格。 </p><h3 id="3-1-Big-Bench"><a href="#3-1-Big-Bench" class="headerlink" title="3.1 Big Bench"></a>3.1 Big Bench</h3><p>得分类型：多项选择成绩。</p><table><thead><tr><th>bigbench / standard</th><th>7b</th><th>13b</th><th>70b</th></tr></thead><tbody><tr><td>date_understanding</td><td>0.29%</td><td>0.13%</td><td>0.12%</td></tr><tr><td>general_knowledge</td><td>0.00%</td><td>0.00%</td><td>0.00%</td></tr><tr><td>human_organs_senses</td><td>0.00%</td><td>0.00%</td><td>0.00%</td></tr><tr><td>intent_recognition</td><td>0.00%</td><td>0.11%</td><td>0.00%</td></tr><tr><td>riddle_sense</td><td>0.00%</td><td>0.00%</td><td>0.00%</td></tr><tr><td>similarities_abstraction</td><td>0.00%</td><td>0.58%</td><td>0.00%</td></tr><tr><td>simple_arithmetic_json_multiple_choice</td><td>0.00%</td><td>0.00%</td><td>0.00%</td></tr><tr><td>undo_permutation</td><td>0.19%</td><td>0.19%</td><td>0.18%</td></tr></tbody></table><h3 id="3-2-Multilingual"><a href="#3-2-Multilingual" class="headerlink" title="3.2 Multilingual"></a>3.2 Multilingual</h3><p>得分类型：多项选择成绩。</p><table><thead><tr><th>multilingual / xcopa</th><th>7b</th><th>13b</th><th>70b</th></tr></thead><tbody><tr><td>en-template-mGPT-remove-punctuation</td><td>0.08%</td><td>0.00%</td><td>0.00%</td></tr><tr><td>et-template-mGPT-remove-punctuation</td><td>0.00%</td><td>0.13%</td><td>0.25%</td></tr><tr><td>ht-template-mGPT-remove-punctuation</td><td>0.26%</td><td>0.13%</td><td>0.26%</td></tr><tr><td>id-template-mGPT-remove-punctuation</td><td>0.11%</td><td>0.00%</td><td>0.19%</td></tr><tr><td>it-template-mGPT-remove-punctuation</td><td>0.00%</td><td>0.10%</td><td>0.09%</td></tr><tr><td>qu-template-mGPT-remove-punctuation</td><td>0.00%</td><td>0.00%</td><td>0.27%</td></tr><tr><td>sw-template-mGPT-remove-punctuation</td><td>0.14%</td><td>0.13%</td><td>0.13%</td></tr><tr><td>th-template-mGPT-remove-punctuation</td><td>0.25%</td><td>0.13%</td><td>0.13%</td></tr><tr><td>tr-template-mGPT-remove-punctuation</td><td>0.26%</td><td>0.00%</td><td>0.34%</td></tr><tr><td>vi-template-mGPT-remove-punctuation</td><td>0.00%</td><td>0.11%</td><td>0.00%</td></tr><tr><td>zh-template-mGPT-remove-punctuation</td><td>0.00%</td><td>0.10%</td><td>0.09%</td></tr></tbody></table><h3 id="3-3-LM-Evaluation-Harness"><a href="#3-3-LM-Evaluation-Harness" class="headerlink" title="3.3 LM Evaluation Harness"></a>3.3 LM Evaluation Harness</h3><p>得分类型：多项选择成绩。</p><table><thead><tr><th>lm-eval</th><th>7b</th><th>13b</th><th>70b</th></tr></thead><tbody><tr><td>boolq</td><td>0.04%</td><td>0.04%</td><td>0.07%</td></tr><tr><td>hellaswag</td><td>0.02%</td><td>0.03%</td><td>0.03%</td></tr><tr><td>piqa</td><td>0.00%</td><td>0.00%</td><td>0.07%</td></tr><tr><td>winogrande</td><td>0.00%</td><td>0.11%</td><td>0.20%</td></tr></tbody></table><h3 id="3-4-MMLU"><a href="#3-4-MMLU" class="headerlink" title="3.4 MMLU"></a>3.4 MMLU</h3><p>得分类型：多项选择成绩。</p><p>注意：括号内的数字是每个大类中子任务的数量。</p><table><thead><tr><th>mmlu</th><th>7b</th><th>13b</th><th>70b</th></tr></thead><tbody><tr><td>stem [18]</td><td>0.79%</td><td>0.05%</td><td>0.01%</td></tr><tr><td>humanities [13]</td><td>0.19%</td><td>0.01%</td><td>0.02%</td></tr><tr><td>other (business, health, misc.) [14]</td><td>0.08%</td><td>0.06%</td><td>0.12%</td></tr><tr><td>social sciences [12]</td><td>0.37%</td><td>0.21%</td><td>0.01%</td></tr></tbody></table><p>以上数据可知，模型权重从huggingface格式转换为megatron格式会引起准确率的下降，虽然下降的不多，但是这一结果不是所有的用户都愿意接受的。</p><h2 id="4-小结"><a href="#4-小结" class="headerlink" title="4. 小结"></a><font color="#FF8C00">4. 小结</font></h2><p>本文介绍了模型权重从huggingface格式转换为megatron格式进行训练所造成的影响，准确率只是模型质量的一个约束指标，从工程角度看 训练或微调的性能、收敛精度也是另外两个比较重要的约束指标。</p><p>日拱一卒，功不唐捐，分享是最好的学习，与其跟随不如创新，希望这个知识点对大家有用。另作者能力与认知都有限，”我讲的，可能都是错的“，欢迎大家拍砖留念。</p><h2 id="5-作者简介"><a href="#5-作者简介" class="headerlink" title="5. 作者简介"></a><font color="#FF8C00">5. 作者简介</font></h2><p>常平，为学，闻道，践行。</p><h2 id="6-参考资料"><a href="#6-参考资料" class="headerlink" title="6. 参考资料"></a><font color="#FF8C00">6. 参考资料</font></h2><p>[1] <a href="https://github.com/NVIDIA/Megatron-LM/blob/main/docs/llama2.md" target="_blank" rel="noopener">https://github.com/NVIDIA/Megatron-LM/blob/main/docs/llama2.md</a></p><h2 id="7-版权申明"><a href="#7-版权申明" class="headerlink" title="7. 版权申明"></a><font color="#FF8C00">7. 版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>认识与实践 – 第6篇 - 易经、道德经、矛盾论都在讲什么</title>
      <link href="/2023/06/24/ideology_6/"/>
      <url>/2023/06/24/ideology_6/</url>
      
        <content type="html"><![CDATA[<h2 id="1-易经、道德经、矛盾论都讲了什么"><a href="#1-易经、道德经、矛盾论都讲了什么" class="headerlink" title="1. 易经、道德经、矛盾论都讲了什么"></a><font color="#FF8C00">1. 易经、道德经、矛盾论都讲了什么</font></h2><p>为学日益，闻道日损，一言以蔽之：<strong>易经：不变、简变、易变，理 、数 、象，阴阳辩证；道德经：道、德、无为、有无辩证；矛盾论：对立与统一，普遍与特殊，同一与斗争，矛盾辩证。</strong></p><p><strong>易经、道德经、矛盾论此三者也有共同点，即都在自己的时空内阐述了对辩证法的认识：阴阳辩证、有无辩证、矛盾辩证。</strong></p><h2 id="2-易经在讲什么"><a href="#2-易经在讲什么" class="headerlink" title="2. 易经在讲什么"></a><font color="#FF8C00">2. 易经在讲什么</font></h2><p>《易经》认为世界是变化的，“生生之谓易”，“无极生太极、太极生两仪、两仪生四象、四象生八卦、八卦演化六十四卦、六十四卦又为末济”，如此循环。《易经》虽然是中国的万经之首，但是也有其时代局限限，比如各种卦象的演化已不大适合用于指导现今的工作与生活。然而其“三易三法则”讲述的是这个世界运行的本质，具备普世参考价值与意义。</p><h3 id="2-1-三易-不变、简变、易变"><a href="#2-1-三易-不变、简变、易变" class="headerlink" title="2.1 三易 - 不变、简变、易变"></a>2.1 三易 - 不变、简变、易变</h3><p>《易经》里有三个原则，即“不易、简易、变易”，也可以称之为“不变，简变，易变”，当然这些变化的划分也是相对的。</p><p><strong>不变</strong>，万事万物都在变化，但是变化的背后也有不变，或者说其变化周期超级长。道家称之为“道”， 佛家称之为“如来”，基督称之为“上帝”，数学称之为“公理”，物理学称之为“奇点”。这些即为”不变“。</p><p><strong>简变</strong>，万事万物都在变化，变化的背后也有不变的道理，但不是所有的事物都是不变或者时刻在变化的，比如数学里的“定理”，律法的”法则“。事物在变化，但变化也是有差异的，比如地球自转一次24小时，地球绕太阳一周为一年，太阳系围绕银河系转一圈需要2.3亿年，如果将太阳围绕银河转一圈定义为不变，地球绕太阳一周可以定义为简变。在变化但是不是变化的那么快的事物，称之为”简变“。另外还有一个维度认为 ”简变“是复杂多样的时刻变化的事物的简化。</p><p><strong>易变</strong>，这个世界是变化的，在这个时空中，没有一样东西是不变的，万事万物，思想、情况无时不刻都是在变化。这里的易变更多讲的是无时不刻不在变化的事物、表象，如同数学的各种从公理、定理演化出来的计算题目，题目千变万化，如果掌握不了公理、定理就应对不了各种变化多样的题目。人也是无时不刻不在变化的，人体的细胞在一年左右的时间里身体98%的细胞都会被重新更新一次，那么一年后的你还是那个“你”么？细胞无时不刻不在变化，但基因是不变的。</p><h3 id="2-2-三法则-理-象-数"><a href="#2-2-三法则-理-象-数" class="headerlink" title="2.2 三法则 - 理 象 数"></a>2.2 三法则 - 理 象 数</h3><p>《易经》最为基本的三原则之后还有三法则：即理、象、数，我们可以理解成 事物背后不变的道，易变的表象以及用于度量的数据，每个事物到了一定的数就一定会变，从而产生新的象。</p><p>只要事物无时不刻不在变化就一定有它的不变的理，易变的象以及度量它的数。比如，在地球上往天空上抛的石头总是会落下，石头总是落下这背后是万有引力这个理，现象是石头落下，数是 落下来的速度、时间、加速度。</p><p>事物只要发生变化就有它的“理、象、数”。而且只要到了一定的“数”就一定会发生变化，从而产生新的“象”，这也是由它背后的那个“理”决定的。这个数 也是用于 “占”即推理的依据。人们常说做人不要太过分，也是这个道理，过犹不及。</p><h3 id="2-3-阴阳辩证"><a href="#2-3-阴阳辩证" class="headerlink" title="2.3 阴阳辩证"></a>2.3 阴阳辩证</h3><p>“一阴一阳之谓道”。既有阴，又有阳，这就是道，这就是事物发展的规律。《易经》里阴阳是64卦的基础，如同计算机里的二进制。其告诉我们一个时空最基本的秘密：阴阳是构成万事万物最基本的元素。阴阳也是易经的朴素辩证法。阴阳辩证法具有几个特点：相生、相克、共存、转化、平衡。</p><p>阴阳相生，事物的阴阳两个方面是运动变化的，比如四季更迭，白天黑夜的变化，此进彼退，此消彼长；</p><p>阴阳相克，万事万物存在着对立的两个方面，比如冷热、福祸、高低、快慢、难易等；</p><p>阴阳共存，事物的两个方面都以对立的另一个方面作为自己存在的前提，互相共存，互相作用，不可独立存在，比如手心与手背，身体与影子，桌面桌背等；</p><p>阴阳互转，事物的阴阳两个方面并在在一定条件下也会发生相互转化最终达到新的平衡。比如，我们已知地球的白天黑夜更替是由地球自转而产生的，有白天就有黑夜，白天黑夜是共存的，比如南半球白天，北半球就黑夜，白天与黑夜在一定的条件下可以相互转化。有正离子就有负离子，再一定条件下正负离子也可以互相发生转化，最终达成新的平衡，共存于同一个物体内。</p><p>“潜龙勿用、见龙在田、终日乾乾、或跃在渊、飞龙在天、亢龙有悔”，也是一个相生相克相互转化的过程。</p><h2 id="3-道德经在讲什么"><a href="#3-道德经在讲什么" class="headerlink" title="3. 道德经在讲什么"></a><font color="#FF8C00">3. 道德经在讲什么</font></h2><p>《道德经》概要来说主要讲了“道“，”德“， ”无为“， ”有无辩证“ 这四个方面。</p><h3 id="3-1-道德"><a href="#3-1-道德" class="headerlink" title="3.1 道德"></a>3.1 道德</h3><p>“有物混成，先天地生，寂兮寥兮，独立而不改，周行而不殆，可以为天地母。吾不知其名，字之曰道，强为之名曰大。”，“上德不德，是以有德；下德不失德，是以无德。”。</p><p>《道德经》里的道，指的是产生万物的不变规律，而德指的是万物生长的内在根据。道生万物，德养万物：“道生之，德畜之，物形之，势成之。是以万物莫不尊道，而贵德。”</p><p>“道，人之所蹈，使万物不知其所由；德，人之所得，使万物得其所欲。”，道是人应该遵循的规律，但是万事万物又不知道这个道是从哪来的，德是人之所得到的给养，是使万事万物能生养的基本欲求。“</p><h3 id="3-2-无为"><a href="#3-2-无为" class="headerlink" title="3.2 无为"></a>3.2 无为</h3><p>《道德经》里讲的无为，是个容易令人误解的地方，按现代文字面的意思就是啥都不做，躺平，比较消极。然而“法无定法”，躺平对一些人来说也不一定就是坏事。</p><p>按道家思想来说“无为”可以分为五层意思。即：<strong>天为、顺为、先为、疏为，勿为。</strong></p><p>天为，无为的第一层意思是天为。“为学者日益，闻道者日损，损之又损，以至于无为，无为而无所不为。”，学习技能是日益，学习道要日损，逐步去掉人的“贪嗔痴慢疑”，剥离人为剩下的天为即为无为。这里的无为是按规律办事，主观要符合客观。</p><p>顺为，无为的第二层意思是顺为。顺势而为，“道生之,德畜之,物形之,势成之”，“上善若水”，水总是顺势而为的，这里的无为是顺为，要顺势而为。</p><p>先为，无为的第三层意思是先为。比如扁鹊他哥，扁鹊在与魏文王对话中告诉魏文王：“真正好的医生，早在病人还没有患病的时候，就能看出病人将要出现的问题。。。。”，这里的无为表达的是先为的意思，要具备预见能力，在事物刚出现苗头时就能预见到，先为之。</p><p>疏为，无为的第四层意思是疏为。到了这里面向的对象是掌握一定社会资源的人。”上德不德，是以有德；下德不失德，是以无德，上德无为而无以为；下德无为而有以为。“，上位者如果什么事都亲力亲为，有时候反而不好，要该亲为的时候亲为，不该亲为的时候不亲为，即疏为。事事亲为，容易打击下属的积极性。锻炼不了新人，培养不出新人，也容易导致后继无人。比如诸葛亮鞠躬精粹，事事亲为，把自己累死不说，还导致的一个后果是蜀国后继无人很快就亡国了。这里的无为也是在说，该放手就放手，该亲为就亲为，不要事事亲为，过犹不及。</p><p>勿为，无为的第5层意思是勿为。这一层也是面向掌握一定社会资源的人，如果是掌握较大的社会资源就不要妄为。比如 各朝亡国之君，到了这一层次，不瞎搞不乱折腾就是最好的”有为“。还比如这几年乱去炒A股，只要不炒A股，收益就是超过90%的人了。</p><h3 id="3-3-有无辩证法"><a href="#3-3-有无辩证法" class="headerlink" title="3.3 有无辩证法"></a>3.3 有无辩证法</h3><p>“无，名天地之始；有，名万物之母。故常无欲，以观其妙；常有欲，以观其徼。此两者同，出而异名。同谓之玄，玄之又玄，众妙之门。“，道生德养，道无德有，《道德经》里还有个非常重要的概念即”有、无“，体现了有无辩证法。有无辩证法具有几个特点：有无相同，有无相生、相互转化，有无平衡。</p><p>有无相同，“此二者同，出而异名”。杯子的周边是有，中间的空是。房子的周边是有，房间内部是无。车轱辘的轮子是有，轮子中间的轴孔是无。 ”有“提供价值，然后通过“无”发挥出这个价值。</p><p>有无相生，“故有无相生，难易相成，长短相形，高下相倾，音声相和，前后相随。” ，“祸兮福所倚；福兮祸所伏。孰知其极？”。有和无互相转化，难和易互相形成，长和短互相显现，高和下互相倾向，音与声互相相和，前和后互相跟随， 福祸互相倚伏 - 这些都是一定这样的。“曲则全，枉则直；洼则盈，弊则新；少则得，多则惑。。。。”，有时候委屈反而能是周全，弯腰反而能更好的站直。</p><p>有无相互转化。旧的有无可以在一定的条件下转化成新的有无。“反者道之动，弱者道之用。天下万物生于有，有生于无。” ，事物总是向相反的方向运动的，当违反道的规律时，道就动起来了。道有德无，有之以为利（价值），无之以为用（作用）。</p><h2 id="4-矛盾论"><a href="#4-矛盾论" class="headerlink" title="4. 矛盾论"></a><font color="#FF8C00">4. 矛盾论</font></h2><p>矛盾即对立统一，矛盾论里讲了一个最主要的内容即矛盾辩证法。矛盾辩证法里对立统一的观点是最核心的基本观点，其精髓是矛盾的普遍性与特殊性。</p><h3 id="4-1-矛盾辩证法"><a href="#4-1-矛盾辩证法" class="headerlink" title="4.1 矛盾辩证法"></a>4.1 矛盾辩证法</h3><h4 id="4-1-1-对立与统一"><a href="#4-1-1-对立与统一" class="headerlink" title="4.1.1 对立与统一"></a>4.1.1 对立与统一</h4><p>矛盾就是对立统一，就是用对立统一的观点看问题，矛盾的对立统一规律告诉我们矛盾双方具备普遍性与特性性，同一性与斗争性的关系。</p><h4 id="4-1-2-普遍性与特殊性"><a href="#4-1-2-普遍性与特殊性" class="headerlink" title="4.1.2 普遍性与特殊性"></a>4.1.2 普遍性与特殊性</h4><p>矛盾的普遍性是指”矛盾存在于一切事物中，存在于一切事物发展过程的始终，旧的矛盾解决了，新的矛盾又产生，事物始终在矛盾中运动。即“矛盾无处不在,矛盾无时不有”。矛盾的普遍性告诉我们事物是普遍矛盾存在的，问题也是普遍的，不同的人，不同的场景，不同的时空，矛盾都是普遍的。</p><p>矛盾的特殊性是矛盾分析法的核心所在，是”各种物质运动形式中的矛盾都带特殊性“。矛盾的特殊性告诉我们做事具体问题要具体分析。以普遍打特殊或者以特殊打普遍，都必然会出问题。这就要求我们工作中要注意具体问题具体分析，不搞一刀切。</p><p>普遍性与特殊性在一定的条件下也可以互相转化。</p><h4 id="4-1-3-矛盾不平衡"><a href="#4-1-3-矛盾不平衡" class="headerlink" title="4.1.3 矛盾不平衡"></a>4.1.3 矛盾不平衡</h4><p>矛盾的不平衡，是矛盾特殊性在不同阶段不同时期的表现。矛盾的不平衡，要求我们做事事既要坚持重点论，又要坚持两点论，要用“弹钢琴”的手法来做事，有重按键，有轻按键，还要每个键都兼顾到，这样弹出来的才是美妙的音律。</p><p>坚持两点论和重点论相统一， 要求我们做事既要抓住主要矛盾 同时也要兼顾次要矛盾，在工作中要抓重点带全局，稳定全局、重点突破、以点及面、梯度推进、波浪式前进。</p><p>按矛盾辩证法办事就是坚持两点论和重点论相统一，坚持两点论、两分法、一分为二，全面的观点看问题。</p><h3 id="4-1-4-同一性和斗争性"><a href="#4-1-4-同一性和斗争性" class="headerlink" title="4.1.4 同一性和斗争性"></a>4.1.4 同一性和斗争性</h3><p>同一性和斗争性，即统一性 与 对立性，双方是共存的。同一性和斗争性相互联结、相互制约。同一性离不开斗争性,没有斗争就没有同一，斗争性也离不开同一性,斗争性寓于同一性之中。同一性与斗争性在一定的条件下能互相转化。</p><h2 id="5-小结"><a href="#5-小结" class="headerlink" title="5. 小结"></a><font color="#FF8C00">5. 小结</font></h2><p>本文简要讲述了易经、道德经、矛盾论的主要观点，并且简要比较了阴阳辩证法、有无辩证法、矛盾辩证法这三者的差异。为学日益，闻到日损，理论要能联系实际，要能用于指导实践才能发挥出其应有的价值。在阴阳辩证法，有无辩证法，矛盾辩证法中，矛盾辩证法最与时俱进，对工作实践最具备指导价值。另作者能力与认知都有限，”我讲的，可能都是错的“。</p><h2 id="6-作者简介"><a href="#6-作者简介" class="headerlink" title="6. 作者简介"></a><font color="#FF8C00">6. 作者简介</font></h2><p>常平，中科大硕，某AI独角兽深度学习高级软件主管工程师、架构师，前EMC资深首席工程师，主要工作背景在深度学习、大数据、云计算、分布式中间件以及Linux内核领域。</p><h2 id="7-参考资料"><a href="#7-参考资料" class="headerlink" title="7. 参考资料"></a><font color="#FF8C00">7. 参考资料</font></h2><p>[1] 《易经》 </p><p>[2]《易经杂说》</p><p>[3] 《道德经》</p><p>[4] 《矛盾论》</p><h2 id="8-版权申明"><a href="#8-版权申明" class="headerlink" title="8. 版权申明"></a><font color="#FF8C00">8. 版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p>]]></content>
      
      
      <categories>
          
          <category> ideology </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ideology </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>深度学习 - 第6篇 - 超大规模分布式训练集群性能调优之美</title>
      <link href="/2023/03/03/ai_6/"/>
      <url>/2023/03/03/ai_6/</url>
      
        <content type="html"><![CDATA[<p>​                </p><h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a><font color="#FF8C00">1. 概述</font></h2><p><strong>考虑到信息安全问题，这里不会写什么架构设计方案，更不会写什么具体的落地方案，有的只是从理论到实践再从实践回到理论的一些系统工程经验总结</strong>。超大规模集群性能调优的目标是为了解决以下两个系统级难题：</p><p>1）如何将Ai加速卡千卡分布式训练集群某个模型的加速比调到0.90+以上？</p><p>2）如何夯实Ai加速卡整体的分布式训练集群产品的系统级性能质量？</p><p>千卡级别的超大规模分布式训练集群性能调试是一个系统级的难题，将理论与实践相结合，从实践中来到实践中去，需要手把手的去调、去敲代码、系统梳理、具体问题具体分析、人技合一，才能有效达成目标。</p><p>系统级的性能优化考验的是具体问题具体分析的能力，考验的是根据不同的实际情况的变化进行全局优化的能力。</p><h2 id="2-基本约束条件"><a href="#2-基本约束条件" class="headerlink" title="2. 基本约束条件"></a><font color="#FF8C00">2. 基本约束条件</font></h2><p>1）分布式训练必须以模型能收敛、精度达标、曲线拟合为前提，一切不能收敛、精度不达标、不能曲线集合的性能优化方案都是无效的；</p><p>2）加速比计算公式的 speedup = 分布式的单卡性能/单卡性能，这里的分母不是单机的性能，也不是单机内多卡并行计算的单卡性能，做低分母数值从而获得较高的加速比数据属于自欺欺人的行为；</p><p>3）理论上加速比也可以是  计算时间/(计算时间 + 非计算时间)，因此，加速比调优的本质在于减少或者隐藏非计算时间；</p><p>4）这里讲的属于数据并行的分布式训练范畴，非模型并行、流水并行以及混合并行；</p><p>5）这里的Ai加速卡指的是某国产化加速卡，在软硬件功能与生态上对比GPU都还有很大差距，短板也更明显，因此更难以调试。</p><h2 id="3-性能优化总诀"><a href="#3-性能优化总诀" class="headerlink" title="3.性能优化总诀"></a><font color="#FF8C00">3.性能优化总诀</font></h2><p>在软件工程中，不管场景是怎么样的，性能优化的策略本质上都可以抽象成以下几个方案：</p><ul><li><p>少读少写少依赖: 少读，即减少读放大，减少需要读的数据量；少写，即减少写放大，减少需要写的数据量；少读少写的策略可以是提高cache命中率也可以是进行数据压缩，还可以是合适的读写算法与数据结构等，少依赖，高内聚低耦合、资源解耦与隔离，一个组件的IO尽量做到不需要等待另外组件IO完成才能返回；</p></li><li><p>时空换同异换： 时空换同异换讲的是性能优化的路数，解读开来说即是：时间换空间、空间换时间、同步换异步。例如：采用cache的功能可以减少计算的时间，这是存储空间换时间从而提升性能；采用批处理的方式提升性能，这是减少计算时间；采用同步换异步的方式提升性能也是减少计算时间；减少IO的数据量从而提升性能，这是存储空间换时间；缩短IO路径提升性能，这也是网络空间换时间，采用最新的硬件提升性能，这可以是计算换时间，也可以是存储或网络空间换时间；</p></li><li><p>硬件顺天性：硬件顺天性讲的是软件设计要遵循硬件的原生特性，XPU不同于GPU、CPU的亲合性、机械盘性能不如固态硬盘、磁盘数据分块需要对齐、内存性能好适合做缓存但是下电就丢数据、网络是不可靠的并且有带宽限制、RDMA网络比IP网络性能好、且是可以双工的，不同的应用场景要依据硬件的不同特性做架构选型以及架构设计等。</p></li></ul><p>对于系统优化来说，不管场景怎么变化，不变的道理其实也还是上面那三项，性能优化也是万变不离其宗的。</p><h2 id="4-几个关键点"><a href="#4-几个关键点" class="headerlink" title="4. 几个关键点"></a><font color="#FF8C00">4. 几个关键点</font></h2><p>关于整体的超大规模分布式训练系统性能优化，需要考虑的主要关键点有以下几项：</p><ul><li><p>工程方法论</p></li><li><p>极致系统平衡</p></li><li><p>具体问题具体分析</p></li><li><p>网络通信优化</p></li><li><p>数据IO优化</p></li><li><p>训练框架优化</p></li><li><p>模型优化</p></li><li><p>系统优化</p></li></ul><p>下面将围绕这几项展开讲述。</p><h2 id="5-工程方法论之美"><a href="#5-工程方法论之美" class="headerlink" title="5. 工程方法论之美"></a><font color="#FF8C00">5. 工程方法论之美</font></h2><h3 id="5-1-组织到位"><a href="#5-1-组织到位" class="headerlink" title="5.1 组织到位"></a>5.1 组织到位</h3><p>千卡性能调优是个系统工程，要干活就首先需要有人，有人就需要组织能到位。这里的组织到位有两层意思：一是需要有人，需要组织给与人力保障以及多团队合作保障；二是合适的人，事是需要人去做的，攻坚的课题用到合适的人才具备达成目标的可能性，用错人半途而废或者数据造假忽悠群众、效果打折的可能性也不是没有。</p><h3 id="5-2-架构先行"><a href="#5-2-架构先行" class="headerlink" title="5.2 架构先行"></a>5.2 架构先行</h3><p>从系统而非单点的角度分析问题，要解决问题首先是需要能发现问题，在对调优任务进行拆解之前需要对性能调优方案先进行系统分析，挖掘出存在的软硬件问题拿出具体可执行的调优解决方案，并形成架构设计文档。</p><h3 id="5-3-分而治之"><a href="#5-3-分而治之" class="headerlink" title="5.3 分而治之"></a>5.3 分而治之</h3><p>系统思考分而治之，大问题拆解成小问题，将非常大的不确定性的千卡加速比 0.90+ 这个目标进行拆解，将非确定性的大问题拆解成确定性的小问题，步步迭代进行解决。宏观是不确定的，但微观却可以确定，系统梳理每个要素，拆解为确定的细分任务，先将确定的任务落实到人，再将剩下的不确定任务根据实际情况的变化，逐步进一步分解，逐步迭代。</p><h3 id="5-4-小即是大"><a href="#5-4-小即是大" class="headerlink" title="5.4 小即是大"></a>5.4 小即是大</h3><p>从主机内单卡到主机内多卡，新增主机内通信单元，从主机内多卡到主机间多卡新增主机间通信单元，这些系统间要素连接关系变化会引起系统整体功能的变化，因此，需要先聚焦主机内单机多卡调优，再聚焦主机间2机性能调优，在这二者达成既定目标后，后续扩展到千卡规模也就是水到渠成之事。</p><h3 id="5-5-众策众智"><a href="#5-5-众策众智" class="headerlink" title="5.5 众策众智"></a>5.5 众策众智</h3><p>众策众智多方协作，集群性能调优是个系统工程，需要多方合作与协调，其涉及多方组件，千卡性能调优是多方合作的结果，是软硬件联合，软件内部多方合作，跨部门跨团队联调达成的结果。</p><h3 id="5-6-躬身入局"><a href="#5-6-躬身入局" class="headerlink" title="5.6 躬身入局"></a>5.6 躬身入局</h3><p>躬身入局不达目标不罢休，实践出真知，“黄沙百战穿金甲,不破楼兰终不还”，在认知上确定关键路径后，更重要的是躬身入局实践，一个问题一个问题的攻克，步步为营，步步迭代，一个小目标一个小目标的攻克递进。</p><h2 id="6-系统平衡之美"><a href="#6-系统平衡之美" class="headerlink" title="6. 系统平衡之美"></a><font color="#FF8C00">6. 系统平衡之美</font></h2><p>系统是有灵魂的，如下图《一根羽毛的力量》(图片来源于网络版权归原作者所有)，其将平衡用到极致，风、呼吸、声音等微小的外部条件变化都可能造成失败，体现了整体的系统平衡之美。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/aitraining/6/1-1.png" title="" alt="平衡之美" data-align="center"></p><p>而分布式训练系统也有自己的灵魂，其可以表达为FPS每秒处理的帧数指标图，一个好的分布式训练系统FPS指标也是很有规律很漂亮的，如下图所示，千卡某模型加速比0.90+达标的训练集群FPS指标可以稳得如同一根直线，完美的诠释了什么是系统工程平衡之美。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/aitraining/6/1-2.png" title="" alt="平衡之美" data-align="center"></p><p>而一个加速比指标很差的训练系统FPS指标可能如下图，各种指标上串下跳极其不稳定，缺少一种平衡感。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/aitraining/6/1-3.png" title="" alt="平衡之美" data-align="center"></p><h2 id="7-具体问题具体分析之美"><a href="#7-具体问题具体分析之美" class="headerlink" title="7. 具体问题具体分析之美"></a><font color="#FF8C00">7. 具体问题具体分析之美</font></h2><p>GPU有适合GPU的最佳性能优化方案，XPU有XPU的最佳性能优化方案，而现有的分布式训练方案基本上都是基于GPU硬件体系结构以及CUDA的软件生态方案，不一定适合于各家国产化的AI加速卡的实际情况，因此针对国产化加速卡的性能优化方案也需要具体问题具体分析。</p><p>其实对于分布式训练性能优化来说，具体问题具体分析这一步才是最重要的，也是各路性能优化专家的掉坑点。每个AI加速卡都具备矛盾的普遍性也具备自身的矛盾特殊性。要根据自家加速卡的实际情况具体问题具体分析，首先是需要能发现具体的问题，再根据这个具体问题进行具体分析，再根据分析的结果给出最佳适合的性能优化方案，这就跟人的能力强相关，不是看完这篇文章或者网上找的几篇论文就可以完成超大规模训练集群性能优化这个系统级难题的。</p><p>各个国产化厂家的硬件存在矛盾特殊性，软件也存在自身的矛盾特殊性，具体问题具体分析就是挖掘这些矛盾特殊性，形成系统性的调研报告，从而给出系统级的性能优化方案。</p><h2 id="8-网络通信优化之美"><a href="#8-网络通信优化之美" class="headerlink" title="8.网络通信优化之美"></a><font color="#FF8C00">8.网络通信优化之美</font></h2><h3 id="8-1-网络拓扑结构"><a href="#8-1-网络拓扑结构" class="headerlink" title="8.1 网络拓扑结构"></a>8.1 网络拓扑结构</h3><p>实践证明，如果网络优化的足够到位，2D-RING ALLReduce拓扑算法就能满足千卡集群某模型的加速比达0.90+的，如下图，主机内一个ring  Allreduce，主机间一个ring AllReduce，再主机内一个Broadcast：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/aitraining/6/1-5.png" title="" alt="2DRING" data-align="center"></p><p>这种拓扑算法只需要消耗一个RDMA网卡的一个网口以及一个交换机端口，因此，适合在有成本约束的生产环境，除非有更高的加速比要求，不然简单的两层RING结构拓扑算法就能满足绝大多数的生产需求。</p><p>而这种网络拓扑优化的关键在于主机内从单卡到多卡，发生了物理连接结构变化，主机间从单机到多机也发生了物理连接结构的变化，要专注于这两种结构变化的优化，使得FPS性能掉的足够少，才有望在千卡这种规模的集群下获得较高的加速比。</p><h3 id="8-2-网络存在的问题"><a href="#8-2-网络存在的问题" class="headerlink" title="8.2 网络存在的问题"></a>8.2 网络存在的问题</h3><p>网络是分布式训练系统的连接方式，因此分布式训练系统也继承了网络的原生缺点，即：</p><ul><li>网络是不可靠的；</li><li>网络是会出故障的；</li><li>网络是有时延的；</li><li>网络是会抖动的；</li><li>网络是不安全的；</li><li>网络是会丢包的；</li><li>网络是有带宽限制的；</li><li>网络消息是会乱序的</li></ul><p>这些原生缺点的存在会给分布式训练系统带来以下一些问题：</p><h4 id="8-2-1-同步通信问题"><a href="#8-2-1-同步通信问题" class="headerlink" title="8.2.1 同步通信问题"></a>8.2.1 同步通信问题</h4><p>在Ring拓扑下每个XPU只与相邻XPU通信，而在该拓扑下所有传输都是在离散迭代中同步进行的并且每张XPU都需要进行迭代周期同步，所有传输的速度受到环中相邻XPU之间最慢(或最低带宽)连接的限制，性能瓶颈也非常明显。</p><h4 id="8-2-2-落后者问题"><a href="#8-2-2-落后者问题" class="headerlink" title="8.2.2 落后者问题"></a>8.2.2 落后者问题</h4><p>落后者 (Straggler)问题，指的是当一个平台上不同的工作单元具有不同的运行性能时，整个系统的性能受限于运行效率最低的工作单元。Straggler可能是确定性的，比如某台机器的计算能力或者网络带宽低于其他机器。也可能是随机性的，比如低性能是因为资源共享，后台操作系统任务，缓存，功耗限制等引起的，解决Straggler问题的一种常用方式是进行<strong>异步训练</strong>。</p><h4 id="8-2-3-异质问题"><a href="#8-2-3-异质问题" class="headerlink" title="8.2.3  异质问题"></a>8.2.3  异质问题</h4><p>当前我们的国产化软硬件存在一些技术约束，这些约束条件会造成很大的计算异质问题，比如主机内网络非全连接，主机间RDMA全连接并且主机间RDMA有些场景下又是分层交换机互联，这就是网络异质，而目前使用的Ring-Based通信拓扑又是同步的，当整个集群内存在较慢的计算节点时，整个系统的性能受限于这个性能最差的节点。除了网络拓扑，网络本身的缺点也决定了需要对网络进行细致的优化。</p><h2 id="9-数据IO优化之美"><a href="#9-数据IO优化之美" class="headerlink" title="9.数据IO优化之美"></a><font color="#FF8C00">9.数据IO优化之美</font></h2><p>在分布式训练系统里，数据IO最重要的优化即数据预取以及IO时间隐藏的优化，如下图所示，数据首先从磁盘读取进主机缓存，再从主机缓存读取进加速卡内存HBM，这个过程带宽是受PCIE限制的，如果IO 速率跟不上加速卡的计算消耗数据速率，数据IO就会成为整个训练系统的瓶颈。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/aitraining/6/1-7.png" alt="数据IO"></p><p>基于此，需要打通pinned memory ，数据预取以及IO时间隐藏功能。</p><h2 id="10-训练框架优化之美"><a href="#10-训练框架优化之美" class="headerlink" title="10.训练框架优化之美"></a><font color="#FF8C00">10.训练框架优化之美</font></h2><p>如下图所示，神经网路是分层的，因此训练框架计算出来的梯度也是分层结构，如果不进行融合优化，那么每个梯度层都会触发一次全局通信规约，100个梯度就需要进行100次全局通信100次全局规约，这种行为会极大的拖垮整个分布式训练系统的性能。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/aitraining/6/1-8.png" alt="神经网络"></p><p>基于此需要采用 梯度融合的策略进行优化，通过梯度融合计算将多个梯度合成一个，从而减少全局规约的次数能大幅提高分布式训练的训练性能，如下图所示，将N个小梯度Tensor合成两个，能将全局通信的次数减少到2次，从而大幅提升训练性能：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/aitraining/6/1-9.png" alt="tensorfusion"></p><h2 id="11-模型优化之美"><a href="#11-模型优化之美" class="headerlink" title="11. 模型优化之美"></a><font color="#FF8C00">11. 模型优化之美</font></h2><p>这需要具体问题具体分析，根据不同的模型以及实际情况进行优化。除了通信、框架、数据IO等，模型也是影响整体系统性能的一个关键点，数据dataset的效率，训练session 的合并还是分离，采用的是动态训练策略还是静态训练策略，FPS统计的计算方式这些要素也会极大的影响整体的系统性能，因此也需要针对具体情况进行具体分析。</p><h2 id="12-系统优化之美"><a href="#12-系统优化之美" class="headerlink" title="12.系统优化之美"></a><font color="#FF8C00">12.系统优化之美</font></h2><p>如下图，是一个AI服务器主板，在这个服务器里，加速卡间的通信带宽大于PCIE带宽又大于CPU间的UPI带宽，因此需要启用NUMA优化，使得数据不跨越UPI通信，另外CPU 的AFFINITY也需要进行平衡优化。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/aitraining/6/1-4.png" alt="数据IO"></p><p>除了CPU的优化，计算机节点还有一下特性：</p><ul><li>计算机节点是会出故障的，主板、CPU、网卡、硬盘、内存、电源等都会出故障，比如老化、失效等；</li><li>计算机节点内的操作系统是会突然奔溃不能提供服务的；</li><li>计算机节点是会突然掉电的；</li><li>计算机节点里的内存下电是不保数据的；</li><li>计算机节点的资源是有限的：CPU是有算力上限的、内存是有大小限制的、网卡有吞吐量限制、硬盘有空间大小限制以及速率限制；</li></ul><p>这些特性也会影响到训练FPS的平衡，也需要针对性的根据具体情况进行优化。</p><h2 id="13-小结"><a href="#13-小结" class="headerlink" title="13. 小结"></a><font color="#FF8C00">13. 小结</font></h2><p>本文介绍了从实践中来的关于一些超大规模训练集群性能优化的理论上的思考，考虑到信息安全问题，有些地方写的不是很透明，见谅。另外性能优化也是需要具体问题具体分析，根据不同的实际情况而进行优化的，普遍的策略可以学习，但是特殊的情况考验的还是个人以及团队发现问题、分析问题、解决问题的能力。</p><p>日拱一卒，功不唐捐，分享是最好的学习，与其跟随不如创新，希望这个知识点对大家有用。另作者能力与认知都有限，”我讲的，可能都是错的“，欢迎大家拍砖留念。</p><h2 id="14-作者简介"><a href="#14-作者简介" class="headerlink" title="14. 作者简介"></a><font color="#FF8C00">14. 作者简介</font></h2><p>常平，中科大硕，某AI芯片公司深度学习高级软件主管、架构师，前EMC资深首席工程师，主要工作背景在深度学习、Ai平台、系统调优、大数据、云计算以及Linux内核领域。</p><h2 id="15-参考资料"><a href="#15-参考资料" class="headerlink" title="15. 参考资料"></a><font color="#FF8C00">15. 参考资料</font></h2><p>[1] <a href="https://www.changping.me">https://www.changping.me</a></p><p>[2] NF5468M5 用户手册</p><h2 id="16-版权申明"><a href="#16-版权申明" class="headerlink" title="16. 版权申明"></a><font color="#FF8C00">16. 版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>认识与实践 – 第5篇 - 世界观、辩证法、实践论、矛盾论、历史观五大哲学思维与工作方法</title>
      <link href="/2023/02/12/ideology_5/"/>
      <url>/2023/02/12/ideology_5/</url>
      
        <content type="html"><![CDATA[<h2 id="1-前言"><a href="#1-前言" class="headerlink" title="1. 前言"></a><font color="#FF8C00">1. 前言</font></h2><p>哲学是系统化的世界观与方法论，也是分析问题、解决问题的无上心法，当我们面临的问题越复杂时它就越有用，越能发挥出它的无上威力。分析问题、解决问题的无上心法是通过不断的实践和积累经验来炼成的。它需要一个人不断地思考、分析、实践，以及从失败中吸取教训，不断积累经验，最终形成一套完整的分析问题、解决问题的方法。</p><p>这里给大家分享一套经过实践证明比较有效的分析问题、解决问题的工作方法，即以世界观、辩证法、实践论、矛盾论与历史观这五大哲学思维来分析问题、解决问题。</p><p>另外，社会存在决定社会意识，我写的都是我的社会存在方式所决定的意识形态，是在我个人特殊的立场下的观点与方法，因此我讲的不一定都是对的，也不一定适用于大家的普遍或特殊情况。</p><h2 id="2-世界观"><a href="#2-世界观" class="headerlink" title="2. 世界观"></a><font color="#FF8C00">2. 世界观</font></h2><p>唯物主义世界观认为：<font color="#FF8C00"><strong>世界是物质的，世界是系统的，世界是运动、变化、联系、发展的，世界是对立统一矛盾的，世界是可以认识与改造的，世界是由利益与价值驱动的。</strong></font></p><h3 id="2-1-世界是物质的"><a href="#2-1-世界是物质的" class="headerlink" title="2.1 世界是物质的"></a>2.1 世界是物质的</h3><h4 id="2-1-1-一切从客观实际出发"><a href="#2-1-1-一切从客观实际出发" class="headerlink" title="2.1.1 一切从客观实际出发"></a>2.1.1 一切从客观实际出发</h4><p>世界是物质的，客观实在性是物质的根本属性，客观存在决定主观意识，主观意识必须符合客观实际。这告诉我们工作中要一切从客观实际出发，使主观符合客观。人的一切认识、意图、设想、目标规划等都是主观，而人的生活环境、生活关系、生产方式、自然物质等都是客观，更进一步可以认为”别人的想法也是客观事实”，比如”上情与下情“，因此可以认为”除我之外皆是客观”，一切从客观实际出发也是从 “除我之外”出发。</p><h4 id="2-1-2-解放思想实事求是"><a href="#2-1-2-解放思想实事求是" class="headerlink" title="2.1.2 解放思想实事求是"></a>2.1.2 解放思想实事求是</h4><p>一切从客观实际出发也要求我们在工作中 “解放思想，实事求是”。 “实事”即客观存在的事物，“求”即探索、研究、调查，“是”即事物的内部规律、本质。实事求是要求我们事前要解放思想从客观实际出发充分调查研究，找出其中的内部规律与本质，从而避免或减少犯主观错误。</p><h4 id="2-1-3-认识并且利用规律"><a href="#2-1-3-认识并且利用规律" class="headerlink" title="2.1.3 认识并且利用规律"></a>2.1.3 认识并且利用规律</h4><p>世界是物质的，物质是运动的，运动是有规律的，因此我们工作中也可以认识并且利用规律，比如“如何将酷技术转化成好产品”，这就是有规律可循的，找出这个规律就可以指导任何的将技术转化成产品的各种产品化场景。</p><h3 id="2-2-世界是系统的"><a href="#2-2-世界是系统的" class="headerlink" title="2.2 世界是系统的"></a>2.2 世界是系统的</h3><h4 id="2-2-1-全面观"><a href="#2-2-1-全面观" class="headerlink" title="2.2.1 全面观"></a>2.2.1 全面观</h4><p>世界是系统的，系统具有整体性，因此我们要整体全面地认识问题、分析问题、解决问题。看一个茶杯，坐在不同位置的人看到的都有可能是不同的图案，盲人摸象也是因为只看到局部而没看到全局做造成，因此世界是系统的首先就要求我们办事要具备全局观，从而减少犯错误。</p><h4 id="2-2-2-要素联系与目的"><a href="#2-2-2-要素联系与目的" class="headerlink" title="2.2.2 要素联系与目的"></a>2.2.2 要素联系与目的</h4><p>系统观认为系统是由相互联系、相互作用的要素组成的，这些要素的组合达成了统一的目标、目的或功能。在系统里，要素的联系以及系统的整体目标、目的、功能，会比要素更为重要，属于系统质的部分，而要素属于系统 量的部分，量的变化在没有引起质的变化之前是不大会影响到整体系统的功能或目标的，而 质的部分的变化会导致系统功能发生剧烈变化。</p><p>比如一个企业也可以看做一个系统，企业内部的员工可以看成是要素，要素未达到质变的有限变化前并不会改变这个企业系统的基本功能与目标，比如“企业裁员或员工跳槽”。而企业功能的改变，比如从生产水产变成生产芯片，其功能就发生质的变化，再比如汇报关系即联系关系发生变化也会大面积的引起企业基本功能或目标的变化。</p><h4 id="2-2-3-平衡"><a href="#2-2-3-平衡" class="headerlink" title="2.2.3 平衡"></a>2.2.3 平衡</h4><p>系统 = 要素 x 联系 + 目的/功能。系统论也告诉我们要让系统跑的又稳又快那么就要求系统内的各要素之间的联系与资源竞用达到了最佳的平衡态，即熵的平衡态。热力学第一定律告诉我们 一个系统一定会从有序走向无序，从整齐走向混乱，要改变这个状态即需要从外部做功，给系统输入新的能量，比如企业的管理也是为了减少内部的熵增，从而延长企业系统的生命周期。因此，我们在工作中要平衡/隔离各个团队要素，令组织资源竞用达到平衡，从而减少组织冲突，延缓熵增。</p><h3 id="2-3-世界是运动、变化、联系、发展的"><a href="#2-3-世界是运动、变化、联系、发展的" class="headerlink" title="2.3 世界是运动、变化、联系、发展的"></a>2.3 世界是运动、变化、联系、发展的</h3><h4 id="2-3-1-一切以时间、空间、条件为转移"><a href="#2-3-1-一切以时间、空间、条件为转移" class="headerlink" title="2.3.1 一切以时间、空间、条件为转移"></a>2.3.1 一切以时间、空间、条件为转移</h4><p>世界是运动、变化、联系、发展的，这告诉我们办事要 “一切以时间、空间、条件为转移”，时间：过去、现在、未来，空间：大势、环境、境况、民意、民情，条件：客观条件与主观条件。当事物的时间、空间、条件发生变化时，我们工作中也要根据具体情况、具体条件以及时间、空间调整办事的策略。</p><h3 id="2-4-世界是对立统一矛盾的"><a href="#2-4-世界是对立统一矛盾的" class="headerlink" title="2.4 世界是对立统一矛盾的"></a>2.4 世界是对立统一矛盾的</h3><h4 id="2-4-1-一分为二"><a href="#2-4-1-一分为二" class="headerlink" title="2.4.1 一分为二"></a>2.4.1 一分为二</h4><p>世界是对立统一矛盾的，回答了事物发展过程的原因是什么的问题，揭示了发展的根源是事物内部的矛盾运动。矛盾就是对立统一，这告诉我们要坚持 一分为二、全面地看待问题。这一部分对应着 伟人三大绝学的《矛盾论》，后续章节详解。</p><h3 id="2-5-世界是可以认识与改造的"><a href="#2-5-世界是可以认识与改造的" class="headerlink" title="2.5 世界是可以认识与改造的"></a>2.5 世界是可以认识与改造的</h3><h4 id="2-5-1-学以致用"><a href="#2-5-1-学以致用" class="headerlink" title="2.5.1 学以致用"></a>2.5.1 学以致用</h4><p>世界是可以认识与改造的，告诉我们认识世界是为了改造世界，人的精力与时间都是有限的，学习要能致用、要能指导工作实践、要能对工作对生活对人生有价值，不然学习也是一种玩物丧志。这一部分对应着伟人三大绝学的《实践论》，后续章节详解。</p><h3 id="2-6-世界是由利益与价值驱动的"><a href="#2-6-世界是由利益与价值驱动的" class="headerlink" title="2.6 世界是由利益与价值驱动的"></a>2.6 世界是由利益与价值驱动的</h3><h4 id="2-6-1-利益、价值与面子"><a href="#2-6-1-利益、价值与面子" class="headerlink" title="2.6.1 利益、价值与面子"></a>2.6.1 利益、价值与面子</h4><p>世界是由利益与价值驱动的，利益与价值也是这个世界基本的运作规律，当然有些时候除了利益与价值还有国人的面子问题。这一部分对应着伟人三大绝学的《历史观》，后续章节详解。</p><h2 id="3-唯物辩证法"><a href="#3-唯物辩证法" class="headerlink" title="3. 唯物辩证法"></a><font color="#FF8C00">3. 唯物辩证法</font></h2><p>唯物辩证法由一个主义、两种观点、三个定律、四项思维以及五大范畴所组成，即：</p><ul><li><p>一个主义：世界是物质的</p></li><li><p>两种观点：世界是联系与发展的</p></li><li><p>三个定律：对立统一，质量互变，否定之否定</p></li><li><p>四项思维：归纳与演绎，分析与综合，抽象与具体，逻辑与历史</p></li><li><p>五大范畴：原因与结果，内容与形式，本质与现象，必然与偶然，可能与现实</p></li></ul><p>世界是物质的定义了唯物辩证法的 立场、观点与方法，辩证法是唯物的辩证法。联系与发展，告诉我们要以系统的观点看问题，以变化的观点看待问题。三大定律里对立统一规律是本质，质量互变规律是质与量的对立与统一，否定之否定规律是肯定与否定的对立与统一。而四项思维是四项对立与统一的关系，五大范畴是质与量的关系，因此唯物辩证法也可以认为是客观世界的联系与发展以及对立与统一的根本方法。</p><p>这一章节也被分散到 世界观，系统观，实践论、矛盾论、历史观里做了讲述，因此这里不再重复。</p><h2 id="4-实践论"><a href="#4-实践论" class="headerlink" title="4. 实践论"></a><font color="#FF8C00">4. 实践论</font></h2><p><strong>“纸上得来终觉浅，绝知此事要躬行“</strong>，实践是认识的来源、标准、动力与目的，从感性认识上升为理性认识是实践出真知，实践的观点是认识论的基本观点，认识与实践 的关系等同于 知与行的关系，如同“知行合一”的观点一样实践的观点也有三大层次：</p><ul><li><p>第一层是认识指导实践，比如以已往的经验、知识指导工作实践；</p></li><li><p>第二层次是：认识与实践是循环往复以至无穷的，实践认识再认识实践，事前调查研究，事后复盘总结；</p></li><li><p>第三层次是：坚持以上两种层次，做事有韧性；</p></li></ul><p>实践论也认为认识世界是为了改造世界，认识是人对客观事物的认识，只有解放思想才能实事求是，要根据客观事实，引出思想路线，提出方针政策才能把事情能做好。实践的观点也要求我们在工作中要“去粗存精，去伪存真，由此及彼，由表及里”， 才能将感性认识升级成理性认识，从而更好的指导实践。</p><h2 id="5-矛盾论"><a href="#5-矛盾论" class="headerlink" title="5. 矛盾论"></a><font color="#FF8C00">5. 矛盾论</font></h2><p>矛盾即对立统一，唯物辩证法里的三大规律里，否定与肯定是对立与统一，质与量也是对立与统一，因此对立统一规律是最为基本的规律。对立统一规律告诉我们要一分为二的看待问题，但是这个一分为二与系统论的一分为三，一分为多是有本质差别的，前者是质，后者是量。</p><h4 id="5-1-对立统一"><a href="#5-1-对立统一" class="headerlink" title="5.1 对立统一"></a>5.1 对立统一</h4><p>矛盾就是对立统一，更好理解一点可以将矛盾理解成 国人熟知的 “阴阳”， 阴阳是循环运动在一定的条件下变化发展的，矛盾的对立统一规律告诉我们做事要一分为二，要辩证的看待问题，不要非黑即白。</p><h4 id="5-2-普遍与特殊"><a href="#5-2-普遍与特殊" class="headerlink" title="5.2 普遍与特殊"></a>5.2 普遍与特殊</h4><p>矛盾的普遍性告诉我们事物是普遍矛盾存在的，问题也是普遍的，不同的人，不同的场景，不同的时空，矛盾都是普遍的。工作中觉得一这份工作不顺利，就想通过换工作来解决，但是矛盾的普遍性会告诉我们换了工作这个问题也许是解决了，但是新的问题一定会出现。矛盾的普遍性也决定了工作中员工有员工的难处，老板也有老板的难处，而且“钱多事少离家近，位高权重责任轻。睡觉睡到自然醒，数钱数到手抽筋” 这样的情况是基本上不可能会存在的。</p><p>矛盾的特殊性告诉我们做事具体问题要具体分析。以普遍打特殊或者以特殊打普遍，都必然会出问题。比如公司内政策是自带普遍属性的，但是不同的部门，不同的个人情况又是有特殊的，这就要求我们工作中要注意具体问题具体分析，不搞一刀切。</p><h4 id="5-3-不平衡"><a href="#5-3-不平衡" class="headerlink" title="5.3 不平衡"></a>5.3 不平衡</h4><p>矛盾的不平衡要求我们做事既要坚持重点论，又要坚持两点论，要用“弹钢琴”的手法来做事，有重按键，有轻按键，还要每个键都兼顾到，这样弹出来的才是美妙的音律。</p><p>坚持两点论和重点论相统一， 要求我们做事既要抓住主要矛盾 同时也要兼顾次要矛盾，在有限的资源下，要集中资源打歼灭战，打关键的卡脖子重点战，如果分散资源普遍开花只会得不偿失，或者达不到想要的效果。</p><p>矛盾的不平衡，也告诉我们工作中要抓重点带全局，稳定全局、重点突破、以点及面、梯度推进、波浪式前进。</p><h3 id="5-4-质量互变"><a href="#5-4-质量互变" class="headerlink" title="5.4 质量互变"></a>5.4 质量互变</h3><p>量变是重视量的积累，反对急于求成。质变是要果断抓住时机，实现事物的飞跃，也要坚持适度原则，不能随意造成质变。</p><p>质量互变，关键是度的达成，水在100°时会变成气态，在0°时会变成固态，条件达成才会触发质与量的互变。因此要想质与量发生互变，就要积累条件使之发生变化。</p><h3 id="5-5-否定之否定"><a href="#5-5-否定之否定" class="headerlink" title="5.5 否定之否定"></a>5.5 否定之否定</h3><p>否定之否定，维持自身为“肯定”，灭亡自身为“否定”。肯定与否定是对立与统一的，事物通过否定自我达成肯定自我，通过批评自我达成提升自我，因此我们工作过程中也要经常开展批评与自我批评，从而提升自我的工作能力。</p><p>新事物是从旧事物中通过否定自我来达成的，因此这也给我们工作中的创新提供了指导思想：需要从旧事物中进行否定从而获得新事物的肯定。</p><h2 id="6-历史观"><a href="#6-历史观" class="headerlink" title="6. 历史观"></a><font color="#FF8C00">6. 历史观</font></h2><h3 id="6-1-群众观"><a href="#6-1-群众观" class="headerlink" title="6.1 群众观"></a>6.1 群众观</h3><p>群众观是历史观的基本观点，走群众路线从群众中来才能形成正确的认识，到群众中去，才能将正确的认识转化成群众的行动。从群众中来，到群众中去，领导与群众相结合是集体组织工作的根本工作路线与方法。</p><p>群众观，告诉我们做事的时候，要走群众路线，关注群众观点，关注上情，也关注下情，通过<strong>民主集中制</strong>的原则，从群众中来到群众中去。事前调查研究、事中交换意见比较调整、事后复盘总结。</p><h3 id="6-2-利益观"><a href="#6-2-利益观" class="headerlink" title="6.2 利益观"></a>6.2 利益观</h3><p>物质利益是这个世界的最基本的驱动力之一，国家、集体、个人都有自己的利益述求。利益是引起一切社会冲突、组织冲突、个人冲突的最终根源也是社会历史发展的内在动因，人们通过追求利益促使社会历史不断前进。</p><p>如果不讲利益只讲道德与奉献，是犯了维心主义的主观错误，不符合客观实际、也不实事求是，但如果只讲利益而不讲道德与奉献，那是唯利是图，也不符合人的 真 善 美要求。</p><p>利益分析法也是基本的工作方法之一，在推动一项组织工作时，心里要清楚干系人的利益与立场，谁会支持、谁可能会反对、谁可能无所谓、谁可能会需要更多信息输入都要心里有数，支持的原因是什么，反对的原因是什么，无所谓的原因是什么，事前调查研究充分，事中交换意见比较调整，才能增加把事情做成的成功概率。</p><h3 id="6-3-价值观"><a href="#6-3-价值观" class="headerlink" title="6.3 价值观"></a>6.3 价值观</h3><p>价值分为两大类，事物的价值与人的价值。常见的价值可从以下五个维度划分：命、利、真、善、美。即保命的，满足物质利益的，求知求真的，道德向善与超我成圣的。</p><p>价值是客观的，事物的价值在工作中可以理解为产品的价值，产品要能给用户带来价值，能满足用户的需要，才具备价值。人的价值体现在工作中，本质上是价值的交换，企业给你发工资（价格），个人贡献你的价值，当价格匹配价值时就符合价值规律，当不匹配时时间一长就总有一方会感到不满。</p><p>价值也是主观的，会因人而已的，不同的时间、条件、环境下对于不同的人来说价值也会不尽相同，也会出现不断的变化。价值因人而异是十分常见的现象，价值评价标准是由价值制定阶层来决定的，带有人的好与恶，以及天然利于自我阶层的属性，而被评价阶层往往只能承受这个评价标准。</p><p>价值分析法也是基本的工作法之一。因此，工作中，要令价值评价尽量达到客观，就需要在评价前多做调查，多做研究，多交换意见，不以人的好恶为标准，而应该以客观事实为标准。</p><h3 id="6-4-社会存在与社会意识"><a href="#6-4-社会存在与社会意识" class="headerlink" title="6.4 社会存在与社会意识"></a>6.4 社会存在与社会意识</h3><p>一个组织内的高层人员有时会觉得执行人员缺乏全局观，而执行层又觉得高层们”肉食者鄙”。这是由其社会存在方式的差异所决定的，在生产过程中形成的位置的不同获得的信息也不同，自然看到的情况也不同。</p><p>社会存在决定社会意识，但社会意识也能反作用于社会存在。高层可以通过躬身实践获得更多的细节特殊性，而执行层也能通过学习以及请教获得更多的信息以及提升自己的全局观能力。</p><p>但，虽然社会意识也能反作用于社会存在，要改变自己的社会意识（认知），最主要的还是要改变自己的社会存在方式，毕竟，认识来自于实践。</p><h2 id="7-小结"><a href="#7-小结" class="headerlink" title="7. 小结"></a><font color="#FF8C00">7. 小结</font></h2><p>基于以上的五大哲学心法：世界观、辩证法、实践论、矛盾论、历史观。可知要做成事、做好事，首先要解放思想 、实事求是 、一切从客观实际出发、使主观符合客观，要全面 、本质、联系 、发展 、矛盾地看待问题与分析问题，工作上要走群众路线，抓重点带一般，抓普遍带特殊，抓整体带局部，看利益也看价值，具体问题具体分析，事前调查研究、事中交换意见比较调整、事后复盘总结，实践认识认识再实践如此循环往复以至无穷。</p><h2 id="8-作者简介"><a href="#8-作者简介" class="headerlink" title="8. 作者简介"></a><font color="#FF8C00">8. 作者简介</font></h2><p>常平，中科大硕，某AI芯片公司深度学习高级软件主管、架构师，前EMC资深首席工程师，主要工作背景在深度学习、Ai平台、系统调优、大数据、云计算以及Linux内核领域。邮箱：<a href="mailto:wu@changping.me" target="_blank" rel="noopener">wu@changping.me</a></p><h2 id="9-参考资料"><a href="#9-参考资料" class="headerlink" title="9. 参考资料"></a><font color="#FF8C00">9. 参考资料</font></h2><p>[1] 《新大众哲学》</p><p>[2] 《哲学思维方式与领导工作方法》</p><p>[3] 《遨游之舟》公众号</p><p>[4] 《毛选》</p><h2 id="10-版权申明"><a href="#10-版权申明" class="headerlink" title="10. 版权申明"></a><font color="#FF8C00">10. 版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p>]]></content>
      
      
      <categories>
          
          <category> ideology </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ideology </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>深度学习 - 第5篇 - 分布式训练服务框架基本原理与架构解析</title>
      <link href="/2022/04/17/ai_5/"/>
      <url>/2022/04/17/ai_5/</url>
      
        <content type="html"><![CDATA[<p>​                </p><h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a><font color="#FF8C00">1. 概述</font></h2><p>分布式训练服务框架与集合通信库的组合构成了分布式训练的整体服务软件栈，在第3篇、第4篇文章里已经剖析完集合通信的相关内容，而本文会以Horovod为例介绍数据并行下分布式训练服务框架的基本原理以及进行架构解析。当前，在分布式训练里分布式训练服务框架需要解决以下几个核心问题 ：</p><ul><li>计算与通信同步耦合问题：如果反向传播一产生一份梯度，就马上对其调用全局AllReduce，计算与通信同步耦合，容易造成死锁同时性能也会很不如意；</li><li>计算时间与通信时间串行问题：神经网络是分层的，梯度计算的过程是数据加载，然后前向传播算出损失值，再反向传播算出梯度，而反向计算时梯度是从输出层往输入层方向一层一层产生的，在有些模型里，如果需要等所有的梯度都计算完毕才能触发全局AllReduce，那么对性能的影响也会很大；</li><li>梯度生成的落后者问题：集群内每个计算节点的同一份梯度的产生不一定都是同一时刻的，如果梯度没有全部生成就发起对这个梯度的全局规约，否则容易造成训练出来的模型精度不达标或者不收敛的问题；</li><li>梯度融合问题：如果每一份梯度都触发一次全局AllReduce，在梯度Tensor较多的神经网络训练里，整体的训练系统性能会变得极低；</li><li>易用性问题：从TensorFlow，PyTorch迁移过来需要改的代码需要极少，从单卡训练迁移到多卡训练需要改动的代码也需要极少；</li><li>可移植问题：支持多种多样的深度学习训练框架，比如 TensorFlow、PyTorch、MxNet等，也能支持多种多样的通信库，比如openMPI、NCCL、Gloo、CCL、RCCL等；</li><li>可靠性问题：在集群训练的过程中网络时不可靠的、计算卡是会出故障的、服务器是会出故障的、系统软件也是会出Bug的，这些因素造成了分布式训练过程中还存在可靠性问题，如何解决这个问题也是一个难题。</li></ul><p>软件是由人实现的，解析一个软件系统最难的地方在于从庞杂的代码里倒推出背后实现它的人的设计意图，为了更好的理解Horovod，本文会基于以上这几个分布式训练的核心问题，以Horovod为例介绍分布式训练服务框架的基本原理以及进行架构解析。</p><h2 id="2-基础知识"><a href="#2-基础知识" class="headerlink" title="2. 基础知识"></a><font color="#FF8C00">2. 基础知识</font></h2><h3 id="2-1-单卡训练"><a href="#2-1-单卡训练" class="headerlink" title="2.1 单卡训练"></a>2.1 单卡训练</h3><p>神经网络的训练，本质上就是Y=F(x)的迭代，通过反复输入X、输出Y，使得神经网络的参数变化与输入输出间的复杂关系拟合。在神经网络训练的过程中，通过输入数据利用梯度下降的方法进行迭代从而优化神经网络参数，并最终输出神经网络模型。而神经网络可以看作一种运算模型，其由大量的神经元（节点）相互联接构成，其由输入层、隐藏层以及输出层组合而成（如下图左侧所示）。神经元(neuron)是神经网络的基本计算单元，也被称作节点(node)，它可以接受来自其他神经元或外部数据的输入，然后计算出一个输出（如下图右上角所示）。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/aitraining/5/image-framework-single-card.png" alt="单卡训练"></p><p>如上图右下角所示，在单卡训练迭代中，基于并行梯度下降法，会有以下操作：</p><p>第一步，读取部分数据，并且将数据加载进训练卡的存储空间；</p><p>第二步，对模型进行前向传播计算，从输入层往输出层一层一层的进行计算，得到损失差LOSS；</p><p>第三步，对模型进行反向传播计算，从输出层往输入层一层一层的进行计算，得到梯度值，注意这一步会把每一层都计算出一个梯度张量（Gradient Tensor）出来；</p><p>第四步，将新的到的梯度与部分数据 作为新的输入，重新开始以上步骤的迭代。</p><p>在这一步里有一个很重要的与性能优化相关的信息是反向传播是每一层输出一个梯度张量，以及反向传播是从输出层往输入层一层一层的进行计算的，这一点信息可以用通信隐藏性能优化与梯度融合优化。</p><h3 id="2-2-多卡训练"><a href="#2-2-多卡训练" class="headerlink" title="2.2 多卡训练"></a>2.2 多卡训练</h3><p>以数据并行随机梯度下降法( SGD )为例，多卡神经网络的训练过程如下图，与单卡训练相比，多卡训练多了梯度全局规约的过程：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/aitraining/5/image-framework-multi-card.png" alt="多卡训练"></p><p>第一步，通过Broadcast操作将第一个节点参数同步到集群内的所有的训练卡上，保证每个计算节点的初始参数是一致的，同时训练脚本在多个计算节点上运行，每个计算节点包含了整体的模型参数；</p><p>第二步，将数据样本切片分发到整个集群内的个计算节点（训练卡）上并且通过数据流水技术将数据样本加载进训练卡的高速内存空间内，作为输入X;</p><p>第三步，每个训练卡在其数据样本上运行前向传播，计算出损失差LOSSi；</p><p>第四步，对计算出的LOSSi进行反向传播，得到梯度GRADi，这一步也需要注意得是每一层都会计算出一个梯度，同时梯度是以输出的Tensor来表示的；</p><p>第五步，所有的训练卡计算出来的部分梯度，在主机内及主机之间通过集合通信进行全局归约(AllReduce)得到全局梯度；</p><p>第六步，最后再将这个全局梯度作为参数进行更新，再进行以上2-5步骤的迭代从而获得新的梯度。</p><p>以上2-6步骤就是多卡并行梯度下降的基本思想，即多个计算节点通过分片的数据样本进行梯度计算，得到分区梯度后，再通过全局梯度规约以及将这个聚合好的梯度作为新的参数进行更新，从而实现并行梯度下降。</p><h2 id="3-几个核心问题"><a href="#3-几个核心问题" class="headerlink" title="3. 几个核心问题"></a><font color="#FF8C00">3. 几个核心问题</font></h2><p>在本章节里会解读本文概述里提到的分布式服务框架需要解决的几个与性能、易用性等相关的几个核心问题，并且以Horovod为例讲述Horovod是如何解决这个几个难题的。</p><h3 id="3-1-计算与通信解耦"><a href="#3-1-计算与通信解耦" class="headerlink" title="3.1 计算与通信解耦"></a>3.1 计算与通信解耦</h3><p>在神经网络的训练过程中，每一神经网络层都会计算出一个梯度，同时梯度是以输出Tensor来表示的，如果反向传播一计算出一个梯度就马上调用通信去做梯度规约，将计算与通信同步耦合，那么整体的性能的表现就会很差。比如一个ResNet-50 v3的梯度张量个数是153个，如果一计算出一个梯度就马上进行通信，假设计算梯度花了1ms，通信这个梯度花了 500ms，那么这个过程就是 501ms，总体上就需要501x153 = 76653ms，即近76.6s才能完成一次梯度迭代。而将计算与通信解耦，计算的归计算，通信的归通信，通过性能优化策略减少通信的次数，既能提升整体训练性能也能避免某些死锁问题，比如计算梯度grad i的时候花了很长时间，而通信线程一直在等待这个梯度，表现出来就是死锁现象。</p><p>Horovod采用计算与通信分离的设计思想，解耦了计算过程与通信过程，从而提升了整体训练的性能与可靠性。如下图的Horovod逻辑架构图所示，从图中可以看出Horovod解耦了计算与通信，其将框架层计算出来的梯度request信息push 到一个消息队列message_queue里，同时将梯度信息push到一个Tensor_table里，再通过控制层在后台起一个loop线程，周期性的从消息队列里读取梯度消息，在控制层集群的节点之间协商达成一致后，再进行消息分发触发训练行为。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/aitraining/5/image-Horovod-architecture.png" alt="Horovod逻辑架构"></p><p>如上图可看出，Horovod从下到上分为7层：物理层、链路层、数据传输层、控制层、消息层、框架层以及用户层。框架层，控制层以及数据传输层体现了Horovod的核心设计理念，即：框架层，用户可以自定义Op，以插件的形式hack进框架；在控制层，worker节点与master节点之间协商达成触发训练行为的约定；在数据传输层，服务器内以及服务器之间采用集合通信库传输数据。</p><p>本质上Horovod的整体设计理念之一遵循的是生产者消费者模式，如下图所示：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/aitraining/5/image-horovod-msgqueue.png" alt="生产者-消费者"></p><p>在Horovod里每个计算节点都会有有两个核心线程：Execution thread 和 Background thread ：</p><ul><li>生产者Execution Thread 是用来做梯度计算的，在TensorFlow、PyTorch之类的之类的训练框架计算出梯度Tensor后，将Tensor 信息push进tenor_table队列，同时将Tensor的request信息push进message_queue队列;</li><li>消费者Background thread 是做集合通讯以及全局Allreduce的，后台线程会每隔一段时间轮询消息队列，拿到一批Tensor信息之后，会进行相应的操作。</li></ul><h3 id="3-2-通信隐藏"><a href="#3-2-通信隐藏" class="headerlink" title="3.2 通信隐藏"></a>3.2 通信隐藏</h3><p>神经网络是分层的，在训练的过程中，先是数据加载，然后前向传播算出LOSS，再反向传播算出梯度，而反向计算时梯度是从输出层往输入层方向一层一层产生的，如果需要等所有的梯度都计算完毕才能触发全局AllReduce，对性能不是很友好。如下图所示，计算时间与通信时间是串行的，如果能将全局梯度规约的通信时间与计算时间想办法并行起来，将通信时间隐藏在计算时间之内，那么就能节约梯度的训练时间从而提升分布式训练系统整体的训练性能。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/aitraining/5/image-wfbp-1.png" alt="通信隐藏"></p><p>如下图所示，将计算出来的梯度进行分桶触发异步Allreduce，一边反向传播计算梯度，一边做部分梯度的全局规约通信，从而达到将通信时间隐藏在计算时间内的效果。而Horovod为达成这一效果，Background thread 会每隔一段时间轮询梯度消息队列里的梯度信息，获取了可以过全局规约的梯度后，就进行全局规约操作，而这个时间其他的梯度还在计算过程中，通过调整轮询的时间间隔从而达到调整梯度分桶的效果。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/aitraining/5/image-wfbp-2.png" alt="通信隐藏"></p><h3 id="3-3-梯度协商"><a href="#3-3-梯度协商" class="headerlink" title="3.3 梯度协商"></a>3.3 梯度协商</h3><p>神经网络的每一层对应一个梯度Tensor，在分布式训练集群里每张训练卡对同一份梯度计算产生的时间是有差异的，当集群内每个计算节点的同一神经网络层的同一梯度都产生时，才能发起对这个梯度的全局AllReduce规约，否则容易造成丢梯度，训练出来模型精度不达标或者模型不收敛。比如在一个128卡的训练集群里，同一份梯度是对应同一个神经网络模型里的同一层神经网络的，只有每张训练卡上都计算出了同一层神经网络的梯度 才能对这一层神经网络的梯度进行全局规约，如下图所示：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/aitraining/5/image-grad-state-1.png" alt="梯度分层"></p><p>Horovod设计了一种梯度状态协商机制，它将 计算节点Rank0 作为coordinator（master），其余的rank1-N节点进程为worker，由coordinator来协商确定同一份梯度是否在每个计算节点上都已经计算出来，只有在每个计算节点上都计算出来的同一梯度才可以进行全局规约操作。在Horovod里每个计算节点上都有一个message_queue以及tensor_table，而在coordinator节点上除此之外，还有一个message_table用于保存可以进行全局Allreduce的梯度请求次数信息。Horovod 控制面的ComputeResponseList 函数里实现了这一梯度的协商过程，在从message_queue获取了本节点生成的梯度信息后，coordinator会与其他节点协商这个梯度是否都计算出来，这一过程是阻塞进行的，这个协商过程如下图：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/aitraining/5/image-grad-state-2.png" alt="梯度状态协商"></p><p>一个梯度是否能满足全局规约AllReduce的协商过程如下：</p><p>首先，集群内的每个计算节点进程都会往coordinator Rank0发送一个 tensor的请求request，表示说本节点这一层神经网络的梯度已经生成，比如tensor1，每个rank都会往rank0 发送一个本梯度tensor1已经计算出来的请求信息；</p><p>第二步，coordinator接收到节点的梯度协商请求后（包括本节点），会把收到的tensor请求次数进行累加，并将这个信息记录在message_table里，当这个梯度的请求信息达到集群内节点的个数时，比如在N个节点的集群，一个神经网络层的梯度tensor的通信请求出现了N次，那就表示在本集群里所有的计算节点都已经发出了对该梯度tensor的通信request，这就表明这个梯度tensor是符合全局规约要求的，就能进行集合通信全局规约，不符合要求的梯度tensor将继续留在message_table中，直到条件符合为止；</p><p>第三步，再接着coordinator会将满足全局allreduce规约条件的梯度Tensor通过response返回给其他节点，告诉其他节点这个梯度可以启动全局规约AllReduce。</p><p>经过这几步的协商达成梯度全局状态一致的目的，从而避免梯度丢失造成的模型精度不达标、不收敛或者进程死锁问题。</p><h3 id="3-4-梯度融合"><a href="#3-4-梯度融合" class="headerlink" title="3.4 梯度融合"></a>3.4 梯度融合</h3><p>神经网络的每一层都能对应一个梯度，假设每生成一个梯度就进行一次全局规约时，100个梯度就需要进行100次全局通信100次全局规约，而通信对训练的性能有巨大的影响，这种情况表现出来的效果就是分布式训练集群的整体性能极差。通过梯度融合计算将多个梯度合成一个，从而减少全局规约的次数能大幅提高分布式训练的训练性能，如下图所示，将N个小梯度Tensor合成两个，能将全局通信的次数减少到2次，从而大幅提升训练性能，在Horovod里这个功能对TensorFusion特性。但这个特性也会与<strong>3.2通信隐藏</strong>特性相冲突，需要根据具体情况进行合理的调试优化。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/aitraining/5/image-tensorfusion.png" alt="tensorfusion"></p><h3 id="3-5-易用性"><a href="#3-5-易用性" class="headerlink" title="3.5 易用性"></a>3.5 易用性</h3><p>从TensorFlow，PyTorch等框架迁移到Horovod需要改的的代码极少，horovod接入方式比较简单，与原生训练框架对比，主要的区别在于：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs undefined">1，初始化 Horovod，包括机器资源的分配：<br>horovod.init()<br><br>2，向每个进程分配XPU资源， 典型的设置是 1 个 XPU 一个进程，即设置 local rank：<br><br>config.gpu_options.visible_device_list = str(hvd.local_rank())<br><br>3，对原优化器进行包装，分布式优化器将梯度计算委托给原始优化器，使用allreduce或allgather对梯度求平均，然后应用这些平均梯度：<br><br>opt=hvd.DistributedOptimizer(opt)<br><br>4， 将初始化参数从rank 0广播给其他进程(rank表示进程序号)，实现参数的初始化，确保所有节点的初始化参数保持一致：<br>hvd.BroadcastGlobalVariablesHook(0)：<br></code></pre></td></tr></table></figure><h3 id="3-6-可移植"><a href="#3-6-可移植" class="headerlink" title="3.6 可移植"></a>3.6 可移植</h3><p>可移植问题，Horovod通过 OP和OpKernels的插件化机制支持多种多样的深度学习训练框架，比如 TensorFlow、PyTorch、MxNet等。基于的opKernels的可定制化机制，Horovod自定义了Op然后hack了数据链路层的通信协议，从而达到在多个深度学习框架之间可移植。</p><h3 id="3-7-可靠性问题"><a href="#3-7-可靠性问题" class="headerlink" title="3.7 可靠性问题"></a>3.7 可靠性问题</h3><p>在集群训练的过程中网络时不可靠的、计算卡是会出故障的、服务器是会出故障的的，这些因素造成了分布式训练过程中需要考虑训练集群的可靠性，Horovod结合集合通信库Gloo对外提供了弹性训练的特性，但可靠性不只是弹性训练就能完全解决的，它还有更多的系统级的问题需要解决，因此可靠性问题留着一个后续研究问题，不在本文阐述。</p><h2 id="4-优点缺点、改进点"><a href="#4-优点缺点、改进点" class="headerlink" title="4. 优点缺点、改进点"></a><font color="#FF8C00">4. 优点缺点、改进点</font></h2><p>选择一个框架也是辩证的，在获得它优点的同时也得接受它的缺点，Horovod的优点、缺点以及改进点描述如下：</p><h3 id="4-1-Horovod优点"><a href="#4-1-Horovod优点" class="headerlink" title="4.1 Horovod优点"></a>4.1 Horovod优点</h3><ul><li>简单易用、可移植，并且支持弹性训练提升了可靠性；</li><li>不依赖于某个框架，其通过MPI机制独立建立了一套分布式训练服务系统；</li><li>将计算与通信分离，完成了allreduce、allgather等集合通信工作，实现了规模可扩展；</li><li>巧妙的通过间隔轮询的机制支持通信时间隐藏，并且完成了梯度协商从而保证训练出来的模型是可收敛、精度达标的；</li><li>支持梯度融合，支持将小的tensor合并成一个大的tensor再进行通信传递，从而减小通信操作的额外开销；</li><li>自带压缩算法，可以减少集合通信的数据量；</li></ul><h3 id="4-2-Horovod的缺点"><a href="#4-2-Horovod的缺点" class="headerlink" title="4.2 Horovod的缺点"></a>4.2 Horovod的缺点</h3><ul><li>与GPU绑定，对新的训练加速设备的支持不够友好，缺乏设备插件化的机制，要添加一个新的训练加速设备比较困难；</li><li>所有的代码都与CUDA绑定，所有的性能优化机制都是针对GPU的，对新的DSA架构的芯片基本忽视；</li><li>弹性训练特性比较复杂，很难在生产上使用起来；</li><li>的Message_queue，Tensor_table缺乏容错机制，如果丢失数据容易造成丢tensor，从而影响整体模型的收敛与精度；</li></ul><h3 id="4-3-Horovod的改进点"><a href="#4-3-Horovod的改进点" class="headerlink" title="4.3 Horovod的改进点"></a>4.3 Horovod的改进点</h3><ul><li>简单易用的插件化支持新的训练芯片；</li><li>即支持SIMT架构芯片的性能优化，也支持DSA架构的芯片性能优化；</li><li>支持消息队列、张量表的容错，支持Rank 0 容错机制；</li></ul><h2 id="5-思考题"><a href="#5-思考题" class="headerlink" title="5. 思考题"></a><font color="#FF8C00">5. 思考题</font></h2><ul><li>问题1，将通信时间隐藏在计算时间内能有助于提升训练系统的整体性能，但这一特性是针对SIMT芯片的架构的进行性能优化的，如果DSA芯片不能支持这一特性，那应该如何优化Horovod从而大幅提升整体的训练性能？（可以确定这一定是能做到的）</li><li>问题2，梯度协商的过程中，每个梯度都需要协商一次，在梯度较多，网络规模较大的集群里，这一特性也会影响性能，如何进行优化才能有效提升Horovod性能？</li><li>问题3，不同的模型对梯度融合有不同的要求，那么梯度融合需要融合到什么程度才能有效提升性能？</li></ul><p>可以说明的是，这三个问题解决后还能继续提升Horovod在DSA架构芯片上的整体的分布式训练系统级性能。</p><h2 id="6-小结"><a href="#6-小结" class="headerlink" title="6. 小结"></a><font color="#FF8C00">6. 小结</font></h2><p>本文介绍了分布式训练的基础知识以及剖析了分布式训练服务框架所面临的几个核心问题，以Horovod为例从计算与通信解耦、通信隐藏、梯度协商、梯度融合、易用性以及可移植这几个角度倒推了分布式训练服务框架背后的设计意图，从而帮助大家能更好的理解分布式训练服务框架。</p><p>日拱一卒，功不唐捐，分享是最好的学习，与其跟随不如创新，希望这个知识点对大家有用。另作者能力与认知都有限，”我讲的，可能都是错的“，欢迎大家拍砖留念。</p><h2 id="7-作者简介"><a href="#7-作者简介" class="headerlink" title="7. 作者简介"></a><font color="#FF8C00">7. 作者简介</font></h2><p>常平，中科大硕，某AI芯片公司深度学习高级软件主管、架构师，前EMC资深首席工程师，主要工作背景在深度学习、Ai平台、系统调优、大数据、云计算以及Linux内核领域。</p><h2 id="8-参考资料"><a href="#8-参考资料" class="headerlink" title="8. 参考资料"></a><font color="#FF8C00">8. 参考资料</font></h2><p>[1] <a href="https://www.changping.me">https://www.changping.me</a><br>[2] <a href="https://horovod.ai" target="_blank" rel="noopener">https://horovod.ai</a><br>[3] <a href="https://www.cnblogs.com/rossiXYZ/p/14910959.html" target="_blank" rel="noopener">https://www.cnblogs.com/rossiXYZ/p/14910959.html</a><br>[4] <a href="https://zhuanlan.zhihu.com/p/374575049" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/374575049</a></p><h2 id="9-版权申明"><a href="#9-版权申明" class="headerlink" title="9. 版权申明"></a><font color="#FF8C00">9. 版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>深度学习 – 第4篇 - 分布式训练常用的网络结构及集合通信拓扑算法</title>
      <link href="/2022/04/10/ai_4/"/>
      <url>/2022/04/10/ai_4/</url>
      
        <content type="html"><![CDATA[<h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a><font color="#FF8C00">1. 概述</font></h2><p>在深度学习的分布式训练里，Ring AllReduce拓扑算法奠定了数据并行训练的集合通信基础，但集合通信拓扑不只是仅有Ring Allreduce，经典的集合通信拓扑算法还有2D-Ring/Hierarchical Ring AllReduce，halving and doubling AllReduce，Butterfly AllReduce，2D-Torus AllReduce，2D-Mesh AllReduce，double binary tree等。拓扑算法很多，但也不是所有的拓扑算法都能满足实际的生产需求的，这需要具体问题具体分析、具体场景具体设计。</p><p>集合通信的难点在于需要在固定的网络互联结构的约束下进行高效的通信，集合通信拓扑算法与物理网络互联结构强相关，为了发挥网络通信的效率，也不是说就能随意发挥通信拓扑算法，更多的是在效率与成本、带宽与时延、客户要求与质量、创新与产品化等之间进行合理取舍。</p><p>充分发挥训练加速卡与网络的效率是通信拓扑算法的初衷，但除了设计高效的集合通信拓扑算法外，分布式训练中需要解决的通信难题还有：网络是异构的，网络带宽是有限的，主机内PCIE SWITCH是有亲和性的，网络是会出故障的，节点是有落后者效应的，设备成本是需要考虑的，数据中心是有部署约束的，用户是有多租户要求的等，这些属于产品化的范畴不在本文阐述。</p><h2 id="2-网络互联结构"><a href="#2-网络互联结构" class="headerlink" title="2. 网络互联结构"></a><font color="#FF8C00">2. 网络互联结构</font></h2><p>分布式训练的集合通信拓扑算法与物理的网络互联结构强相关，而网络互联结构又多种多样，因此，本文需要先对网络互联结构进行约束，依据生产中常用的、既定的互联结构设计集合通信算法，网络互联结构描述如下：</p><h3 id="2-1-服务内网络互联结构"><a href="#2-1-服务内网络互联结构" class="headerlink" title="2.1 服务内网络互联结构"></a>2.1 服务内网络互联结构</h3><p>以一台集成了8张训练加速卡的服务器为例，如下图:</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/aitraining/4/image-nvlink.png" alt="服务器内互联结构"></p><center>图片来源于《volta-architecture-whitepaper》，版权归原作者所有</center><p>这台服务器内的网络互联情况如下：</p><p>1）在这台服务器内，8张训练加速卡通过私有协议连接组成多个主机内的物理ring环，且可双工；</p><p>2）服务期内网络带宽 NVLINK&gt;PCIE switch &gt; QPI；</p><p>3）加速卡1、2、3、4之间两两全互联，加速卡5,、6、7、8之间两两全互联，2、5、3、8之间非全互联；</p><p>4）加速卡1、4与网卡NIC1 挂在同一个PCIE Switch上，具有亲和性，加速卡2、3与网卡NIC2挂在同一个PCIE Switch上，具有亲和性，而PCIE Switch之间也互联，因此 加速卡 1、2、3、4 与网卡NIC 1、NIC2具备亲和性，它们无需通过CPU的QPI线进行通信；</p><p>5）加速卡5、8与网卡NIC3 挂在同一个PCIE Switch上，具有亲和性，加速卡6、7与网卡NIC4挂在同一个PCIE Switch上，具有亲和性，而PCIE Switch之间也互联的，因此 加速卡 5、6、7、8 与网卡NIC 3、NIC4具备亲和性，它们也无需通过CPU的QPI线进行通信；</p><p>6）网卡可根据需要 选择 1张、2张、4张或8张，最多可以采用8张RDMA物理网卡；</p><h3 id="2-2-服务器间网络互联结构"><a href="#2-2-服务器间网络互联结构" class="headerlink" title="2.2 服务器间网络互联结构"></a>2.2 服务器间网络互联结构</h3><p>以一个训练加速卡集群为例，如下图是一个常用的CLOS互联架构方案：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/aitraining/4/image-net-topo.png" alt="整体网络拓扑结构"></p><p>在这个集群内，其网络互联情况如下：</p><p>1）集群内每台服务器自带高速RDMA网卡，通过RDMA 交换机在主机间两两全互联；</p><p>2）交换机组成CLOS架构，分为Spine与Leaf交换机，当然也可以是更为高端的Spine、Leaf合一的高端交换机；</p><p>3）RDMA网卡与Leaf交换机互联，每台服务器的RDMA网卡数量根据成本与性能考虑，可以是1张、2张+每卡虚拟化4卡、4张+每卡虚拟化2卡或8张；</p><h3 id="2-3-高速网卡及其虚拟化使用"><a href="#2-3-高速网卡及其虚拟化使用" class="headerlink" title="2.3 高速网卡及其虚拟化使用"></a>2.3 高速网卡及其虚拟化使用</h3><p>RDMA网卡是双工的且可虚拟化，在这里每台服务器可根据成本、性能的考虑选用1张、2张、4张或8张，且在服务器内左右对称，如下图：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/aitraining/4/image-net-nic.png" alt="网卡配置"></p><p>从成本与效率的角度考虑，每台服务器内的网卡可以是以下配置：</p><ul><li>1张物理RDMA网卡，不进行虚拟化，直接用双工通道，适合选用2D/Hierarchical Ring拓扑算法；</li><li>2张物理RDMA网卡，可以每张虚拟化出4个虚拟网卡，2X4共8卡，适合选用2D-MESH、2D-Torus拓扑算法；</li><li>4张物理RDMA网卡，可每张虚拟化出2个虚拟网卡，4X2共8卡，适合选用2D-MESH、2D-Torus拓扑算法；</li><li>8张物理RDMA网卡，不需要虚拟化，直接采用双工通道，适合选用2D-MESH、2D-Torus拓扑算法；</li></ul><p>在实际的分布式训练生产集群中，集合通信算法也可以结合RDMA网卡端口（包括虚拟化的）的具体个数进行设计，而拓扑算法的选择也是需要根据成本与效率的进行合理取舍的。</p><h3 id="2-4-网络结构抽象"><a href="#2-4-网络结构抽象" class="headerlink" title="2.4 网络结构抽象"></a>2.4 网络结构抽象</h3><p>网络根据连接情况可分为ring结构、mesh结构、 torus 结构以及tree结构，基于以上的服务器内网络互联结构、服务器间网络互联结构以及网卡的具体情况，可以抽象出一个网络结构，即二维环面网络：Torus 网络，而Torus网络横向与纵向都可以看成ring结构，因此相应的拓扑算法基本上就是Ring-Based 集合通信拓扑算法。如下图：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/aitraining/4/image-2dtorus-logictopo.png" alt="Torus网络结构"></p><p>TORUS网络是常见的大规模并行计算机的互连网络，在上图这个Torus网络里：</p><p>1）横向：主机内8卡通过私有连接协议，比如CXL/CCIX/NVLINK等组成一个或多个ring，如上图的黄色连接线，横向8卡组成二维Torus的横向维度；</p><p>2）纵向：主机间通过RDMA（RoCE/IB）网卡、交换机互联组成1到8个ring，如上图的红色连接线，纵向采用RDMA网卡组成二维Torus的纵向维度；</p><p>3）根据物理网卡数量、网卡虚拟化以及PCIe Switch亲和性的实际情况：</p><ul><li>每台服务器1张网卡可组成主机间一个ring，网卡与XPU0 挂载同一个PCIE switch上，依据最佳实践原则（比如性能、成本、客户要求等），适合选用2D/Hierarchical Ring拓扑算法；</li><li>两张网卡可组成主机间两个ring或者经过虚拟化组成8个ring，根据PCIE SWITCH亲和性原则，一张网卡与XPU0挂在同一个pcie switch，另一张网卡与XPU4挂在同一个pcie switch，依据最佳实践原则（比如性能、成本、客户要求等），适合选用2D-MESH、2D-Torus拓扑算法；</li><li>4张网卡、8张网卡以此类推，也是根据PCIE SWITCH亲和性原则进行连接，主机间RDMA物理网卡不够就虚拟化网口来凑，并且要服务器内的RDMA出口端口数左右平衡，依据最佳实践原则（比如性能、成本、客户要求等），也是适合选用2D-MESH、2D-Torus拓扑算法，这样才能发挥多张网卡以及XPU的算力优势。</li></ul><p>4）更复杂的Torus网络组合关系还可以如下图，从横向只有 主机内的8卡纵向只有主机间的RDMA互联，扩展到 横向与纵向 主机内互联与主机间互联混合，但本文仅限于在横向8卡的二维Torus网络下进行拓扑算法选择与设计，因此不展开讲述。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/aitraining/4/image-torus-topo.png" alt="Torus网络结构"></p><h2 id="3-常用的通信拓扑算法"><a href="#3-常用的通信拓扑算法" class="headerlink" title="3. 常用的通信拓扑算法"></a><font color="#FF8C00">3. 常用的通信拓扑算法</font></h2><p>Torus 网络结构可以解读本文中的物理网络互联结构的一切，而Torus网络的横向与纵向都可以看成ring结构，因此，相应的集合通信拓扑算法都可以看成是Ring-Based 集合通信拓扑算法。</p><h3 id="3-1-Ring-AllReduce"><a href="#3-1-Ring-AllReduce" class="headerlink" title="3.1 Ring AllReduce"></a>3.1 Ring AllReduce</h3><p>在分布式训练中，Ring 是最基础的互联结构，在本文中Ring AllReduce的应用场景是在服务器内将8张加速卡组环通信进行分布式训练。每个XPU都是这个主机内互联环上的一个计算节点，每个节点都有一个前向和一个后向，它只会向它的前向接收数据，并向它的右向发送数据，如下图所示，8张XPU 通过主机内的私有互联网络组成一个环，当然因为这些通信网络是双工的，这8张XPU训练加速卡也可以看成是通过多个逻辑环互联起来的，同时缺点是，如果这个ring太大，Ring Allreduce的效率也会变得很低。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/aitraining/4/image-ring-topo.png" alt="ring拓扑"></p><p>Ring Allreduce 有两种组合实现策略：1）先Reduce后broadcast；2）先ScatterReduce后AllGather，这两个策略执行后都会让每个XPU节点得到一样的平均梯度，如下图所示：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/aitraining/4/image-allreduce.png" alt="allreduce"></p><h4 id="3-1-1-Reduce-broadcast"><a href="#3-1-1-Reduce-broadcast" class="headerlink" title="3.1.1 Reduce +broadcast"></a>3.1.1 Reduce +broadcast</h4><p>在Reduce + broadcast里，reduce先将8张卡的梯度reduce sum到master节点 XPU0 上，再通过broadcast将这个总的平均梯度复制给其他XPU，如下图：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/aitraining/4/image-ring-reducebroadcast.png" alt="ring reduce broadcast"></p><p>Reduce + broadcast这种策略有几个比较大的缺点：1）8张卡的数据都reduce sum到一张卡，假设每张卡的梯度是100MB，8张卡就是800MB，这可能存在XPU 0计算很久，而其他7张卡空闲的情况存在，整体效率不高；2）XPU0 的网络带宽可能会成为瓶颈，8张卡的数据都只能通过XPU0的互联网络进行reduce和broadcast，在数据量比较大的场景 XPU0的带宽成为瓶颈；3）8张XPU不都是两两全互联的，因此，要把8张卡的数据一次Reduce或broadcast，这一点受限于网络互联条件做不到，那么就需要采用 ring或tree的策略进行reduce或broadcast，这样效率也不高。</p><h4 id="3-1-2-ScatterReduce-AllGather"><a href="#3-1-2-ScatterReduce-AllGather" class="headerlink" title="3.1.2 ScatterReduce + AllGather"></a>3.1.2 ScatterReduce + AllGather</h4><p>Ring AllReduce 的Ring ScatterReduce + Ring AllGather策略组合里，每个 XPU只会从前向接受数据，并发送数据给后向，其算法主要分为：</p><ul><li>ScatterReduce：这一步会先scatter拆分数据块再进行reduce，并且在执行完毕后，每张XPU都会包括一个完整的经过融合的同维梯度；</li><li>AllGather：这一步会进行全局Gather同步，最后所有 XPU都会得到完整的大的整个梯度；</li></ul><p>Ring ScatterReduce + Ring AllGather是效率比较高的 Ring AllReduce 组合策略，这个策略考虑到了XPU上的梯度可能很大的情况，比如一个梯度有400MB，在scatterreduce阶段就会先被拆分成 ring上XPU个数份，比如主机内XPU个数等于8，那么 这400MB 就会被 拆分成8份，每份50MB，从而减少了加速卡的计算量以及节约带宽。此外，scatterReduce通过将数据拆分成小块，同时并发进行scatterReduce，从而将通信时间隐藏在计算时间内进而提高Ring AllReduce的效率。</p><h5 id="3-1-2-1-ScatterReduce"><a href="#3-1-2-1-ScatterReduce" class="headerlink" title="3.1.2.1 ScatterReduce"></a>3.1.2.1 ScatterReduce</h5><p>首先， ScatterReduce先将梯度拆分为N个更小的块，N等于ring里XPU个数，8张卡就拆分成8份，然后进行N-1次scatterreduce迭代。在第一轮迭代中XPU 0上的A0传递给XPU1上A1并相加，XPU1上的B1传递给XPU2上的B2并相加，XPU 2上的C2传递给XPU3上C3并相加，XPU3上的D3传递给XPU4上的D4并相加，以此类推，过程如下图左侧：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/aitraining/4/image-ring-scatterreduce.png" alt="ring acatterreduce"></p><p>接下来，XPU还会进行N-2次 ScatterReduce 迭代，在每次迭代过程中，XPU都会从前向接收一个小梯度块并累加到自己的梯度块中，并且也会向其后向发送一个小梯度块，每个XPU接收和发送的小梯度块在每次迭代中都是不同的，这样经过迭代，到最后，每个XPU将有一个完整的同维梯度，该块梯度中包含所有XPU中该块对应的所有梯度的总和，如上图右侧的累加和部分。</p><h5 id="3-1-2-2-Allgather"><a href="#3-1-2-2-Allgather" class="headerlink" title="3.1.2.2 Allgather"></a>3.1.2.2 Allgather</h5><p>在scatterReduce迭代完成之后，每个XPU都会得到一个同维度的完整的梯度累加值，将这些完整的累加值复制到其他的加速卡后，才算完成allReduce。Allgather的迭代次数与scatterReduce是相同的，也都需要进行N-1次（N是ring上的XPU卡数）迭代，但是不同于ScatterReduce的是allGather没有reduce的过程，只有数值的复制。这样迭代到最后，每个XPU都得到大的拆分前的梯度的完整累加值，如下图演示了这一过程，从第一次迭代开始，到最后AllGather拿到整体的结果。这里头的具体过程就不在这里描述了，可以查相关资料。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/aitraining/4/image-ring-allgather.png" alt="image-20220409203458896"></p><p>Ring AllReduce 实现简单，在ring较少时，效率也较高，但是在ring比较大时需要的网络节点跳数变得比较大，通信时延增加，因此效率也会降低。比如，一个1000张XPU的 ring，这里头网络的跳数 是N-1= 1000-1 =999， 同时传输的过程中，传输效率还受效率最低、带宽最低的XPU的限制，这时网络上的时延会变得巨高，这个时候ring allreduce拓扑算法就变得不大适用这个场景，同时如果在异构网络里涉及网络的不同连接方式，Ring AllReduce也不大适合使用，因此就需要采用另外的更适合网络结构的更高效的集合通信拓扑算法来进行优化。</p><h3 id="3-2-2D-Ring-AllReduce"><a href="#3-2-2D-Ring-AllReduce" class="headerlink" title="3.2 2D-Ring AllReduce"></a>3.2 2D-Ring AllReduce</h3><p>如果一台2.1里的服务器只配置了一张RDMA网卡，每台服务器通过RDMA交换机互联，这个集群的网络是异构的（如下图），那么Ring AllReduce拓扑算法就不适用了，这个时候，对于这个网络拓扑结构比较适合的是2D-Ring AllReduce也叫Hierarchical Ring AllReduce。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/aitraining/4/image-2dring-topo.png" alt="2D-RING 拓扑"></p><p>经过抽象，可以将这个网络结构表达成如下的Torus结构：</p><p>横向：每台服务器8个XPU节点，每个XPU节点通过私有协议网络互联；</p><p>纵向：每台服务器通过一张RDMA网卡NIC 0 通过交换机互联，这个网卡NIC0 与XPU0 挂在同一个PCIE switch上，满足具备亲和性条件，XPU0上的梯度可以通过NIC 0 与其他服务器上的XPU进行全局规约。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/aitraining/4/image-2dring-topo-1.png" alt="2D-RING TOPO"></p><p>2D-Ring AllReduce的过程如下图所示：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/aitraining/4/image-2dring.png" alt="2D-RING allreduce"></p><p>第1步，先进行主机内Ring AllReduce，也可以是 Ring Reduce或者根据主机内的互联情况选用的分层reduce方式，将8张卡上的梯度累加到Master节点 XPU0 上；</p><p>第2步，进行主机间XPU 0的 Ring AllReduce，将每台服务器的XPU0上的数据进行全局规约；</p><p>第3步，进行主机内Broadcast，将XPU0上的梯度复制到服务器内的其他XPU上</p><p>2D-Ring AllReduce能充分发挥异构网络的优势，将主机内、主机间的网络带宽充分利用起来。但是XPU的利用率也不是很高，比如在做主机间的Ring AllReduce，每台服务器内的其他7张XPU是处于空闲状态的。</p><p>再假设，如果每台服务器配置了 2张/4张/8张RDMA网卡，这个时候 2D-RING AllReduce又难以将网络的优势发挥出来，那么就需要选用 2D-Torus/2D-Mesh AllReduce拓扑算法。</p><h3 id="3-3-2D-Torus-AllReduce"><a href="#3-3-2D-Torus-AllReduce" class="headerlink" title="3.3 2D-Torus AllReduce"></a>3.3 2D-Torus AllReduce</h3><p>考虑到服务器内PCIE SWITCH 的亲和性问题，2D-Torus至少需要配备2张 左右对称的RDMA网卡才能发挥这个拓扑算法的优势。在这个集群里主机内每张卡都通过私有的通信协议组成Ring，而主机间，可以通过RDMA网卡（包括虚拟化出来的）与RDMA交换机将XPU两两互联，这个网络也是异构的，如下图所示：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/aitraining/4/image-2dmesh-topo.png" alt="设备互联拓扑"></p><p>经过抽象，可以将这个网络结构表达成如下的Torus结构：</p><ul><li>横向：每台服务器8个XPU节点，每个XPU节点通过私有协议网络互联；</li><li>纵向：每台服务器通过至少2张RDMA网卡NIC 0 /NIC 1通过交换机互联，这个网卡NIC0 与XPU0、1、2、3 挂在同一个PCIE switch上，具备亲和性条件，XPU0、1、2、3上的梯度数据可以通过NIC 0 与其他服务器上的XPU进行交换。网卡NIC1 与XPU4、5、6、7 挂在同一个PCIE switch上，具备亲和性条件，XPU4、5、6、7上的梯度数据可以通过NIC 1 与其他服务器上的XPU进行交换；</li><li>当然如果网卡是4个或者8个，也可以根据PCIE SWITCH的亲和性情况合理安排XPU与NIC的对应关系。</li></ul><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/aitraining/4/image-2d-logictopo.png" alt="2D 拓扑"></p><p>2D-Torus AllReduce的过程如下图所示：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/aitraining/4/image-2dtorus-allreduce.png" alt="2dtorus allreduce"></p><p>第1步，横向，先进行主机内Ring ScatterReduce，将主机内8张卡上的梯度进行拆分与规约，这样经过迭代，到最后每个XPU将有一个完整的同维梯度，该块梯度包含所有XPU中该块所对应的所有梯度的总和（参考3.1.2.1 scatterReduce)</p><p>第2步，纵向，进行主机间N个（N等于服务器内XPU个数，这里是8个）纵向的 Ring AllReduce，将每台服务器的XPU0-XPU7上的数据进行集群内纵向全局规约；</p><p>第3步，横向，进行主机内AllGather，将XPUi(i=0-7)上的梯度复制到服务器内的其他XPU上；</p><p>2D-Torus AllReduce能充分挖掘XPU的效率以及发挥异构网络里多网卡的优势，将XPU以及主机内、主机间的网络带宽优势充分利用起来。此外，除了 2D-Torus AllReduce外，2D-Mesh AllReduce也能发挥类似效率。</p><h3 id="3-4-2D-Mesh-AllReduce"><a href="#3-4-2D-Mesh-AllReduce" class="headerlink" title="3.4 2D-Mesh AllReduce"></a>3.4 2D-Mesh AllReduce</h3><p>2D-Mesh AllReduce的主要思想也是分层，与2D-Torus AllReduce类似，都是水平和垂直两个方向，但是有点差异，如下图所示：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/aitraining/4/image-2dmesh-allreduce.png" alt="2D-MESH allreduce"></p><p>不同于2D-Torus AllReduce的拓扑算法，2D-Mesh AllReduce 过程是：</p><p>第1步，横向，先进行主机内Ring AllReduce 将主机内的8张XPU的梯度都进行规约；</p><p>第2步，纵向，进行主机间N个（N等于主机内XPU个数，这里是8个）纵向的 Ring AllReduce；</p><p>经过这两步，完成了整体的梯度累加，2D-Mesh AllReduce 也能充分发挥XPU与多网卡异构网络的优势，将XPU与主机内、主机间的网络带宽优势充分利用起来。这里的2D-Mesh与Google论文上的有点差异，主要是吸取了其分层的思想而不是复制其一样的设计。理论上2D-Mesh AllReduce对比 2D-Torus AllReduce，主机间AllReduce用的是 主机内8卡的全局梯度，数据量会比ScatterReduce部分来的大点，因此效率也会相应降低一点。</p><h2 id="4-问题探讨"><a href="#4-问题探讨" class="headerlink" title="4. 问题探讨"></a><font color="#FF8C00">4. 问题探讨</font></h2><p>如下图所示，基于Torus网络的结构，组合Ring AllReduce，2D-Ring AllReduce, 2D-Mesh AllReduce，2D-Torus AllReduce还能构建 3D-Ring/Mesh/Torus AllReduce拓扑算法，但是这些拓扑算法的效率需要进行实践才能证实，也许在规模较大的集群里才能发挥出3D 拓扑算法的优势。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/aitraining/4/image-2dtorus-logictopo.png" alt="2D-Torus拓扑"></p><p>关于 3D-Ring/Mesh/Torus AllReduce的拓扑算法，这里就不在阐述，可作为研究使用。</p><h2 id="5-小结"><a href="#5-小结" class="headerlink" title="5. 小结"></a><font color="#FF8C00">5. 小结</font></h2><p>本文讲述了分布式训练里最常用的几个网络结构以及通信拓扑算法：</p><ul><li>Ring AllReduce 的最佳组合是 ScatterReduce + AllGather；</li><li>2D-Ring AllReduce = 主机内 ringAllReduce/Ring Reduce +主机间 RingAllReduce + 主机内Broadcast；</li><li>2D-Torus AllReduce = 主机内 Ring ReduceScatter + 主机间N个Ring AllReduce + 主机内Ring AllGather；</li><li>2D-Mesh AllReduce = 主机内Ring AllReduce + 主机间N个Ring AllReduce;</li></ul><p>Ring AllReduce适合主机内互联Ring的情况使用，2D-Ring AllReduce适合一台服务器配置了一张网卡的异构网络场景，2D-Torus AllReduce与2D-Mesh AllReduce适合一台服务器配置了2/4/8张网卡的异构网络场景。</p><p>集合通信拓扑算法多种多样，但基于成本以及效率的取舍考虑，可生产适用的其实也不多，除了理论上的理解之外更重要的是自己编写代码去实践落地。除此之外，还需要解决网络带宽有限、网络容易出故障、落后者效应、部署约束、多租户等产品化的质量要求。日拱一卒，功不唐捐，分享是最好的学习，与其跟随不如创新，希望这个知识点对大家有用。另作者能力与认知都有限，”我讲的，可能都是错的“，欢迎大家拍砖留念。</p><h2 id="6-作者简介"><a href="#6-作者简介" class="headerlink" title="6. 作者简介"></a><font color="#FF8C00">6. 作者简介</font></h2><p>常平，中科大硕，某AI芯片公司深度学习高级软件主管、架构师，前EMC资深首席工程师，主要工作背景在深度学习、Ai平台、系统调优、大数据、云计算以及Linux内核领域。</p><h2 id="7-参考资料"><a href="#7-参考资料" class="headerlink" title="7. 参考资料"></a><font color="#FF8C00">7. 参考资料</font></h2><p>[1]  <a href="https://www.changping.me">https://www.changping.me</a></p><p>[2] 《volta-architecture-whitepaper》</p><p>[3]  2D-HRA: Two-Dimensional Hierarchical Ring-based All-reduce Algorithm in Large-Scale  Distributed Machine Learning</p><p>[4]  Massively Distributed SGD:  ImageNet/ResNet-50 Training in a Flash</p><p>[5]  <a href="https://zhuanlan.zhihu.com/p/79030485" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/79030485</a> , 腾讯机智团队分享–AllReduce算法的前世今生</p><p>[6]   <a href="https://zhuanlan.zhihu.com/p/370548366" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/370548366</a>,  ring allreduce和tree allreduce的具体区别是什么？</p><p>[7]   <a href="https://zhuanlan.zhihu.com/p/184942777" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/184942777</a> ,  分布式深度学习初探</p><p>[8]   <a href="https://arxiv.org/abs/1811.06992" target="_blank" rel="noopener">https://arxiv.org/abs/1811.06992</a> ， Image Classification at Supercomputer Scale</p><h2 id="8-版权申明"><a href="#8-版权申明" class="headerlink" title="8. 版权申明"></a><font color="#FF8C00">8. 版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>深度学习 – 第3篇 - 分布式训练集合通信及其通信原语</title>
      <link href="/2022/04/04/ai_3/"/>
      <url>/2022/04/04/ai_3/</url>
      
        <content type="html"><![CDATA[<h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a><font color="#FF8C00">1. 概述</font></h2><p>集合通信（Collective Communications）是一个进程组的所有进程都参与的全局通信操作，其最为基础的操作有 发送send、接收receive、复制copy、组内进程栅障同步Barrier以及节点间进程同步(signal +wait )，这几个最基本的操作经过组合构成了一组通信模板也叫通信原语，比如：1对多的广播broadcast、多对1的收集gather、多对多的收集all-gather、1对多的发散scatter、多对1的规约reduce、多对多的规约all-reduce、组合的规约与发散reduce-scatter、多对多的all-to-all等，集合通信的难点在于通信效率以及网络硬件连接拓扑结构的最佳适用。</p><h2 id="2-通信原语"><a href="#2-通信原语" class="headerlink" title="2. 通信原语"></a><font color="#FF8C00">2. 通信原语</font></h2><p>以一台集成了4张训练加速卡的服务器为例，如下图，服务器内四张训练加速卡是全连接的，物理连接方式可以是私有物理互联协议，比如CXL、NVLINK，也可以是PCIe、InfiniBand、Ethernet等，本文将以此物理拓扑结构描述集合通信中常用的几组通信原语。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/aitraining/3/image-connect-topo.png" alt="image-connect-topo"></p><h3 id="2-1-Broadcast"><a href="#2-1-Broadcast" class="headerlink" title="2.1 Broadcast"></a>2.1 Broadcast</h3><p>Broadcast属于1对多的通信原语，一个数据发送者，多个数据接收者，可以在集群内把一个节点自身的数据广播到其他节点上。如下图所示，圈圈表示集群中的训练加速卡节点，相同的颜色的小方块则代表相同的数据。当主节点 0 执行Broadcast时，数据即从主节点0被广播至其他节点。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/aitraining/3/image-broadcast.png" alt="image-20220404193446314"></p><p>Broadcast是数据的1对多的同步，它将一张XPU卡上的数据同步到其他所有的XPU卡上，其应用场景有：</p><p>1）数据并行的参数初始化，确保每张卡上的初始参数是一致的；</p><p>2）allReduce里的 broadcast + reduce组合里的broadcast操作；</p><p>3）分布式训练parameter server 参数服务器结构里的 master节点 broadcast 数据到worker节点，再从worker节点reduce数据回master节点里的broadcast操作；</p><h3 id="2-2-Scatter"><a href="#2-2-Scatter" class="headerlink" title="2.2 Scatter"></a>2.2 Scatter</h3><p>同Broadcast一样，Scatter也是一个1对多的通信原语，也是一个数据发送者，多个数据接收者，可以在集群内把一个节点自身的数据发散到其他节点上。与Broadcast不同的是Broadcast把主节点0的数据发送给所有节点，而Scatter则是将数据的进行切片再分发给集群内所有的节点，如下图所示，不相同的颜色的小方块代表不相同的数据，主节点 0 将数据分为四份分发到了节点0-3。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/aitraining/3/image-scatter.png" alt="image-20220404193446314"></p><p>Scatter是数据的1对多的分发，它将一张XPU卡上的数据进行分片再分发到其他所有的XPU卡上，他的反向操作对应Gather，其应用场景有：</p><p>1）ReduceScatter组合里的 Scatter操作；</p><p>2）模型并行里初始化时将模型scatter到不同的XPU上；</p><h3 id="2-3-Gather"><a href="#2-3-Gather" class="headerlink" title="2.3 Gather"></a>2.3 Gather</h3><p>Gather操作属于多对1的通信原语，具有多个数据发送者，一个数据接收者，可以在集群内把多个节点的数据收集到一个节点上，如下图所示，不相同的颜色的小方块代表不相同的数据。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/aitraining/3/image-gather.png" alt="image-20220404193952158"></p><p>Gather是数据的多对1的收集，它将多张XPU卡上的数据收集到1张XPU卡上，他的反向操作对应Scatter，其应用场景有：</p><p>1）ReduceScatter组合里的 Scatter操作；</p><h3 id="2-4-AllGather"><a href="#2-4-AllGather" class="headerlink" title="2.4 AllGather"></a>2.4 AllGather</h3><p>AllGather属于多对多的通信原语，具有多个数据发送者，多个数据接收者，可以在集群内把多个节点的数据收集到一个主节点上（Gather），再把这个收集到的数据分发到其他节点上（broadcast），即收集集群内所有的数据到所有的节点上。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/aitraining/3/image-allgather.png" alt="image-20220404194323067"></p><p>AllGather是数据的多对多的同步全收集，它将多张XPU卡上的数据收集到多张XPU卡上，可以看做Gather + Broadcast的操作组合，它的反向操作对应ReduceScatter，其最应用场景有：</p><p>1） AllGather可应用于模型并行；</p><p>2）模型并行里前向计算里的参数全同步，需要用allgather把模型并行里将切分到不同的XPU上的参数全同步到一张XPU上才能进行前向计算。</p><h3 id="2-5-Reduce"><a href="#2-5-Reduce" class="headerlink" title="2.5 Reduce"></a>2.5 Reduce</h3><p>Reduce属于多对1的通信原语，具有多个数据发送者，一个数据接收者，可以在集群内把多个节点的数据<strong>规约运算</strong>到一个主节点上，常用的规约操作符有：求累加和SUM、求累乘积PROD、求最大值MAX、求最小值MIN、逻辑与 LAND、按位与BAND、逻辑或LOR、按位或BOR、逻辑异或LXOR、按位异或BOXR、求最大值和最小大的位置MAXLOC、求最小值和最小值的位置MINLOC等，这些规约运算也需要加速卡支持对应的算子才能生效。</p><p>Reuduce操作从集群内每个节点上获取一个输入数据，通过规约运算操作后，得到精简数据，如下图的SUM求累加和：节点0数值 5、节点1数值6、节点2数值7、节点3数值8，经过SUM运算后 累积和为 26，即得到更为精简的数值，在reduce原语里回会去调用 reduce SUM算子来完成这个求和累加。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/aitraining/3/image-reduce.png" alt="image-20220404194633808"></p><p>Reduce是数据的多对1的规约运算，它将所有张XPU卡上的数据规约（比如SUM求和）到1张XPU卡上，其应用场景有：</p><p>1）AllReduce里的 broadcast + reduce组合里的reduce操作；</p><p>2）ReduceScatter组合里的 reduce操作；</p><p>3）分布式训练parameter server 参数服务器结构里的 master节点 broadcast 数据到worker节点，再从worker节点reduce数据回master节点里的reduce操作；</p><h3 id="2-6-ReduceScatter"><a href="#2-6-ReduceScatter" class="headerlink" title="2.6 ReduceScatter"></a>2.6 ReduceScatter</h3><p>ReduceScatter属于多对多的通信原语，具有多个数据发送者，多个数据接收者，其在集群内的所有节点上都按维度执行相同的Reduce规约运算，再将结果发散到集群内所有的节点上，Reduce-scatter等价于节点个数次的reduce规约运算操作，再后面执行节点个数的scatter次操作，其反向操作是AllGather。</p><p>如下图所示，先reduce操作 XPU 0-3的数据reduce为 A(A0+A1+A2+A3) + B(B0 + B1 +B2 + B3) + C(C0 + C1 + C2 + C3) + D(D0 + D1 + D2 + D3 ) 到一张XPU上，再进行分片scatter到集群内所有的XPU卡上。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/aitraining/3/image-reducescatter.png" alt="image-20220404200227476"></p><p>ReduceScatter是数据的多对多的reduce + scatter运算，它将所有的XPU卡上的数据先规约（比如SUM求和）到1张XPU卡上，再进行scatter，其应用场景有：</p><p>1）ReduceScatter即可应用于数据并行也可应用于模型并行；</p><p>2）数据并行allReduce里的 ReduceScatter+ Allgather组合里的ReduceScatter操作；</p><p>3）模型并行里在前向allgather后的反向计算里的ReduceScatter；</p><h3 id="2-7-AllReduce"><a href="#2-7-AllReduce" class="headerlink" title="2.7 AllReduce"></a>2.7 AllReduce</h3><p>AllReduce属于多对多的通信原语，具有多个数据发送者，多个数据接收者，其在集群内的所有节点上都执行相同的Reduce操作，可以将集群内所有节点的数据<strong>规约运算</strong>得到的结果发送到所有的节点上。AllReduce操作可通过在主节点上执行Reduce + Broadcast或ReduceScatter + AllGather实现，如下图所示：先在主节点上执行reduce得到规约累加和26，再把这个累加和26 broadcast到其他的节点，这样整个集群内，每个节点的数值就都保持一致。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/aitraining/3/image-allreduce.png" alt="image-20220404195550358"></p><p>AllReduce是数据的多对多的规约运算，它将所有的XPU卡上的数据规约（比如SUM求和）到集群内每张XPU卡上，其应用场景有：</p><p>1） AllReduce应用于数据并行；</p><p>2）数据并行各种通信拓扑结构比如Ring allReduce、Tree allReduce里的 allReduce操作；</p><h3 id="2-8-All-To-All"><a href="#2-8-All-To-All" class="headerlink" title="2.8 All-To-All"></a>2.8 All-To-All</h3><p>All-To-All操作每一个节点的数据会scatter到集群内所有节点上，同时每一个节点也会Gather集群内所有节点的数据。ALLTOALL是对ALLGATHER的扩展，区别是ALLGATHER 操作中，不同节点向某一节点收集到的数据是相同的，而在ALLTOALL中，不同的节点向某一节点收集到的数据是不同的，如下图所示</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/aitraining/3/image-allgather-alltoall.png" alt="image-20220404202332268"></p><p>AllToAll是数据的多对多的转置，它将所有张XPU卡上的数据转置到所有的XPU卡上，其主要应用场景有：</p><p>1） AllToAll应用于模型并行；</p><p>2）模型并行里的矩阵转置；</p><p>3）数据并行到模型并行的矩阵转置；</p><h3 id="2-9-Send-与-Receive"><a href="#2-9-Send-与-Receive" class="headerlink" title="2.9 Send 与 Receive"></a>2.9 Send 与 Receive</h3><p>数据或参数在不同XPU之间的发送与接收。</p><h3 id="2-10-Barrier"><a href="#2-10-Barrier" class="headerlink" title="2.10 Barrier"></a>2.10 Barrier</h3><p>BARRIER同步操作会阻塞所有的调用者直到所有的组内成员都调用了它， 用于一个集合通信子中所有进程的同步，调用函数时进程将处于等待状态，直到通信子中所有进程 都调用了该函数后才继续执行。</p><h3 id="2-11-Signal与Wait"><a href="#2-11-Signal与Wait" class="headerlink" title="2.11 Signal与Wait"></a>2.11 Signal与Wait</h3><p>Signal与Wait属于记录型信号量机制： wait(s)，signal(s)可用于解决进程间的同步问题，在通信原语里从一个节点发送一个数据到另外一个节点时，会同时signal一个event值到对端，对端的wait操作接收到这个event时会返回一个确认给signal，这样保证在节点的进程间进行数据的同步操作。</p><h2 id="3-小结"><a href="#3-小结" class="headerlink" title="3. 小结"></a><font color="#FF8C00">3. 小结</font></h2><p>在分布式训练过程中，深度学习训练框架不会去直接操作底层的通信网络，而是通过使用网络通信库来完成数据的集合通信，各家AI芯片加速卡厂家都会提供私有的网络通信库比如：xxx-AWARE OpenMPI或xCCL来完成这个底层通信硬件的屏蔽与抽象。在分布式训练集群里网络通信硬件连接样式多种多样，可以是Ethernet、InfiniBand 、RoCE v2/v1 等也可以是CXL、NVLINK等私有协议，这就要求在通信的后端层根据各个厂家的自己的SDK开发库接口，根据实际情况实现 各自的网络通信库，比如cuda-aware MPI、NCCL、NVSHMEM，以及根据实际的网络拓扑组合完成对应的最有效的网络拓扑算法。</p><p>本文讲述了分布式训练里的集合通信原语，这些原语是集合通信拓扑算法的基本组成单元，后续的文章里会讲述如何组合这些通信原语以完成合适的通信拓扑算法。日拱一卒，功不唐捐，分享是最好的学习，与其跟随不如创新，希望这个知识点对大家有用。另作者能力与认知都有限，”我讲的，可能都是错的“，欢迎大家拍砖留念。</p><h2 id="4-作者简介"><a href="#4-作者简介" class="headerlink" title="4. 作者简介"></a><font color="#FF8C00">4. 作者简介</font></h2><p>常平，中科大硕，某AI芯片公司深度学习高级软件主管、架构师，前EMC资深首席工程师，主要工作背景在深度学习、Ai平台、系统调优、大数据、云计算以及Linux内核领域。</p><h2 id="5-参考资料"><a href="#5-参考资料" class="headerlink" title="5. 参考资料"></a><font color="#FF8C00">5. 参考资料</font></h2><p>[1] <a href="https://www.changping.me">https://www.changping.me</a></p><p>[2] <a href="http://scc.ustc.edu.cn/zlsc/cxyy/200910/MPICH" target="_blank" rel="noopener">http://scc.ustc.edu.cn/zlsc/cxyy/200910/MPICH</a></p><p>[3] 《用这拌元宵，一个字：香！| 分布式训练硬核技术——通讯原语》</p><p>[4] 《NCCL-Woolley》</p><p>[5] 《利用MegEngine分布式通信算子实现复杂的并行训练》</p><h2 id="6-版权申明"><a href="#6-版权申明" class="headerlink" title="6. 版权申明"></a><font color="#FF8C00">6. 版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>认识与实践 – 第4篇 - 如何弥补开源项目与企业级商业产品之间的差距</title>
      <link href="/2022/04/03/ideology_4/"/>
      <url>/2022/04/03/ideology_4/</url>
      
        <content type="html"><![CDATA[<h2 id="1-前言"><a href="#1-前言" class="headerlink" title="1. 前言"></a><font color="#FF8C00">1. 前言</font></h2><p>需要回答如何弥补开源项目与企业级商业产品之间的差距，首先需要回答两个基本问题：”什么是产品？“以及“如何将一个开源的软件项目产品化？”。一套科学技术分析方法的背后有一定有着深刻的理论基础和哲学背景。找到了这套技术分析的源头，才能从本质上把握这套技术，看清其全貌，明了其长处和短处，这样在具体应用中，才能得心应手，提高胜算，并不断的丰富和发展这套技术。基于此，本文提出了一套方法论，回答如何将开源软件项目产品化从而弥补开源项目与企业级商业产品之间的差距。</p><h2 id="2-什么是产品"><a href="#2-什么是产品" class="headerlink" title="2. 什么是产品"></a><font color="#FF8C00">2. 什么是产品</font></h2><p>依据公开的信息对产品的定义如下：</p><blockquote><p>产品是指做为商品提供给市场，被人们使用和消费，并能满足人们某种需求的任何东西，包括有形的物品、无形的服务、组织、观念或它们的组合。</p></blockquote><p>从产品的定义中我们可以看到以下几点：</p><ul><li><p>属性：有形的物品、无形的服务、组织、观念或它们的组合，因此产品自带有形或无形属性；</p><ul><li>有形属性：狭义上产品是被生产出的能满足人们需求的具有物理属性的有形的物品。在绝大多数人的认知里，对产品的理解是停留在这一层次的，产品具有看得见、摸得着的物理形态；</li><li>无形属性：广义上产品是可以满足人们需求的任何东西，无形的服务、组织、观念或者它们的组合也是产品。广义上的产品定义对人的认知有更高的要求。服务是产品、企业是产品、团队是产品、认知是产品、本文是产品，这些东西的组合也是产品。万物皆产品，它目前不是产品，那只是没被产品化、或者不在对的时间与空间里；</li></ul></li><li><p>价值：产品首先是商品，其具有交易的价值，能提供给市场，供人们使用与消费，所有不能交易的东西不在产品的定义范围之内，因此这里可以推导出产品是具有价值的，没有价值的东西不属于产品的范畴；</p></li><li><p>交易：产品是做为商品提供给市场，被人们使用和消费，因此具有交易的价值，能满足市场的某种需求；</p></li></ul><p>因此基于以上的产品的公理化定义以及定理化推导得出产品的第一性原理定义：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs undefined">产品 = 属性 + 价值 + 交易<br></code></pre></td></tr></table></figure><p>从以上公式中可以认为产品是<font color="#FF8C00"><strong>以属性为要素，以价值为连接，以交易为目的</strong></font>，属性又可分为有形属性与无形属性，二者之间有时候并不是割裂的，价值是能满足人们的某些需求，是物品与货币之间的连接关系，交易是产品生产的目的。</p><p>然而这些都是教科书式的 定义，对产品的认知到这一层次已经可以超越绝大部分人，但它也只是停留在”产品“层次，而不是“作品”，更不是“艺术品”。</p><p>在我看来 产品 还是具有灵魂的，产品是由人创造的，其自然会带有人的思想、人的创造、人的理念在里头，宗师与学徒画同样的一幅画，虽然东西都一样但是那个味道往往是不一样的。因此，要理解一款产品还需要理解其背后的人的设计理念，在此，我给产品注入人的灵魂，即“理念”，从而进一步扩展产品的第一性原理：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs undefined">产品 = 属性 + 价值 + 交易 + 理念<br></code></pre></td></tr></table></figure><p>开源软件是信息的载体，其表现形式是具有无形的信息属性，是作为计算机程序的形式而存在的，要将开源软件产品化就需要将开源软件的属性价值化、可交易化以及注入人的设计理念。</p><h2 id="3-开源软件产品化"><a href="#3-开源软件产品化" class="headerlink" title="3. 开源软件产品化"></a><font color="#FF8C00">3. 开源软件产品化</font></h2><h3 id="3-1-价值与交付"><a href="#3-1-价值与交付" class="headerlink" title="3.1 价值与交付"></a><font color="#00CED1">3.1 价值与交付</font></h3><p>如何将一个软件产品化回答的是<strong>“How”</strong> 的问题，在此之前还应该搞明白<strong>“Why”</strong>的问题，一个软件产品或者其特性为什么需要做也有一套方法论，这里我称之为 <font color="#E01000"><strong>“产品交付之双轮驱动模型”</strong></font>（如下图）：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/product/product-value-and-delivery.PNG" alt="价值与交付"></p><p>在这个双轮驱动思维模型里有以下几个原则：</p><ul><li><p>以客户价值为前轮，前轮把握方向，解决的是需求探索、价值确定、特性探讨以及价值精炼的过程。首先是以客户价值为导向输入客户需求、但是这个需求还需要去伪存真、去粗纯精、过滤提炼，才能作为产品交付轮的输入，而不是只要是客户需求，不管是真需求还是假需求、也不管是有价值的、还是无价值的都全部输出到产品交付轮，无效的消耗产品交付资源；</p></li><li><p>以产品交付为后轮，后轮提供驱动力，解决的是开发、测试、运维以及获取客户反馈，再根据这个客户反馈的结果作为开发的输入的过程。在产品交付轮中很重要的一环是<strong>“反馈“</strong>，其角色是作为客户与交付之间的桥梁，开发需要依据”客户反馈”作为输入，而不是自个闭门造车；</p></li><li><p>客户价值又可分为主动式客户价值与被动式客户价值，获取客户需求的方式也需要合理取舍：</p><ul><li>主动式客户价值：有些客户”久病成医“，非常清楚自个痛点、难点、挑战点在哪里，也非常清楚自个需要什么样的解决方案可以药到病除，从而可以精确的输出自我的需求。这种客户对产品交付来说可遇而不可得，成本最低，需求最精确；</li><li>被动式客户价值：这种情况下，光是在那里等待，从而期望客户能给出明确的需求作为输入，那是缘木求鱼、刻舟求剑，效率也非常低下。如同医院里的医生给病人看病一样，绝大多数客户其实只能知道表征，而不知道根因，因此就需要由产品交付轮以客户专家的角色提出解决方案，作为客户价值需求输入给客户，再看客户的使用效果得出反馈，再依据这个反馈调整解决方案。</li></ul></li><li><p>在双轮驱动模型里，二者谁都离不开谁，不是厚此薄彼的关系，而是二者互相协作从而推动产品往商业成功这个目标前进的关系；</p></li><li><p>先有买家需求再有产品交付，而不是先有产品交付再找买家需求，需要明晰这个先后关系，为客户找出差异化需求才是产品交付的本质，寻求差异化、避免同质化，才是真正的以客户为中心。</p></li></ul><p>因此，在将一个技术产品化之前，先花几分钟时间问问其价值在哪里，为什么需要做这个，这一点很重要，要能区分客户要的是能马上就能解决痛点的止痛片还是可有可无的无关紧要的维生素，从而以此进行任务排序，明晰产品交付与客户价值的双轮驱动关系，要能清楚的理解<font color="#00CED1"><strong>“以客户为中心”</strong></font>的价值理念以及让产品的获得<font color="#00CED1"><strong>“商业成功”</strong></font>的终极目标。</p><h3 id="3-2-技术产品化"><a href="#3-2-技术产品化" class="headerlink" title="3.2 技术产品化"></a><font color="#00CED1">3.2 技术产品化</font></h3><p>通常来讲开源软件的产品化可以从价值、交易以及理念这三个方面进行。价值：可服务化、无形化有形、价值竞争，交易：可度量化、个性标准化，以及融入人的设计理念：复杂简单化等。</p><h4 id="3-2-1-可服务化"><a href="#3-2-1-可服务化" class="headerlink" title="3.2.1 可服务化"></a><font color="#E01000">3.2.1 可服务化</font></h4><p>可服务化指的是从技术实现上支持可服务化，ToB产品常常是半产品半服务的，而且一般会签约服务质量保证协议SLA，因此除了团队需要有替客户解决问题的能力外，还需要从技术与流程上支持可服务化，其中包括：</p><ul><li>可运维性：易用的部署（步骤量化）、升级（AB测试、in-place、replace、rolling-back等）、数据迁移、自动化运维支持等。在一个产品的全生命周期里，开发也许只占20%不到的时间，而将近80%的时间都需要运维，因此需要拿出近4倍比的开发重视程度，重视可运维的设计与实现；</li><li>可观测性：可观测性主要分为四大类: 监控、告警、日志、追踪；</li><li>可操作性：支持远程接入、开放服务接口、后台管理UI、CLI、特性参数配置开关；</li><li>健康管理：健康检查支持、健康报告支持、自动提交故障问题单支持；</li><li>安全性：安全性是企业级产品必备，数据保护、密码安全、连接检查、LIB库授权协议等；</li><li>多租户：多租户可以支持多团队、多部门小规模部署，进行业务隔离，也是非常重要的企业级特性；</li><li>可视化：提供易用的用户UI、CLI;</li><li>可支持：如何指定进行客户支持规则？如何升级成工程师团队介入提供服务定位问题或者排除问题？</li></ul><p>当看到以上类目，脑海里就能闪现出需要怎么去实现这些以及用什么组件可以最佳实践的快速完成交付，而不是停留在概念的阶段，那才算对可服务化有了自己的理解。</p><h4 id="3-2-2-无形化有形"><a href="#3-2-2-无形化有形" class="headerlink" title=" 3.2.2 无形化有形"></a><font color="#E01000"> 3.2.2 无形化有形</font></h4><p>无形化有形指的是将无形的软件硬件化或者云化，单单一个软件包是难以让用户买单的，需要把它硬件化，打包到服务器里以有形产品的形态销售出去，或者云化后以服务的无形形态销售出去。</p><h4 id="3-2-3-价值竞争"><a href="#3-2-3-价值竞争" class="headerlink" title="3.2.3 价值竞争"></a><font color="#E01000">3.2.3 价值竞争</font></h4><p>价值竞争指的是<strong>“参与到客户的购买周期中，在每个阶段为客户创造价值”</strong>[3]，从单纯的销售产品到提供整套生态化的解决方案。单纯的依靠销售产品往往已经难以给客户提供差异化的价值，并且也会面临低利润的同质化竞争，那么这个时候就需要更进一步的提供生态化的解决方案，针对行业需求做端到端的全生态化的解决方案。</p><p>生态化的解决方案化能给客户提供差异化的价值关系。比如，一份药品在药店里只能卖30块，而且只是一次销售无法挖掘后续价值。但是到了医院就不一样了，其依据客户的”恐惧“为刚需的基石，提供一整套的类生态化的医疗解决方案，从挂号预约、望闻问切、到各种仪器设备过一遍、再到开出药方、再依据客户的反应效果把这个过程再来几遍，因此在药店里30块钱的药，在医院里就能卖到 300块、3000块，获取十倍、百倍、千倍利润。当然这从道德上讲这是比较无耻的一种行为。</p><h4 id="3-2-4-可度量化"><a href="#3-2-4-可度量化" class="headerlink" title="3.2.4 可度量化"></a><font color="#E01000">3.2.4 可度量化</font></h4><p>可度量化指的是质量要可以量化，可预测的业务指标（比如AI训练里的精度、加速比、收敛时间、训练次数等）、性能、可靠性、可用性、可伸缩性、稳定性、容错性、可测试性等，这些很抽象的指标要能量化。在产品功能同质化的场景下，质量是最重要的差异化竞争力。</p><p>业务性能、可靠性、可用性、可伸缩性这几者之间页互相制约，质量与成本、时间也互相制约，同时在云化的场景下客户又有SLA要求，不满足SLA要求的服务，除了要赔钱，还严重影响商业信誉，因此质量指标之间也需要合理取舍。</p><h4 id="3-2-5-个性标准化"><a href="#3-2-5-个性标准化" class="headerlink" title=" 3.2.5 个性标准化"></a><font color="#E01000"> 3.2.5 个性标准化</font></h4><p>个性标准化指的是将个性化的、“DIY”化的开源项目转成标准化的、可复制的、可量化的，同时依据资源的规格约束进行标准化，比如依据服务器规格、虚机规格，机架规格等进行标准化，例如AI服务器的配置就需要定义CPU、内存、磁盘、带宽以及训练卡的标准的规格，这样才能提供可预测的性能、可预测的加速比等质量指标，再比如云端场景下的服务监控，除了定义指标的名称之外，还需要定义监控指标的类型、故障码、输出的标记以及对应的处理措施等，所有的这些都要能标准化、可操作性化。</p><h4 id="3-2-6-复杂简单化"><a href="#3-2-6-复杂简单化" class="headerlink" title="3.2.6 复杂简单化"></a><font color="#E01000">3.2.6 复杂简单化</font></h4><p>复杂简单化指的是把复杂的体验简单化， 抽象及简化API、量化的安装步骤、高内聚低耦合的设计、易用的UI等，这里又涉及到产品设计哲学、人类的心理学等，也跟人的设计理念相关。</p><h2 id="4-小结"><a href="#4-小结" class="headerlink" title="4. 小结"></a><font color="#FF8C00">4. 小结</font></h2><p>本文以方法论的形式解读了软件开发过程当中经常会遇到的两个问题：”什么是产品？如何将一个开源的软件产品化？“，从而解答了 “如何弥补开源项目与企业级商业产品之间的差距？”的问题，讲的是“无用”的知识。然而理论与实践是相互作用的，宏观角度知道方法论之后还需要从微观上进行实践，不然就如同知道很多道理却过不好这一生，知道很多原则却写不好代码一样一样的。</p><p>日拱一卒，功不唐捐，分享是最好的学习，与其跟随不如创新，希望这个知识点对大家有用，另作者能力与认知都有限，”我讲的，可能都是错的“，欢迎大家拍砖留念。</p><h2 id="5-作者简介"><a href="#5-作者简介" class="headerlink" title="5. 作者简介"></a><font color="#FF8C00">5. 作者简介</font></h2><p>常平，中科大硕，某AI独角兽深度学习高级软件主管工程师、架构师，前EMC资深首席工程师，主要工作背景在深度学习、大数据、云计算、分布式中间件以及Linux内核领域。</p><h2 id="6-参考资料"><a href="#6-参考资料" class="headerlink" title="6. 参考资料"></a><font color="#FF8C00">6. 参考资料</font></h2><p>[1] <a href="https://a16z.com/2019/10/04/commercializing-open-source/" target="_blank" rel="noopener">https://a16z.com/2019/10/04/commercializing-open-source/</a></p><p>[2] <a href="https://baike.baidu.com/item/%E4%BA%A7%E5%93%81/105875" target="_blank" rel="noopener">https://baike.baidu.com/item/%E4%BA%A7%E5%93%81/105875</a></p><p>[3] 《价值竞争：以客户为中心的销售转型》 </p><h2 id="7-版权申明"><a href="#7-版权申明" class="headerlink" title="7. 版权申明"></a><font color="#FF8C00">7. 版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p>]]></content>
      
      
      <categories>
          
          <category> ideology </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ideology </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>认识与实践 – 第3篇 - 让技术回归常识,先有客户再有技术</title>
      <link href="/2022/04/03/ideology_3/"/>
      <url>/2022/04/03/ideology_3/</url>
      
        <content type="html"><![CDATA[<h2 id="1-先有客户再有技术"><a href="#1-先有客户再有技术" class="headerlink" title="1. 先有客户再有技术"></a><font color="#FF8C00">1. 先有客户再有技术</font></h2><p>技术不同于科学，科学是人类对自然的认知，它可以很前沿很理论也不用讲究工程价值，而技术更多指的是功能与工程得实现，更需要关注的是“利他”的常识。技术人员其比较关注的是技术架构、实现方式、技术价值以及开发成本，而比较容易忽略客户需求、使用场景以及产品价值与用户体验。忽略这些产品相关的内容而维技术论就容易犯错进而浪费有限的开发资源，在工程实现上维技术论常见的有四错：</p><ul><li>第一错：“我为用户想”，这是研发人员最容易犯的错，其已经有用户意识，但是却没有进一步与用户沟通，直接替用户做决定，也不清楚用户的使用场景，因此容易造成”所想“实际上并不是用户真正所想；</li><li>第二错：追求有挑战的技术而非技术的实用价值，也非从合适的解决用户问题的角度出发，将技术上的自嗨当成客户需求，比如用户需要从A地到B地，简单一点给用户一辆自行车就可以解决的问题，而技术自嗨就容易非要先自行造个飞机，然后拼命的给用户推销这个好这个快，但是用户却不买单；</li><li>第三错：维性价比论，总以为又便宜的又好的就是真的好，性价比是大杀器，但是很多情况下其实客户也讲ROI(投入产出比)，比如双11秒杀活动，用户可以不计成本的采用最新进最前沿的技术，只要能扛得住双11的流量就可以不计成本，因为再大的成本，跟双11带来的收益对比都是毛毛雨；</li><li>第四错：闭门造车，不实事求是，不与客户做探讨，不做调查就把想象的或还处于概念上的东西当成客户需求。</li></ul><p>因此，研发人员不能维技术论，维技术论就不是一个合格的研发工程师，工程师还需要关注客户价值，在实现一个架构之前先确定这个是对客户有价值的，同时平衡好客户价值与技术前沿之间的取舍关系。</p><h2 id="2-什么是客户，又什么是客户价值"><a href="#2-什么是客户，又什么是客户价值" class="headerlink" title="2. 什么是客户，又什么是客户价值"></a><font color="#FF8C00">2. 什么是客户，又什么是客户价值</font></h2><h3 id="2-1-什么是客户"><a href="#2-1-什么是客户" class="headerlink" title="2.1 什么是客户"></a>2.1 什么是客户</h3><p>用英文单词表示，客户与用户其实是比较容易区别的，客户是 customers, 用户 是users，而中文二者都有个“户”字就比较容易混淆。To C产品客户可以是用户，但是To B产品， 客户却不是就等于就是用户。狭义的客户 = 买单的，广义上的客户 = 客户的客户 + 客户 + 客户的用户 + 利益链上的所有，用户也不就是一个角色或者某人，对to B产品来说，用户的本质是“需求“的集合。</p><h3 id="2-2-什么是客户价值"><a href="#2-2-什么是客户价值" class="headerlink" title="2.2 什么是客户价值"></a>2.2 什么是客户价值</h3><p>“任何先进的技术、产品和解决方案，只有转化为客户的商业成功才能产生价值“ [1]  ，客户价值就是对客户有用的东西，价值来源于价值的交换。技术的目的就是做对客户有用的东西，并且技术的进化方向是由市场所决定的。</p><p>以客户为中心，就是给客户创造价值，替解决用户难点、痛点、挑战点、为客户提供高质量低成本的产品，同时响应要及时。病根是需，药是求，拿出 “求” 解决 “需”，药到病除就是为客户创造价值[1]。</p><h2 id="3-如何做到以客户价值为中心？"><a href="#3-如何做到以客户价值为中心？" class="headerlink" title="3. 如何做到以客户价值为中心？"></a><font color="#FF8C00">3. 如何做到以客户价值为中心？</font></h2><p>认知上做到技术要先从客户价值开始，那么执行上应该如何拆分？使得认知具有可量化的执行性？这里从以下三个方面对“如何做到以客户价值为中心”这个问题进行拆解：</p><ul><li>价值探索 - 价值与交付双轮驱动思维模型，PMF-MVP思维模型</li><li>价值确定 - 三三制需求分析思维模型</li><li>价值输出 - 卡诺需求分级与分类思维模型</li></ul><h3 id="3-1-价值探索1-双轮驱动思维模型"><a href="#3-1-价值探索1-双轮驱动思维模型" class="headerlink" title="3.1 价值探索1 - 双轮驱动思维模型"></a>3.1 价值探索1 - 双轮驱动思维模型</h3><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/product/25/double-ring.png" alt="双轮驱动思维模型"></p><p>价值探索的方法论之一是双轮驱动思维模型，其原则为：</p><ul><li>以客户价值为前轮，前轮把握方向，解决的是需求探索、价值确定、特性探讨以及价值精炼的过程，需求输出需要去伪存真、去粗纯精、过滤提炼；</li><li>产品交付为后轮，后轮提供驱动力，解决的是开发、测试、运维以及获取客户反馈；</li><li>先有客户价值再有产品交付，客户价值又可分为主动式客户价值与被动式客户价值，获取客户需求的方式也需要合理取舍；</li><li>在双轮驱动模型里，二者谁都离不开谁，不是厚此薄彼的关系，而是二者互相协作从而推动产品往商业成功这个目标前进的关系；</li></ul><h3 id="3-2-价值探索2-PMF-MVP-开发模型"><a href="#3-2-价值探索2-PMF-MVP-开发模型" class="headerlink" title="3.2 价值探索2 - PMF-MVP 开发模型"></a>3.2 价值探索2 - PMF-MVP 开发模型</h3><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/product/25/pmf-mvp.png" alt="PMF-MVP"></p><p>如上图所示，PMF（Product-Market Fit）是讲究产品与市场匹配，是产品需要与市场需求相匹配，而MVP （Minimal Viable Product）是 最小可用产品，MVP讲的是每个版本的迭代都是一个可用的产品而非功能的堆砌，PMF-MVP开发法，讲究快速给的输出可用的版本给到客户，再由客户进行使用获取客户的信息反馈，再进行版本迭代。</p><p>价值探索的方法论之二是PMF-MVP开发法，其原则为：</p><ul><li>PMF-MVP 开发法可以帮助团队在早期快速确认客户的真实需求；从特性列表中确定产品（特性）的基本功能， 然后迅速开发MVP，再投放市场提前踩坑，收集用户反馈，然后再进行产品迭代，只有用户用起来，产品才有机会演化；</li><li>做MVP的时候，不是验证产品好不好用，而是验证产品/特性是不是用户真的想要的，减少开发成本，“闭门造车”式的开发经常会遇到“再来一次”;</li><li>跟目标用户产生互动和连接，每一步都收集用户的反馈，前期跟客户多交流，多沟通，“一元共创”与用户一起成长。</li></ul><p>在价值探索之后就需要进行价值确定。</p><h3 id="3-3-价值确定-–-三三制需求分析思维模型"><a href="#3-3-价值确定-–-三三制需求分析思维模型" class="headerlink" title="3.3 价值确定 – 三三制需求分析思维模型"></a>3.3 价值确定 – 三三制需求分析思维模型</h3><p><strong>公式： 需求</strong> <strong>=</strong> <strong>需（痛点、难点、挑战点、恐惧点）</strong> <strong>+</strong> <strong>求 （产品、服务或解决方案）</strong>， 需即痛点、难点、挑战点，求即解决方案、产品或服务，求到需即完成，这就是有客户价值。依据三三制需求分析思维模型我们可以进行价值确定，三三制需求分析思维模型是一个价值确定思维模型，其如下表：</p><table><thead><tr><th><strong>类别</strong></th><th><strong>功能</strong></th><th><strong>质量</strong></th><th><strong>约束</strong></th></tr></thead><tbody><tr><td>“大”客户</td><td>业务目标：  商业成功，比如科技向善</td><td>业务质量：    多、快、好、省</td><td>业务约束：  时间、质量、成本，法律法规，信息安全，技术趋势，竞争对手，行业标准等</td></tr><tr><td>“大”用户</td><td>业务需求</td><td>运行时质量：  性能、可用性、可靠性，可伸缩性、可观测性、可运维性、易用性、兼容性、安全性等</td><td>使用时约束：  遗留系统，业务环境，用户能力，用户群特征等</td></tr><tr><td>“大”团队</td><td>功能需求：  基本功能P0  、增值功能P1、潜在功能P2 、可有可无功能P3  、有害无益功能P100</td><td>编程时质量：  可扩展，可读性，可测试性，可维护性，可移植性</td><td>编程时约束：  开发进度，资源预算、上级要求、开发团队能力、产品规划、运行环境</td></tr></tbody></table><p>三三制需求分析思维模型进行价值确定之后即价值输出。</p><h3 id="3-4-价值输出-–-卡诺需求分类与分级思维模型"><a href="#3-4-价值输出-–-卡诺需求分类与分级思维模型" class="headerlink" title="3.4 价值输出 – 卡诺需求分类与分级思维模型"></a>3.4 价值输出 – 卡诺需求分类与分级思维模型</h3><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/product/25/kano-model.png" alt="KANO"></p><p>这里采用KANO需求分类与分解思维模型进行价值输出，依据kano模型，需求可以分为：</p><ul><li>基本需求：必须有的最根本的需求，没这个根本就没法谈，会阻塞产品交付；</li><li>增值需求：当提供此需求时用户满意度会提升；当不提供此需求时用户满意度会降低；</li><li>竞争力需求：若不提供此需求，用户满意度不会降低；若提供此需求，用户满意度会有所的提升，属于亮点要素；</li><li>可有可无需求：用户根本不在意的需求，对用户体验毫无影响；</li><li>有害无益需求：提供后用户满意度反而下降；</li></ul><p>卡诺模型将需求进行了分级与分类，进一步的区分了需求的价值。</p><h2 id="4-小结"><a href="#4-小结" class="headerlink" title="4. 小结"></a><font color="#FF8C00">4. 小结</font></h2><p>本文首先确定了 “先有客户再有技术”的认知，再讲述了什么是客户，什么是客户价值，并且以思维模型的方式讲述了如何做到以客户价值为中心。日拱一卒，功不唐捐，分享是最好的学习，与其跟随不如创新，希望这个思维模型对大家有用。另作者能力与认知都有限，”我讲的，可能都是错的“，欢迎大家拍砖留念。</p><h2 id="5-作者简介"><a href="#5-作者简介" class="headerlink" title="5. 作者简介"></a><font color="#FF8C00">5. 作者简介</font></h2><p>常平，中科大硕，某AI独角兽深度学习高级软件主管工程师、架构师，前EMC资深首席工程师，主要工作背景在深度学习、大数据、云计算、分布式中间件以及Linux内核领域。</p><h2 id="6-版权申明"><a href="#6-版权申明" class="headerlink" title="6. 版权申明"></a><font color="#FF8C00">6. 版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p><h2 id="7-参考资料"><a href="#7-参考资料" class="headerlink" title="7. 参考资料"></a><font color="#FF8C00">7. 参考资料</font></h2><p>[1] 《华为增长法》</p>]]></content>
      
      
      <categories>
          
          <category> ideology </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ideology </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>认识与实践 – 第2篇 - 五大原则，三大基石 - 极简产品开发法</title>
      <link href="/2022/04/02/ideology_2/"/>
      <url>/2022/04/02/ideology_2/</url>
      
        <content type="html"><![CDATA[<h2 id="产品开发的本质"><a href="#产品开发的本质" class="headerlink" title="产品开发的本质"></a><font color="#FF8C00">产品开发的本质</font></h2><p>根据<strong>第一性原理</strong>思维，可以得出产品开发的本质即：<strong>“高效、高质量地交付有用的价值”</strong>[1]。那么从这句话可以推导出四个需要解决的命题，即：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs undefined">1，需要交付的价值是什么？<br>2，如何判断什么是有用的价值？<br>3，如何高效地交付？<br>4，如何高质量地交付？<br></code></pre></td></tr></table></figure><p>此外，在软件产品开发过程中除了面临确定性复杂度之外还经常面临不确定性复杂度，不确定性的复杂度比确定性的复杂度更难解决，更容易引起焦虑，更容易带来团队<strong>熵增</strong>，也更容易造成软件开发交付的失败。因此，为了<strong>简单有效</strong>地解决这四个命题以及其所自带的复杂度问题，结合精益产品理论，本文提出一种从实战中总结出来的<strong>“极简产品开发法”</strong>。需要额外说明的是，本方法论还有两个约束条件：</p><ul><li><p>本方法论仅适用于以搞生产力为主而非以搞生产关系为主的企业、部门、团队或个人；</p></li><li><p>本方法论仅适用于小团队或单兵作战能力很强的个体，比如10倍工程师；</p></li></ul><h2 id="极简精益产品开发法"><a href="#极简精益产品开发法" class="headerlink" title="极简精益产品开发法"></a><font color="#FF8C00">极简精益产品开发法</font></h2><p>为了简单有效地解决<strong>“需要交付的价值是什么？如何判断什么是有用的价值？如何高效地交付？如何高质量地交付？”</strong> 这四大命题以及软件开发所面临的确定与不确定复杂度，这里采用结构化的方法提出的极简产品开发思维模型，其涵盖五大原则与三大基石，即：</p><ul><li>五大原则：以终为始，架构先行，有拆有合，迭代更新，相关满意</li><li>三大基石：领域能力，企业文化，组织到位</li></ul><p>本极简产品开发法思维模型导图如下：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/product/lean/lean-1.png" alt=""></p><p>在极简产品开发法思维模型里，“领域能力、企业文化、组织到位”属于基石的范畴，三大基石不到位，则产品开发与交付的原则与行动无效。在五大原则里，“以终为始”是为了解决“判断需要交付的价值是什么？如何判断什么是有用的价值？”这两个问题，“架构先行，有拆有合，迭代更新，相关满意”是为了解决如何高效地交付，如何高质量地交付以及如何解决软件开发的确定性与不确定性复杂度。</p><h2 id="五大原则"><a href="#五大原则" class="headerlink" title="五大原则"></a><font color="#FF8C00">五大原则</font></h2><h3 id="以终为始"><a href="#以终为始" class="headerlink" title="以终为始"></a><font color="#008C">以终为始</font></h3><p>“以终为始”是一种逆向思维，在软件开发里的应用指的是从最终的交付价值出发，反向推理交付过程，寻找软件开发的关键要素，获取反馈采取正确的策略，从而达成有用的价值交付。如下图所示，从未来的终局看现在，使用获取的未来信息强化现在的行为，赋予现在的行为以塑造未来的力量。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/product/lean/lean-4.png" alt=""></p><p>“以终为始”是确保正确地做事以及做的是正确的事的一种思维方式，在进行软件开发之前就进行了从交付结果开始的倒推分析，从交付结果得出开发的方向与方案。这里以“逆向工作法”以及“客户导向法” 为例说明软件开发过程中 “以终为始”思维的使用。</p><h4 id="逆向工作法"><a href="#逆向工作法" class="headerlink" title="逆向工作法"></a>逆向工作法</h4><p>逆向工作法是亚马逊所推崇的商业新哲学，因为产品最终的交付要“以客户为中心”，那就先从客户侧开始倒推开发，逆向工作法有助于一开始就把重心放在客户所真正关心的问题上，而不是一堆程序员坐在办公室内拍脑袋替客户做假想，进而避免一些无效的开发决策，使得确保推出的是有用、有价值、用户体验佳的产品。</p><p>拆解这个概念为具体的行动，亚马逊讲述了这个思维方式的应用步骤[4]：</p><p>1，先写一篇内部用的产品新闻稿，简单描述一下这个产品的特点与好处是什么，是为了解决什么痛点而产生，然后描述具体的问题，拿出一个新的解决方案，虚构一个用户的心声，设身处地为用户着想，然后发出来给内部同事，经过审核的也可以外发给公众；</p><p>2，写一个常见的FAQ问题文档，定义产品的用途以及考虑用户使用时会遇到的问题以及回答如何解决，FAQ需要包含外部客户会问的问题以及内部用户会问的问题；</p><p>3，定义客户体验，详细描述客户使用产品时会遇到的使用场景。比如用户界面是怎么样的，软件部署是怎么部署的，软件的技术架构图是怎么样的，先给客户一个能够呈现端到端体验的假象视图；</p><p>4，编写用户手册，用户手册是客户用来真正了解产品是什么以及如何使用它的，用户手册通常有三个部分：概念、操作方法和参考，它们之间告诉用户使用产品所需的所有知识。,</p><p>5，获取反馈，以上内容完成后，获取用户/客户反馈，然后在产品的生命周期中，不断迭代而演化产品的开发交付文档。</p><p>逆向工作法的目的是为了明白真正的用户/客户是谁，用户/客户的真实需求是什么，用户/客户的需要最先解决什么痛点等，而且以上步骤也只是一种应用方案，目的一致则无需拘泥于形式，只要思路和效果可以达到有效理解客户的目的即可。</p><h4 id="客户导向法"><a href="#客户导向法" class="headerlink" title="客户导向法"></a>客户导向法</h4><p>客户导向法讲的是“先有客户再有产品与技术”，其理念上与逆向工作法类似，不同之处在于 逆向工作法是具体的行动，而客户导向法是认知上的提升。在这里，需要先定义什么是客户以及什么是客户价值：</p><ul><li>什么是客户？狭义的客户 = 买单的，广义上的客户 = 客户的客户 + 客户 + 客户的用户 + 所有相关方；</li><li>什么是客户价值？客户价值就是对客户有用的东西，价值来源于价值的交换。技术的目的就是做对客户有用的东西，并且技术的进化方向是由市场所决定的。以客户为中心，就是给客户创造价值，替解决用户难点、痛点、挑战点、为客户提供高质量低成本的产品，同时响应要及时；</li></ul><p>在产品开发上，软件开发人员常见的认知错误有：</p><ul><li>“我为用户想”，这是研发人员最容易犯的错，其已经有用户意识，但是却没有进一步与用户沟通，直接替用户做决定，也不清楚用户的使用场景，因此容易造成”所想“实际上并不是用户真正所想；</li><li>追求有挑战的技术而非技术的实用价值，也非从合适的解决用户问题的角度出发，将技术上的自嗨当成客户需求，比如用户需要从A地到B地，简单一点给用户一辆自行车就可以解决的问题，而技术自嗨就容易非要先自行造个飞机，然后拼命的给用户推销这个好这个快，但是用户却不买单；</li><li>闭门造车，不实事求是，不与客户做探讨，不做调查就把想象的或还处于概念上的东西当成客户需求，带来的是低效、低质量的产品开发过程；</li></ul><p>因此，开发产品需要先关注客户价值，在实现一个产品之前先确定这个是对客户有价值的，与客户/用户多沟通、一起共创，在“客户要的与我能提供的”二者之间保持理解一致，避免无效开发与交付。</p><h3 id="架构先行"><a href="#架构先行" class="headerlink" title="架构先行"></a><font color="#008C">架构先行</font></h3><h4 id="架构投影"><a href="#架构投影" class="headerlink" title="架构投影"></a>架构投影</h4><p>柏拉图在《理想国》中构建了他的哲学王国—理念世界，其把世界分成两个：“现象世界与理念世界，柏拉图认为这两个世界的关系是原本和慕本的关系，理念世界是原本、模型，现象世界是理念世界的影子或慕本”。基于此设想，产品架构可以是产品在现象世界的原本，通过产品架构可以看到产品的最终形态。在开发（编码）产品之前可以先定义软件产品的架构，给出产品的画像，提供产品的总体概要架构设计文档（注意这里概要设计文档即可，无需详细设计文档），设计文档内定义产品的设计哲学、设计原则、技术架构图、设计提案、所需要实现的功能特性、交付目标以及风险管理、用户操作等，然后发给团队一起评审，利用团队的力量避免交付的技术路线风险，同时为下一阶段的工作分解做准备。</p><h4 id="架构思维"><a href="#架构思维" class="headerlink" title="架构思维"></a>架构思维</h4><p>狭义上的架构通常指的是架构的技能，其属于“术”的范畴，而广义的架构则是客户需求、市场趋势、架构理念、架构方法论、架构技能、架构用的工具以及架构的边界这几个方面的组合体，应用抽象思维，即<strong>“势、道、法、术、器、界”</strong>这六个字 ，简称架构思维六元组，具体可以参考《第15式 - 架构思维》。</p><p><strong>势：时势</strong></p><p>“势”是架构的方向。从宏观处着眼，“势”是产品架构设计的市场趋势、是客户需求趋势也是技术的应用趋势；从微观处着手，“势”是功能设计的价值与目的。架构设计需要从宏观处着眼微观处着手，看清客户的需求趋势、市场趋势以及技术趋势，功能设计需要分析清楚当前功能的价值与目的。</p><p><strong>道：本质</strong></p><p>“道”是架构的认知，是架构师的设计理念、设计意图，是产品架构的灵魂，这里我把它定义为产品架构的设计哲学。</p><p><strong>法：方法论</strong></p><p>”法“是方法论，是架构设计的方法论，是架构设计的套路，这里我把它定义为产品架构的设计原则</p><p><strong>术：技能</strong></p><p>术，技能，是架构技能，这里定义为设计提案，以及各种功能与特性实现的思路</p><p><strong>器：工具</strong></p><p>”器“是工具，是架构设计用的工具，”工欲善其事必先利其器“，</p><p><strong>界：边界</strong></p><p>”界“是边界，是架构的约束限制，是技术边界、也是技术约束与技术限制，也是架构的取舍因素之一，是架构能做什麽不能做什麽的解读，对市场来说它是技术壁垒，对产品来说它是法律法规、是功能约束，对团队来说它是资源约束、是自我能力约束。</p><h3 id="有拆有合"><a href="#有拆有合" class="headerlink" title="有拆有合"></a><font color="#008C">有拆有合</font></h3><p>有拆有合指的是工作分解结构法，基于“架构先行”这一步输出的概要设计进行工作分解，工作分解的结果可以直接影响了产品开发的效率与质量。</p><p>工作分解是个有拆有合的过程，一个大的工程任务往往是由很多的小个的任务组成的，如何将一个大任务拆解成合适的小任务，能将大任务拆解成什么样的小任务，能拆解到什么粒度，拆解是否准确，这是”拆“的过程。怎样对任务进行量化与质化，怎么将任务落地到具体的执行人员上，怎么进集成怎么验收，这是“合”。以下图的工作包分解表为例：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/product/wbs/wbs-7.PNG" alt="项目"></p><p>1，首先前三行定义了项目的目标、原则以及投入，说明了项目的交付目标、交付进度、交付的原则以及约束、还有确定了人力资源的投入；</p><p>2，任务分解成了一级任务、二级任务以及工作包、工作包名称，关键特性可以是具体需要实现的功能，也包括项目文档、测试部署、相关采购等；</p><p>3，除这些在任务树上也可以体现的内容外，还增加了 工作进展、状态、评论、风险、阶段目标、执行的人员、复杂度以及依赖条件；</p><p>4，输出最终交付成果。</p><p>工作包分解表可以使得团队协作更加顺畅，将不确定的大任务包分解成一个个确定的最小可执行工作包，是的开发工作从不确定到确定，有利于保证软件产品开发的效率与质量。</p><h3 id="迭代更新"><a href="#迭代更新" class="headerlink" title="迭代更新"></a><font color="#008C">迭代更新</font></h3><p>产品根据环境改变而迭代，根据反馈结果而更新。迭代更新其目的为了逐步逼近所需的最终目标，而每一次迭代更新得到的结果都会作为下一次迭代更新的初始输入。在不确定性较大的软件产品开发过程中，将产品开发分为迭代0、 迭代1、迭代2…..最终迭代目标这几个阶段，每个阶段的输出都是一个最小可行产品，即 MVP（Minimum Viable Product）。</p><p>如下图“10人以内小团队你极简精益产品开发法”所示：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/product/lean/lean-2.png" alt=""></p><p>1，迭代0，先完成信息输入，依据“以终为始、架构先行、有拆有合”的步骤完成客户目标确认、价值确定、需求分析、初版概要设计、初版工作拆解；</p><p>2，迭代1，进行软件开发，输出MVP1，依据“以终为始、架构先行、有拆有合”的步骤刷新客户目标、交付价值、客户需求、概要设计、进行二次工作拆解；</p><p>3，迭代2，进行软件开发，输出MVP2，依据“以终为始、架构先行、有拆有合”的步骤刷新客户目标、交付价值、客户需求、概要设计、进行三次工作拆解；</p><p>以此类推，逐步迭代更新，过程根据变化微调控保证方向正确，直至抵达最终交付目标。</p><h3 id="相关满意"><a href="#相关满意" class="headerlink" title="相关满意"></a><font color="#008C">相关满意</font></h3><p>相关满意指的是项目相关方满意，项目相关方是会影响项目或受项目所影响的组织、团队或人员。项目相关方的参与是项目成功的前提与保证，没有项目相关方，也就没有项目，忽略任何项目相关方都可能导致项目的失败。项目的开启、过程以及结果都需要能令项目相关方满意。</p><p>达成项目相关方满意需要从以下4个方面进行迭代推进以支持项目团队的工作：</p><p>1，识别相关方，相关方一般包括需要知晓情况的用户、客户、供应商、合作第三方，需要通知到的项目批准人、项目负责人，负责具体执行的项目开发团队：项目经理、产品经理、架构师、领域专家、各级工程师、测试、采购，以及其他的组织内外的项目支持职能部门；</p><p>2，管理预期，准确识别相关方的需求和期望；</p><p>3，提出方案，依据”以终为始、架构先行、有拆有合、迭代更新“法输出满足相关方需求和期望的提案；</p><p>4，迭代更新确保事态向最终目标的方向逐步推进；</p><p>项目相关方满意的核心就是在所有的相关方的预期中取得一个彼此都接受的解。</p><h2 id="三大基石"><a href="#三大基石" class="headerlink" title="三大基石"></a><font color="#FF8C00">三大基石</font></h2><h3 id="领域能力"><a href="#领域能力" class="headerlink" title="领域能力"></a><font color="#008C">领域能力</font></h3><p>领域能力狭义上指的是个人或团队所具备的相应专业能力，广义上指完成整个软件开发交付所需要的技能，包括产品思维能力、项目管理能力、架构设计能力、编码能力、测试能力、维护能力以及质量保证能力。领域能力是软件开发原则与行动的最重要的基石之一。没有对应的交付能力就不要谈什么产品开发原则与交付，比如一个拧螺丝的团队你非要他们在限定的时间内打造一根火箭，必然无法达成。</p><h3 id="企业文化"><a href="#企业文化" class="headerlink" title="企业文化"></a><font color="#008C">企业文化</font></h3><p>企业文化是极简产品开发法的基石之一，其涵盖了使命，目标，制度，边界，奖罚等，属于软件开发团队运作、开发原则与产品交付的最底层的基础设施。企业的使命讲的是企业与世界的关系，这跟企业员工离的较远，姑且不谈。而目标讲的是员工与企业的关系，每年制定的企业发展目标属于企业的战略范畴，体现了企业的战略方向以及资源投入的方向，团队目标与企业目标保持一致，个人目标与团队目标保持一致，这是最基本的团队运作准则，如果个人或团队年度目标不与企业目标对齐，那么个人或团队也拿不到资源得不到发展。而企业制度、边界与奖罚是团队运作的保障，奖什么罚什么更是最明显的企业文化导向，这里就不作举例说明了。</p><h3 id="组织到位"><a href="#组织到位" class="headerlink" title="组织到位"></a><font color="#008C">组织到位</font></h3><p>组织到位的第一个意思是：”组织结构影响产品结构“，组织基因即产品基因，依据康威第一定律：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs undefined">Organizations which design systems are constrained to produce designs which are copies of the communication structures of these organizations. - Melvin Conway(1967)<br></code></pre></td></tr></table></figure><p>翻译成中文即：”组织设计的产品/设计等价于这个组织的沟通结构“，通俗的来讲：产品结构必然是其组织内成员沟通结构的缩影，比如微服务。</p><p>组织到位的第二个意思是：人员到位，人事匹配。进行软件产品开发一方面需要配备相应的能力需求的人员，另一方面也需要讲究合适的人放在合适的岗位上，合适的岗位需要合适的人选，人选对了，事就成一半。</p><h2 id="自组织、自平衡与强管控"><a href="#自组织、自平衡与强管控" class="headerlink" title="自组织、自平衡与强管控"></a><font color="#FF8C00">自组织、自平衡与强管控</font></h2><p>软件产品的开发过程除了是一个业务管理过程也是一个团队/个人管理过程，“极简精益产品开发法”更多讲的是业务管理的过程，然而团队/个人管理的成功与否也可以决定产品开发的成败。软件开发过程是一个复杂的系统过程，而业务与团队也是一个复杂系统，需要以系统化的思维而非线性思维来看待。团队能否有效的自我组织、自我驱动直接影响软件开发的效率与质量。</p><p>基于此，这里提出团队/个人的三个组织形态：<strong>自组织、自平衡与强管控</strong>，如下面的组织形态变化图所示，组织的形态变化有自组织、自平衡、强管控这三个形态，自组织态会过度到自平衡态，如果没有外力的干预作用，自组织态与自平衡态都容易滚落到强管控态，强管控态势能最低也是最稳定的最终形态。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/product/lean/lean-0.png" alt=""></p><p>在一定的企业文化以及组织架构下，每一个管理决策和管理措施的输出背后，都有一种人性假设，道斯·麦格里格（Douglas McGregor）的X-Y理论（Theory X-Theory Y）概括了对人性的根本性理解：X理论-人性本恶，Y理论-人性本善。中国古代也有儒家人性论之争，最具有代表的就是孟子的“人性本善论”和荀子的“人性本恶论”。</p><p>人性本恶论认为员工需要被强力控制与安排，员工都讨厌工作、工作的驱动力只是为了保住饭碗、对于工作能躲就躲，因此有了强KPI管理法，271、361、末位淘汰、设定严格的规则制度等，如上图所示，其“具有低势能稳定性的形态，但不会带来创新和竞争力”[1]；</p><p>人性本善论认为员工是能自我驱动的，愿意自我承担责任、积极向上、会自我以目标为驱动努力工作，因此有了OKR管理法、工作-生活平衡、对员工授权、人性激发、信任管理法等，如上图所示，其具有“高势能非稳定的状态，但确是激发创造力、提升效能的利器”[1]；</p><p>软件开发是一个创造性的脑力劳动，其并不适合以人性本恶论为出发点强管控管理法，但是高效率、高创造性的自组织形态却具有不稳定性的特征，因此需要微管控使之一直处于自平衡态，既保持自组织的高效能、高创造力的特性，又规避了强管控管理法带来的无创新、无竞争力、低效率的弊端。以上三种形态在一个大的组织结构内可能同时存在。</p><p>本文将方法论局限在“10人以内小团队” 也是为了更容易达到团队的自组织或自平衡态，使之保持团队的勇于担当、自管理、高效率、高质量输出、高创造力形态。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font color="#FF8C00">小结</font></h2><p>本文提出了一种 “小团队极简产品开发法”，用以解决软件开发的复杂度问题以及需要解决的四个命题，即：需要交付的价值是什么？如何判断什么是有用的价值？如何高效地交付？如何高质量地交付？详解了“以终为始，架构先行，有拆有合，迭代更新，相关满意”这五大原则以及“领域能力，企业文化，组织到位”这三大基石，此外还论述了“自组织、自平衡、强管控”这三种团队组织形态。其目的都是为了使得团队/个人目标与组织目标保持一致并且“高效、高质量地交付有用的价值”。此外，作者能力与认知都有限，”我讲的，可能都是错的“，欢迎大家拍砖留念。</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中科大硕，某AI独角兽深度学习高级软件主管工程师、架构师，前EMC资深首席工程师，主要工作背景在深度学习、大数据、云计算、分布式中间件以及Linux内核领域。</p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a><font color="#FF8C00">参考资料</font></h2><p>[1] 《精益产品开发：原则、方法与实施》 何勉著</p><p>[2] <a href="https://zhuanlan.zhihu.com/p/56556328" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/56556328</a></p><p>[3] <a href="https://www.cnblogs.com/yanglang/p/10270592.html" target="_blank" rel="noopener">https://www.cnblogs.com/yanglang/p/10270592.html</a></p><p>[4] <a href="https://www.allthingsdistributed.com/2006/11/working_backwards.html" target="_blank" rel="noopener">https://www.allthingsdistributed.com/2006/11/working_backwards.html</a></p><p>[5] <a href="https://www.sohu.com/a/299920333_263553" target="_blank" rel="noopener">https://www.sohu.com/a/299920333_263553</a></p>]]></content>
      
      
      <categories>
          
          <category> ideology </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ideology </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>认识与实践 – 第1篇 - 系统思考，分而治之 - 工作分解结构法</title>
      <link href="/2022/04/01/ideology_1/"/>
      <url>/2022/04/01/ideology_1/</url>
      
        <content type="html"><![CDATA[<h2 id="1-前言"><a href="#1-前言" class="headerlink" title="1. 前言"></a><font color="#FF8C00">1. 前言</font></h2><p>在一个软件工程项目组里有四种角色特别重要，即：架构师、领域专家、产品经理以及项目经理，在一个比较大的项目里或者大公司大部门里，这四类角色一般分别对应四个人，然而在中小型项目里，特别是创业型公司或大公司里的小部门，这四类角色可能是四者合一的，即从团队当中选定一位有能力担当这四个角色的成员。如果这个成员原来就是架构师，那么对这位架构师的要求就是除了专业技能之外还应该具有项目管理能力。</p><p>根据定义项目是“为提供某项独特产品或服务所做的临时性努力”，其本身的特点是<strong>“变化”</strong>，因此，项目管理对架构师本身来说也是具有很大的挑战性的一项管理工作。项目管理具有入门容易、精通难的特性，大多数项目管理给工程师的感觉就是定计划、看进度、催活、做汇报，实际上这是没有领悟项目管理的精髓。</p><p>PMBOK定义项目管理为：“项目的管理者，在有限的资源约束下，运用系统的观点、方法和理论，对项目涉及的全部工作进行有效地管理。即从项目开始到项目结束的全过程进行启动、计划、执行、监控和验收，以实现项目的目标。”，即项目管理有其自身的<strong>“观点、方法与理论”</strong>，而在项目的落地过程中，所有节点的计划、执行、监控、风险管理以及验收等都依赖于工作分解结构（WBS: Work Breakdown Structure ），不同的行业对项目管理有不同的需求，进而有不同的工作分解结构方法，本文讲述的是与软件工程紧密相关的工作分解结构法。</p><h2 id="2-项目管理方法论"><a href="#2-项目管理方法论" class="headerlink" title="2. 项目管理方法论"></a><font color="#FF8C00">2. 项目管理方法论</font></h2><p>依据PMBOK理论定义以及软件工程实践，软件工程项目管理可以分为两大部分：一是5大流程，二是12大知识领域 ，如下：</p><h3 id="2-1-项目管理五过程"><a href="#2-1-项目管理五过程" class="headerlink" title="2.1 项目管理五过程"></a>2.1 项目管理五过程</h3><p>项目管理五大过程包括项目的启动、计划、执行、监视和验收，如下图所示：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/product/wbs/wbs-2.PNG" alt="项目5过程"></p><ul><li><p>启动阶段，首先需要确定项目的目标和项目的关键负责人、进行业务分析、需求分析以及组建团队，并且宣布项目正式立项；</p></li><li><p>计划阶段，编写项目计划，把项目目标量化与质化，制定达到目标的里程碑，在这个阶段，还需要完成的是概要设计、目标分解、任务分派、风险评估等工作内容；</p></li><li><p>执行阶段，按计划开展项目，进行详细设计、编写代码、调试自测，阶段性的实现目标，这一步是软件工程最核心的一个步骤；</p></li><li><p>监控阶段，监控阶段与执行阶段是循环的关系，这一阶段需要准确识别偏差，判断影响项目进度因素，同时进行计划刷新与风险刷新以及任务刷新；</p></li><li><p>验收阶段，按照项目要求，进行项目验收，包括版本发布、文档归档以及项目复盘。</p></li></ul><p>不同于理论，在实践中，这5大过程是个计划、执行、检查、更新的循环过程，而不是一个线性过程。</p><h3 id="2-2-项目管理12项"><a href="#2-2-项目管理12项" class="headerlink" title="2.2 项目管理12项"></a>2.2 项目管理12项</h3><p>项目管理1.0版里涉及 范围、时间、成本以及质量，这四者是个平衡的过程。项目管理2.0里，又增加了 业务与组织，项目管理是为业务服务的，同时给组织保证结果。而在实践过程中容易发现软件工程项目管理其实涉及12大领域，即：业务、范围、进度、成本、质量、资源、风险、采购、相关方、沟通、测试以及综合管理，具体如下：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/product/wbs/wbs-0.PNG" alt="项目12项"></p><ul><li>业务管理，其涉及业务分析、客户管理；</li><li>范围管理，包括规划范围、需求分析、定义范围、工作分解、确认范围以及控制范围；</li><li>进度管理，其包括：规划进度里程碑，定义任务，排列任务优先级，估算人力资源，估算所需时间，制定进度计划表以及控制进度；</li><li>成本管理，包括规划成本管理，估算成本，制定预算以及控制成本；</li><li>质量管理，包括规划质量指标，QA测试，质量保证以及控制质量；</li><li>资源管理，这一部分与组织结构相关，是决定项目成败的关键要素，合适的项目需要合适的人选，其包括4个子过程：人力资源管理，组建团队，建设团队以及管理团队；</li><li>沟通管理，包括3个子过程：规划沟通，管理沟通，控制沟通；</li><li>风险管理，包括识别风险，风险分析，定量风险，提出应对以及控制风险；</li><li>采购管理，包括4个子过程：规划采购，实施采购，控制采购，结束采购；</li><li>相关方管理，相关方管理也是项目成败与否的一个非常关键的要素，包括4个过程：识别相关方，相关方参与，相关方满意度等；</li><li>测试管理，项目管理往往容易忽略掉QA测试的作用，在代码编写好后需要提前安排QA介入，记住一点没有经过QA严格质量测试的软件包是不能输出给客户的；</li><li>综合管理，综合管理的关键是综合平衡最优，平衡以上11项使之达到最优，包括制订章程，制定计划，指导与管理执行，监控项目，变更控制，结束项目。</li></ul><p>不管是项目管理5大流程还是项目管理12项，其中有一个非常重要的工作即创建<strong>“工作分解结构”</strong>，工作分解结构是开展一切项目管理的依据与基础，可以说没有“工作分解结构”就没有项目管理。</p><h3 id="2-3-工作分解结构"><a href="#2-3-工作分解结构" class="headerlink" title="2.3 工作分解结构"></a>2.3 工作分解结构</h3><p>在工作过程中，人的认知是有差异的，比较资深的人员描述一个任务或问题时会比较的抽象，而初级工程师比较能理解的是具体的任务描述，为了团队具有较好的执行力，就需要把抽象的概念或描述分解成具体的可执行的行为或任务，这就需要一种合适的工具或方法来分解概念与工作。</p><p>工作分解结构法（WBS: Work Breakdown Structure，是一个“描述思路的规划和设计的工具”，是以项目结果为导向的工作过程的结构分解方法论，是将抽象的概念或任务分解成具体的行为的一种工具。将工作进行合理的分解是项目负责人的重要能力之一，缺乏项目分解能力的项目负责人容易造成项目失败，“工作分解”的好坏与否 也可以决定项目的成败与否。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/product/wbs/wbs-1.PNG" alt="项目"></p><p>如上图所示，项目管理有两大基石：<strong>工作分解结构法与 企业文化+组织结构</strong>， WBS在PMBOK中给出的定义是：“WBS是针对可交付成果对项目要素进行的分组，它归纳和定义了项目的整个工作范围，每下降一层就代表对项目工作更详细地定义。”。这一定义说明WBS所分解的目标是工作包(Work Package)，以可交付成果为导向的。企业文化与组织结构也是项目成功与否的基石，企业文化作保证，组织调整到位可以给项目提供坚强的基础资源与能力。</p><p>“工作分解结构法”的任务拆解是个有拆有合的过程。一个大的工程任务往往是由很多的小个的任务组成的，如何将一个大任务拆解成合适的小任务，能将大任务拆解成什么样的小任务，能拆解到什么粒度，拆解是否准确，这是”拆“的过程。怎样对任务进行量化与质化，怎么将任务落地到具体的执行人员上，怎么进集成怎么验收，这是“合”。任务拆解比较的考验工程人员的工程能力，任务拆解是否成功是工程进度与工程交付能否成功的关键要素。</p><h2 id="3-如何进行工作结构分解"><a href="#3-如何进行工作结构分解" class="headerlink" title="3. 如何进行工作结构分解"></a><font color="#FF8C00">3. 如何进行工作结构分解</font></h2><h3 id="3-1-任务树分解法"><a href="#3-1-任务树分解法" class="headerlink" title="3.1 任务树分解法"></a>3.1 任务树分解法</h3><p>如下图所示，工作分解结构就是把项目可交付成果，比如总目标一级级的分解成较小的、更易于执行的组成部分的过程，建立工作分解结构的过程就是将项目进行显性化、结构化，将复杂的总目标分解成一级任务、二级任务，最后分解成最小可执行工作包的过程。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/product/wbs/wbs-4.PNG" alt="项目"></p><p>工作分解结构可以按功能、组成、生命周期以及组织的形式进行分析，在软件工程项目中，通常以项目生命周期 + 功能以任务树的方式分解项目。如下图所示，</p><p><strong>最终交付成果</strong>按生命周期分解成了 项目管理、业务、需求、设计与编码、集成以及交付这6项。然后设计与编码又按功能的形式分为一级任务特性：关键特性1、关键特性2、关键特性N，以此类推，直至分解成最小可执行工作包。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/product/wbs/wbs-3.PNG" alt="项目"></p><p>工作分解结构法是面向结果为导向的分解，分解过程中也需要适可而止，比如初级工程师需要给他分解到很具体的最小可执行工作包这种层次，而比较资深的工程师可以给他分解到关键特性这一层次即可，当然前提是这个资深工程师有能力承担这一特性的分解与执行。</p><p>此外，任务树适合项目汇报使用，而工作包表格适合团队内部协作使用，其能提供更详细的细节，因此在任务树拆解后，下一步是进行工作表格分解。</p><h3 id="3-2-工作表格分解法"><a href="#3-2-工作表格分解法" class="headerlink" title="3.2 工作表格分解法"></a>3.2 工作表格分解法</h3><p>对比于任务树，工作包表格可以在右侧增加更多的细节，这有利于团队协作，以下图的软件项目工作包表格为例：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/product/wbs/wbs-7.PNG" alt="项目"></p><p>1，首先前三行定义了项目的目标、原则以及投入，说明了项目的交付目标、交付的原则以及约束、还有确定了人力资源的投入,；</p><p>2，任务分解成了一级任务、二级任务以及工作包、工作包名称；</p><p>3，除这些在任务树上也可以体现的内容外，还增加了 工作进展、状态、评论、风险、阶段目标、执行的人员、复杂度以及依赖条件；</p><p>4，输出最终交付成果。</p><p>工作包表格的这些细节可以使得团队协作更加顺畅，所以一般开发过程中选用工作包分解表作为项目跟进的任务进度表。</p><h3 id="3-3-关键路径网络图分解法"><a href="#3-3-关键路径网络图分解法" class="headerlink" title="3.3 关键路径网络图分解法"></a>3.3 关键路径网络图分解法</h3><p>除了任务树与工作包表格之外还有关键路径网络图分解法，在项目当中有些任务比较重要而复杂，有些任务相互独立、有些任务又有依赖关系，</p><p>如下图所示，S 表示Start，F表示Finish，SS 表示同时启动，FS表示先完成再启动。F11任务需要在F1任务启动后10天再启动，F23与F31任务可以同时并发进行，</p><p>而最终交付的目标需要 F2211 与 F3111 同时完成。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/product/wbs/wbs-5.PNG" alt="项目"></p><p>关键路径网络图分解法明确了任务之间逻辑关系、先后关系、时间关系，有利于项目计划进度时间的评估与规划。</p><h2 id="4-工作分解结构法的理念与原则"><a href="#4-工作分解结构法的理念与原则" class="headerlink" title="4. 工作分解结构法的理念与原则"></a><font color="#FF8C00">4. 工作分解结构法的理念与原则</font></h2><p>以上内容讲的都是 工作分解结构法的 “术”的层次，其本身还有背后的理念 ，即“道”。工作分解结构法是<strong>“系统思维与分治思维”</strong>在软件工程项目中的应用。工作分解除了非常重要的专业技能，还需要遵循以下几个理念与原则：</p><p>1，滚动原则</p><p>如下图所示，项目的推进是一个 “分解、执行、检查、更新”滚动推进的过程，依据导弹思维，先保证大方向正确，开工，然后再在过程中调整小方向，直至最终精确的命中目标。项目管理也是一个逐步实现目标的过程，时间上近的获取的信息多、那么分解的层次与类目自然也就更细、更多、更准确，而时间上远的，因为信息不够完善，分解的层次与类目自然更少少，也没那么精确，在目标逐步达成后，可以进行刷新重新进行分解，完善工作包，直至最终达成目标。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/product/wbs/wbs-6.PNG" alt="项目"></p><p>2，MECE原则</p><p>MECE即“相互独立，完全穷尽”，是应用系统思维从全局的角度分解任务，既不重复也不遗漏，纵向递进，横向遍历。</p><p>3，量化质化原则</p><p>分解出来的工作包需要能量化，需要可量化的完成时间、可量化的验收标准，不能量化的任务需要质化，即以满意度的方式验收。</p><p>4，以上统下原则</p><p>工作包分解的目标是可交付成果，每一个下级成果有且只有一个上级成果，每一个上级成果是其下级成果之和，不同的交付成果可以分解到不同的层级；</p><p>5，适可而止原则</p><p>工作包并不是分解的越细越好，而应当根据项目特性的难易程度进行分解，难的复杂度高的分解细点、适当增加分解的层级，而容易的复杂度低的可以减少分层。</p><p>6，人事匹配原则</p><p>需要考虑每一级任务到底需要什么样的领域专家或者工程人员，任务要能匹配工程人员的能力，工程人员能力要能匹配任务，考虑到执行力，还需要将任务分解到人人有事做，事事能完成的层次。</p><h2 id="5-小结"><a href="#5-小结" class="headerlink" title="5. 小结"></a><font color="#FF8C00">5. 小结</font></h2><p>本文从宏观角度讲述了工作分解结构法的“术”与“道”，在宏观上理解了工作分解结构法，还需要微观上进行实践，才能做到“学以致用”。另作者能力与认知都有限，”我讲的，可能都是错的“，欢迎大家拍砖留念。</p><h2 id="6-作者简介"><a href="#6-作者简介" class="headerlink" title="6. 作者简介"></a><font color="#FF8C00">6. 作者简介</font></h2><p>常平，中科大硕，某AI独角兽深度学习高级软件主管工程师、架构师，前EMC资深首席工程师，主要工作背景在深度学习、大数据、云计算、分布式中间件以及Linux内核领域。</p><h2 id="7-版权申明"><a href="#7-版权申明" class="headerlink" title="7. 版权申明"></a><font color="#FF8C00">7. 版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p><h2 id="8-参考资料"><a href="#8-参考资料" class="headerlink" title="8. 参考资料"></a><font color="#FF8C00">8. 参考资料</font></h2><p>[1] 《极简项目管理》 郭致星著</p>]]></content>
      
      
      <categories>
          
          <category> ideology </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ideology </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>深度学习 – 第2篇 - 模型训练与系统评价指标</title>
      <link href="/2021/07/25/ai_2/"/>
      <url>/2021/07/25/ai_2/</url>
      
        <content type="html"><![CDATA[<h2 id="1-前言"><a href="#1-前言" class="headerlink" title="1. 前言"></a><font color="#FF8C00">1. 前言</font></h2><p>不同于教科书里讲的深度学习的评价指标，这里主要讲述生产训练中常用的评价指标。通常在分布式训练中对训练的过程与结果会进行评价，比如选择一个评价指标：准确率，即表明模型求解给定问题的准确度。而本文提到的评价指标主要分为两大类，即训练结果评价与训练系统评价。</p><h2 id="2-训练指标"><a href="#2-训练指标" class="headerlink" title="2. 训练指标"></a><font color="#FF8C00">2. 训练指标</font></h2><p>教科书里经常提到的深度学习的评价指标有准确率、精确率、召回率、F1值等，如下：</p><ul><li><p>准确率（Accuracy），所有的预测正确（正类负类）的占总的比重；</p></li><li><p>精确率（Precision），查准率，即正确预测为正的占全部预测为正的比例；</p></li><li><p>召回率（Recall），查全率，即正确预测为正的占全部实际为正的比例；</p></li><li><p>F1值（H-mean值），F1值为算数平均数除以几何平均数，且越大越好；</p></li></ul><p>实际上这些指标在真正的生产过程中用的不多，在实际的分布式训练过程中，比较关心的训练评价指标有：</p><ul><li>加速比（speedup），即多卡训练下的单卡吞吐量平均指标除以单卡训练下的吞吐量平均指标，比如，大规模训练下的 ResNet-50 v1.5的单卡FPS指标是600，而单卡训练的FPS指标是800，那么加速比即 600/800 = 0.75，加速比体现的是训练集群的效率与可扩展性，越高的加速比表明训练集群的资源利用率越高，但是越高的加速比要求对训练集群的技术要求也越高。比如 一个 1000张卡的训练集群，要求 加速比 0.9以上，那么对于主机间的网络、主机内的网络、全栈软件、训练卡内部的硬件架构、集合通信拓扑算法、训练算法的优化等的要求都极高，这就涉及到整个分布式训练系统的问题，而不是单个点能彻底解决的；</li><li>吞吐量，sequence/sec 或 FPS, 即每秒能处理的图片数或数据量；</li><li>收敛时间（Time）与训练次数（epoch），生产过程中对训练所有的时间是有要求的，假设给定一个模型的训练次数(epoch)为100，如果要把这个100次都训练完需要 好几天，甚至好几个星期，那么可以认为生产不适用，基本上可以定义 训练一个模型到收敛需要 24小时以上，都可以看做是生产不适用，需要扩大训练集群的规模，使之训练时间控制在24小时之内；</li><li>平均准确率(eval Accuracy)，平均准确率是训练是否收敛的重要评判标准之一，比如定义一个 Resnet50 v1.5 的训练模型的准确率为 76%，如果训练结束的平均准确率能达到这个值就认为训练是收敛的；</li><li>可收敛，训练的最终结果可以达到 平均准确率的要求，即认为可收敛，否者即任务训练失败；</li><li>学习率(Learning rate)与损失率(Loss)，学习率大模型训练学习速度快，但是易导致损失率爆炸, 学习率小模型训练学习速度慢，而且容易过拟合，收敛速度慢；</li><li>曲线拟合(Curve Fitting)，这是一个非常重要的评价手段，在XPU训练的场景下，通常先用一个已有的之前训练好模型为基础或先用GPU训练出一个基础模型，然后把XPU训练的结果指标跟GPU训练模型的指标进行比较，曲线拟合即认为XPU的训练结果达标，这也是调试XPU训练结果的一个重要手段。这里埋一个问题，按照曲线拟合的说法，假设有一个2000张XPU卡的集群，怎样评价这个集群训练的结果是正确的？以GPU训练的结果做比较，那么找一个这么大规模的GPU集群进行训练然后得到想要的模型做基础匹配也是不大现实的，那么需要采用什么技术方案才能解决这个问题？</li></ul><p>以TensorBoard为例，说明模型的评价指标，在下面的命令行列输入一个baseline:/log_path_2：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs undefined"># tensorboard --logdir=training_model:/log_path_1, baseline:/log_path_2<br></code></pre></td></tr></table></figure><p>这个baseline 的模型已经确定是精度达标，生产可用的。然后 XPU训练的模型的 <code>training_model:/log_path_1</code> 与这个GPU训练处的baseline进行比，在tensorboard里可以表现如下图：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/aitraining/2/training-results.png" alt="训练结果"></p><p>在上图里，新的模型的eval_accuracy值与baseline的值最终是一样的，这说明训练结果是收敛且精度达标，eval_accuracy中间的线有点差异是由于按不同的训练次数进行tensorboard指标保存所造成。新模型的Loss线与Learning_rate 线也与基础线吻合，这说明XPU训练的模型质量可生产适用。eval_accuracy、Loss、Learning_rate是三个最重要的度量指标，只要这样三个指标达标，那么大概率即可判断这个在XPU下新训练的模型具备生产可用能力。</p><h2 id="3-系统指标"><a href="#3-系统指标" class="headerlink" title="3. 系统指标"></a><font color="#FF8C00">3. 系统指标</font></h2><p>分布式训练系统其本身也是一个分布式系统，因此除了训练领域相关的度量指标，也有与分布式系统质量有关的一套度量指标，其中比较重要的几项内容如下：</p><ul><li><p>可用性(Availability)，可用性指的是分布式训练系统长时间可对外提供服务的能力，通常采用小数点后的9的个数作为度量指标，按照这种约定“五个九”等于0.99999（或99.999％）的可用性，默认企业级达标的可用性为6个9。但是当前从时间维度来度量可用性已经没有太大的意义，因为设计得好的系统可以在系统出现故障得情况下也能保证对外提供得服务不中断，因此，当前更合适得可用性度量指标 是请求失败率;</p></li><li><p>可靠性(Reliability)，可靠性一般指系统在一定时间内、在一定条件下可以无故障地执行指定功能的能力或可能性， 也是采用小数点后的9的个数作为度量指标，通常5个9的可靠性就可以满足企业级达标；</p></li><li><p>可伸缩性(Scalability)，是指通过向系统添加资源来处理越来越多的工作并且维持高质量服务的能力，其受可用性以及可靠性的制约，集群规模越大出故障的概率越高从而降低可用性、可靠性，为了保证可用性以及可靠性达标，需要适配合理的可伸缩性指标；</p></li><li><p>韧性(resilience)，通常也叫容错性（fault-tolerant），也就是健壮和强壮的意思，指的是系统的对故障与异常的处理能力，比如在软件故障、硬件故障、认为故障这样的场景下，系统还能保持正常工作的能力，分布式训练系统的容错能力是一个非常重要的指标。</p></li></ul><h2 id="4-小结"><a href="#4-小结" class="headerlink" title="4. 小结"></a><font color="#FF8C00">4. 小结</font></h2><p>本文从实践的角度讲述了分布式训练的训练结果评价指标与系统评价指标，这些指标是度量一个分布式训练系统与训练的模型是否生产可用的重要参考。日拱一卒，功不唐捐，分享是最好的学习，与其跟随不如创新，希望这个知识点对大家有用。另作者能力与认知都有限，”我讲的，可能都是错的“，欢迎大家拍砖留念。</p><h2 id="5-作者简介"><a href="#5-作者简介" class="headerlink" title="5. 作者简介"></a><font color="#FF8C00">5. 作者简介</font></h2><p>常平，中科大硕，某AI芯片公司深度学习高级软件主管、架构师，前EMC资深首席工程师，主要工作背景在深度学习、Ai平台、系统调优、大数据、云计算以及Linux内核领域。</p><h2 id="6-参考资料"><a href="#6-参考资料" class="headerlink" title="6. 参考资料"></a><font color="#FF8C00">6. 参考资料</font></h2><p>[1] <a href="https://www.changping.me">https://www.changping.me</a></p><h2 id="7-版权申明"><a href="#7-版权申明" class="headerlink" title="7. 版权申明"></a><font color="#FF8C00">7. 版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>深度学习 – 第1篇 - 什么是分布式训练</title>
      <link href="/2021/04/18/ai_1/"/>
      <url>/2021/04/18/ai_1/</url>
      
        <content type="html"><![CDATA[<h2 id="1-前言"><a href="#1-前言" class="headerlink" title="1. 前言"></a><font color="#FF8C00">1. 前言</font></h2><p>深度学习软件工程具有一体两面性：单卡的功能完备性、质量、用户体验以及多卡大规模。多卡大规模的出现是为了解决这样一个主要矛盾，即：“日益增长的数据、模型训练的需求与当前单卡计算能力无法满足这个需求之间的矛盾”，而分布式训练可以通过扩展卡子的规模解决这个矛盾，因此，这就是分布式训练的价值。</p><p>然而，正如懂得很多道理，仍旧过不好这一生一样，懂得很多分布式训练的理论与知识，也不一定就能做好一个分布式训练系统。把这么多机器连接跑起来、跟跑好也是两回事，分布式训练是一门实践的软件工程，只有你PK过设计方案，调试过一个个Bug，手把手的敲过一行行的代码，为了性能指标能达标无所不用其极的去验证各种性能优化方案，才能知道细节在哪里，难点在哪里，痛点、挑战点在哪里。因此，宏观处着眼，微观处着手，才能完全理解分布式训练的道理。</p><p>一个知识领域里的 “道 法 术 器” 这四个境界需要从 微观、中观以及宏观 三个角度来把握，微观是实践，中观讲方法论，宏观靠领悟。本系列文章我把它命名为《分布式训练与推理实战》，从工程实战的角度拆解分布式训练里最重要的十八个套路，也是从“微观实践、中观方法论、宏观领悟”这三个维度系统性的讲述分布式训练技术，本文讲述第1式，也是最难讲清楚的一式（也后续再迭代更新），即本质的一问：<strong>“什么是分布式训练“</strong>。</p><h2 id="2-什么是分布式训练"><a href="#2-什么是分布式训练" class="headerlink" title="2. 什么是分布式训练"></a><font color="#FF8C00">2. 什么是分布式训练</font></h2><p>简单来说，<strong>分布式训练 = 分布式训练系统 = 分布式系统 + 训练系统</strong>，因此，要解答什么是分布式训练就需要解答什么是分布式系统以及什么是训练系统，而<strong>“系统 = 要素x连接 + 目的 + 边界”</strong>，因此进一步的就是需要分析分布式系统的要素、连接、目的与边界以及训练系统的要素、连接、目的与边界。</p><h3 id="2-1-分布式系统"><a href="#2-1-分布式系统" class="headerlink" title="2.1 分布式系统"></a>2.1 分布式系统</h3><p>在AI训练过程中采用单卡总会遇到一些问题，比如原始的数据样本太大无法加载进训练卡，或者模型太大无法训练，那么这就需要用到分布式技术把大量的数据分割成小块由多个训练卡分别进行计算，在更新运算结果后，再将结果统一合并得出最终的可用模型。百科上对分布式系统的定义有：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs undefined">A distributed system is a system whose components are located on different networked computers, which communicate and coordinate their actions by passing messages to one another. The components interact with one another in order to achieve a common goal.<br></code></pre></td></tr></table></figure><p>即：</p><blockquote><p>分布式系统是指其组件位于不同的网络计算机上的系统，这些组件通过相互传递消息来进行通信和协调其动作，且彼此相互交互以完成一个共同的任务目标。</p></blockquote><p>从这句话可以得出三个结论：</p><ul><li>分布式系统的组件是位于不同的网络计算机上的；</li><li>分布式系统的组件通过传递消息进行通信与协调的；</li><li>分布式系统的组件是通过相互交互以完成一个共同的任务目标，同时是有边界的；</li></ul><p>因此基于此定义，拆解分布式系统的概念，从中可以看到分布式系统里的要素即为组件，连接即网络，目的是共同的任务目标。其中的位于不同的网络计算机上的“组件”是分布式系统的要素，即各种计算单元，比如Ai训练卡，“网络”是分布式系统的连接，即神经网与数据网，“共同的任务目标”是分布式系统的目的，即训练，至此，再进一步抽象，可以推导出分布式系统的公理化定义，也是分布式系统的本质理论定义：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs undefined">分布式系统 = 计算 x 网络 + 目的 + 边界<br></code></pre></td></tr></table></figure><p>在这个公式里，计算即计算单元，是各种AI训练卡，比如GPU, TPU, DPU, DTU。网络即网络连接单元，在单个训练卡内为计算用的神经网，主机内的多个卡子之间是PCIE 以及PCIE Switch，以及各种高带宽通信网，比如GenZ,CXL,NVLINK,OpenCAPI,CCIX等，在主机之间是各种通信网络，比如RDMA网络、InfiniBand网络、普通的TCP网络以及对应的各种交换机，另外从磁盘 + 主机内存 + 训练卡的HBM这个IO路径我们认为属于IO网络，而这里的目的 即<strong>训练</strong>，同时这个系统是有边界的，其专注于解决Ai训练过程中的难题，不是什么功能都能往里塞都能解决。</p><h3 id="2-2-训练系统"><a href="#2-2-训练系统" class="headerlink" title="2.2 训练系统"></a>2.2 训练系统</h3><p>以数据并行随机梯度下降( SGD )技术为例，神经网络训练的过程如下:</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/aitraining/1/ai-training.PNG" alt="AI训练"></p><p>1，首先需要通过在第一个step进行Broadcast操作将参数同步到集群内的所有的训练卡上;</p><p>2，将数据样本切片分发到整个集群的每张训练卡上并且通过data pipeline技术将数据样本加载进训练卡的高速内存空间内，作为输入X;</p><p>3，每个训练卡在其数据样本上运行前向传播，计算出误差LOSSi；</p><p>4，对计算出的LOSSi进行反向传播，得到梯度GRADi；</p><p>5，所有的训练卡在主机内及主机之间进行集合通信并进行梯度归约(AllReduce)；</p><p>6，最后再进行参数更新以获得新的梯度参数。</p><p>本质上分布式训练是<strong><em>数据加载、前向传播、反向传播、集合通信以及参数更新\</em></strong>这5个步骤的逻辑组合，因此，基于以上步骤，这里可以推导出<strong>训练系统</strong>的公式定义如下：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs undefined">训练系统 = 数据加载 + （前向传播 + 反向传播） + 集合通信 + 参数更新<br></code></pre></td></tr></table></figure><p>从上面的步骤可知分布式训练是在固定的步骤迭代中进行的，并且需要系统内的所有的训练卡都完成它们的迭代步骤，才能进行最后的参数更新，这相当于在单个训练卡上执行梯度下降技术，但是通过在系统内所有的训练卡之间分发数据样本并同时执行计算来获得训练的加速。</p><h3 id="2-3-举例说明"><a href="#2-3-举例说明" class="headerlink" title="2.3 举例说明"></a>2.3 举例说明</h3><p>以TensorFlow为例说明模型的训练过程，TensorFlow 是用数据流图做计算的，如下图所示:</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/tensorflow/tf_arch_dataflow.gif" alt="计算流图示例" style="zoom:150%;"></p><center>图片来源于网络版权归原作者所有</center><p>图中显示了 TensorFlow 的训练过程，其包含输入（input）、塑形（reshape）、Relu 层（Relu layer）、Logit 层（Logit layer）、Softmax、交叉熵（cross entropy）、梯度（gradient）、SGD 训练（SGD Trainer）等部分。</p><p>它的训练过程是，首先从数据分片输入开始，经过Reshape数据清洗后，进行前向传播运算，通过Relu 层后得到LOSS值，然后进入 Logit  层，再进行反向传播并且用 Cross Entropy、softmax等  来计算梯度，接着进行梯度归约(Allreduce)，这一步在分布式场景就涉及集合通信的过程，最后进行参数更新SGD  Trainer，如此迭代循环直到获得收敛指标达标的结果为止。</p><h2 id="4-小结"><a href="#4-小结" class="headerlink" title="4. 小结"></a><font color="#FF8C00">4. 小结</font></h2><p>采用分布式训练的目的往往也是因为数据量或模型太大，一个训练卡放不下，因此对数据或者模型进行切分，分发到多卡上进行计算与归约。本文很概况性的讲述了什么是分布式训练，简单来说分布式训练就是分布式计算的一种，通过对数据样本的计算，得出最后可用的模型再用于数据推理。本系列文章的后续内将展开讲述分布式训练系统的基础理论、训练过程、质量保证、集合通信、系统工程、产品化等，同样分布式训练系统除了解决训练所带来的各种故障也还需要解决分布式所带来的各种故障。</p><p>日拱一卒，功不唐捐，分享是最好的学习，与其跟随不如创新，希望这个知识点对大家有用。另作者能力与认知都有限，”我讲的，可能都是错的“，欢迎大家拍砖留念。</p><h2 id="5-作者简介"><a href="#5-作者简介" class="headerlink" title="5. 作者简介"></a><font color="#FF8C00">5. 作者简介</font></h2><p>常平，中科大硕，某AI芯片公司深度学习高级软件主管、架构师，前EMC资深首席工程师，主要工作背景在深度学习、Ai平台、系统调优、大数据、云计算以及Linux内核领域。</p><h2 id="6-参考资料"><a href="#6-参考资料" class="headerlink" title="6. 参考资料"></a><font color="#FF8C00">6. 参考资料</font></h2><p>[1] <a href="https://blog.tensorflow.org/2019/09/tensorflow-20-is-now-available.html" target="_blank" rel="noopener">https://blog.tensorflow.org/2019/09/tensorflow-20-is-now-available.html</a></p><h2 id="7-版权申明"><a href="#7-版权申明" class="headerlink" title="7. 版权申明"></a><font color="#FF8C00">7. 版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>思想体系 – 第28式 - 五大原则，三大基石 - 10人以内小团队极简精益产品开发法</title>
      <link href="/2021/02/17/distributed-product_Lean_development/"/>
      <url>/2021/02/17/distributed-product_Lean_development/</url>
      
        <content type="html"><![CDATA[<h2 id="产品开发的本质"><a href="#产品开发的本质" class="headerlink" title="产品开发的本质"></a><font color="#FF8C00">产品开发的本质</font></h2><p>根据<strong>第一性原理</strong>思维，可以得出产品开发的本质即：<strong>“高效、高质量地交付有用的价值”</strong>[1]。那么从这句话可以推导出四个需要解决的命题，即：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs undefined">1，需要交付的价值是什么？<br>2，如何判断什么是有用的价值？<br>3，如何高效地交付？<br>4，如何高质量地交付？<br></code></pre></td></tr></table></figure><p>此外，在软件产品开发过程中除了面临确定性复杂度之外还经常面临不确定性复杂度，不确定性的复杂度比确定性的复杂度更难解决，更容易引起焦虑，更容易带来团队<strong>熵增</strong>，也更容易造成软件开发交付的失败。因此，为了<strong>简单有效</strong>地解决这四个命题以及其所自带的复杂度问题，结合精益产品理论，本文提出一种从实战中总结出来的<strong>“极简精益产品开发法”</strong>。需要额外说明的是，本方法论还有两个约束条件：</p><ul><li><p>本方法论仅适用于以搞生产力为主而非以搞生产关系为主的企业、部门、团队或个人；</p></li><li><p>本方法论仅适用于<strong>“The two pizza team”</strong>，即小于10人的小团队或单兵作战能力很强的个体，比如10倍工程师；</p></li></ul><h2 id="极简精益产品开发法"><a href="#极简精益产品开发法" class="headerlink" title="极简精益产品开发法"></a><font color="#FF8C00">极简精益产品开发法</font></h2><p>为了简单有效地解决<strong>“需要交付的价值是什么？如何判断什么是有用的价值？如何高效地交付？如何高质量地交付？”</strong> 这四大命题以及软件开发所面临的确定与不确定复杂度，这里采用结构化的方法提出的极简精益产品开发思维模型，其涵盖五大原则与三大基石，即：</p><ul><li>五大原则：以终为始，架构先行，有拆有合，迭代更新，相关满意</li><li>三大基石：领域能力，企业文化，组织到位</li></ul><p>本极简精益产品开发法思维模型导图如下：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/product/lean/lean-1.png" alt=""></p><p>在极简精益产品开发法思维模型里，“领域能力、企业文化、组织到位”属于基石的范畴，三大基石不到位，则产品开发与交付的原则与行动无效。在五大原则里，“以终为始”是为了解决“判断需要交付的价值是什么？如何判断什么是有用的价值？”这两个问题，“架构先行，有拆有合，迭代更新，相关满意”是为了解决如何高效地交付，如何高质量地交付以及如何解决软件开发的确定性与不确定性复杂度。</p><h2 id="五大原则"><a href="#五大原则" class="headerlink" title="五大原则"></a><font color="#FF8C00">五大原则</font></h2><h3 id="以终为始"><a href="#以终为始" class="headerlink" title="以终为始"></a><font color="#008C">以终为始</font></h3><p>“以终为始”是一种逆向思维，在软件开发里的应用指的是从最终的交付价值出发，反向推理交付过程，寻找软件开发的关键要素，获取反馈采取正确的策略，从而达成有用的价值交付。如下图所示，从未来的终局看现在，使用获取的未来信息强化现在的行为，赋予现在的行为以塑造未来的力量。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/product/lean/lean-4.png" alt=""></p><p>“以终为始”是确保正确地做事以及做的是正确的事的一种思维方式，在进行软件开发之前就进行了从交付结果开始的倒推分析，从交付结果得出开发的方向与方案。这里以“逆向工作法”以及“客户导向法” 为例说明软件开发过程中 “以终为始”思维的使用。</p><h4 id="逆向工作法"><a href="#逆向工作法" class="headerlink" title="逆向工作法"></a>逆向工作法</h4><p>逆向工作法是亚马逊所推崇的商业新哲学，因为产品最终的交付要“以客户为中心”，那就先从客户侧开始倒推开发，逆向工作法有助于一开始就把重心放在客户所真正关心的问题上，而不是一堆程序员坐在办公室内拍脑袋替客户做假想，进而避免一些无效的开发决策，使得确保推出的是有用、有价值、用户体验佳的产品。</p><p>拆解这个概念为具体的行动，亚马逊讲述了这个思维方式的应用步骤[4]：</p><p>1，先写一篇内部用的产品新闻稿，简单描述一下这个产品的特点与好处是什么，是为了解决什么痛点而产生，然后描述具体的问题，拿出一个新的解决方案，虚构一个用户的心声，设身处地为用户着想，然后发出来给内部同事，经过审核的也可以外发给公众；</p><p>2，写一个常见的FAQ问题文档，定义产品的用途以及考虑用户使用时会遇到的问题以及回答如何解决，FAQ需要包含外部客户会问的问题以及内部用户会问的问题；</p><p>3，定义客户体验，详细描述客户使用产品时会遇到的使用场景。比如用户界面是怎么样的，软件部署是怎么部署的，软件的技术架构图是怎么样的，先给客户一个能够呈现端到端体验的假象视图；</p><p>4，编写用户手册，用户手册是客户用来真正了解产品是什么以及如何使用它的，用户手册通常有三个部分：概念、操作方法和参考，它们之间告诉用户使用产品所需的所有知识。,</p><p>5，获取反馈，以上内容完成后，获取用户/客户反馈，然后在产品的生命周期中，不断迭代而演化产品的开发交付文档。</p><p>逆向工作法的目的是为了明白真正的用户/客户是谁，用户/客户的真实需求是什么，用户/客户的需要最先解决什么痛点等，而且以上步骤也只是一种应用方案，目的一致则无需拘泥于形式，只要思路和效果可以达到有效理解客户的目的即可。</p><h4 id="客户导向法"><a href="#客户导向法" class="headerlink" title="客户导向法"></a>客户导向法</h4><p>客户导向法讲的是“先有客户再有产品与技术”， 详细可以参考《第25式- 让技术回归常识,先有客户再有技术》，其理念上与逆向工作法类似，不同之处在于 逆向工作法是具体的行动，而客户导向法是认知上的提升。在这里，需要先定义什么是客户以及什么是客户价值：</p><ul><li>什么是客户？狭义的客户 = 买单的，广义上的客户 = 客户的客户 + 客户 + 客户的用户 + 所有相关方；</li><li>什么是客户价值？客户价值就是对客户有用的东西，价值来源于价值的交换。技术的目的就是做对客户有用的东西，并且技术的进化方向是由市场所决定的。以客户为中心，就是给客户创造价值，替解决用户难点、痛点、挑战点、为客户提供高质量低成本的产品，同时响应要及时；</li></ul><p>在产品开发上，软件开发人员常见的认知错误有：</p><ul><li>“我为用户想”，这是研发人员最容易犯的错，其已经有用户意识，但是却没有进一步与用户沟通，直接替用户做决定，也不清楚用户的使用场景，因此容易造成”所想“实际上并不是用户真正所想；</li><li>追求有挑战的技术而非技术的实用价值，也非从合适的解决用户问题的角度出发，将技术上的自嗨当成客户需求，比如用户需要从A地到B地，简单一点给用户一辆自行车就可以解决的问题，而技术自嗨就容易非要先自行造个飞机，然后拼命的给用户推销这个好这个快，但是用户却不买单；</li><li>闭门造车，不实事求是，不与客户做探讨，不做调查就把想象的或还处于概念上的东西当成客户需求，带来的是低效、低质量的产品开发过程；</li></ul><p>因此，开发产品需要先关注客户价值，在实现一个产品之前先确定这个是对客户有价值的，与客户/用户多沟通、一起共创，在“客户要的与我能提供的”二者之间保持理解一致，避免无效开发与交付。</p><h3 id="架构先行"><a href="#架构先行" class="headerlink" title="架构先行"></a><font color="#008C">架构先行</font></h3><h4 id="架构投影"><a href="#架构投影" class="headerlink" title="架构投影"></a>架构投影</h4><p>柏拉图在《理想国》中构建了他的哲学王国—理念世界，其把世界分成两个：“现象世界与理念世界，柏拉图认为这两个世界的关系是原本和慕本的关系，理念世界是原本、模型，现象世界是理念世界的影子或慕本”。基于此设想，产品架构可以是产品在现象世界的原本，通过产品架构可以看到产品的最终形态。在开发（编码）产品之前可以先定义软件产品的架构，给出产品的画像，提供产品的总体概要架构设计文档（注意这里概要设计文档即可，无需详细设计文档），设计文档内定义产品的设计哲学、设计原则、技术架构图、设计提案、所需要实现的功能特性、交付目标以及风险管理、用户操作等，然后发给团队一起评审，利用团队的力量避免交付的技术路线风险，同时为下一阶段的工作分解做准备。</p><h4 id="架构思维"><a href="#架构思维" class="headerlink" title="架构思维"></a>架构思维</h4><p>狭义上的架构通常指的是架构的技能，其属于“术”的范畴，而广义的架构则是客户需求、市场趋势、架构理念、架构方法论、架构技能、架构用的工具以及架构的边界这几个方面的组合体，应用抽象思维，即<strong>“势、道、法、术、器、界”</strong>这六个字 ，简称架构思维六元组，具体可以参考《第15式 - 架构思维》。</p><p><strong>势：时势</strong></p><p>“势”是架构的方向。从宏观处着眼，“势”是产品架构设计的市场趋势、是客户需求趋势也是技术的应用趋势；从微观处着手，“势”是功能设计的价值与目的。架构设计需要从宏观处着眼微观处着手，看清客户的需求趋势、市场趋势以及技术趋势，功能设计需要分析清楚当前功能的价值与目的。</p><p><strong>道：本质</strong></p><p>“道”是架构的认知，是架构师的设计理念、设计意图，是产品架构的灵魂，这里我把它定义为产品架构的设计哲学。</p><p><strong>法：方法论</strong></p><p>”法“是方法论，是架构设计的方法论，是架构设计的套路，这里我把它定义为产品架构的设计原则</p><p><strong>术：技能</strong></p><p>术，技能，是架构技能，这里定义为设计提案，以及各种功能与特性实现的思路</p><p><strong>器：工具</strong></p><p>”器“是工具，是架构设计用的工具，”工欲善其事必先利其器“，</p><p><strong>界：边界</strong></p><p>”界“是边界，是架构的约束限制，是技术边界、也是技术约束与技术限制，也是架构的取舍因素之一，是架构能做什麽不能做什麽的解读，对市场来说它是技术壁垒，对产品来说它是法律法规、是功能约束，对团队来说它是资源约束、是自我能力约束。</p><h3 id="有拆有合"><a href="#有拆有合" class="headerlink" title="有拆有合"></a><font color="#008C">有拆有合</font></h3><p>有拆有合指的是工作分解结构法，详细参考《第27式- 系统思考，分而治之 - 工作分解结构法》。基于“架构先行”这一步输出的概要设计进行工作分解，工作分解的结果可以直接影响了产品开发的效率与质量。</p><p>工作分解是个有拆有合的过程，一个大的工程任务往往是由很多的小个的任务组成的，如何将一个大任务拆解成合适的小任务，能将大任务拆解成什么样的小任务，能拆解到什么粒度，拆解是否准确，这是”拆“的过程。怎样对任务进行量化与质化，怎么将任务落地到具体的执行人员上，怎么进集成怎么验收，这是“合”。以下图的工作包分解表为例：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/product/wbs/wbs-7.PNG" alt="项目"></p><p>1，首先前三行定义了项目的目标、原则以及投入，说明了项目的交付目标、交付进度、交付的原则以及约束、还有确定了人力资源的投入；</p><p>2，任务分解成了一级任务、二级任务以及工作包、工作包名称，关键特性可以是具体需要实现的功能，也包括项目文档、测试部署、相关采购等；</p><p>3，除这些在任务树上也可以体现的内容外，还增加了 工作进展、状态、评论、风险、阶段目标、执行的人员、复杂度以及依赖条件；</p><p>4，输出最终交付成果。</p><p>工作包分解表可以使得团队协作更加顺畅，将不确定的大任务包分解成一个个确定的最小可执行工作包，是的开发工作从不确定到确定，有利于保证软件产品开发的效率与质量。</p><h3 id="迭代更新"><a href="#迭代更新" class="headerlink" title="迭代更新"></a><font color="#008C">迭代更新</font></h3><p>产品根据环境改变而迭代，根据反馈结果而更新。迭代更新其目的为了逐步逼近所需的最终目标，而每一次迭代更新得到的结果都会作为下一次迭代更新的初始输入。在不确定性较大的软件产品开发过程中，将产品开发分为迭代0、 迭代1、迭代2…..最终迭代目标这几个阶段，每个阶段的输出都是一个最小可行产品，即 MVP（Minimum Viable Product）。</p><p>如下图“10人以内小团队你极简精益产品开发法”所示：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/product/lean/lean-2.png" alt=""></p><p>1，迭代0，先完成信息输入，依据“以终为始、架构先行、有拆有合”的步骤完成客户目标确认、价值确定、需求分析、初版概要设计、初版工作拆解；</p><p>2，迭代1，进行软件开发，输出MVP1，依据“以终为始、架构先行、有拆有合”的步骤刷新客户目标、交付价值、客户需求、概要设计、进行二次工作拆解；</p><p>3，迭代2，进行软件开发，输出MVP2，依据“以终为始、架构先行、有拆有合”的步骤刷新客户目标、交付价值、客户需求、概要设计、进行三次工作拆解；</p><p>以此类推，逐步迭代更新，过程根据变化微调控保证方向正确，直至抵达最终交付目标。</p><h3 id="相关满意"><a href="#相关满意" class="headerlink" title="相关满意"></a><font color="#008C">相关满意</font></h3><p>相关满意指的是项目相关方满意，项目相关方是会影响项目或受项目所影响的组织、团队或人员。项目相关方的参与是项目成功的前提与保证，没有项目相关方，也就没有项目，忽略任何项目相关方都可能导致项目的失败。项目的开启、过程以及结果都需要能令项目相关方满意。</p><p>达成项目相关方满意需要从以下4个方面进行迭代推进以支持项目团队的工作：</p><p>1，识别相关方，相关方一般包括需要知晓情况的用户、客户、供应商、合作第三方，需要通知到的项目批准人、项目负责人，负责具体执行的项目开发团队：项目经理、产品经理、架构师、领域专家、各级工程师、测试、采购，以及其他的组织内外的项目支持职能部门；</p><p>2，管理预期，准确识别相关方的需求和期望；</p><p>3，提出方案，依据”以终为始、架构先行、有拆有合、迭代更新“法输出满足相关方需求和期望的提案；</p><p>4，迭代更新确保事态向最终目标的方向逐步推进；</p><p>项目相关方满意的核心就是在所有的相关方的预期中取得一个彼此都接受的解。</p><h2 id="三大基石"><a href="#三大基石" class="headerlink" title="三大基石"></a><font color="#FF8C00">三大基石</font></h2><h3 id="领域能力"><a href="#领域能力" class="headerlink" title="领域能力"></a><font color="#008C">领域能力</font></h3><p>领域能力狭义上指的是个人或团队所具备的相应专业能力，广义上指完成整个软件开发交付所需要的技能，包括产品思维能力、项目管理能力、架构设计能力、编码能力、测试能力、维护能力以及质量保证能力。领域能力是软件开发原则与行动的最重要的基石之一。没有对应的交付能力就不要谈什么产品开发原则与交付，比如一个拧螺丝的团队你非要他们在限定的时间内打造一根火箭，必然无法达成。</p><h3 id="企业文化"><a href="#企业文化" class="headerlink" title="企业文化"></a><font color="#008C">企业文化</font></h3><p>企业文化是极简精益产品开发法的基石之一，其涵盖了使命，目标，制度，边界，奖罚等，属于软件开发团队运作、开发原则与产品交付的最底层的基础设施。企业的使命讲的是企业与世界的关系，这跟企业员工离的较远，姑且不谈。而目标讲的是员工与企业的关系，每年制定的企业发展目标属于企业的战略范畴，体现了企业的战略方向以及资源投入的方向，团队目标与企业目标保持一致，个人目标与团队目标保持一致，这是最基本的团队运作准则，如果个人或团队年度目标不与企业目标对齐，那么个人或团队也拿不到资源得不到发展。而企业制度、边界与奖罚是团队运作的保障，奖什么罚什么更是最明显的企业文化导向，这里就不作举例说明了。</p><h3 id="组织到位"><a href="#组织到位" class="headerlink" title="组织到位"></a><font color="#008C">组织到位</font></h3><p>组织到位的第一个意思是：”组织结构影响产品结构“，组织基因即产品基因，依据康威第一定律：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs undefined">Organizations which design systems are constrained to produce designs which are copies of the communication structures of these organizations. - Melvin Conway(1967)<br></code></pre></td></tr></table></figure><p>翻译成中文即：”组织设计的产品/设计等价于这个组织的沟通结构“，通俗的来讲：产品结构必然是其组织内成员沟通结构的缩影，比如微服务。</p><p>组织到位的第二个意思是：人员到位，人事匹配。进行软件产品开发一方面需要配备相应的能力需求的人员，另一方面也需要讲究合适的人放在合适的岗位上，合适的岗位需要合适的人选，人选对了，事就成一半。</p><h2 id="自组织、自平衡与强管控"><a href="#自组织、自平衡与强管控" class="headerlink" title="自组织、自平衡与强管控"></a><font color="#FF8C00">自组织、自平衡与强管控</font></h2><p>软件产品的开发过程除了是一个业务管理过程也是一个团队/个人管理过程，“极简精益产品开发法”更多讲的是业务管理的过程，然而团队/个人管理的成功与否也可以决定产品开发的成败。软件开发过程是一个复杂的系统过程，而业务与团队也是一个复杂系统，需要以系统化的思维而非线性思维来看待。团队能否有效的自我组织、自我驱动直接影响软件开发的效率与质量。</p><p>基于此，这里提出团队/个人的三个组织形态：<strong>自组织、自平衡与强管控</strong>，如下面的组织形态变化图所示，组织的形态变化有自组织、自平衡、强管控这三个形态，自组织态会过度到自平衡态，如果没有外力的干预作用，自组织态与自平衡态都容易滚落到强管控态，强管控态势能最低也是最稳定的最终形态。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/product/lean/lean-0.png" alt=""></p><p>在一定的企业文化以及组织架构下，每一个管理决策和管理措施的输出背后，都有一种人性假设，道斯·麦格里格（Douglas McGregor）的X-Y理论（Theory X-Theory Y）概括了对人性的根本性理解：X理论-人性本恶，Y理论-人性本善。中国古代也有儒家人性论之争，最具有代表的就是孟子的“人性本善论”和荀子的“人性本恶论”。</p><p>人性本恶论认为员工需要被强力控制与安排，员工都讨厌工作、工作的驱动力只是为了保住饭碗、对于工作能躲就躲，因此有了强KPI管理法，271、361、末位淘汰、设定严格的规则制度等，如上图所示，其“具有低势能稳定性的形态，但不会带来创新和竞争力”[1]；</p><p>人性本善论认为员工是能自我驱动的，愿意自我承担责任、积极向上、会自我以目标为驱动努力工作，因此有了OKR管理法、工作-生活平衡、对员工授权、人性激发、信任管理法等，如上图所示，其具有“高势能非稳定的状态，但确是激发创造力、提升效能的利器”[1]；</p><p>软件开发是一个创造性的脑力劳动，其并不适合以人性本恶论为出发点强管控管理法，但是高效率、高创造性的自组织形态却具有不稳定性的特征，因此需要微管控使之一直处于自平衡态，既保持自组织的高效能、高创造力的特性，又规避了强管控管理法带来的无创新、无竞争力、低效率的弊端。以上三种形态在一个大的组织结构内可能同时存在。</p><p>本文将方法论局限在“10人以内小团队” 也是为了更容易达到团队的自组织或自平衡态，使之保持团队的勇于担当、自管理、高效率、高质量输出、高创造力形态。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font color="#FF8C00">小结</font></h2><p>本文提出了一种 “10人以内小团队极简精益产品开发法”，用以解决软件开发的复杂度问题以及需要解决的四个命题，即：需要交付的价值是什么？如何判断什么是有用的价值？如何高效地交付？如何高质量地交付？详解了“以终为始，架构先行，有拆有合，迭代更新，相关满意”这五大原则以及“领域能力，企业文化，组织到位”这三大基石，此外还论述了“自组织、自平衡、强管控”这三种团队组织形态。其目的都是为了使得团队/个人目标与组织目标保持一致并且“高效、高质量地交付有用的价值”。此外，作者能力与认知都有限，”我讲的，可能都是错的“，欢迎大家拍砖留念。</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中科大硕，某AI独角兽深度学习首席软件工程师，前EMC 大数据资深首席工程师，主要工作背景在深度学习、流式大数据、云计算、分布式中间件以及Linux内核。</p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a><font color="#FF8C00">参考资料</font></h2><p>[1] 《精益产品开发：原则、方法与实施》 何勉著</p><p>[2] <a href="https://zhuanlan.zhihu.com/p/56556328" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/56556328</a></p><p>[3] <a href="https://www.cnblogs.com/yanglang/p/10270592.html" target="_blank" rel="noopener">https://www.cnblogs.com/yanglang/p/10270592.html</a></p><p>[4] <a href="https://www.allthingsdistributed.com/2006/11/working_backwards.html" target="_blank" rel="noopener">https://www.allthingsdistributed.com/2006/11/working_backwards.html</a></p><p>[5] <a href="https://www.sohu.com/a/299920333_263553" target="_blank" rel="noopener">https://www.sohu.com/a/299920333_263553</a></p>]]></content>
      
      
      <categories>
          
          <category> product </category>
          
      </categories>
      
      
        <tags>
            
            <tag> product </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>思想体系 – 第27式- 系统思考，分而治之 - 工作分解结构法</title>
      <link href="/2021/02/13/distributed-product_project_wbs/"/>
      <url>/2021/02/13/distributed-product_project_wbs/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a><font color="#FF8C00">前言</font></h2><p>在一个软件工程项目组里有四种角色特别重要，即：架构师、领域专家、产品经理以及项目经理，在一个比较大的项目里或者大公司大部门里，这四类角色一般分别对应四个人，然而在中小型项目里，特别是创业型公司或大公司里的小部门，这四类角色可能是四者合一的，即从团队当中选定一位有能力担当这四个角色的成员。如果这个成员原来就是架构师，那么对这位架构师的要求就是除了专业技能之外还应该具有项目管理能力。</p><p>根据定义项目是“为提供某项独特产品或服务所做的临时性努力”，其本身的特点是<strong>“变化”</strong>，因此，项目管理对架构师本身来说也是具有很大的挑战性的一项管理工作。项目管理具有入门容易、精通难的特性，大多数项目管理给工程师的感觉就是定计划、看进度、催活、做汇报，实际上这是没有领悟项目管理的精髓。</p><p>PMBOK定义项目管理为：“项目的管理者，在有限的资源约束下，运用系统的观点、方法和理论，对项目涉及的全部工作进行有效地管理。即从项目开始到项目结束的全过程进行启动、计划、执行、监控和验收，以实现项目的目标。”，即项目管理有其自身的<strong>“观点、方法与理论”</strong>，而在项目的落地过程中，所有节点的计划、执行、监控、风险管理以及验收等都依赖于工作分解结构（WBS: Work Breakdown Structure ），不同的行业对项目管理有不同的需求，进而有不同的工作分解结构方法，本文讲述的是与软件工程紧密相关的工作分解结构法。</p><h2 id="项目管理方法论"><a href="#项目管理方法论" class="headerlink" title="项目管理方法论"></a><font color="#FF8C00">项目管理方法论</font></h2><p>依据PMBOK理论定义以及软件工程实践，软件工程项目管理可以分为两大部分：一是5大流程，二是12大知识领域 ，如下：</p><h3 id="项目管理五过程"><a href="#项目管理五过程" class="headerlink" title="项目管理五过程"></a>项目管理五过程</h3><p>项目管理五大过程包括项目的启动、计划、执行、监视和验收，如下图所示：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/product/wbs/wbs-2.PNG" alt="项目5过程"></p><ul><li><p>启动阶段，首先需要确定项目的目标和项目的关键负责人、进行业务分析、需求分析以及组建团队，并且宣布项目正式立项；</p></li><li><p>计划阶段，编写项目计划，把项目目标量化与质化，制定达到目标的里程碑，在这个阶段，还需要完成的是概要设计、目标分解、任务分派、风险评估等工作内容；</p></li><li>执行阶段，按计划开展项目，进行详细设计、编写代码、调试自测，阶段性的实现目标，这一步是软件工程最核心的一个步骤；</li><li>监控阶段，监控阶段与执行阶段是循环的关系，这一阶段需要准确识别偏差，判断影响项目进度因素，同时进行计划刷新与风险刷新以及任务刷新；</li><li>验收阶段，按照项目要求，进行项目验收，包括版本发布、文档归档以及项目复盘。</li></ul><p>不同于理论，在实践中，这5大过程是个计划、执行、检查、更新的循环过程，而不是一个线性过程。</p><h3 id="项目管理12项"><a href="#项目管理12项" class="headerlink" title="项目管理12项"></a>项目管理12项</h3><p>项目管理1.0版里涉及 范围、时间、成本以及质量，这四者是个平衡的过程。项目管理2.0里，又增加了 业务与组织，项目管理是为业务服务的，同时给组织保证结果。而在实践过程中容易发现软件工程项目管理其实涉及12大领域，即：业务、范围、进度、成本、质量、资源、风险、采购、相关方、沟通、测试以及综合管理，具体如下：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/product/wbs/wbs-0.PNG" alt="项目12项"></p><ul><li>业务管理，其涉及业务分析、客户管理；</li><li>范围管理，包括规划范围、需求分析、定义范围、工作分解、确认范围以及控制范围；</li><li>进度管理，其包括：规划进度里程碑，定义任务，排列任务优先级，估算人力资源，估算所需时间，制定进度计划表以及控制进度；</li><li>成本管理，包括规划成本管理，估算成本，制定预算以及控制成本；</li><li>质量管理，包括规划质量指标，QA测试，质量保证以及控制质量；</li><li>资源管理，这一部分与组织结构相关，是决定项目成败的关键要素，合适的项目需要合适的人选，其包括4个子过程：人力资源管理，组建团队，建设团队以及管理团队；</li><li>沟通管理，包括3个子过程：规划沟通，管理沟通，控制沟通；</li><li>风险管理，包括识别风险，风险分析，定量风险，提出应对以及控制风险；</li><li>采购管理，包括4个子过程：规划采购，实施采购，控制采购，结束采购；</li><li>相关方管理，相关方管理也是项目成败与否的一个非常关键的要素，包括4个过程：识别相关方，相关方参与，相关方满意度等；</li><li>测试管理，项目管理往往容易忽略掉QA测试的作用，在代码编写好后需要提前安排QA介入，记住一点没有经过QA严格质量测试的软件包是不能输出给客户的；</li><li>综合管理，综合管理的关键是综合平衡最优，平衡以上11项使之达到最优，包括制订章程，制定计划，指导与管理执行，监控项目，变更控制，结束项目。</li></ul><p>不管是项目管理5大流程还是项目管理12项，其中有一个非常重要的工作即创建<strong>“工作分解结构”</strong>，工作分解结构是开展一切项目管理的依据与基础，可以说没有“工作分解结构”就没有项目管理。</p><h3 id="工作分解结构"><a href="#工作分解结构" class="headerlink" title="工作分解结构"></a>工作分解结构</h3><p>在工作过程中，人的认知是有差异的，比较资深的人员描述一个任务或问题时会比较的抽象，而初级工程师比较能理解的是具体的任务描述，为了团队具有较好的执行力，就需要把抽象的概念或描述分解成具体的可执行的行为或任务，这就需要一种合适的工具或方法来分解概念与工作。</p><p>工作分解结构法（WBS: Work Breakdown Structure，是一个“描述思路的规划和设计的工具”，是以项目结果为导向的工作过程的结构分解方法论，是将抽象的概念或任务分解成具体的行为的一种工具。将工作进行合理的分解是项目负责人的重要能力之一，缺乏项目分解能力的项目负责人容易造成项目失败，“工作分解”的好坏与否 也可以决定项目的成败与否。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/product/wbs/wbs-1.PNG" alt="项目"></p><p>如上图所示，项目管理有两大基石：<strong>工作分解结构法与 企业文化+组织结构</strong>， WBS在PMBOK中给出的定义是：“WBS是针对可交付成果对项目要素进行的分组，它归纳和定义了项目的整个工作范围，每下降一层就代表对项目工作更详细地定义。”。这一定义说明WBS所分解的目标是工作包(Work Package)，以可交付成果为导向的。企业文化与组织结构也是项目成功与否的基石，企业文化作保证，组织调整到位可以给项目提供坚强的基础资源与能力。</p><p>“工作分解结构法”的任务拆解是个有拆有合的过程。一个大的工程任务往往是由很多的小个的任务组成的，如何将一个大任务拆解成合适的小任务，能将大任务拆解成什么样的小任务，能拆解到什么粒度，拆解是否准确，这是”拆“的过程。怎样对任务进行量化与质化，怎么将任务落地到具体的执行人员上，怎么进集成怎么验收，这是“合”。任务拆解比较的考验工程人员的工程能力，任务拆解是否成功是工程进度与工程交付能否成功的关键要素。</p><h2 id="如何进行工作结构分解"><a href="#如何进行工作结构分解" class="headerlink" title="如何进行工作结构分解"></a><font color="#FF8C00">如何进行工作结构分解</font></h2><h3 id="任务树分解法"><a href="#任务树分解法" class="headerlink" title="任务树分解法"></a>任务树分解法</h3><p>如下图所示，工作分解结构就是把项目可交付成果，比如总目标一级级的分解成较小的、更易于执行的组成部分的过程，建立工作分解结构的过程就是将项目进行显性化、结构化，将复杂的总目标分解成一级任务、二级任务，最后分解成最小可执行工作包的过程。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/product/wbs/wbs-4.PNG" alt="项目"></p><p>工作分解结构可以按功能、组成、生命周期以及组织的形式进行分析，在软件工程项目中，通常以项目生命周期 + 功能以任务树的方式分解项目。如下图所示，</p><p><strong>最终交付成果</strong>按生命周期分解成了 项目管理、业务、需求、设计与编码、集成以及交付这6项。然后设计与编码又按功能的形式分为一级任务特性：关键特性1、关键特性2、关键特性N，以此类推，直至分解成最小可执行工作包。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/product/wbs/wbs-3.PNG" alt="项目"></p><p>工作分解结构法是面向结果为导向的分解，分解过程中也需要适可而止，比如初级工程师需要给他分解到很具体的最小可执行工作包这种层次，而比较资深的工程师可以给他分解到关键特性这一层次即可，当然前提是这个资深工程师有能力承担这一特性的分解与执行。</p><p>此外，任务树适合项目汇报使用，而工作包表格适合团队内部协作使用，其能提供更详细的细节，因此在任务树拆解后，下一步是进行工作表格分解。</p><h3 id="工作表格分解法"><a href="#工作表格分解法" class="headerlink" title="工作表格分解法"></a>工作表格分解法</h3><p>对比于任务树，工作包表格可以在右侧增加更多的细节，这有利于团队协作，以下图的软件项目工作包表格为例：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/product/wbs/wbs-7.PNG" alt="项目"></p><p>1，首先前三行定义了项目的目标、原则以及投入，说明了项目的交付目标、交付的原则以及约束、还有确定了人力资源的投入,；</p><p>2，任务分解成了一级任务、二级任务以及工作包、工作包名称；</p><p>3，除这些在任务树上也可以体现的内容外，还增加了 工作进展、状态、评论、风险、阶段目标、执行的人员、复杂度以及依赖条件；</p><p>4，输出最终交付成果。</p><p>工作包表格的这些细节可以使得团队协作更加顺畅，所以一般开发过程中选用工作包分解表作为项目跟进的任务进度表。</p><h3 id="关键路径网络图分解法"><a href="#关键路径网络图分解法" class="headerlink" title="关键路径网络图分解法"></a>关键路径网络图分解法</h3><p>除了任务树与工作包表格之外还有关键路径网络图分解法，在项目当中有些任务比较重要而复杂，有些任务相互独立、有些任务又有依赖关系，</p><p>如下图所示，S 表示Start，F表示Finish，SS 表示同时启动，FS表示先完成再启动。F11任务需要在F1任务启动后10天再启动，F23与F31任务可以同时并发进行，</p><p>而最终交付的目标需要 F2211 与 F3111 同时完成。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/product/wbs/wbs-5.PNG" alt="项目"></p><p>关键路径网络图分解法明确了任务之间逻辑关系、先后关系、时间关系，有利于项目计划进度时间的评估与规划。</p><h2 id="工作分解结构法的理念与原则"><a href="#工作分解结构法的理念与原则" class="headerlink" title="工作分解结构法的理念与原则"></a><font color="#FF8C00">工作分解结构法的理念与原则</font></h2><p>以上内容讲的都是 工作分解结构法的 “术”的层次，其本身还有背后的理念 ，即“道”。工作分解结构法是<strong>“系统思维与分治思维”</strong>在软件工程项目中的应用。工作分解除了非常重要的专业技能，还需要遵循以下几个理念与原则：</p><p>1，滚动原则</p><p>如下图所示，项目的推进是一个 “分解、执行、检查、更新”滚动推进的过程，依据导弹思维，先保证大方向正确，开工，然后再在过程中调整小方向，直至最终精确的命中目标。项目管理也是一个逐步实现目标的过程，时间上近的获取的信息多、那么分解的层次与类目自然也就更细、更多、更准确，而时间上远的，因为信息不够完善，分解的层次与类目自然更少少，也没那么精确，在目标逐步达成后，可以进行刷新重新进行分解，完善工作包，直至最终达成目标。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/product/wbs/wbs-6.PNG" alt="项目"></p><p>2，MECE原则</p><p>MECE即“相互独立，完全穷尽”，是应用系统思维从全局的角度分解任务，既不重复也不遗漏，纵向递进，横向遍历。</p><p>3，量化质化原则</p><p>分解出来的工作包需要能量化，需要可量化的完成时间、可量化的验收标准，不能量化的任务需要质化，即以满意度的方式验收。</p><p>4，以上统下原则</p><p>工作包分解的目标是可交付成果，每一个下级成果有且只有一个上级成果，每一个上级成果是其下级成果之和，不同的交付成果可以分解到不同的层级；</p><p>5，适可而止原则</p><p>工作包并不是分解的越细越好，而应当根据项目特性的难易程度进行分解，难的复杂度高的分解细点、适当增加分解的层级，而容易的复杂度低的可以减少分层。</p><p>6，人事匹配原则</p><p>需要考虑每一级任务到底需要什么样的领域专家或者工程人员，任务要能匹配工程人员的能力，工程人员能力要能匹配任务，考虑到执行力，还需要将任务分解到人人有事做，事事能完成的层次。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font color="#FF8C00">小结</font></h2><p>本文从宏观角度讲述了工作分解结构法的“术”与“道”，在宏观上理解了工作分解结构法，还需要微观上进行实践，才能做到“学以致用”。另作者能力与认知都有限，”我讲的，可能都是错的“，欢迎大家拍砖留念。</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中科大硕，某AI独角兽深度学习首席软件工程师，前EMC 大数据资深首席工程师，主要工作背景在深度学习、流式大数据、云计算、分布式中间件以及Linux内核。</p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a><font color="#FF8C00">参考资料</font></h2><p>[1] 《极简项目管理》 郭致星著</p>]]></content>
      
      
      <categories>
          
          <category> product </category>
          
      </categories>
      
      
        <tags>
            
            <tag> product </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>分布式系统架构设计 – 第26式- 什么是工程化与如何做项目管理</title>
      <link href="/2020/12/27/distributed-product_the_engineering_and_project_management/"/>
      <url>/2020/12/27/distributed-product_the_engineering_and_project_management/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a><font color="#FF8C00">前言</font></h2><p>不同于科研可以专研的很深而无需转化成生产力，工程化是一套将项目转化成产品从而达成生产力目标的科学方法论。架构师是业务与技术、产品之前的桥梁，除了熟练掌握软件开发的本质、方法论、技能、工具还应该具备工程化能力与项目管理能力，即任务的分析，拆解，计划，执行，领导，管控与团队的组织与管理。</p><h2 id="工程化"><a href="#工程化" class="headerlink" title="工程化"></a><font color="#FF8C00">工程化</font></h2><h3 id="工程化就是任务拆解"><a href="#工程化就是任务拆解" class="headerlink" title="工程化就是任务拆解"></a>工程化就是任务拆解</h3><p>任务拆解是个有拆有合的过程。一个大的工程任务往往是由很多的小个的任务组成的，如何将一个大任务拆解成合适的小任务，能将大任务拆解成什么样的小任务，能拆解到什么粒度，拆解是否准确，这是”拆“。怎样对任务进行量化与质化，怎么将任务落地到具体的执行人员上，这是“合”。任务拆解比较的考验工程人员的工程能力，任务拆解是否成功是工程进度与工程交付能否成功的关键要素之一。</p><h3 id="工程化就是取舍"><a href="#工程化就是取舍" class="headerlink" title="工程化就是取舍"></a>工程化就是取舍</h3><p>工程化是取舍的艺术，工程受限于已有的条件，需要做出适当的取舍，才能解决实际问题。资源都是有限的，项目开工之前先搞清资源与人员能力，然后制定人员调配策略与合理的进度安排，需要计划让哪些人员去处理哪些问题，也需要制定合理的资源调度策略，从而才能稳操胜券。</p><p>比如“田忌赛马”就是一个经典的人力与资源的调配故事，精明的项目管理人员在项目开工之前就能彻底的预判结果，告诉资源掌控者我缺啥需要啥，满足这些条件才有取胜可能，然后再采用合理的策略从而抵达目标获取胜利。不同的人员会制定不同的策略，这也是工程人员的能力差异所在。</p><h3 id="工程化就是组织与沟通"><a href="#工程化就是组织与沟通" class="headerlink" title="工程化就是组织与沟通"></a>工程化就是组织与沟通</h3><p>一个工程往往需要几十、几百甚至几千、几万人协同工作为达成一个共同的目标而奋斗，因此，在工程中人员的组织、沟通协调也非常重要，合理的人放到合适的位置，才能发挥其能力从而高效的解决实际问题，同时工程也讲究文档化、标准化、流程化与规范化。</p><h3 id="工程化就是进度安排"><a href="#工程化就是进度安排" class="headerlink" title="工程化就是进度安排"></a>工程化就是进度安排</h3><p>将任务进行拆解仅是工程化解决问题的一个步骤，任务拆解之后还要区别主要矛盾与次要矛盾，进行优先级排序与里程碑确定，需要从时间上进行合理的安排与调度，最终让每一个子任务之间做到有效的协同与交付。</p><h3 id="项目管理是工程化的子集"><a href="#项目管理是工程化的子集" class="headerlink" title="项目管理是工程化的子集"></a>项目管理是工程化的子集</h3><p>工程化是以现有资源与技术为基础，通过加人员、技能、知识组合起来，短时间内快速解决实际的复杂问题的一种方法。软件工程是指将系统化、规范、可度量的方法应用于软件开发的过程以及软件的运行和维护，其包括两方面内容：<strong>软件开发和软件项目管理</strong>。因此，项目管理是工程化的子集。</p><h2 id="项目管理"><a href="#项目管理" class="headerlink" title="项目管理"></a><font color="#FF8C00">项目管理</font></h2><h4 id="项目铁三角"><a href="#项目铁三角" class="headerlink" title="项目铁三角"></a>项目铁三角</h4><p>项目铁三角指的是项目管理的四个重要方面，即：</p><ul><li><p>范围：需要做什么；</p></li><li><p>时间：什么时间做完；</p></li><li><p>成本：投入多少资源；</p></li><li><p>质量：做到什么程度才算达标。</p></li></ul><p>范围、成本、时间三者之间任何一个变动均会对其他两项产生影响，如下图所示：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/product/distributed-product-project_management.png" alt="image-20201227171818955"></p><p>范围扩大（需求增加），做的事情多了，时间进度就需要延长，并且成本也会增加。如果做的事情多了而时间与成本投入又不变那么必然影响到质量。如果不打算减少所做的事情，就必然需要多投入成本（比如时间，人力），否者质量与范围又无法保证。范围、时间、成本之间的制约关系是必然存在的，但是也要依据实际情况而采取合适的方法，有的项目时间节点是固定的、有的质量要求严格、有的有固定的成本约束等，因此，需要根据情况进行合理的调整。</p><h4 id="项目三重境"><a href="#项目三重境" class="headerlink" title="项目三重境"></a>项目三重境</h4><p>第一重，满足客户质量要求，这是项目管理的最基本的需求，在范围、时间、成本之间获取平衡是为了达到客户的质量要求；</p><p>第二重，满足业务的需求，项目管理人员需要懂业务，需要知道为什么需要做，什么是客户需要的，避免项目大方向的错误；</p><p>第三重，满足组织成员的需求，项目是由人实施的，其注入了人的精神与意志，因此也需要了解组织成员的需求，准确并且满足成员的需求，才能更好的推进项目。</p><h3 id="项目拆解"><a href="#项目拆解" class="headerlink" title="项目拆解"></a>项目拆解</h3><h4 id="道与法"><a href="#道与法" class="headerlink" title="道与法"></a>道与法</h4><p>架构师完成概要设计后就需要进行项目拆解，拆解的成功与否是项目能否按期交付的关键，在进行项目拆解的时候需要遵循以下的<strong>“一人二法三要素四角色”</strong>原则，</p><ul><li><p>一人： 项目是由人执行的，人是项目里最关键的要素，合适的任务要拆解到具体的合适的人员上；</p></li><li><p>二法：量化与质化，任务拆解需要能量化（类似KPI，比如先赚它一个小目标：一个亿）有具体的时间、具体的数值，不能量化的需要质化（如同OKR，比如客户对这个质量感到满意，这个缺陷的修复方案QA已验证接受等，这个策略已经被客户所接受）；</p></li><li><p>三要素：即范围、时间、成本，在有限的成本、范围、时间约束下达成质量目标；</p></li><li><p>四角色：即RACI角色: 谁负责（R = Responsible）: 谁来干这活，谁批准（A = Accountable）：谁说了算，咨询谁（C = Consulted）：专家团，顾问是谁， 通知谁 (I =Informed)：谁需要被通知到，谁需要知道这个进度与风险。</p></li></ul><h4 id="术与器"><a href="#术与器" class="headerlink" title="术与器"></a>术与器</h4><p>如何进行拆解，能拆解成什么样的任务，这也比较考验项目管理人员的专业技能，这属于”术” 的范畴，同时也可以借助合适的工具（器）编排拆解的任务与进度。</p><h3 id="项目计划"><a href="#项目计划" class="headerlink" title="项目计划"></a>项目计划</h3><p>1，项目计划的本质是项目执行人员的<strong>承诺</strong>，因此，不同于产品与项目制定人员比较看重的是项目的价值，执行人员通常会比较关注项目的资源投入、技术难度、技术实现、里程碑、奖罚等，因此对于计划都会比较的谨慎；</p><p>2，计划本身没有太大作用的，但是没有计划却万万不行，如同“天气预报”，没几次预报会准确，但是好处是有了计划就有了可预测性；</p><p>3，大的项目计划需要拆分成合理的里程碑，每个里程碑都能对应到一个最小可交付版本（MVP）用于进行市场验证（PMF）；</p><p>4， 大方向与里程碑先保证正确，过程中进行小调整。</p><p>有时候计划的交付时间点是固定的，其由商业交付时间点反推，那么就需要在 “范围，成本与质量承诺”这三点上进行合理的取舍。</p><h3 id="人员与组织"><a href="#人员与组织" class="headerlink" title="人员与组织"></a>人员与组织</h3><p>项目是由人完成的，了解团队成员的需求，满足TA所要的，这样具有保持团队稳定以及项目价值输出的可行性。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font color="#FF8C00">小结</font></h2><p>本文从宏观角度概述了工程化与项目管理的差异，只会项目计划那是最初级的项目管理，更高级的项目管理是懂方法论，懂任务拆解，懂项目计划，懂业务、也懂人与组织等。在宏观上了解了工程化与项目管理，还需要微观上进行实践，手把手的操作过、练过、蹲过坑、吃过苦头才能叫做“实践出真知”。另作者能力与认知都有限，”我讲的，可能都是错的“，欢迎大家拍砖留念。</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中科大硕，某AI独角兽深度学习首席软件工程师，前EMC 大数据资深首席工程师，主要工作背景在深度学习、流式大数据、云计算、分布式中间件以及Linux内核。</p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a><font color="#FF8C00">参考资料</font></h2><p>[1] <a href="https://www.zhihu.com/question/26699139" target="_blank" rel="noopener">https://www.zhihu.com/question/26699139</a></p><p>[2] 《网易一千零一夜 - 互联网产品项目管理实战》 网易杭研项目管理部著</p>]]></content>
      
      
      <categories>
          
          <category> product </category>
          
      </categories>
      
      
        <tags>
            
            <tag> product </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>思想体系 – 第25式- 让技术回归常识,先有客户再有技术</title>
      <link href="/2020/10/25/distributed-product_the_customer_and_technology/"/>
      <url>/2020/10/25/distributed-product_the_customer_and_technology/</url>
      
        <content type="html"><![CDATA[<h2 id="先有客户再有技术"><a href="#先有客户再有技术" class="headerlink" title="先有客户再有技术"></a><font color="#FF8C00">先有客户再有技术</font></h2><p>技术不同于科学，科学是人类对自然的认知，它可以很前沿很理论也不用讲究工程价值，而技术更多指的是功能与工程得实现，更需要关注的是“利他”的常识。技术人员其比较关注的是技术架构、实现方式、技术价值以及开发成本，而比较容易忽略客户需求、使用场景以及产品价值与用户体验。忽略这些产品相关的内容而维技术论就容易犯错进而浪费有限的开发资源，在工程实现上维技术论常见的有四错：</p><ul><li>第一错：“我为用户想”，这是研发人员最容易犯的错，其已经有用户意识，但是却没有进一步与用户沟通，直接替用户做决定，也不清楚用户的使用场景，因此容易造成”所想“实际上并不是用户真正所想；</li><li>第二错：追求有挑战的技术而非技术的实用价值，也非从合适的解决用户问题的角度出发，将技术上的自嗨当成客户需求，比如用户需要从A地到B地，简单一点给用户一辆自行车就可以解决的问题，而技术自嗨就容易非要先自行造个飞机，然后拼命的给用户推销这个好这个快，但是用户却不买单；</li><li>第三错：维性价比论，总以为又便宜的又好的就是真的好，性价比是大杀器，但是很多情况下其实客户也讲ROI(投入产出比)，比如双11秒杀活动，用户可以不计成本的采用最新进最前沿的技术，只要能扛得住双11的流量就可以不计成本，因为再大的成本，跟双11带来的收益对比都是毛毛雨；</li><li>第四错：闭门造车，不实事求是，不与客户做探讨，不做调查就把想象的或还处于概念上的东西当成客户需求。</li></ul><p>因此，架构人员不能维技术论，维技术论就不是一个合格的架构师，架构师还需要关注客户价值，在实现一个架构之前先确定这个是对客户有价值的，同时平衡好客户价值与技术前沿之间的取舍关系。</p><h2 id="什么是客户，又什么是客户价值"><a href="#什么是客户，又什么是客户价值" class="headerlink" title="什么是客户，又什么是客户价值"></a><font color="#FF8C00">什么是客户，又什么是客户价值</font></h2><h3 id="什么是客户"><a href="#什么是客户" class="headerlink" title="什么是客户"></a>什么是客户</h3><p>用英文单词表示，客户与用户其实是比较容易区别的，客户是 customers, 用户 是users，而中文二者都有个“户”字就比较容易混淆。To C产品客户可以是用户，但是To B产品， 客户却不是就等于就是用户。狭义的客户 = 买单的，广义上的客户 = 客户的客户 + 客户 + 客户的用户 + 利益链上的所有，用户也不就是一个角色或者某人，对to B产品来说，用户的本质是“需求“的集合。</p><h3 id="什么是客户价值"><a href="#什么是客户价值" class="headerlink" title="什么是客户价值"></a>什么是客户价值</h3><p>“任何先进的技术、产品和解决方案，只有转化为客户的商业成功才能产生价值“ [1]  ，客户价值就是对客户有用的东西，价值来源于价值的交换。技术的目的就是做对客户有用的东西，并且技术的进化方向是由市场所决定的。</p><p>以客户为中心，就是给客户创造价值，替解决用户难点、痛点、挑战点、为客户提供高质量低成本的产品，同时响应要及时。病根是需，药是求，拿出 “求” 解决 “需”，药到病除就是为客户创造价值[1]。</p><h2 id="如何做到以客户价值为中心？"><a href="#如何做到以客户价值为中心？" class="headerlink" title="如何做到以客户价值为中心？"></a><font color="#FF8C00">如何做到以客户价值为中心？</font></h2><p>认知上做到技术要先从客户价值开始，那么执行上应该如何拆分？使得认知具有可量化的执行性？这里从以下三个方面对“如何做到以客户价值为中心”这个问题进行拆解：</p><ul><li>价值探索 - 价值与交付双轮驱动思维模型，PMF-MVP思维模型</li><li>价值确定 - 三三制需求分析思维模型</li><li>价值输出 - 卡诺需求分级与分类思维模型</li></ul><h3 id="价值探索1-双轮驱动思维模型"><a href="#价值探索1-双轮驱动思维模型" class="headerlink" title="价值探索1 - 双轮驱动思维模型"></a>价值探索1 - 双轮驱动思维模型</h3><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/product/25/double-ring.png" alt="双轮驱动思维模型"></p><p>价值探索的方法论之一是双轮驱动思维模型，其原则为：</p><ul><li>以客户价值为前轮，前轮把握方向，解决的是需求探索、价值确定、特性探讨以及价值精炼的过程，需求输出需要去伪存真、去粗纯精、过滤提炼；</li><li>产品交付为后轮，后轮提供驱动力，解决的是开发、测试、运维以及获取客户反馈；</li><li>先有客户价值再有产品交付，客户价值又可分为主动式客户价值与被动式客户价值，获取客户需求的方式也需要合理取舍；</li><li>在双轮驱动模型里，二者谁都离不开谁，不是厚此薄彼的关系，而是二者互相协作从而推动产品往商业成功这个目标前进的关系；</li></ul><h3 id="价值探索2-PMF-MVP-开发模型"><a href="#价值探索2-PMF-MVP-开发模型" class="headerlink" title="价值探索2 - PMF-MVP 开发模型"></a>价值探索2 - PMF-MVP 开发模型</h3><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/product/25/pmf-mvp.png" alt="PMF-MVP"></p><p>如上图所示，PMF（Product-Market Fit）是讲究产品与市场匹配，是产品需要与市场需求相匹配，而MVP （Minimal Viable Product）是 最小可用产品，MVP讲的是每个版本的迭代都是一个可用的产品而非功能的堆砌，PMF-MVP开发法，讲究快速给的输出可用的版本给到客户，再由客户进行使用获取客户的信息反馈，再进行版本迭代。</p><p>价值探索的方法论之二是PMF-MVP开发法，其原则为：</p><ul><li>PMF-MVP 开发法可以帮助团队在早期快速确认客户的真实需求；从特性列表中确定产品（特性）的基本功能， 然后迅速开发MVP，再投放市场提前踩坑，收集用户反馈，然后再进行产品迭代，只有用户用起来，产品才有机会演化；</li><li>做MVP的时候，不是验证产品好不好用，而是验证产品/特性是不是用户真的想要的，减少开发成本，“闭门造车”式的开发经常会遇到“再来一次”;</li><li>跟目标用户产生互动和连接，每一步都收集用户的反馈，前期跟客户多交流，多沟通，“一元共创”与用户一起成长。</li></ul><p>在价值探索之后就需要进行价值确定。</p><h3 id="价值确定-–-三三制需求分析思维模型"><a href="#价值确定-–-三三制需求分析思维模型" class="headerlink" title="价值确定 – 三三制需求分析思维模型"></a>价值确定 – 三三制需求分析思维模型</h3><p><strong>公式： 需求</strong> <strong>=</strong> <strong>需（痛点、难点、挑战点、恐惧点）</strong> <strong>+</strong> <strong>求 （产品、服务或解决方案）</strong>， 需即痛点、难点、挑战点，求即解决方案、产品或服务，求到需即完成，这就是有客户价值。依据三三制需求分析思维模型我们可以进行价值确定，三三制需求分析思维模型是一个价值确定思维模型，其如下表：</p><table><thead><tr><th><strong>类别</strong></th><th><strong>功能</strong></th><th><strong>质量</strong></th><th><strong>约束</strong></th></tr></thead><tbody><tr><td><strong>“大”**</strong>客户**</td><td>业务目标：  商业成功，比如科技向善</td><td>业务质量：    多、快、好、省</td><td>业务约束：  时间、质量、成本，法律法规，信息安全，技术趋势，竞争对手，行业标准等</td></tr><tr><td><strong>“大”**</strong>用户**</td><td>业务需求</td><td>运行时质量：  性能、可用性、可靠性，可伸缩性、可观测性、可运维性、易用性、兼容性、安全性等</td><td>使用时约束：  遗留系统，业务环境，用户能力，用户群特征等</td></tr><tr><td><strong>“大”**</strong>团队**</td><td>功能需求：  基本功能P0  、增值功能P1、潜在功能P2 、可有可无功能P3  、有害无益功能P100</td><td>编程时质量：  可扩展，可读性，可测试性，可维护性，可移植性</td><td>编程时约束：  开发进度，资源预算、上级要求、开发团队能力、产品规划、运行环境</td></tr></tbody></table><p>三三制需求分析思维模型进行价值确定之后即价值输出。</p><h3 id="价值输出-–-卡诺需求分类与分级思维模型"><a href="#价值输出-–-卡诺需求分类与分级思维模型" class="headerlink" title="价值输出 – 卡诺需求分类与分级思维模型"></a>价值输出 – 卡诺需求分类与分级思维模型</h3><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/product/25/kano-model.png" alt="KANO"></p><p>这里采用KANO需求分类与分解思维模型进行价值输出，依据kano模型，需求可以分为：</p><ul><li>基本需求：必须有的最根本的需求，没这个根本就没法谈，会阻塞产品交付；</li><li>增值需求：当提供此需求时用户满意度会提升；当不提供此需求时用户满意度会降低；</li><li>竞争力需求：若不提供此需求，用户满意度不会降低；若提供此需求，用户满意度会有所的提升，属于亮点要素；</li><li>可有可无需求：用户根本不在意的需求，对用户体验毫无影响；</li><li>有害无益需求：提供后用户满意度反而下降；</li></ul><p>卡诺模型将需求进行了分级与分类，进一步的区分了需求的价值。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font color="#FF8C00">小结</font></h2><p>本文首先确定了 “先有客户再有技术”的认知，再讲述了什么是客户，什么是客户价值，并且以思维模型的方式讲述了如何做到以客户价值为中心。日拱一卒，功不唐捐，分享是最好的学习，与其跟随不如创新，希望这个思维模型对大家有用。另作者能力与认知都有限，”我讲的，可能都是错的“，欢迎大家拍砖留念。</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中科大硕，某AI独角兽深度学习首席软件工程师，前EMC 大数据资深首席工程师，主要工作背景在深度学习、流式大数据、云计算、分布式中间件以及Linux内核。</p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a><font color="#FF8C00">参考资料</font></h2><p>[1] xx增长法</p>]]></content>
      
      
      <categories>
          
          <category> product </category>
          
      </categories>
      
      
        <tags>
            
            <tag> product </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>分布式系统架构设计 – 第24式- 如何撰写一个好的架构设计文档</title>
      <link href="/2020/09/26/distributed-product-how-to-write-a-architecture-document/"/>
      <url>/2020/09/26/distributed-product-how-to-write-a-architecture-document/</url>
      
        <content type="html"><![CDATA[<h2 id="为什么需要写文档"><a href="#为什么需要写文档" class="headerlink" title="为什么需要写文档"></a><font color="#FF8C00">为什么需要写文档</font></h2><p>软件工程师有两大难：1，没有文档；2，写文档。设计文档是用于描述如何去解决一个产品或特性的问题的，好的设计文档可以确保正在做的是正确的事情。</p><p>架构设计文档通常又可以分成概要设计文档以及详细设计文档。概要设计文档把握产品架构的宏观方向，而详细设计文档确定微观的代码实现。通常详细设计文档应该由具体负责这个模块实现的人员来完成，只有负责代码落地的人员才最清楚具体的微观问题，其他人员可以参与审阅设计方案、把握正确的方向。在工作中经常会遇到这样的情况：设计人员写完详细设计文档再把文档交付给写代码的人，去要求按这个文档写代码，经常会遇到的矛盾是：负责具体写代码的人觉得这个文档脱离实际没价值，而写文档的人又指责写代码的人员不理解他的意图。 因此，比较合适的方案是 谁负责写代码谁就负责详细设计（这对技术人员的能力要求也较高），其他人员提供检阅与建议，把握风险与方向。</p><p>那么如何撰写一个好的架构设计文档呢？这里提出一个常用的架构设计模板，以供参考，如下：</p><h2 id="架构设计文档模板"><a href="#架构设计文档模板" class="headerlink" title="架构设计文档模板"></a><font color="#FF8C00">架构设计文档模板</font></h2><h3 id="动机介绍"><a href="#动机介绍" class="headerlink" title="动机介绍"></a>动机介绍</h3><p>描述需要完成的内容，介绍上下文以及需要达到的目标。</p><h3 id="需求分析"><a href="#需求分析" class="headerlink" title="需求分析"></a>需求分析</h3><p>以三三制需求分析模型分析客户、用户以及团队的功能、质量与约束需求，首要方针是“价值优先”。</p><table><thead><tr><th><strong>类别</strong></th><th><strong>功能</strong></th><th><strong>质量</strong></th><th><strong>约束</strong></th></tr></thead><tbody><tr><td>“大”客户</td><td>业务目标：  商业成功</td><td>业务质量：    多、快、好、省</td><td>业务约束：  时间、质量、成本，法律法规，信息安全，技术趋势，竞争对手，行业标准等</td></tr><tr><td>“大”用户</td><td>业务需求：比如AI模型训练</td><td>运行时质量：  精度、线性度、收敛性，性能、可用性、可靠性，可伸缩性、可观测性、可运维性、易用性、兼容性、安全性</td><td>使用时约束：  遗留系统，业务环境，用户能力，用户群特征等</td></tr><tr><td>“大”团队</td><td>功能需求：  基本功能P0  、增值功能P1、潜在功能P2 、可有可无功能P3  、有害无益功能P100</td><td>编程时质量：  可扩展，可读性，可测试性，可维护性，可移植性</td><td>编程时约束：开发进度，资源预算、上级要求、开发团队能力、产品规划、运行环境</td></tr></tbody></table><h3 id="目标非目标"><a href="#目标非目标" class="headerlink" title="目标非目标"></a>目标非目标</h3><p>目标与非目标主要是解释本文档做什么与不做什么，定义需要完成的任务与约束边界。</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs undefined">目标：定义本设计文档需要解决的问题以及需要达到的质量指标，是说明需要做什么。<br><br>非目标：说明本设计文档的约束，是说明不做什么。<br></code></pre></td></tr></table></figure><h3 id="里程碑"><a href="#里程碑" class="headerlink" title="里程碑"></a>里程碑</h3><p>计划本身是“无用”的，但是没有计划却是万万不能，通过制定里程碑可以让文档的其他用户知道项目所需要的大概的时间周期。例如，可以按如下格式定义里程碑：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs undefined">开工日期：2020年10月10日<br>里程碑 1 - 2020年10月30日，完成概要设计文档<br>里程碑 2 - 2020年11月30日，完成详细设计文档，并且编写完代码<br>结束日期: 2020年12月30日，完成自我测试、文档、质量保证以及特性交付<br></code></pre></td></tr></table></figure><h3 id="设计哲学"><a href="#设计哲学" class="headerlink" title="设计哲学"></a>设计哲学</h3><p>产品的设计哲学是产品的宪法，也是产品的灵魂与价值观，是产品的不可违背的最高指导思想，其把握了架构设计的方向，例如:</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs undefined">设计哲学<br> - 以客户价值为中心<br> - 以持续创新为竞争力<br></code></pre></td></tr></table></figure><h3 id="设计原则"><a href="#设计原则" class="headerlink" title="设计原则"></a>设计原则</h3><p>架构交付的是功能需求，但是真正的差距体现在非功能需求（质量与约束），因此可以通过制定设计原则确定产品的非功能要素，设计原则是产品的法则，也是架构取舍的依据，例如:</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs undefined">设计原则<br>- 最佳物种原则<br>- 高内聚低耦合原则<br>- 可用性原则<br>- 可靠性原则<br>- 稳定性原则<br>- 可服务化原则<br>- 兼容性、可迁移原则<br>- 服务化、组件化<br>- 接口隔离与服务自治<br>- 用户触达成本原则<br>- 用户体验原则<br>- 持续演进原则<br></code></pre></td></tr></table></figure><h3 id="设计提案"><a href="#设计提案" class="headerlink" title="设计提案"></a>设计提案</h3><p>设计提案可以从三个方面进行考虑：客户想要的、对手怎么做以及自身打算怎么进行，还需要分析每个方案的优点、缺点以及方案取舍的依据。</p><h4 id="当前提案"><a href="#当前提案" class="headerlink" title="当前提案"></a>当前提案</h4><p>当前方案需要分当前已有的提案、也可包括当前竞争对手的方案，以及客户/用户所期待的方案。</p><h4 id="自身提案"><a href="#自身提案" class="headerlink" title="自身提案"></a>自身提案</h4><p>提出自身的设计方案，可以提出多个设计方案：比如 提案1，提案2等，确定大的架构设计方向。</p><h4 id="提案比较"><a href="#提案比较" class="headerlink" title="提案比较"></a>提案比较</h4><p>提出以上方案后，制定技术提案评审表，分析提案的优缺点，确定最终的可选方案。</p><h3 id="架构设计"><a href="#架构设计" class="headerlink" title="架构设计"></a>架构设计</h3><p>这一部分是最重要、最核心的内容，属于架构设计文档的核心。在确定设计提案后进行概要设计，通常可以采用 4+1 架构设计法完成这一部分内容。如下图：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/product/product-how-to-write-arch-document.png" alt="4+1视图"></p><p>常用的4+1视图涵盖有物理视图、逻辑视图、处理视图、开发视图以及用例视图，其中与用例视图交叉的部分是描述共同的细节，同时每种视图中又有各自的需求，例如：</p><ul><li>物理视图关注安装、部署、升级、运维的需求；</li><li>逻辑视图关注架构设计的功能需求；</li><li>处理视图关注非功能里的用户运行质量需求；</li><li>开发视图关注团队的开发质量需求；</li></ul><h3 id="跨团队影响"><a href="#跨团队影响" class="headerlink" title="跨团队影响"></a>跨团队影响</h3><p>这里阐述需要的团队依赖以及对其他团队的影响。</p><h3 id="详细的交付计划"><a href="#详细的交付计划" class="headerlink" title="详细的交付计划"></a>详细的交付计划</h3><p>这里可以以表格的方式，制定详细的交付计划。</p><h3 id="开放问题讨论"><a href="#开放问题讨论" class="headerlink" title="开放问题讨论"></a>开放问题讨论</h3><p>提出需要讨论的问题。</p><h3 id="作者与评审人员"><a href="#作者与评审人员" class="headerlink" title="作者与评审人员"></a>作者与评审人员</h3><p>确定作者与评审人员信息，例如：</p><table><thead><tr><th>类目</th><th>修改</th><th>时间</th><th>作者</th><th>评审</th></tr></thead><tbody><tr><td>类目 1</td><td>init</td><td>2020/09/26</td><td>xxxxxxxxx</td><td>xxxxxxxxx</td></tr><tr><td>类目 2</td><td>xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx</td><td>xxxxxxxxxxx</td><td>xxxxxxxxx</td><td>xxxxxxxxxx</td></tr><tr><td>类目 3</td><td>xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx</td><td>xxxxxxxxxxx</td><td>xxxxxxxxxx</td><td>xxxxxxxxxxx</td></tr></tbody></table><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font color="#FF8C00">小结</font></h2><p>本文提出了一个常用的架构设计模板，希望这个设计模板对大家有用。另作者能力与认知都有限，”我讲的，可能都是错的“[1]，欢迎大家拍砖留念。</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中科大硕，某AI独角兽深度学习首席软件工程师，前EMC 大数据资深首席工程师，主要工作背景在深度学习、流式大数据、云计算、分布式中间件以及Linux内核。</p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a><font color="#FF8C00">参考资料</font></h2><p>[1] <a href="https://www.freecodecamp.org/news/how-to-write-a-good-software-design-document-66fcf019569c/" target="_blank" rel="noopener">https://www.freecodecamp.org/news/how-to-write-a-good-software-design-document-66fcf019569c/</a></p>]]></content>
      
      
      <categories>
          
          <category> product </category>
          
      </categories>
      
      
        <tags>
            
            <tag> product </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>分布式系统架构设计 – 第23式- 产品创新与宇宙奇点大爆炸</title>
      <link href="/2020/08/30/distributed-ideamodel-singularity_action/"/>
      <url>/2020/08/30/distributed-ideamodel-singularity_action/</url>
      
        <content type="html"><![CDATA[<h2 id="什么是奇点"><a href="#什么是奇点" class="headerlink" title="什么是奇点"></a><font color="#FF8C00">什么是奇点</font></h2><p>物理学认为宇宙从无到有始于一个点，这个点叫做“奇点”，它积聚了形成现有宇宙中所有物质的势能，当这一个点的能量平衡被破坏后，宇宙大爆炸发生，从而生成我们现在的宇宙。如果把宇宙比作我们的产品，奇点就是这个产品赖以出现与存在的关键点。</p><h2 id="产品创新与奇点理论"><a href="#产品创新与奇点理论" class="headerlink" title="产品创新与奇点理论"></a><font color="#FF8C00">产品创新与奇点理论</font></h2><h3 id="一个问题"><a href="#一个问题" class="headerlink" title=" 一个问题"></a><font color="#008C"> 一个问题</font></h3><p>奇点是这个产品赖以出现与存在的关键点，那么第一个需要回答的问题是：“你的产品的奇点是什么？”。一个企业就是一个产品，那么使命就是这个企业的第一原理点，价值观就是这个企业的奇点，是这个企业赖以存在的关键点。一个软件平台是一个产品，那么以客户为中心可以是这个产品的第一原理点，逻辑基石可以使这个产品的奇点，这个基石是这个产品赖以生存的关键点。</p><p>因此将奇点理论应用于产品创新的第一个关键步骤在于 找出你的产品的”逻辑奇点“，比如在AI训练市场，GPU是原来的产品的奇点，是原有的产品赖以依存的关键点，而XPU就是新生的产品的奇点，是新生产品赖以生存的基石，他们的第一原理都是客户的AI训练。</p><h3 id="两重境界"><a href="#两重境界" class="headerlink" title="两重境界"></a><font color="#008C">两重境界</font></h3><blockquote><p>创新 = 更好 | 不同 | 新生</p></blockquote><ul><li><p><strong>更好，</strong>指的是市场是明确存在需求的，但是提供的新产品在质量、功能、渠道、价格等方面比原有产品更具优势，是用更好的体验来满足客户的真需求；</p></li><li><p><strong>不同，</strong>指的是差异化竞争，”与其更好不如不同”，不同不只是技术面的不同，而是处处差异化不同，理念、技术、渠道，运营，销售等处处差异化竞争；</p></li><li><p><strong>新生，</strong>指的是 从0到1，从无到有的创造一个新物种，是指用凭空创造出一个新产品来满足客户需求，这种形态的产品要么是颠覆式的创造带来巨大的商业上的成功，要么就是没有真实客户需求的新事物，商业上完全失败。</p></li></ul><p>这里，AI训练芯片采用的是“<strong>更好与不同”</strong>这两个产品创新方法论，组合原有的技术开拓出新产品，规避风险，满足客户真实的需求。从GPU到XPU 体现的是“不同”的创新理念，而从XPU1.0到 XPU 2.0 再到N.0 体现的是“更好”的创新理念。</p><p>因此，这里提出：<strong>创新的第一重境界是“与其更好不如不同”，第二重境界是“与其不同不如更好”</strong>。</p><h4 id="与其更好不如不同"><a href="#与其更好不如不同" class="headerlink" title=" 与其更好不如不同"></a><font color="#00CED1"> 与其更好不如不同</font></h4><p>生物学家通过分析人与猩猩的遗传基因发现人与猩猩的基因相比较仅有约1.2%的差异，但是就是这约1.2%的差异却造就出两个完全不同的物种以及生态位，猩猩呆树上吃果子，人类败走树上行走平地却成了万物之灵长。决定你是猩猩还是人类的差异只有那约1.2%的差异而已。</p><p>“与其更好不如不同”这句话讲的是错位竞争，远古时期要是人类跟猩猩拼命的争树上的好位置，做得再好也不过还是猩猩，也许如今都还在树上跟别的猩猩抢香蕉而已，但是，人类不跟猩猩争抢树上的位置，其不爬树了，开始出走平原，环境因素逼迫其直立行走进而进化成万物之灵长。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/product/qidian_product_model_1.PNG" alt="与其更好不如不同"></p><p>同样的道理，在AI训练芯片的产品市场里，如上图之左，GPU是其奇点，它有自己的生态位，有自己的壁垒，也有自己的第一原理点。一款产品要是跟GPU抢占同样的生态位，做得好也还在它的那个圈圈里，后来者再怎么的努力也难以突破它的那个圈圈。然而错位竞争，从GPU到XPU，击破GPU的奇点位置，从新定义自己的那个壁垒与圈圈，却使得产品有了新的生态位，新的可能。</p><h4 id="与其不同不如更好"><a href="#与其不同不如更好" class="headerlink" title=" 与其不同不如更好"></a><font color="#00CED1"> 与其不同不如更好</font></h4><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/product/qidian_product_model_2.PNG" alt="与其不同不如更好"></p><p>“与其不同不如更好”讲的是在重新定义好自己的奇点后，再进行进化，从奇点1.0到奇点2.0，再到奇点3.0。人类的进化也是经历了猿人类、原始人类、智人类、现代人类这四个阶段，体现的是一步步的更好。而不是一会不同成猩猩、一会不同成大鱼、一会不同成大鸟，这样永远难以出现代人类，或者需要多付出几百万年的代价才能得到现在的结果。</p><p>在AI训练芯片重新定义了自己XPU的奇点之后，需要的是以“市场需求”为进化的引力与方向，从XPU1.0到XPU2.0再到XPU3.0，从而才能进化出未来的XPU N.0。</p><h3 id="三个步骤"><a href="#三个步骤" class="headerlink" title="三个步骤"></a><font color="#008C">三个步骤</font></h3><p>如上面两图里的”奇点下移，破界创新“，依据奇点理论进行创新的步骤是奇点破界的三个步骤：<strong>“破坏，外延，重生”</strong>：</p><p>1，破坏，找到产品奇点并加以破坏。产品缺点不是奇点，奇点是产品赖以出现与存在的点，找到它，然后破坏它，类似于使得宇宙奇点能量失去平衡；</p><p>2，外延，产品奇点下移，产品边界外延，类似于宇宙大爆炸从而造成宇宙边界外延；</p><p>3，重生，重构产品奇点，形成新的产品体系，类似于新宇宙的形成。</p><p> 以AI训练芯片的创新为例，这里只涉及技术面的创新，销售、渠道、运营、管理、商业模式等方面的创新不在本文范围。可以知道的是目前市面上的AI芯片的最大竞争对手是GPU，对其应用奇点创新思维模型的步骤有：</p><p>1， 破坏，找出产品奇点，然后破坏它的奇点。例如，我们知道GPU的赖以依存的关键点有：提供图像视频处理功能，依赖于图像视频横向扩展出AI训练功能，依据初代版本时间点的硬件特性进行软件的设计；</p><p>2，外延，产品奇点下移，破界，新的产品边界外延。针对以上GPU的三条关键点，提出AI芯片的新奇点：去除图像视频的处理功能简化软硬件的设计，从而节约成本。抓住技术进步的福利，去除历史包裹，依据当前最新的软硬件特性进行产品设计，使之更符合现代的市场需求；</p><p>3， 重生，最后更新的、更具有成本竞争力以及技术竞争力的、针对AI训练而实现的新产品”XPU“诞生。</p><p>这一套创新思维模型的关键点在于找出原有的产品赖以出现以及存在的“奇点”，然后破界重生。</p><h2 id="阿基米德产品思维模型"><a href="#阿基米德产品思维模型" class="headerlink" title="阿基米德产品思维模型"></a><font color="#FF8C00">阿基米德产品思维模型</font></h2><p>阿基米德产品思维模型灵感来自于阿基米德的一句话:”给我一个支点,我可以撬起地球。“，因此我定义它为阿基米德产品思维模型，奇点创新思维模型是 阿基米德产品思维模型的子集，如下图：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/product/ajimide_product_model.PNG" alt=""></p><p>在阿基米德产品思维模型里产品是一个圆，圆内的三角形是打造产品所需的技术，在产品圆里除了技术三角、还补充了企业文化、企业制度以及组织结构这三个要素，在圆之外还有奇点、壁垒、价值网以及一个支点、一个杠杆、一个作用力。</p><p>在这个模型里，支点可以认为是“以客户为中心”，关键能力可以是团队也可以是资本，还可以是二者的组合，产品离客户越远，需要的作用力就越大，产品离客户越近，需要的作用力就越小。企业文化、制度、组织关系是产品的关键要素，但不是决定要素，技术才是产品打造的决定要素，其面积占产品圆的近2/3，狭义上的技术指的是技能，但这里的技术不是，它是广义的，其涵盖：大势、理念、方法论、技能、工具与边界。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font color="#FF8C00">小结</font></h2><p>本文结合奇点理论讲述了产品的创新思维模型，日拱一卒，功不唐捐，分享是最好的学习，与其跟随不如创新，希望这个思维模型对大家有用。另作者能力与认知都有限，”我讲的，可能都是错的“[1]，欢迎大家拍砖留念。</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中科大硕，某AI独角兽深度学习首席软件工程师，前EMC 大数据资深首席工程师，主要工作背景在深度学习、流式大数据、云计算、分布式中间件以及Linux内核。</p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a><font color="#FF8C00">参考资料</font></h2><p>[1]《第二曲线创新》 李善友</p>]]></content>
      
      
      <categories>
          
          <category> product </category>
          
      </categories>
      
      
        <tags>
            
            <tag> product </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>思想体系 – 第22式 - 什么是产品以及如何将一个开源软件项目产品化</title>
      <link href="/2020/08/28/distributed-product_and_producibility/"/>
      <url>/2020/08/28/distributed-product_and_producibility/</url>
      
        <content type="html"><![CDATA[<h2 id="导言"><a href="#导言" class="headerlink" title="导言"></a><font color="#FF8C00">导言</font></h2><p>架构师是业务与产品之间的桥梁，其应该具备技术与产品的商业意识并且需要有将技术转化为产品的能力。而当前软件架构师在工作过程中往往离不开开源的软件项目，因此经常面临两个问题：”什么是产品？“以及“如何将一个开源的软件项目产品化？”</p><p>一套科学技术分析方法的背后有一定有着深刻的理论基础和哲学背景。找到了这套技术分析的源头，才能从本质上把握这套技术，看清其全貌，明了其长处和短处，这样在具体应用中，才能得心应手，提高胜算，并不断的丰富和发展这套技术。基于此，本文提出了一套如何将开源软件项目产品化的方法论。</p><p>然而理论与实践是相互作用的，宏观角度知道方法论之后还需要从微观上进行实践，不然就如同知道很多道理却过不好这一生，知道很多原则却写不好代码一样一样的。</p><h2 id="什么是产品"><a href="#什么是产品" class="headerlink" title="什么是产品"></a><font color="#FF8C00">什么是产品</font></h2><p>产品的定义：</p><blockquote><p>产品是指做为商品提供给市场，被人们使用和消费，并能满足人们某种需求的任何东西，包括有形的物品、无形的服务、组织、观念或它们的组合。</p></blockquote><p>从产品的定义中我们可以看到以下几点：</p><ul><li><p>属性：有形的物品、无形的服务、组织、观念或它们的组合，因此产品自带有形或无形属性；</p><ul><li>有形属性：狭义上产品是被生产出的能满足人们需求的具有物理属性的有形的物品。在绝大多数人的认知里，对产品的理解是停留在这一层次的，产品具有看得见、摸得着的物理形态；</li><li>无形属性：广义上产品是可以满足人们需求的任何东西，无形的服务、组织、观念或者它们的组合也是产品。广义上的产品定义对人的认知有更高的要求。服务是产品、企业是产品、团队是产品、认知是产品、本文是产品，这些东西的组合也是产品。万物皆产品，它目前不是产品，那只是没被产品化、或者不在对的时间与空间里；</li></ul></li><li><p>价值：产品首先是商品，其具有交易的价值，能提供给市场，供人们使用与消费，所有不能交易的东西不在产品的定义范围之内，因此这里可以推导出产品是具有价值的，没有价值的东西不属于产品的范畴；</p></li><li>交易：产品是做为商品提供给市场，被人们使用和消费，因此具有交易的价值，能满足市场的某种需求；</li></ul><p>因此基于以上的产品的公理化定义以及定理化推导得出产品的第一性原理定义：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs undefined">产品 = 属性 + 价值 + 交易<br></code></pre></td></tr></table></figure><p>从以上公式中可以认为产品是<font color="#FF8C00"><strong>以属性为要素，以价值为连接，以交易为目的</strong></font>，属性又可分为有形属性与无形属性，二者之间有时候并不是割裂的，价值是能满足人们的某些需求，是物品与货币之间的连接关系，交易是产品生产的目的。</p><p>然而这些都是教科书式的 定义，对产品的认知到这一层次已经可以超越绝大部分人，但它也只是停留在”产品“层次，而不是“作品”，更不是“艺术品”。</p><p>在我看来 产品 还是具有灵魂的，产品是由人创造的，其自然会带有人的思想、人的创造、人的理念在里头，宗师与学徒画同样的一幅画，虽然东西都一样但是那个味道往往是不一样的。因此，要理解一款产品还需要理解其背后的人的设计理念，在此，我给产品注入人的灵魂，即“理念”，从而进一步扩展产品的第一性原理：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs undefined">产品 = 属性 + 价值 + 交易 + 理念<br></code></pre></td></tr></table></figure><p>开源软件是信息的载体，其表现形式是具有无形的信息属性，是作为计算机程序的形式而存在的，要将开源软件产品化就需要将开源软件的属性价值化、可交易化以及注入人的设计理念。</p><h2 id="如何将一个软件产品化"><a href="#如何将一个软件产品化" class="headerlink" title="如何将一个软件产品化"></a><font color="#FF8C00">如何将一个软件产品化</font></h2><h3 id="价值与交付"><a href="#价值与交付" class="headerlink" title="价值与交付"></a><font color="#00CED1">价值与交付</font></h3><p>如何将一个软件产品化回答的是<strong>“How”</strong> 的问题，在此之前还应该搞明白<strong>“Why”</strong>的问题，一个软件产品或者其特性为什么需要做也有一套方法论，这里我称之为 <font color="#E01000"><strong>“产品交付之双轮驱动模型”</strong></font>（如下图）：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/product/product-value-and-delivery.PNG" alt="价值与交付"></p><p>在这个双轮驱动思维模型里有以下几个原则：</p><ul><li>以客户价值为前轮，前轮把握方向，解决的是需求探索、价值确定、特性探讨以及价值精炼的过程。首先是以客户价值为导向输入客户需求、但是这个需求还需要去伪存真、去粗纯精、过滤提炼，才能作为产品交付轮的输入，而不是只要是客户需求，不管是真需求还是假需求、也不管是有价值的、还是无价值的都全部输出到产品交付轮，无效的消耗产品交付资源；</li><li>以产品交付为后轮，后轮提供驱动力，解决的是开发、测试、运维以及获取客户反馈，再根据这个客户反馈的结果作为开发的输入的过程。在产品交付轮中很重要的一环是<strong>“反馈“</strong>，其角色是作为客户与交付之间的桥梁，开发需要依据”客户反馈”作为输入，而不是自个闭门造车；</li><li><p>客户价值又可分为主动式客户价值与被动式客户价值，获取客户需求的方式也需要合理取舍：</p><ul><li>主动式客户价值：有些客户”久病成医“，非常清楚自个痛点、难点、挑战点在哪里，也非常清楚自个需要什么样的解决方案可以药到病除，从而可以精确的输出自我的需求。这种客户对产品交付来说可遇而不可得，成本最低，需求最精确；</li><li>被动式客户价值：这种情况下，光是在那里等待，从而期望客户能给出明确的需求作为输入，那是缘木求鱼、刻舟求剑，效率也非常低下。如同医院里的医生给病人看病一样，绝大多数客户其实只能知道表征，而不知道根因，因此就需要由产品交付轮以客户专家的角色提出解决方案，作为客户价值需求输入给客户，再看客户的使用效果得出反馈，再依据这个反馈调整解决方案。</li></ul></li><li><p>在双轮驱动模型里，二者谁都离不开谁，不是厚此薄彼的关系，而是二者互相协作从而推动产品往商业成功这个目标前进的关系；</p></li><li><p>先有买家需求再有产品交付，而不是先有产品交付再找买家需求，需要明晰这个先后关系，为客户找出差异化需求才是产品交付的本质，寻求差异化、避免同质化，才是真正的以客户为中心。</p></li></ul><p>因此，在将一个技术产品化之前，先花几分钟时间问问其价值在哪里，为什么需要做这个，这一点很重要，要能区分客户要的是能马上就能解决痛点的止痛片还是可有可无的无关紧要的维生素，从而以此进行任务排序，明晰产品交付与客户价值的双轮驱动关系，要能清楚的理解<font color="#00CED1"><strong>“以客户为中心”</strong></font>的价值理念以及让产品的获得<font color="#00CED1"><strong>“商业成功”</strong></font>的终极目标。</p><h3 id="技术产品化"><a href="#技术产品化" class="headerlink" title="技术产品化"></a><font color="#00CED1">技术产品化</font></h3><p>通常来讲开源软件的产品化可以从价值、交易以及理念这三个方面进行。价值：可服务化、无形化有形、价值竞争，交易：可度量化、个性标准化，以及融入人的设计理念：复杂简单化等。</p><h4 id="可服务化"><a href="#可服务化" class="headerlink" title="可服务化"></a><font color="#E01000">可服务化</font></h4><p>可服务化指的是从技术实现上支持可服务化，ToB产品常常是半产品半服务的，而且一般会签约服务质量保证协议SLA，因此除了团队需要有替客户解决问题的能力外，还需要从技术与流程上支持可服务化，其中包括：</p><ul><li>可运维性：易用的部署（步骤量化）、升级（AB测试、in-place、replace、rolling-back等）、数据迁移、自动化运维支持等。在一个产品的全生命周期里，开发也许只占20%不到的时间，而将近80%的时间都需要运维，因此需要拿出近4倍比的开发重视程度，重视可运维的设计与实现；</li><li>可观测性：可观测性主要分为四大类: 监控、告警、日志、追踪；</li><li>可操作性：支持远程接入、开放服务接口、后台管理UI、CLI、特性参数配置开关；</li><li>健康管理：健康检查支持、健康报告支持、自动提交故障问题单支持；</li><li>安全性：安全性是企业级产品必备，数据保护、密码安全、连接检查、LIB库授权协议等；</li><li>多租户：多租户可以支持多团队、多部门小规模部署，进行业务隔离，也是非常重要的企业级特性；</li><li>可视化：提供易用的用户UI、CLI;</li><li>可支持：如何指定进行客户支持规则？如何升级成工程师团队介入提供服务定位问题或者排除问题？</li></ul><p>当看到以上类目，脑海里就能闪现出需要怎么去实现这些以及用什么组件可以最佳实践的快速完成交付，而不是停留在概念的阶段，那才算对可服务化有了自己的理解。</p><h4 id="无形化有形"><a href="#无形化有形" class="headerlink" title=" 无形化有形"></a><font color="#E01000"> 无形化有形</font></h4><p>无形化有形指的是将无形的软件硬件化或者云化，单单一个软件包是难以让用户买单的，需要把它硬件化，打包到服务器里以有形产品的形态销售出去，或者云化后以服务的无形形态销售出去。</p><h4 id="价值竞争"><a href="#价值竞争" class="headerlink" title=" 价值竞争"></a><font color="#E01000"> 价值竞争</font></h4><p>价值竞争指的是<strong>“参与到客户的购买周期中，在每个阶段为客户创造价值”</strong>[3]，从单纯的销售产品到提供整套生态化的解决方案。单纯的依靠销售产品往往已经难以给客户提供差异化的价值，并且也会面临低利润的同质化竞争，那么这个时候就需要更进一步的提供生态化的解决方案，针对行业需求做端到端的全生态化的解决方案。</p><p>生态化的解决方案化能给客户提供差异化的价值关系。比如，一份药品在药店里只能卖30块，而且只是一次销售无法挖掘后续价值。但是到了医院就不一样了，其依据客户的”恐惧“为刚需的基石，提供一整套的类生态化的医疗解决方案，从挂号预约、望闻问切、到各种仪器设备过一遍、再到开出药方、再依据客户的反应效果把这个过程再来几遍，因此在药店里30块钱的药，在医院里就能卖到 300块、3000块，获取十倍、百倍、千倍利润。</p><font color="#E01000"><strong>PS: 做生意要走正道，有良心的医院“以客户为中心”药到病除，无良医院“以利润为中心”无尽压榨客户，祝早日倒闭。</strong></font><h4 id="可度量化"><a href="#可度量化" class="headerlink" title="可度量化"></a><font color="#E01000">可度量化</font></h4><p>可度量化指的是质量要可以量化，可预测的业务指标（比如AI训练里的精度、加速比、收敛时间、训练次数等）、性能、可靠性、可用性、可伸缩性、稳定性、容错性、可测试性等，这些很抽象的指标要能量化。在产品功能同质化的场景下，质量是最重要的差异化竞争力。</p><p>业务性能、可靠性、可用性、可伸缩性这几者之间页互相制约，质量与成本、时间也互相制约，同时在云化的场景下客户又有SLA要求，不满足SLA要求的服务，除了要赔钱，还严重影响商业信誉，因此质量指标之间也需要合理取舍。</p><h4 id="个性标准化"><a href="#个性标准化" class="headerlink" title=" 个性标准化"></a><font color="#E01000"> 个性标准化</font></h4><p>个性标准化指的是将个性化的、“DIY”化的开源项目转成标准化的、可复制的、可量化的，同时依据资源的规格约束进行标准化，比如依据服务器规格、虚机规格，机架规格等进行标准化，例如AI服务器的配置就需要定义CPU、内存、磁盘、带宽以及训练卡的标准的规格，这样才能提供可预测的性能、可预测的加速比等质量指标，再比如云端场景下的服务监控，除了定义指标的名称之外，还需要定义监控指标的类型、故障码、输出的标记以及对应的处理措施等，所有的这些都要能标准化、可操作性化。</p><h4 id="复杂简单化"><a href="#复杂简单化" class="headerlink" title=" 复杂简单化"></a><font color="#E01000"> 复杂简单化</font></h4><p>复杂简单化指的是把复杂的体验简单化， 抽象及简化API、量化的安装步骤、高内聚低耦合的设计、易用的UI等，这里又涉及到产品设计哲学、人类的心理学等，也跟人的设计理念相关。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font color="#FF8C00">小结</font></h2><p>本文以方法论的形式解读了软件开发过程当中经常会遇到的两个问题：”什么是产品以及如何将一个开源的软件项目产品化“，讲的是“无用”的知识。</p><p>日拱一卒，功不唐捐，分享是最好的学习，与其跟随不如创新，希望这个知识点对大家有用，另作者能力与认知都有限，”我讲的，可能都是错的“，欢迎大家拍砖留念。</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中科大硕，某AI独角兽深度学习首席软件工程师，前EMC 大数据资深首席工程师，主要工作背景在深度学习、流式大数据、云计算、分布式中间件以及Linux内核。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a><font color="#FF8C00">参考资料</font></h2><p>[1] <a href="https://a16z.com/2019/10/04/commercializing-open-source/" target="_blank" rel="noopener">https://a16z.com/2019/10/04/commercializing-open-source/</a></p><p>[2] <a href="https://baike.baidu.com/item/%E4%BA%A7%E5%93%81/105875" target="_blank" rel="noopener">https://baike.baidu.com/item/%E4%BA%A7%E5%93%81/105875</a></p><p>[3] 《价值竞争：以客户为中心的销售转型》 - 付遥</p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p>]]></content>
      
      
      <categories>
          
          <category> product </category>
          
      </categories>
      
      
        <tags>
            
            <tag> product </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>分布式系统架构设计 – 第21式 - 基础理论 - 从CAP到PACELC</title>
      <link href="/2020/04/10/distributed-theory-cap-pacelc/"/>
      <url>/2020/04/10/distributed-theory-cap-pacelc/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a><font color="#FF8C00">前言</font></h2><p>分布式系统是一门讲究实践的软件工程，只有PK过设计方案，从微观处手把手的敲过一行行的代码，才能知道细节在哪里，难点在哪里，痛点、挑战点在哪里。同时，分布式系统也是一门讲究理论的软件工程，从宏观处着眼深刻理解系统设计的理论，将理论与实践相结合，想好、做好、说好才是真的好。因此，宏观处着眼，微观处着手，才能真正掌握分布式系统。自此，本系列文章开始讲诉分布式系统设计里的基础理论，本文为CAP与PACELC理论。</p><h2 id="CAP理论与PACELC理论"><a href="#CAP理论与PACELC理论" class="headerlink" title=" CAP理论与PACELC理论"></a><font color="#FF8C00"> CAP理论与PACELC理论</font></h2><h3 id="CAP理论"><a href="#CAP理论" class="headerlink" title=" CAP理论"></a><font color="#00CED1"> CAP理论</font></h3><p>CAP理论是分布式系统最为基本的指导理论之一，是分布式系统设计时最为基本的取舍依据，CAP理论认为一致性、可用性、分区容忍性不能同时满足，即：</p><ul><li><p>一致性(Consistency): 所有的节点在同一时刻看到同样的数据；</p></li><li><p>可用性(Availability):  节点失效不会影响系统的读写；</p></li><li><p>分区容忍性(Partition Tolerance): 系统能支持网络分区，即使分区之间的消息丢失系统也正常工作。</p></li></ul><p>但是，CAP理论也有其自身的局限性。在工程实践中CAP理论的应用可以一分为二：系统整体以及系统内部。比如，系统整体可以选择CA或者CP，但是系统内部微观处有些特性却可以同时满足CAP三要素，因为分区是件极少发生的事，为了追求卓越的设计理念可以尽量同时满足CAP三要素。根据业务场景的不同，不同的分布式系统会根据自身业务的需求在CAP三者中进行取舍， CAP理论的意义是一种在分布式系统设计时取舍的参考因素，而非绝对的三者必舍其一。</p><p>此外，在CAP理论中是没有提到系统的时延（Latency）的，而访问时延（Latency）却是很重要的可用性(Availability)因素，因此又延申出了PACELC理论。</p><h3 id="PACELC理论"><a href="#PACELC理论" class="headerlink" title="PACELC理论"></a><font color="#00CED1">PACELC理论</font></h3><p>PACELC理论是CAP理论的扩展，PACELC理论在wiki上的定义是:</p><blockquote><p>It states that in case of network partitioning (P) in a distributed computer system, one has to choose between availability (A) and consistency (C) (as per the CAP theorem), but else (E), even when the system is running normally in the absence of partitions, one has to choose between latency (L) and consistency (C).</p></blockquote><p>意思就是：</p><blockquote><p>如果有分区partition (P)，系统就必须在availability 和consistency (A and C)之间取得平衡; 否则else (E) 当系统运行在无分区情况下,系统需要在 latency (L) 和 consistency (C)之间取得平衡</p></blockquote><p>如下图，在PACELC里添加了Latency要素：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/theory/distributed-cap-pacelc-1.PNG" alt="cap-pacelc"></p><p>当前分布式系统设计指导理论应当采用PACELC理论替代CAP理论，理由如下：</p><ul><li><p>PACELC更能满足实际操作中分布式系统的工作场景是更好的工程实现策略；</p></li><li><p>当partition (P)存在的场景下，需要在availability 和consistency (A and C)之间取舍，但是实际上分布式系统中绝大多数时间里partition (P)是不存在的，那么就需要在latency (L) 和 consistency (C)之间作取舍；</p></li><li><p>Availability在不存在partition (P)的场景下跟 latency关联,在partition (P)时跟”可靠性“指标相关联；</p></li><li><p>PACELC 可以在 latency 与 consistency之间获得平衡；</p></li><li><p>CAP 理论忽略了 一致性和时延之间的取舍；</p></li></ul><p>PACELC理论是建立在CAP理论之上的，二者都描述了一致性(Consistency)、可用性(Availability)和分区容忍性(Partition Tolerance)之间的约束与取舍。而PACELC理论则更进一步描述了即使在没有Partition的场景下，也存在Latency和Consistency之间的取舍，从而为分布式系统的Consistency模型提供了一个更为完整的理论依据。</p><h3 id="理论应用"><a href="#理论应用" class="headerlink" title="理论应用"></a><font color="#00CED1">理论应用</font></h3><p>要保证系统数据的高可用（high availability）那么有个技术方案是采用数据冗余备份的方式，那么就涉及到复制数据，而进行分布式系统的数据复制，就会出现在Consistency和Latency之间做个取舍的要求。举个例子，如下图所示：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/theory/distributed-cap-pacelc-2.PNG" alt="consistency-latency"></p><p>在强一致性复制场景下，需要三副本都下盘才能返回OK确认信息给client端，假设Master节点向 Slave 节点复制数据，时延的限制是 20ms，有时候，slave 2 硬盘或网络出现故障，Master 往 Slave 复制数据的时延超过 了20ms，这个时候如果还一直等待 slave 2 返回结果再通知给client就会出现性能和时延抖动，而且这种抖动是经常会发生的长尾效应。</p><p>依据PACELC理论，我们可以在 consistency和Latency之间做个取舍，比如 slave 2 节点的时延超过 20ms了，就不等待slave 2 返回，master 和 slave 1 返回结果给client即可，如果 slave 2 出现 超时的 次数超过 5次那么就认为 这个节点可能出现故障，打个故障标签，进行后续的处理。采用这种方式可以消除写时的长尾抖动，获得更优雅的写时性能曲线。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font color="#FF8C00">小结</font></h2><p>本文遵循理论与实践相结合的指导思想讲述了CAP理论与PACELC理论。日拱一卒，功不唐捐，分享是最好的学习，与其跟随不如创新，希望这个知识点对大家有用。另作者能力与认知都有限，”我讲的，可能都是错的“，欢迎大家拍砖留念。</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中国科学技术大学硕士研究生，深度学习首席软件主管工程师，前EMC 大数据资深首席工程师，主要从事Linux内核以及分布式产品的架构设计、开发以及交付工作。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a><font color="#FF8C00">参考文献</font></h2><p>[1] <a href="https://en.wikipedia.org/wiki/PACELC_theorem" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/PACELC_theorem</a></p><p>[2] CAP理论与分布式系统设计，S先生</p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>分布式系统架构设计 – 第20式 - 编程思维模型</title>
      <link href="/2020/03/15/distributed-ideamodel-programing/"/>
      <url>/2020/03/15/distributed-ideamodel-programing/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a><font color="#FF8C00">前言</font></h2><p>编程是一种创造性解决问题的能力， 其本质上是一种思维体操，可以大大的提升人的逻辑能力、推理能力以及解决问题的能力， 那么什么是分布式系统的编程思维呢？</p><h2 id="编程思维模型"><a href="#编程思维模型" class="headerlink" title="编程思维模型"></a><font color="#FF8C00">编程思维模型</font></h2><p>具体来看分布式系统的编程思维包含11大内容：</p><blockquote><p>抽象、分层、解耦、拆分、聚合、治理、取舍、模型、演化、质量、边界。</p></blockquote><font color="#FF8C00">这个主题的解读，留待以后完善了再补充</font><p>//TODO</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font color="#FF8C00">小结</font></h2><p>本文解读了分布式系统的编程思维模型。日拱一卒，功不唐捐，分享是最好的学习，与其跟随不如创新，希望这个知识点对大家有用。另作者能力与认知都有限，”我讲的，可能都是错的“，欢迎大家拍砖留念。</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中科大硕，DELL EMC 资深首席工程师，曾就职于Marvell、AMD，主要从事Linux内核以及分布式产品的交付、架构设计以及开发工作。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a><font color="#FF8C00">参考资料</font></h2><p>[1] </p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>分布式系统架构设计 – 第19式 - 分布式系统八卦思维模型</title>
      <link href="/2020/03/14/distributed-ideamodel-distributedsystem/"/>
      <url>/2020/03/14/distributed-ideamodel-distributedsystem/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a><font color="#FF8C00">前言</font></h2><p>懂得很多道理，仍旧过不好这一生。懂得很多分布式系统的概念以及设计方法，依旧做不好分布式系统。分布式系统设计是一门实践软件工程，只有你PK过设计方案，手把手的敲过一行行的代码，才能知道细节在哪里，难点在哪里，痛点、挑战点在哪里，不是看书或者看文章就可以完全掌握的。因此，宏观处着眼，微观处着手，才能完全掌握分布式系统设计的道理。本文抽象出分布式系统的思维模型，当你看到这个模型里的字眼与图画，就可以从脑海里分解出一个个设计方案、一行行代码的时候，那才是真的掌握了分布式系统的精髓。</p><h2 id="分布式系统八卦思维模型"><a href="#分布式系统八卦思维模型" class="headerlink" title="分布式系统八卦思维模型"></a><font color="#FF8C00">分布式系统八卦思维模型</font></h2><p>这里我提出一个分布式系统八卦思维模型，如下图，其要义如下：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/ideamodel/idea-model-distributed-system.PNG" alt="分布式系统思维模型"></p><h3 id="方法论"><a href="#方法论" class="headerlink" title="方法论"></a><font color="#00CED1">方法论</font></h3><p>核心：在前面的文章里讲到可以用一句话来描述分布式系统：</p><blockquote><p>分布式系统是指其组件位于不同的网络计算机上的系统，这些组件通过相互传递消息来进行通信和协调其动作，且彼此相互交互以完成一个共同的任务目标。</p></blockquote><p>并且提到了“系统 = 要素 + 连接 + 目标”  ， 这个思维模型的核心即分布式系统的第一性原理， 公式：“分布式系统 = 计算机 + 网络 + 协同”，要素是计算机（新的虚机、容器也算），连接是网络，目标是协同以完成共同任务。</p><p>提供：即服务接入的提供，指的是对外提供restful 接口服务：权限、多组合、监控、审计、计费等，对外提供SQL服务接入接口服务、对外提供自然语言接入接口服务等<br>注册：即服务注册，将集群的工作负载注册到集群注册中心<br>配置：即配置管理，将集群的配置管理在配置中心；<br>调用，即服务调用，各种RPC调用，系统内的消息传递<br>路由：即服务路由，目的是集群的负载均衡与扩伸缩性<br>观测：指的是集群内部指标的可观测性，即监控、告警、追踪、日志<br>治理：指的是集群内部的服务治理：熔断、降级、限流、隔离、容错<br>编排：即服务编排，基于k8s+ docker，完成安装、升级、扩容、运维、调度等；<br>质量：指的是安装部署运维质量、客户质量、用户质量与开发质量<br>边界：指的是系统内的约束条件，涵盖 硬件资源、客户约束、用户约束以及团队约束</p><p>这10个功能与核心之间是互相联系、互联影响的，因此类似于一个八卦图。</p><h3 id="底层思维"><a href="#底层思维" class="headerlink" title="底层思维"></a><font color="#00CED1">底层思维</font></h3><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs undefined">抽象、分层、解耦、拆分、聚合、治理、取舍、质量、边界、模型、演化<br></code></pre></td></tr></table></figure><p>抽象、分层、解耦、拆分、聚合、治理、取舍、质量、边界、模型、演化是分布式系统设计的底层思维，也是软件工程的底层思维，这个主题很难掌握，目前，这里不展开讲。</p><h3 id="基石假设"><a href="#基石假设" class="headerlink" title="基石假设"></a><font color="#00CED1">基石假设</font></h3><p>分布式系统有两个隐含的基石假设，即 “资源协同与质量可预测”，资源即计算机、虚拟机、容器以及网络，基于此，分布式系统的第一性原理 即： “分布式系统 = 计算机 + 网络 + 协同 ，以质量为度量”。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font color="#FF8C00">小结</font></h2><p>本文提出一个分布式系统八卦思维模型。分布式系统不是我首创，用这个类八卦图形来表示思维模型也不是我首创，但是用这个类八卦图形表示分布式系统思维模型应该是我首创，目前不管是书籍还是网络都找不到这样的分布式系统思维模型。日拱一卒，功不唐捐，分享是最好的学习，与其跟随不如创新，希望这个知识点对大家有用。另作者能力与认知都有限，”我讲的，可能都是错的“，欢迎大家拍砖留念。</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中科大硕，DELL EMC 资深首席工程师，曾就职于Marvell、AMD，主要从事Linux内核以及分布式产品的交付、架构设计以及开发工作。</p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>分布式系统架构设计 – 第18式 - 以物理学思维破解分布式系统的本质</title>
      <link href="/2020/02/24/distributed-theory-of-essence/"/>
      <url>/2020/02/24/distributed-theory-of-essence/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a><font color="#FF8C00">前言</font></h2><p>本文的动机在于应用物理学思维模型破解分布式系统背后不变的本质，并以此解读分布式系统里的各种算法设计、功能设计以及非功能设计。在“分布式系统” 这个词语里，关键词可以分为“分布式”及“系统”，而<strong>“系统 = 要素 + 连接 + 目标”</strong>，在这个公式里，要素的变化不会影响系统的本质，而“连接或目标”的变化就会改变系统的本质，其中“分布式”是系统的连接方式，挖掘分布式系统背后的本质即是挖掘“分布式系统”的要素、连接以及目标的本质。</p><p>物理学的价值观在于追求所有物理现象背后的共同的底层规律，并以此解读各种物理现象，并且其具有“可解释、可重复、可预测”的可度量性，这种共同的底层规律，被称之为元认知，即第一性原理：“任何变化的背后都有不变的本质”。将这种思维模型应用于挖掘分布式系统的本质，需要解决两个问题，即：“ 什么是分布式系统的第一性原理？以及如何度量分布式系统？”</p><h2 id="分布式系统的价值与目的"><a href="#分布式系统的价值与目的" class="headerlink" title="分布式系统的价值与目的"></a><font color="#FF8C00">分布式系统的价值与目的</font></h2><p>分布式系统的出现是为了解决一个主要矛盾，即：“日益增长的数据计算、传输与存储的需求与当前单点计算机能力无法满足这个需求之间的矛盾”。分布式系统可以通过伸展集群规模解决这个矛盾，因此这就是分布式系统的价值，而可伸缩性(Scalability，避免与可扩展性extensibility混淆)也是分布式系统的根本目的。</p><h2 id="分布式系统必知的基础理论与算法"><a href="#分布式系统必知的基础理论与算法" class="headerlink" title="分布式系统必知的基础理论与算法"></a><font color="#FF8C00">分布式系统必知的基础理论与算法</font></h2><p>分布式系统必须理解、必须会的基础理论算法有：CAP/PACELC、BASE、2PC、3PC、TCC、ACID、PAXOS、RAFT这9个：</p><ul><li>CAP: CAP理论认为以下三者不能同时满足：<ul><li>一致性(Consistency): 所有的节点在同一时刻数据是完全一样的；</li><li>可用性(Availability): 节点失效不会影响系统的IO；</li><li>分区容忍性(Partition Tolerance): 系统能支持网络分区（网络连接故障），即使分区之间的消息丢失系统也正常工作。</li></ul></li><li>PACELC: PACELC理论是CAP理论的扩展，如果有分区partition (P)，系统就必须在availability 和consistency (A and C)之间取得平衡; 否则else (E) 当系统运行在无分区情况下,系统需要在 latency (L) 和 consistency (C)之间取得平衡”；</li><li>BASE: BASE是基本可用（Basically Available）、软状态（Soft state）和最终一致性（Eventually consistent）三个短语的缩写；</li><li>2PC：two-phase commit protocol，两阶段提交；</li><li>3PC: three-phase commit protocol ，三阶段提交，其在两阶段提交的基础上增加了CanCommit阶段，并引入了超时机制；</li><li>TCC: Try-Confirm-Cancel，又称补偿事务，其核心思想是：”针对每个操作都要注册一个与其对应的确认和补偿（撤销操作）”；</li><li>ACID: 原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持久性（Durablity）；</li><li>PAXOS/RAFT ：PAXOS与RAFT算法都是最有效的解决分布式一致性问题的算法。</li></ul><p>这几条基础理论与算法需要自己深入学习理解，其是分布式系统的必备知识点。</p><h2 id="分布式系统的功能与非功能"><a href="#分布式系统的功能与非功能" class="headerlink" title="分布式系统的功能与非功能"></a><font color="#FF8C00">分布式系统的功能与非功能</font></h2><h4 id="功能"><a href="#功能" class="headerlink" title="功能"></a>功能</h4><p>功能可按职责划分为服务功能与算法功能:</p><ul><li>分布式系统里的最主要的服务功能有：服务提供，服务注册，服务配置，服务调用、服务路由、服务治理设计，服务观测、服务安全这8项；</li><li>分布式系统里的最主要的算法功能有：幂等性设计、事务算法设计、端到端的校验算法设计、路由算法设计、分区分配算法设计、集群视图变更算法设计、心跳算法设计、注册算法设计、复制一致性算法设计以及容量规划算法设计。</li></ul><h4 id="非功能"><a href="#非功能" class="headerlink" title="非功能"></a>非功能</h4><p>非功能可划分为质量与约束：</p><ul><li><p>质量是分布式系统在约束条件下的度量方式，其涵盖：合适的性能（Performant）、可用性(Availability)、可靠性(Reliability)、可伸缩性(Scalability)、韧性(resilience)、可观测性(Observability)、安全性（security）、易用性（usability）、可运维性（operability）、可测试性(testability)、可维护性(maintainability)、可扩展性(extensibility)、可读性(readability)等。</p></li><li><p>约束是分布式系统的资源限制：网络物理容量与计算机节点的物理容量，以及客户、用户、团队的边界约束。</p></li></ul><p><strong>分布式系统交付的目的是功能的价值，但是产品的功夫却体现在非功能</strong>，分布式系统的质量是分布式系统的度量方式，分布式系统要可度量就需要具有“可解释、可复制、可预测”的质量保证。</p><h2 id="分布式系统的第一性原理"><a href="#分布式系统的第一性原理" class="headerlink" title="分布式系统的第一性原理"></a><font color="#FF8C00">分布式系统的第一性原理</font></h2><p>依据李善友老师的定义： <font color="#00CED1"><strong>“第一性原理思维 = 逻辑奇点 + 公理化方法 ”</strong></font>，逻辑奇点即基石假设，公理化方法我认为是”定公理、推定理、再公式化应用”。因此欲找出分布式系统的第一性原理，就需要先挖掘出分布式系统的公理化定义及其逻辑奇点。</p><p>首先把分布式系统概念化，Google 出来的对分布式系统的定义有：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs undefined">A distributed system is a system whose components are located on different networked<br>computers, which communicate and coordinate their actions by passing messages to one<br>another. The components interact with one another in order to achieve a common goal.<br></code></pre></td></tr></table></figure><p>即：</p><blockquote><p>分布式系统是指其组件位于不同的网络计算机上的系统，这些组件通过相互传递消息来进行通信和协调其动作，且彼此相互交互以完成一个共同的任务目标。</p></blockquote><p>拆解这句话，从中可以看到分布式系统里的要素即为组件，连接即网络，目标是共同的任务，并且还可以看出4个要点：</p><ul><li><p>分布式系统的组件是位于不同的网络计算机上；</p></li><li><p>分布式系统的组件通过传递消息进行通信其动作；</p></li><li><p>分布式系统的组件通过传递消息进行协调其动作；</p></li><li><p>分布式系统的组件是通过相互交互以完成一个共同的任务目标；</p></li></ul><p>其中最最重要的可以看作是分布式系统的基石假设的要点是：</p><p>1，分布式系统的组件是位于不同的网络计算机上；</p><p>2，这些组件通过相互传递消息来进行通信和协调其动作，且彼此相互交互以完成一个共同的任务目标。</p><p>这两点即为分布式系统的逻辑奇点，破除了这两点那就不是分布式系统，比如去掉网络计算机的定义，那就是单机系统，去掉协调以完成共同的任务目标，那就只是一个计算机网络。这两点基石假设构成分布式系统的逻辑奇点。</p><p>到此，可以得出分布式系统的公理化定义：</p><blockquote><p>分布式系统是指其组件位于不同的网络计算机上的系统，这些组件通过相互传递消息来进行通信和协调其动作，且彼此相互交互以完成一个共同的任务目标。</p></blockquote><p>以及分布式系统的逻辑起点：</p><blockquote><ul><li><p>分布式系统是指其组件位于不同的网络计算机上的系统：即计算机网络；</p></li><li><p>这些组件通过相互传递消息来进行通信和协调其动作，且彼此相互交互以完成一个共同的任务目标：即协同：“谐调一致，和合共同，协调两个或者两个以上的不同资源或者个体，一致地完成某一共同目标”；</p></li></ul></blockquote><p>再进一步抽象，可以推断出“分布式系统就是通过计算机网络进行协同工作的系统”， 至此，可以推出分布式的公理化定义公式：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs undefined">分布式系统 = 计算机 + 网络 + 协同，其以质量为度量。<br></code></pre></td></tr></table></figure><p>这个公式就是分布式的第一性原理公式，是分布式的本质理论定义，其中“计算机”是分布式系统的要素，“网络”是分布式系统的连接，“协同”是分布式系统的目标，从这公式里可以看出分布式系统的3个原生的难题：</p><ul><li><p>分布式系统是基于网络的系统，那么网络自身所具有的所有的优点与缺点它都有，那么如何提高服务的可靠性？如何保证服务的可用性？如何保证网络可运维？</p></li><li><p>分布式系统是基于消息传递的系统，消息传递是不可靠的，那么如何保证消息的正确性？如何保证消息传递的可靠性？如何传递消息到目的地？如何保证消息传递的负载均衡？</p></li><li><p>分布式系统是协同工作的系统，那么如何协调大量的计算机节点的完成一个共同的目标，如何解决协调的复杂性以及提高协调的可靠性、可用性？那么如何一起交互完成一个共同的目标任务？如何拆分目标？如何聚合目标，如何度量完成任务的质量与边界？</p></li></ul><p>因此还需要依据分布式系统的公理化定义推导出定理化定义。</p><h2 id="分布式系统的定理化推导"><a href="#分布式系统的定理化推导" class="headerlink" title="分布式系统的定理化推导"></a><font color="#FF8C00">分布式系统的定理化推导</font></h2><p>“公理是不证自明的，而定理是以若干的公理或其他定理为基础而推导的”。由公理推定理，从分布式的公理化公式<font color="#00CED1"><strong>“分布式系统 =  计算机  + 网络 + 协同”</strong></font>，可知分布式系统是组件位于“不同的计算机网络”上一起“协同”工作的系统，这句话得出分布式系统三要素：<font color="#00CED1">“计算机、网络，协同”</font>。其中计算机是系统要素，改变计算机为虚机或者容器，不会改变分布式系统的本质。网络是系统的连接，改变连接就会改变系统的本质，当连接一台计算机时，就是单机，当连接两台计算机时就是镜像，当连接 多于两台计算机时就是分布式。协同是系统的目标，当改变协同的目标也就改变了系统的功能，比如共同计算与共同存储、共同调度，其功能目标是不一样的。</p><h3 id="计算机"><a href="#计算机" class="headerlink" title="计算机"></a>计算机</h3><p>分布式系统是基于不同的计算机上的系统，计算机也是分布式系统的要素之一，因此分布式系统也继承了计算机的原生缺点，</p><ul><li>计算机节点是会出故障的，主板、CPU、网卡、硬盘、内存、电源等都会出故障，比如老化、失效等；</li><li>计算机节点内的操作系统是会突然奔溃不能提供服务的；</li><li>计算机节点是会突然掉电的；</li><li>计算机节点里的内存下电是不保数据的；</li><li>计算机节点的资源是有限的：CPU是有算力上限的、内存是有大小限制的、网卡有吞吐量限制、硬盘有空间大小限制以及速率限制；</li></ul><p>这几个计算机的原生缺点意味着分布式系统需要能够知道计算机节点是失效的，以及在计算机节点失效的同时保证服务质量设计，那么就应当进行以下几点保证：</p><ul><li><p>可观测性（observability）设计：监控、告警、日志、追踪；</p></li><li><p>可靠性（Reliability）设计：冗余设计、分区分配设计、复制算法设计、幂等性设计、一致性算法设计；</p></li><li><p>容量（capacity）规划设计：计算机节点资源资源有限，就需要分布式系统进行进行容量规划；</p></li><li><p>服务治理（Service governance）设计：CPU算力有限、内存有限、网卡吞吐量有限、磁盘IO有限，因此需要进行服务治理之隔板设计以及限流、限并发设计。</p></li></ul><h3 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h3><p>分布式系统是基于不同的网络上的系统，网络是分布式系统的连接方式之一，连接一台计算机的系统就是单机系统，连接两台计算机的系统就是镜像系统，连接三台及以上数目的计算机的系统就是分布式系统，因此分布式系统也继承了网络的原生缺点，即：</p><ul><li>网络是不可靠的；</li><li>网络是会出故障的；</li><li>网络是有时延的；</li><li>网络是会抖动的；</li><li>网络是不安全的；</li><li>网络是会丢包的；</li><li>网络是有带宽限制的；</li><li>网络消息是会乱序的；</li></ul><p>由此，为了保证分布式系统的服务质量：性能、可用性、可靠性、安全性等，那么就需要进行服务质量保证设计，其可以划分为：</p><ul><li><p>网络是不可靠以及会出现断网之类的故障的，因此分布式系统需要进行服务治理容错设计；</p></li><li><p>网络乱序以及丢包，因此分布式系统需要幂等性算法设计、端到端的校验算法设计；</p></li><li><p>网络带宽有限，因此分布式系统需要网络容量设计以及服务治理限流设计；</p></li><li><p>网络不安全：因此分布式系统需要服务安全设计；</p></li><li><p>网络是有时延的，因此分布式系统需要进行性能设计：更好的硬件、跟短的IO路径；</p></li><li><p>网络是会抖动的，因此分布式系统需要进行服务治理容错之超时处理设计。</p></li></ul><h2 id="协同"><a href="#协同" class="headerlink" title="协同"></a>协同</h2><blockquote><p>协同是指：“谐调一致，和合共同，协调两个或者两个以上的不同资源或者个体，一致地完成某一共同目标“，这些组件通过相互传递消息来进行通信和协调其动作，且彼此相互交互以完成一个共同的任务目标</p></blockquote><p>协同又可以拆分为协调动作与共同完成任务，即：</p><h4 id="协调动作"><a href="#协调动作" class="headerlink" title="协调动作"></a>协调动作</h4><p>分布式系统的组件通过传递消息进行通信及协调其动作，即：因此依据消息传递的特性以及缺点需要进行相应的协调动作设计：</p><ul><li>传递消息特性意味着需要进行RPC调用设计；</li><li>网络里传递的消息是经常不一样的，因此需要序列化编解码设计；</li><li>消息传递具有丢消息、丢处理的弊端，为了解决这个弊端就需要进行 ：幂等性设计、事务处理设计、日志设计；</li><li>消息的传递是会超时的，因此就需要服务治理容错之超时处理设计；</li><li>消息是基于网络传输的，而网络是可能随时出故障的，因此需要对消息进行可观测性设计即消息追踪设计；</li><li>需要知道消息从哪里来，往哪里去就需要一个配置中心管理集群各个计算机的信息，比如IP，因此需要进行配置中心设计；</li><li>光知道可以发往哪里还不够，还要知道发往的节点是活着的可服务的，需要知道计算机节点的服务状态，还需要保证消息路由的负载均衡，因此这就就需要一个协调的服务注册中心，进行服务组件的注册与心跳检测、消息路由以及按集群视图变更算法管理集群状态表，那么就需要注册中心设计、注册算法设计、负载均衡算法设计，心跳算法设计、集群视图变更算法设计以及集群状态表管理设计。</li></ul><h4 id="共同完成任务"><a href="#共同完成任务" class="headerlink" title="共同完成任务"></a>共同完成任务</h4><p>分布式系统的组件是通过相互交互以完成一个共同的任务目标，因此需要解决共同完成任务并且保证任务完成质量带来的难题：</p><ul><li><p>整个分布式系统需要能接收任务以及返回完成的任务，那么就需要有提供服务的能力，需要有服务调用接口设计，服务调用客户端以及可视化界面；</p></li><li><p>为了能让网络里的N台计算机相互交互完成一个共同的目标，就需要对任务进行拆分以及聚合设计；</p></li><li>任务拆分后要能知道发给哪个节点，那么就需要一个配置中心, 从配置中心获取目标节点信息；</li><li>任务拆分后分发给节点同时要保证处理的性能，那么就需要进行可伸缩性设计，一台机器处理不过来就需要N台机器一起处理从而保证处理的性能质量，因此又衍生出需要路由算法设计或分区分配算法设计，这样拆分后的任务可以被分发到不同的独立的节点进行处理，并且，但一个节点不可用时，还可以分发到其他的可用的节点，从而提升了系统性能与可用性；</li><li>任务又可以分为计算任务与存储任务，如果是存储任务，为了保证数据的可用性以及可靠性，就需要对分区进行冗余设计，即节点副本设计，如果需要节点副本设计又引入了选主算法设计、数据一致性复制算法设计与幂等性设计；</li><li>为了解决选主与复制一致性问题，又出现了PAXOS,RAFT,2PC,3PC 等，这样的基础一致性协议算法。</li></ul><p>至此，依据分布式的公理化公式：<font color="#00CED1"><strong>“分布式系统 = 计算机 + 网络 + 协同”</strong></font>，推导出了分布式的定理化推论，解读了分布式系统里为什么需要进行这些功能与非功能设计的问题，接下来还需要讲述分布式系统的度量。</p><h2 id="分布式系统的度量"><a href="#分布式系统的度量" class="headerlink" title="分布式系统的度量"></a><font color="#FF8C00">分布式系统的度量</font></h2><p>分布式系统是依据分布式公理定义的质量进行度量的，其涵盖以下几项内容：</p><ul><li><p>合适的性能（Performant），性能指标一般包括 TPS, QPS, Latency, IOPS， response time等，这里用”合适的性能“作为表达，指的是性能合适即可、够用即可，高性能当然好，但是高性能也意味着更高的成本，有些场景高性能反而是一种浪费行为，性能需求需要理解业务场景适可而止；</p></li><li><p>可用性(Availability)，可用性指的是系统长时间可对外提供服务的能力，通常采用小数点后的9的个数作为度量指标，按照这种约定“五个九”等于0.99999（或99.999％）的可用性，默认企业级达标的可用性为6个9。但是当前从时间维度来度量可用性已经没有太大的意义，因为设计得好的系统可以在系统出现故障得情况下也能保证对外提供得服务不中断，因此，当前更合适得可用性度量指标 是请求失败率；</p></li><li><p>可靠性(Reliability)，可靠性一般指系统在一定时间内、在一定条件下可以无故障地执行指定功能的能力或可能性， 也是采用小数点后的9的个数作为度量指标，通常5个9的可靠性就可以满足企业级达标；</p></li><li><p>可伸缩性(Scalability)，是指通过向系统添加资源来处理越来越多的工作并且维持高质量服务的能力，其受可用性以及可靠性的制约，集群规模越大出故障的概率越高从而降低可用性、可靠性，为了保证可用性以及可靠性达标，需要适配合理的可伸缩性指标；</p></li><li><p>韧性(resilience)，通常也叫容错性（fault-tolerant），也就是健壮和强壮的意思，指的是系统的对故障与异常的处理能力，比如在软件故障、硬件故障、认为故障这样的场景下，系统还能保持正常工作的能力；</p></li><li><p>可观测性(Observability)，是一种设计理念，包括告警、监控、日志与跟踪，可以实时地更深入地观测系统内部的工作状态；</p></li><li><p>安全性（security），指的是阻止非授权使用，阻止非法访问以及使用，保护合法用户的资产的能力；</p></li><li><p>易用性（usability），指的是软件的使用难易程度，对于产品的易用性来说， 易用性不仅仅 是软件使用角度的易用，还包括安装、部署、升级上的易用,升值还包括硬件层面的易用，比如产品的外观，形状等；</p></li><li><p>可运维性（operability），可运维性指的是运维人员对系统进行运维操作的难易程度，主要包含以下几个方面的难以程度： 系统的部署、升级、修改、监控以及告警等；</p></li><li>可测试性（ testability），指的是单元测试，集成测试，打桩测试等的难易；</li><li>可维护性（Maintainability）， 指的是代码升级，部署，定位bug，添加功能的难易；</li><li>可扩展性（ extensibility）， 指的是未来增加新的功能与模块的难易；</li><li><p>可读性（ readability），指的是代码的易理解程度。</p></li><li><p>边界约束：集群规模、计算机的容量等物理资源的限制，以及客户、用户、团队的约束需求。</p></li></ul><p>依据这几项质量度量指标，可以保证分布式的“可解释、可复制、可预测”。其中要保证质量的核心思想是<strong>“共享资源、消除资源竞用性以及平衡负载。”</strong>，共享资源需要注册中心，消除资源竞用性就需要服务治理，平衡负载需要好的路由算法。</p><h2 id="分布式系统的反熵增与数据守恒"><a href="#分布式系统的反熵增与数据守恒" class="headerlink" title="分布式系统的反熵增与数据守恒"></a><font color="#FF8C00">分布式系统的反熵增与数据守恒</font></h2><h3 id="熵增"><a href="#熵增" class="headerlink" title="熵增"></a>熵增</h3><p>熵增定律是物理学的基本定律之一，其被定义为：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs undefined">1, 熵（Entropy）是用以度量一个系统“内在的混乱程度”，即系统中的无效能量；<br>2, 熵增定律：在一个孤立系统里，如果没有外力做功，其总混乱度（熵）会不断增大；<br>3，熵增过程是一个自发的由有序向无序发展的过程并且具有必然性，为了保证有序就必须逆熵增做功。<br></code></pre></td></tr></table></figure><p>分布式系统也是一个孤立的系统，其中的网络与计算机节点（涵盖电源、主板、CPU、内存、网卡、硬盘等）等硬件会老化、会出故障，组件之间协同工作也会遇到负载过高、软件系统出现BUG等问题，这也是一个熵增的过程，并且因为熵增的必然性，分布式系统总是自发地或非自发地不断由有序走向无序，最终不可逆地走向失效不可用。为了保证分布式系统是有序可用的就必须逆熵增做功，即对其反熵增，分布式系统的反熵增过程与方法是：</p><ul><li>可运维设计：软硬件的部署与升级设计、可视化设计、可观测性（监控、告警、日志、追踪）设计；</li><li>可服务设计：由团队解决故障以及提供服务的支持；</li><li>服务治理设计：熔断、限流、降级、隔离、容错，触使分布式系统保持在有序状态；</li><li>智能化设计：参数自我优化、故障自我判断、工作负载自我预测等；</li><li>动态平衡设计：动态平衡是一种设计理念，有进有出；</li></ul><p>因此其中在分布式系统里将需要将可运维、可服务、可治理、可智能化、动态平衡的思想融合到架构设计与开发中。</p><h3 id="数据守恒"><a href="#数据守恒" class="headerlink" title="数据守恒"></a>数据守恒</h3><p>能量守恒定律也是物理学的基本定律之一，其被定义为：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs undefined">1，能量既不会凭空产生，也不会凭空消失，它只会从一种形式转化为另一种形式，或者从一个物体转移到其它物体，<br>   而能量的总量保持不变；<br>2，孤立系统的总能量保持不变。<br></code></pre></td></tr></table></figure><p>在分布式系统里<strong>“数据”</strong>即是分布式系统的能量，因此参照“能量守恒”定义，这里我给分布式系统一个<strong>“数据守恒”</strong>定义：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs undefined">孤立系统的总数据量保持不变。数据既不会凭空产生，也不会凭空消失，它只会从一种形式转化为另一种形式，<br>或者从一个物体转移到其它物体， 而数据的总量保持不变；<br></code></pre></td></tr></table></figure><p>依据上节的定理推导，我们知道分布式系统里网络是不可靠的、消息传递是不可靠的、计算机节点是不可靠的、磁盘是不可靠的、内存是不可靠的、软件组件是不可靠的等等，这些过程都会丢数据，因此为了保证分布式系统里的<strong>“数据守恒”</strong>就需要对分布式系统进行数据可靠性设计：即：</p><ul><li>分区设计、冗余设计、幂等性设计、端到端的校验设计、日志设计、事务处理设计，缓存的MESI设计等。</li></ul><p>因此在分布式系统里将也需要将<strong>“数据守恒”</strong>的思想融合到架构设计与开发中。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font color="#FF8C00">小结</font></h2><p>本文以物理学思维挖掘分布式系统的本质，推导出了分布式系统为什么需要这样的设计的缘由，并且文中阐述了分布式系统的基础理论、功能非功能、反熵增与数据守恒。日拱一卒，功不唐捐，分享是最好的学习，与其跟随不如创新，希望这个知识点对大家有用。另作者能力与认知都有限，”我讲的，可能都是错的“，欢迎大家拍砖留念。</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中科大硕，DELL EMC 资深首席工程师，曾就职于Marvell、AMD，主要从事Linux内核以及分布式产品的交付、架构设计以及开发工作。</p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>分布式系统架构设计 – 第17式 - 为什么开源的项目不如商业产品</title>
      <link href="/2020/02/20/distributed-product_opensource_and_product/"/>
      <url>/2020/02/20/distributed-product_opensource_and_product/</url>
      
        <content type="html"><![CDATA[<h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a><font color="#FF8C00">动机</font></h2><p>架构设计人员需要有产品的商业意识，作为软件开发人员在工作过程中往往离不开开源项目，但是能回答好“为什么开源的项目不如商业产品？”这个问题的并不多，因此本文就为此做个解读。</p><h2 id="为什么开源的项目不如商业产品"><a href="#为什么开源的项目不如商业产品" class="headerlink" title="为什么开源的项目不如商业产品"></a><font color="#FF8C00">为什么开源的项目不如商业产品</font></h2><p>开源的项目从产品化的角度来看可分为三个层次：</p><h3 id="项目与社区锲合"><a href="#项目与社区锲合" class="headerlink" title="项目与社区锲合"></a><font color="#00CED1">项目与社区锲合</font></h3><p>项目与社区锲合，即开源项目在社区内的锲合程度，度量指标是点赞数、fork数、社区的技术文章阅读量，提升项目于社区的锲合度需要通过运营推广的方式，比如参加技术大会、发布技术文章以及发布完整的项目文档等；</p><h3 id="产品与市场锲合"><a href="#产品与市场锲合" class="headerlink" title="产品与市场锲合"></a><font color="#00CED1">产品与市场锲合</font></h3><p>产品与市场锲合，即开源产品在市场的锲合程度，是否满足市场的真正需求，度量指标是下载量、使用量，通常来说开源项目能做到这一步就非常成功了，比如ceph，k8s，Tensorflow, Flink等；</p><h3 id="价值与市场锲合"><a href="#价值与市场锲合" class="headerlink" title="价值与市场锲合"></a><font color="#00CED1">价值与市场锲合</font></h3><p>价值与市场锲合，即客户愿意买单的点，度量指标是收入。其一般指的是开源项目里的增值功能以及企业级特性，即项目自身的商业价值，例如：更好的性能、更好的可用性、可靠性、更加易用的部署与升级功能，更加易用的可视化功能、安全、可观测、质量的可度量性、额外的服务支持以及解决方案化。</p><p>至此，我们可以看出商业模式的差异决定了开源的项目往往不如商业的产品，这是商业模式带来的差异。开源的项目若是完成了第一层次与第二层次就可以认为是非常成功的一个项目，如果把第3层次也完成了反而是个失败的开源项目，因为这不利于项目的商业化，开发团队赚不到钱没有存活下去的可能性。但是商业化的产品必须涵盖这三个层次，开源的项目还只能算是一个项目还不是产品，它只完成了第1、第2两个层次，因此商业化就要求我们需要把开源的项目产品化。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font color="#FF8C00">小结</font></h2><p>本文解读了一个问题：为什么开源的项目不如商业产品？日拱一卒，功不唐捐，分享是最好的学习，与其跟随不如创新，希望这个知识点对大家有用。另作者能力与认知都有限，”我讲的，可能都是错的“，欢迎大家拍砖留念。</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中科大硕，DELL EMC 资深首席工程师，曾就职于Marvell、AMD，主要从事Linux内核以及分布式产品的交付、架构设计以及开发工作。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a><font color="#FF8C00">参考资料</font></h2><p>[1] <a href="https://a16z.com/2019/10/04/commercializing-open-source/" target="_blank" rel="noopener">https://a16z.com/2019/10/04/commercializing-open-source/</a></p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>分布式系统架构设计 – 第16式 - 以第一性原理思维模型解读tensorFlow 2.0的架构设计</title>
      <link href="/2020/02/18/distributed-ideamodel-example_tensorflow/"/>
      <url>/2020/02/18/distributed-ideamodel-example_tensorflow/</url>
      
        <content type="html"><![CDATA[<h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a><font color="#FF8C00">动机</font></h2><p>依据李善友老师的定义“第一性原理思维 = 逻辑奇点 + 公理化方法”，逻辑奇点即基石假设。根据这个第一性原理思维 ，本文解读了tensorFlow 2.0的架构设计，其涵盖了tensorFlow2.0的第一性原理、设计原则以及架构视图，本文的动机是展示第一性原理的架构设计思想在分布式系统架构设计中的应用。</p><h2 id="TensorFlow-的第一性原理"><a href="#TensorFlow-的第一性原理" class="headerlink" title="TensorFlow 的第一性原理"></a><font color="#FF8C00">TensorFlow 的第一性原理</font></h2><p>欲从本质上理解Tensorflow，那么就需要找出tensorflow的第一性原理定义，再依据演绎法，从这个公理性质的定义演化出tensorFlow的设计理念、设计原则以及功能实现。这里首先把tensorFlow概念化，找出它的公理化定义以及基石假设，即TensorFlow是什么的定义。</p><p>通过tensorFlow官网以及Google，得到的6条关于tensorFlow的定义：</p><blockquote><p>1.A machine-learning library based on dataflow programming. </p><p>2.TensorFlow is a free and open-source software library for dataflow and differentiable programming across a range of tasks. </p><p>3.TensorFlow is an end-to-end open source platform for machine learning. </p><p>4.TensorFlow computations are expressed as stateful dataflow graphs. </p><p>5.TensorFlow is an end-to-end open source platform for machine learning. It has a comprehensive, flexible ecosystem of tools, libraries and community resources that lets researchers push the state-of-the-art in ML and developers easily build and deploy ML powered applications.</p><p>6.TensorFlow Enterprise incorporates: Enterprise-grade support, cloud scale performance，managed services</p></blockquote><p>从这6个定义中，可以概括出tensoFlow的<strong>公理化定义</strong>：</p><blockquote><p>TensorFlow is an scalable end-to-end  machine-learning platform based on <strong>stateful dataflow graphs</strong> programming,it has a comprehensive, flexible ecosystem.</p></blockquote><p>即</p><blockquote><p>tensorFlow是一个可伸缩的端到端的面向有状态的数据流图编程的机器学习平台,其具有一个全面而灵活的生态系统。</p></blockquote><p>以及两个<strong>基石假设</strong>，即逻辑奇点：</p><ul><li>可伸缩(scalable)：可伸缩性是分布式的目的，分布式能力是TensorFlow的构建与运维能力，分布式能力是tensorFlow的隐性基石假设；</li><li>机器学习(machine learning)：机器学习是Tensorflow的领域功能，是tensorFlow的显性基石假设。</li></ul><p>从这个公理化的定义以及两个基石假设里可以推导出设计tensorFlow的作者们的对tensorFlow的几条类似定理性质的设计理念：</p><ul><li><p>机器学习(machine learning): 指的是功能领域定位，依据这个设计定位，因此tensorFlow提供的是机器学习相关的功能，其涵盖数据、模型、策略、训练、推理等核心功能。</p></li><li><p>分布式：分布式能力是tensorFlow的构建与运维能力，从抽象的技术实现视角来看tensorFlow就是分布式框架+机器学习的lib库；</p></li><li><p>端到端(end-to-end): 端到端指的是“全程都包”的一种设计理念，用户输入原始数据，经过tensorFlow处理即可以直接得到可用的结果，这个结果可以直接服务于用户，用户无需关注tensorflow的中间过程如何。在tensorFlow里端到端的设计理念体现在 “准备数据 、定义模型、 训练模型、 评估模型、 保存模型以及使用模型”这几个过程，用户只要输入数据即可以得到可用的结果模型。</p></li><li><p>平台(platfrom)：平台化，通常的软件平台指的是能够让用户自己在上面进行业务开发的软件系统，它将业务与技术解耦，用户可以基于这个平台开发自己的业务。其具有可用户自我定义的灵活性、用户可二次开发的开放性、以及接口标准化的特性。在tensorFlow里的平台化的设计理念体现在用户可以自由的定义自己的业务模型而无需关注里头的技术实现即可以得到想要的输出结果。</p></li><li><p>有状态（stateful）：状态是指事物处于产生、发展、消亡时期或各转化临界点时的形态，有状态是指</p><blockquote><p>“该服务的实例可以将一部分上下文的数据随时进行备份，并且在创建一个新的有状态服务时，可以通过备份恢复这些数据，以达到数据持久化的目的。”。</p></blockquote><p>有状态服务在功能上可以保证数据的恰好一次，可以保证数据服务的强正确性，但是有状态服务需要维护大量的信息和状态，因此又引入了数据存储的复杂性，并且多了数据存储加载的过程，在性能方面要弱于无状态服务。而无状态服务不能保证数据的恰好一次处理，但是易于处理实例规模的伸缩性。tensorflow是有状态的设计理念，表明了tensorFlow可以保证数据处理的恰好一次的强正确性，但是又引入了数据存储与IO性能上的复杂性，需要平衡有状态服务下的正确性与复杂性就需要针对数据存储进行专门的设计。</p></li><li><p>数据流图（dataFlow graphs）: 数据流图指的是用节点和有向边描述数学运算的有向无环图，其要素有数据源或宿、数据流、数据处理节点以及数据存储，其中节点代表数学运算等，而有向边代表节点之间的输入与输出关系、数据在边上流动。依据这个设计理念，TensorFlow依据下图的工作过程计算数据：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/tensorflow/tf_arch_dataflow.gif" alt="计算流图示例"></p><p>在这个数据流图里，tensorFlow里需要事先准备数据，接着定义运算操作，然后计算单元被同步或者异步地分配到不同的计算设备上比如CPU、GPU、TPU进行计算，其在边上流动的数据叫tensors。</p></li><li><p>编程（programming）：可编程性，“编程就是指导计算机执行任务的行为”，编程是个动词，是为了让计算机干你想要干的事情。在面向对象编程里，程序=算法+数据结构+方法，依据这个设计理念，即用户可以依据一定的数据结构通过输入算法以及相应的工程方法，就可以指导tensorFlow执行用户想干的事情，其可以二次开发，具有灵活性以及开放性的特征。</p></li><li><p>生态系统（ecosystem）：生态化，指的是tensorFlow的产品商业模式理念，围绕tensorFlow为核心建立一个完整的工具、库以及社区资源生态系统。</p></li></ul><p>通过以上的分析，可以得出tensorFlow的第一性原理，即：tensorFlow是一个端到端的面向有状态的数据流图编程的机器学习平台，自带完整的产品生态系统，其逻辑基石为“分布式及机器学习”。就是这么简单的一句话，但是却是tensorFlow作者们的设计理念，整个tensorFlow的所有设计理念、设计原则以及功能实现都是依据这一句话来做指导的。</p><h2 id="TensorFlow的设计原则"><a href="#TensorFlow的设计原则" class="headerlink" title="TensorFlow的设计原则"></a><font color="#FF8C00">TensorFlow的设计原则</font></h2><p>从tensorflow的官网可以看到几个关键词“easy,robust,powerful,ecosystem”，这几个词即是temsorflow的设计原则，tensorFlow的设计原则是定理性质的定义，其也从tensorFlow的第一性原理定义中推导出来。“端到端”代表了易用性，“平台化”、“可编程”代表了功能强大，“分布式”代表可高可用性、高可靠性，另外tensorFlow还有一个生态化的运营理念，灵活、开放、完整。</p><p><strong>易用</strong>（Easy）</p><p>易用性的设计原则体现在与用户打交道的API接口层、模型的使用以及分布式训练：</p><ul><li><p>模型制作简单，API容易调用，TensorFlow 提供多个级别的抽象接口，可以使用高阶的 Keras API 轻松地构建和训练模型</p></li><li><p>开发过程可调试，支持Eager Execution 进行快速迭代和直观的进行调试</p></li><li>训练过程简单，可以使用 Distribution Strategy API 在不同的硬件配置上进行分布式训练而无需更改模型定义</li></ul><p><strong>可靠(Robust，鲁棒性、可靠)</strong></p><ul><li>支持随时随地进行可靠的机器学习生产。支持在本地服务器、边缘设备、云端、web端轻松地训练和部署模型，而无需关注开发语言。TensorFlow Extended (TFX)可用于生产型机器学习， TensorFlow Lite可用于移动设备和边缘设备的推断， 而 TensorFlow.js 支持在web端中训练和部署模型</li></ul><p><strong>强大</strong>（powerful）</p><ul><li>架构简单而灵活，支持最先进的模型，并且可以保证性能。借助 Keras Functional API 和 Model Subclassing API 等功能，TensorFlow 可以灵活地创建复杂拓扑并实现相关控制。TensorFlow 还支持强大的附加库和模型生态系统，包括 Ragged Tensors、TensorFlow Probability、Tensor2Tensor 和 BERT。</li></ul><p><strong>生态化</strong>(ecosystem)</p><ul><li>生态化是产品的商业模型，灵活、开放、强大，tensorFlow具有完整的一个生态环境，其拥有一个包含各种工具、库和社区资源的全面灵活生态系统，可以让研究人员推动机器学习领域的先进技术的发展，并让开发者轻松地构建和部署由机器学习提供支持的应用</li></ul><p>从tensorFlow 1.0 到tensorFlow 2.0 的升级，涵盖了API的易用性升级，动态图的支持、算法的更新、功能迭代以及文档完善，其本质目的还是遵循这四个设计原则，即简单、可靠、强大、生态化。如果只是追寻tensorFlow的版本迭代而不理解其背后的设计理念、设计原则，只会疲于奔命、知其然而不知其所以然。</p><h2 id="TensorFlow-架构视图"><a href="#TensorFlow-架构视图" class="headerlink" title="TensorFlow 架构视图"></a><font color="#FF8C00">TensorFlow 架构视图</font></h2><h4 id="逻辑架构视图"><a href="#逻辑架构视图" class="headerlink" title="逻辑架构视图"></a>逻辑架构视图</h4><p>TensorFlow的逻辑架构视图体现了tensorflow的功能需求，如下图，tensorFlow的功能可分为训练、部署、可视化以及模型仓库。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/tensorflow/tf_arch_logic_architecture.png" alt="逻辑架构图"></p><p><strong>训练</strong></p><ul><li>tf.data用于加载训练用的原始数据</li><li>tf. Keras 或 Premade Estimators 用于构建、训练和验证模型</li><li>eager execution 用于运行和调试</li><li>distribution strategy 用于进行分布式训练，支持单机多卡以及多机多卡的训练场景</li><li>SavedModel用于保存导出的训练模型，并且将训练模型标准化，作为 TensorFlowServing、TensorFlow Lite、TensorFlow.js、TensorFlow Hub 等的交换格式</li></ul><p><strong>部署</strong></p><ul><li>TensorFlow Serving，即TensorFlow允许模型通过REST以及gPRC对外提供服务</li><li>TensorFlow Lite，即TensorFlow针对移动和嵌入式设备提供了轻量级的解决方案</li><li>TensorFlow.js，即TensorFlow支持在 JavaScript 环境中部署模型</li><li>TensorFlow 还支持其他语言 包括 C, Java, Go, C#, Rust 等</li></ul><p><strong>可视化</strong></p><ul><li>TensorBoard 用于TensorFlow可视化</li></ul><p><strong>模型仓库</strong></p><ul><li>TensorFlow hub用于保存训练好的TensorFlow模型，供推理或重新训练使用</li></ul><h4 id="处理架构视图"><a href="#处理架构视图" class="headerlink" title="处理架构视图"></a>处理架构视图</h4><p>TensorFlow的处理架构视图表明了数据处理的流程，其具有tensorFlow的运行期间的质量需求。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/tensorflow/tf_arch_process_architecture.PNG" alt="处理架构视图"></p><p>本图是分布式工作模式，“/job：worker / task:0” 和 “/ job:ps / task:0” 都是工作节点上执行的任务。“PS” 表示 “参数服务器”，负责存储和更新模型参数。</p><p><strong>处理流程</strong></p><p>1）客户端负责将整个计算过程转义成数据流图，并且启动计算发送到分布式主节点；</p><p>2）分布式主节点基于用户传递给的参数对整个完整的图形进行修剪，提取其中的子图，接着将子图拆分成不同部分，并将其分发到不同的进程和设备当中；</p><p>3）工作节点执行其收到的主节点分发给它的数据图片段，并且与其他工作节点 相互发送和接收计算结果；</p><p>4）内核计算单元，执行单个图形操作的计算部分。</p><p><strong>数据处理期的质量与约束</strong></p><p>TensorFlow分布式模式是构建在分布式之上的，其具有分布式系统自身的质量与约束需求：</p><ul><li><p>TensorFlow的质量需求：性能指标：TPS、QPS、IOPS、Latency、ResponseTime、缓存抖动指标、缓存命中指标，可靠性指标: 6个9企业级代表，可用性指标：6个9企业级达标，数据一致性指标，可伸缩性，韧性，可观测性，可服务性，安全性，易用性，可运维性等</p></li><li><p>TensorFlow的约束需求：其可以是资源容量约束：CPU、磁盘、网络、线程、文件描述符个数，也可以是客户的约束、用户的约束等。</p></li></ul><h2 id="TensorFlow-2-0-的缺点"><a href="#TensorFlow-2-0-的缺点" class="headerlink" title="TensorFlow 2.0 的缺点"></a><font color="#FF8C00">TensorFlow 2.0 的缺点</font></h2><ul><li><p><strong>网络</strong>，开源的TensorFlow默认采用gRPC作为基础通信组件，违背<strong>“最佳物种”</strong>里的最佳原则设计哲学，机器学习本身是高吞吐量高性能要求的生产场景，而gRPC是基于HTTP2/Protobuf  协议通信的，而且发送接收都需要序列化，增加了网络传输的延时，并不是机器学习场景的最佳选择，但是好在TensorFlow也支持让你“DIY”的设计理念，例如在网络通信上支持GDP（GPU DIRECT）VERBS(IB,RDMA)以及MPI的扩展（“<a href="https://github.com/tensorflow/networking" target="_blank" rel="noopener">https://github.com/tensorflow/networking</a>: Currently support building GDR, VERBS, and MPI extensions），这相当于把这一部分产品化的工作给了用户或者GPU、TPU之类的芯片原厂。优化手段：将PS算法、RING ALLREDUCE算法融合进MPI，再根据工程实践情况取舍“容错、可服务化、可运维化、智能化“的设计理念，抽象出一个新的分布式调度中间件以替换gRPC，目的是获取更好的性能、更高的GPU、TPU性价比。</p></li><li><p><strong>计算</strong>，计算架构很有限还不能榨尽各种硬件的最佳性能。目前的分布式计算视图架构成熟的方案有：Parameter Server 架构以及Ring AllReduce架构，那么是否还有其它更好的架构，比如区块链的去中心化架构。</p></li><li><p><strong>存储</strong>，存储应用容易被忽视，系统太过于复杂。TesnorFlow里涉及到存储的地方有：海量或非海量的原始数据存储、ETL好的数据的存储、PS架构中的训练参数以及模型的存储，训练好的模型的存储，如果这四个存储需求都是分散的存储系统，其实复杂度挺高，可以专门针对这种场景以及数据特性设计一个专门的机器学习存储系统，除了可以同时满足这四个场景的质量指标外，还将四个系统统一成一个，减少机器学习场景下的系统复杂度。</p></li><li><p><strong>功能</strong>，功能的优化是无止境的，原则是要遵循客户需求适可而止。TensorFlow本质上也是<strong>分布式系统+机器学习领域的能力</strong>，除了机器学习的各种算法魔法的持续优化，分布式系统里的各种分布式算法也是适合迁移过来挖掘的，比如服务治理、路由负载均衡算法、集群视图变更、消息传输等。比如这么一个工程课题：“如何支持上万张训练卡的规模以及如何保证其质量可以达标？如何保证系统性能可以随着训练的卡数线性增长并且保证卡子的利用率在90%以上，同时可以保证训练过程的可靠性？”</p></li><li><p><strong>产品</strong>，一个开源项目的功能特性大多是取舍的结果，就算是缺点往往也会很快演化迭代掉，因此从技术角度看待一个开源项目缺乏可持续性。但是从产品的角度来看，开源项目自带开源的先天弊端，其缺乏“价值与市场的锲合“度，这是开源项目的先天缺点，越成功的开源项目越无法避免，如果避免了这个缺点，开源项目反而是失败的，因为做的太好反而无法收费，团队没法存活，TensorFlow2.0开源版是一个开源的项目因此也逃脱不了这个缺点。从“项目与社区锲合”以及“产品与市场锲合”的角度来看，依据点赞数、fork数、下载量、用户使用量、社区文章阅读量这几个指标做度量，TensorFlow 2.0 开源版是一个非常成功开源的软件，但是从”价值与市场锲合“这个角度看，其离商业产品还是有一段距离。</p><p>开源项目往往是靠一些增值功能、企业级特性以及服务的支持收费而存活，这些特性即为价值与市场的锲合点，是商业客户愿意买单的地方，是商业产品与开源项目差异化所在，这些特性有：更好的性能、更加易用的部署与升级功能，可运维化、更加易用的可视化功能、安全、可观测、质量的可度量性，此外客户往往需要的不只是一个产品，更进一步需要的是行业解决方案。例如，tensorFlow企业版就说明了支持企业级特性、可云端伸缩性能以及无缝管理的支持，而TensorFlow2.0 开源版只是一个开源项目，还没达到这个层度。</p><p>因此，从产品的角度看，开源的tensorFlow2.0开源版只能算是一个成功的开源项目还不是商业产品以及解决方案，它只完成了“项目与社区锲合”以及“产品与市场锲合”这两个层次，因此商业化就要求我们需要把开源的tensorFlow2.0产品化、解决方案化。</p></li></ul><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font color="#FF8C00">小结</font></h2><p>本文依据第一性原理架构设计思维模型解读了TensorFlow2.0。第一性原理思维模型我不是首创，分布式系统架构设计我不是首创，第一性原理思维模型在分布式系统架构设计中的应用我是首创。日拱一卒，功不唐捐，分享是最好的学习，与其跟随不如创新，希望这个知识点对大家有用。另作者能力与认知都有限，”我讲的，可能都是错的“，欢迎大家拍砖留念。</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中科大硕，DELL EMC 资深首席工程师，曾就职于Marvell、AMD，主要从事Linux内核以及分布式产品的交付、架构设计以及开发工作。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a><font color="#FF8C00">参考资料</font></h2><p>[1] <a href="https://blog.tensorflow.org/2019/09/tensorflow-20-is-now-available.html" target="_blank" rel="noopener">https://blog.tensorflow.org/2019/09/tensorflow-20-is-now-available.html</a></p><p>[2] <a href="https://github.com/tensorflow/tensorflow" target="_blank" rel="noopener">https://github.com/tensorflow/tensorflow</a></p><p>[3] <a href="https://en.wikipedia.org/wiki/TensorFlow" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/TensorFlow</a></p><p>[4] <a href="https://www.tensorflow.org/about" target="_blank" rel="noopener">https://www.tensorflow.org/about</a></p><p>[5] <a href="https://tensorflow.google.cn/guide/?hl=zh-CN" target="_blank" rel="noopener">https://tensorflow.google.cn/guide/?hl=zh-CN</a></p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>分布式系统架构设计 – 第15式 - 架构思维</title>
      <link href="/2020/02/16/distributed-ideamodel-architecture/"/>
      <url>/2020/02/16/distributed-ideamodel-architecture/</url>
      
        <content type="html"><![CDATA[<h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a><font color="#FF8C00">动机</font></h2><p>万事万物逃脱不出<strong>“不易、简易、变易”</strong>这三个层次，演绎法认为“道生一、一生二、二生三、三生万物”，而归纳法也可以认为“万物合三，三合二、二合一、一合道”。本文的目的之一是通过归纳法找出分布式系统架构设计最为本质的“道”，使之可以用于解读各式各样的分布式系统架构设计。</p><p>从应用领域来看分布式系统可以分为三大类：分布式计算、分布式存储以及分布式调度，本文做的是从这三大领域的”变易”中找出“不易、简易”，“以”不变“应”万变“，从而抽象出一种分布式架构思维使之可以应用于这三大领域的架构设计。</p><h2 id="架构思维模型"><a href="#架构思维模型" class="headerlink" title="架构思维模型"></a><font color="#FF8C00">架构思维模型</font></h2><p>在面向对象编程有四个最高的思想，即“抽象、封装、继承与多态”，将这个思想迁移应用到本文，可以解读为架构思维是第8式“火箭技术思维模型”的以及第0式”设计总决“的继承，这里我把它定义为“分布式系统火箭架构思维模型”，如下图：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/ideamodel/idea-model-architecture-1.PNG" alt="架构思维模型"></p><h4 id="火箭架构思维模型"><a href="#火箭架构思维模型" class="headerlink" title=" 火箭架构思维模型"></a><font color="#00CED1"> 火箭架构思维模型</font></h4><p>这个架构思维模型用图形是一个内部分层的三角形，类比为一个5级火箭体，它包括“势 道 法 术 器 界”这六个要素，其下一级为上一级的提供动力的同时又受三条边的约束。</p><p>狭义上的分布式系统架构通常指的是架构的技能，其属于“术”的范畴，而广义的分布式系统架构则是市场趋势、架构理念、架构方法论、架构技能、架构用的工具以及架构的边界这几个方面的组合体，应用抽象思维，即“势、道、法、术、器、界”这六个字 ，简称架构思维六元组。</p><h4 id="势：时势，是架构的方向"><a href="#势：时势，是架构的方向" class="headerlink" title=" 势：时势，是架构的方向"></a><font color="#00CED1"> 势：时势，是架构的方向</font></h4><p>“势”是架构的方向。从宏观处着眼，“势”是产品架构设计的市场趋势、是客户需求趋势也是技术的应用趋势；从微观处着手，“势”是功能设计的价值与目的。架构设计需要从宏观处着眼微观处着手，看清客户的需求趋势、市场趋势以及技术趋势，功能设计需要分析清楚当前功能的价值与目的。除了明白架构的是什麽的问题，还需要明白为什麽需要做这个架构设计，这就需要从“势”处定义问题、分析问题、过滤问题以及解决问题。</p><p>团队一起讨论架构选型与功能设计的问题，经常会遇到A说A有理，B说B有理，最终方案无法达成一致致使项目拖延甚至失败的情形。这就需要梳理清楚架构的目的、原则、质量与边界，对方案进行方向上的约束，那么“势”就是架构选型与功能设计的约束条件之一，其用于定义架构的目的。</p><h4 id="道：理念，是架构的认知"><a href="#道：理念，是架构的认知" class="headerlink" title=" 道：理念，是架构的认知"></a><font color="#00CED1"> 道：理念，是架构的认知</font></h4><p>“道”是架构的认知，是架构师的设计理念、设计意图，是产品架构的灵魂。美国学者布卢姆认为认知有六层次：识记、理解、应用、分析、评价、创造。产品架构是由人设计的，那么不可避免的就会带有人的因素在里头，”见其所欲“，你所看到的架构都是架构师欲让你看到的，对分布式系统认知层次不同的人，理念也是不同的，欲深入理解一个产品的架构必须要能找到设计它的人的设计”理念“。</p><p>进行分布式系统的架构设计，首先我们要知道分布式系统的第一性原理是什么？即分布式系统的类似公理性质的定义，Google 出来的对分布式系统的定义有：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs undefined">A distributed system is a system whose components are located on different networked computers, which communicate and coordinate their actions by passing messages to one another. The components interact with one another in order to achieve a common goal.<br>分布式系统是一个组件分布在不同的联网的计算机上，彼此之间仅仅通过消息传递进行通信和协调的系统，这些组件相互交互以实现一个共同的目标。<br></code></pre></td></tr></table></figure><p>这句话就是分布式系统的第一性原理，是分布式系统的类公理性质的理论定义，其非常重要，默认不变的公理性定义，解读开来就是：“分布式系统是由建立在网络上的通过消息进行通信和协调的系统，各个机器相互交互一起完成一个共同的目标。”，从这句话里可以推理出分布式系统的几个类似定理性质的特征定义：</p><ul><li><p>分布式系统是基于网络的，网络所具有的毛病它都有，网络会丢包、网络有带宽限制、网络有安全隐患、网络有负载均衡问题等，那么这些问题在分布式系统里需要怎么解决？那么如何提高服务的可靠性？如何保证服务的可用性？</p></li><li><p>分布式系统是基于消息传递的，那么如何保证消息的幂等性？如何保证消息的正确性？如何保证消息传递的性能？如何保证消息传递的可靠性？</p></li><li>分布式系统是协调工作的，那么如何协调大量的计算机节点的完成一个共同的目标，如何解决协调的复杂性以及提高协调的可靠性？</li><li>分布式系统是一起相互交互完成一个共同的目标的，那么如何一起交互？如何拆分目标？如何聚合目标，如何提高完成目标的性能？</li><li>分布式系统是分布式的，其具有分布性的特点，那么如何保证分布式所要求的负载均衡、可伸缩性、韧性等功能与质量需求？</li></ul><p>依据分布式系统的第一性原理，本文解读了分布式系统的理论认知，除此之外还可以依据个人对分布式系统的工程经验推理出分布式系统的实践认知，依据工程实践经验，这里我定于分布式系统为：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs undefined">分布式系统是面向集群状态的编程, 它是抽象、分层、解耦、拆分、聚合、治理、取舍、模型、质量、边界、演化思维的创造性应用，其要交付的是功能价值，但功夫却体现在非功能。<br></code></pre></td></tr></table></figure><p>不同于教科书以及一些论文对分布式系统的理论定义，这个定义来源于个人工程经验，是认知的创造。分布式系统的功能、质量与约束都来自于这两个理论定义与工程定义。</p><h4 id="法：方法论，是架构的套路"><a href="#法：方法论，是架构的套路" class="headerlink" title=" 法：方法论，是架构的套路"></a><font color="#00CED1"> 法：方法论，是架构的套路</font></h4><p>”法“是方法论，是架构设计的方法论，是架构设计的套路，它是认知论的上一级，方法论体现在产品的设计原则、设计心法以及设计功能。从工程经验的角度，本文认为分布式系统设计可以依从以下的”9法10项2原则“ 作为方法论。</p><h5 id="9法"><a href="#9法" class="headerlink" title="9法"></a><strong>9法</strong></h5><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs undefined">少读少写少依赖，业务拆业务合，功能拆性能聚，时空换同异换<br><br>硬件顺天性，服务需治理，数据保一致，哪都不可靠，事事慎权衡<br></code></pre></td></tr></table></figure><ul><li>少读少写少依赖: 少读，即减少读放大，减少需要读的数据量；少写，即减少写放大，减少需要写的数据量；少读少写的策略可以是提高cache命中率也可以是进行数据压缩，还可以是合适的读写算法与数据结构等，少依赖，即解耦，拆分，高内聚低耦合</li><li><p>业务拆业务合：分布式系统里要有拆有合，拆的目的是为了解耦、是为了集群业务可伸缩，是为了组件上的小可以支持集群规模上的大；合的目的是为了内聚，聚合拆分的服务返回的子结果，从而返回大结果；“业务拆业务合”，其理论依据来源于“康威定律”，即： 设计系统的组织其产生的设计等价于组织间的沟通结构，软件架构的拆合关系来源与团队的组织结构。</p></li><li><p>功能拆性能聚：在分布式系统里有拆有合，那么拆与合的取舍依据在哪里？这句话讲的就是拆与合的取舍关系：依据功能进行拆分，但是也要依据性能进行聚合，拆开后会影响性能的地方最好不拆</p></li><li><p>时空换同异换： 时空换同异换讲的是性能优化的路数，解读开来说即是：时间换空间、空间换时间、同步换异步、异步换同步。例如：采用cache的功能可以减少计算的时间，这是存储空间换时间从而提升性能；采用批处理的方式提升性能，这是减少计算时间；采用异步换同步的方式提升性能也是减少计算时间；减少IO的数据量从而提升性能，这是存储空间换时间；减少IO路径提升性能，这也是网络空间换时间；采用最新的硬件提升性能，这可以是计算换时间，也可以是存储或网络空间换时间</p></li><li><p>硬件顺天性：硬件顺天性讲的是软件设计要遵循硬件的原生特性，CPU的分核调度、机械盘性能不如固态硬盘、磁盘分块需要对齐、磁盘是有可能会电子位飘逸丢数据的、内存性能好适合做缓存但是下电就丢数据、网络是不可靠的并且有带宽限制、RDMA网络比IP网络性能好，机器学习采用GPU比CPU更能获得高计算性能；不同的应用场景要依据硬件的不同特性做架构选型以及架构设计等。</p></li><li>服务需治理：指的是分布式系统是由各种不同的组件进行组合连接而成，其需要服务治理设计，服务需治理背后的原因来源于分布式系统式搭建在网络上的，其继承了网络的毛病，背后的指导思想是“墨菲定律”，即“会出错的事总会出错”，服务治理的具体解决方案可分为容错、降级、限流、熔断、隔板这五个模式</li><li>数据保一致：要保证分布式系统对外提供的服务的数据的一致性，cache掉电会丢数据、网络不可靠会丢数据、磁盘电子不可靠会丢数据，计算丢请求会丢数据，各种场景下都需要保证数据的一致性，比如缓存的MESI算法保数据、掉电刷内存保数据、网络端到端的校验、磁盘扫描校验、数据副本保数据等</li><li>哪都不可靠：指的是磁盘不可靠、网络不可靠、计算不可靠、运维的人不可靠，何种场景都需要进行系统的韧性设计</li><li>事事慎权衡：指的是架构设计本身的设计方法论，即trade-off</li></ul><h5 id="10项"><a href="#10项" class="headerlink" title="10项"></a><strong>10项</strong></h5><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs undefined">提供 注册 配置 调用 路由<br>观测 治理 编排 质量 边界<br></code></pre></td></tr></table></figure><ul><li>提供：即服务接入的提供，指的是对外提供restful 接口服务：权限、多组合、监控、审计、计费等，对外提供SQL服务接入接口服务、对外提供自然语言接入接口服务等</li><li>注册：即服务注册，将集群的工作负载注册到集群注册中心</li><li>配置：即配置管理，将集群的配置管理在配置中心；</li><li>调用，即服务调用，各种RPC调用，系统内的消息传递</li><li>路由：即服务路由，目的是集群的负载均衡与扩伸缩性</li><li>观测：指的是集群内部指标的可观测性，即监控、告警、追踪、日志</li><li>治理：指的是集群内部的服务治理：熔断、降级、限流、隔离、容错</li><li>编排：即服务编排，基于k8s+ docker，完成安装、升级、扩容、运维、调度等；</li><li>质量：指的是安装部署运维质量、客户质量、用户质量与开发质量</li><li>边界：指的是系统内的约束条件，涵盖 硬件资源、客户约束、用户约束以及团队约束</li></ul><h5 id="2原则："><a href="#2原则：" class="headerlink" title="2原则："></a><strong>2原则：</strong></h5><ul><li>最佳物种原则</li><li>功能非功能原则</li></ul><h5 id="最佳物种原则"><a href="#最佳物种原则" class="headerlink" title="最佳物种原则"></a><strong>最佳物种原则</strong></h5><p>最佳物种原则其来源是生物的物种进化理论，讲的是产品原则，其可以一分为二：</p><p>1，最佳原则，做产品架构设计的时候要挖掘不同的业务特性以及其业务本质，从而设计出与业务最为匹配的架构。天上飞的是鸟儿，地上奔跑的是走兽，水里游的是鱼儿。架构设计由大及小，由外及内也是如此。比如计算用的是分布式计算、存储用的是分布式存储，调度用的是分布式调度，其负责的领域各不相同，不存在一个全能的分布式中间件可以最佳的完成计算、存储、调度三合一的功能。从小处来讲也是如此，比如分布式系统内部的注册、路由、成员管理、服务提供、复制、安全、算法模型、存储等各有其自己最佳的设计方案，再依据这些最佳组件、最佳方案组合出一个最佳分布式中间件。</p><p>2，进化原则，万物由微而显，由简而繁，物竞天择，优胜劣汰，好的架构是根据业务演化而来，而不是一开始就完美的设计好的。但是不管是微还是显，其最本质的功能还是不变的，一个产品从POC到MVP再到企业级达标其最核心的功能是不变的，比如计算、存储与调度。</p><h5 id="功能非功能原则"><a href="#功能非功能原则" class="headerlink" title="功能非功能原则"></a><strong>功能非功能原则</strong></h5><p>功能非功能原则，讲的是技术原则，从大体上来说，分布式系统的架构设计都是围绕其功能与非功能的量化设计来进行的，非功能又可以一分为二，即：质量与约束，比如：</p><p>客户对产品质量的需求一般可以用四个字概括，即”多、快、好、省“，然而客户在产品交付的时间、质量与成本上的取舍，客户原来遗留的系统，当前国家的法律法规，市场上的技术趋势以及竞争对手与行业标准等都属于当前客户需要考虑的约束条件。</p><p>用户的产品质量需求一般称为使用质量需求，其一般包括：性能、可用性、可靠性、可伸缩性、韧性、可观测性、可服务性、安全性、易用性、可运维性等，而用户的约束需求包括 用户的业务环境、用户的能力以及用户群的特征等。</p><p>团队的质量需求指的是产品开发周期内的质量需求，高质量的代码几个最重要的要素有：可测试性、可维护性、可扩展性、可读性等，而团队的约束需求有：资源预算、上级要求、开发团队的能力、产品规划、此外还有信息安全以及产品运行环境 的约束等。</p><h4 id="术：技能，是架构技能"><a href="#术：技能，是架构技能" class="headerlink" title=" 术：技能，是架构技能"></a><font color="#00CED1"> 术：技能，是架构技能</font></h4><p>术，技能，是架构技能，其可以分为需求分析、设计哲学定义、设计方法论定义、设计原则定义、架构制图、基础理论理解与应用、基础数据结构理解与应用、基础算法设计、基础组件设计、质量达标设计以及边界约束设计。即：</p><ul><li><p>分布式系统的需求分析：这里可以依据需求分析公式：需求 = [客户，用户，团队] x [功能，质量，约束]，进行全面的架构需求分析。</p></li><li><p>分布式系统的设计思想：抽象、 分层、 解耦、  拆分 、聚合、治理、取舍、模型、质量、边界、演化</p></li><li><p>分布式系统的设计原则：最佳物种原则，功能非功能原则</p></li><li><p>分布式系统的架构视图：我们在学习画法几何或机械制图的时候，要描述一个物体可以采用视图法来表示，比如机械制图里要制造一个零件的时候，需要依据这个零件画出可以根据这个图形加工的视图，其通常采用正视图、俯视图、侧视图，加上额外的细节视图与质量指标、材料约束的方法。同样我们做软件架构设计的时候，也需要将具体的”软件体“抽象成视图来表示，同时也需要标记上质量与边界约束。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/ideamodel/idea-model-architecture-2.PNG" alt="4+1架构模型"></p><p>如上图常用的4+1视图：物理视图、逻辑视图、处理视图、开发视图以及用例视图，其中与用例视图交叉的部分是描述共同的细节，同时每种视图中又有各自的需求，比如物理视图有安装、部署、升级、运维的需求，逻辑视图有功能需求，处理视图有非功能里的用户运行质量需求，开发视图有团队的开发质量需求。</p></li><li><p>分布式系统的基础理论：CAP/PACELC、BASE、ACID、2PC、3PC、PAXOS、RAFT</p></li><li><p>分布式系统的基础数据结构：Array、List、Map、Hash、Tree，及其变种</p></li><li><p>分布式系统的基础算法：负载均衡算法（一致性hash算法、分区分配算法）、选主算法、心跳算法、集群视图变更算法、幂等算法、复制算法、缓存MESI算法</p></li><li><p>分布式系统的基础组件：服务提供(Restful接口,SQL接口,自然语言接口)、服务注册(zookeeper,etcd,consul,etc)、服务配置(zookeeper,etcd, consul,etc)、服务调用(brpc,netty,etc)、服务路由(一致性Hash算法、分区分配算法)、服务追踪（zipkin,pinpoint,skywalking,cat,etc）、服务监控(Metrics)、服务治理(容错、降级、限流、熔断、隔板)、服务编排（k8s、docker）、服务安全(keycloak,etc)</p></li><li><p>分布式系统的质量指标：性能指标：TPS、QPS、IOPS、Latency、ResponseTime、缓存抖动指标、缓存命中指标，可靠性指标: 6个9企业级代表，可用性指标：6个9企业级达标，数据一致性指标，可伸缩性，韧性，可观测性，可服务性，安全性，易用性，可运维性，可测试性，可维护性，可扩展性，可读性等，质量指标要能可度量化，可执行化</p></li><li><p>分布式系统的约束边界：其可以是资源容量约束：CPU、磁盘、网络、线程、文件描述符个数，也可以是客户的约束、用户的约束以及团队的约束</p></li></ul><h4 id="器：工具，架构设计用的工具"><a href="#器：工具，架构设计用的工具" class="headerlink" title=" 器：工具，架构设计用的工具"></a><font color="#00CED1"> 器：工具，架构设计用的工具</font></h4><p>”器“是工具，是架构设计用的工具，”工欲善其事必先利其器“，常用的架构设计制图工具有MS Visio、Draw.io，UML制图用的Enterprise Architect、starUML等，当然组织提供的资源支持也可以算是工具之一。</p><h4 id="界：是边界，是架构的约束"><a href="#界：是边界，是架构的约束" class="headerlink" title=" 界：是边界，是架构的约束"></a><font color="#00CED1"> 界：是边界，是架构的约束</font></h4><p>”界“是边界，是架构的约束限制，火箭架构思维模型里的三角形的三条边代表着“界” ，是技术边界、也是技术约束与技术限制，也是架构的取舍因素之一，是架构能做什麽不能做什麽的解读，对市场来说它是技术壁垒，对产品来说它是法律法规、是功能约束，对团队来说它是资源约束、是自我能力约束。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font color="#FF8C00">小结</font></h2><p>本文讲述了分布式系统的架构思维模型，其目的希望以此架构思维模型应用于各种领域的分布式架构系统设计。日拱一卒，功不唐捐，分享是最好的学习，与其跟随不如创新，希望这个知识点对大家有用。另作者能力与认知都有限，”我讲的，可能都是错的“，欢迎大家拍砖留念。</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中科大硕，DELL EMC 资深首席工程师，曾就职于Marvell、AMD，主要从事Linux内核以及分布式产品的交付、架构设计以及开发工作。</p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>分布式系统架构设计 – 第0式 - 设计总决</title>
      <link href="/2020/02/15/distributed-general-principles/"/>
      <url>/2020/02/15/distributed-general-principles/</url>
      
        <content type="html"><![CDATA[<h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a><font color="#FF8C00">动机</font></h2><p>在<strong>“不易、简易、变易”</strong>这三个范畴里，技术是属于“变易”范畴的，其千变万化；“方法论”是属于“简易”范畴的，其具有领域普适性的指导能力；而架构设计总决属于“不易”的范畴，其具有第一性原理的本质指导能力。本文的目的之一即是挖掘出分布式系统架构设计的第一性原理，使其可以应用于千变万化的不同的技术领域。</p><p>架构是由人设计出来的，其与设计的人的架构理念强相关，欲彻底了解一个产品的架构必须要能量化它的设计理念，从而才能更好的由现象到本质了解一个技术，因此本文的目的之二即是量化人的架构设计理念。</p><h2 id="分布式系统"><a href="#分布式系统" class="headerlink" title="分布式系统"></a><font color="#FF8C00">分布式系统</font></h2><p>软件设计的第一性原理是“定义问题，分析问题，过滤问题以及解决问题。”，其最重要的第一步是“定义问题”，问题定义的准确与否直接决定了后面的分析问题，过滤问题以及解决问题的方向与准确性。那么，什么是分布式系统？各种论文以及书籍都有过自己的定义，比如《分布式系统原理与范型》定义分布式系统为：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs undefined">分布式系统是若干独立计算机的集合，这计算机对用户来说就像单个相关系统。<br></code></pre></td></tr></table></figure><p>还有Google出来的定义：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs undefined">A distributed system is a system whose components are located on different networked computers, which communicate and coordinate their actions by passing messages to one another. The components interact with one another in order to achieve a common goal.<br>分布式系统是一个组件分布在不同的联网的计算机上，彼此之间仅仅通过消息传递进行通信和协调的系统，这些组件相互交互以实现一个共同的目标。<br></code></pre></td></tr></table></figure><p>这是分布式系统理论的第一性原理，不同于这些从理论角度的定义，这里，我从工程实现的角度给分布式系统一个新的定义，即：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs undefined">分布式系统是面向集群状态的编程, 它是抽象、分层、解耦、拆分、聚合、治理、取舍、模型、演化、质量、边界思维的创造性应用，其要交付的是功能价值，但功夫却体现在非功能。<br></code></pre></td></tr></table></figure><p>从工程的角度来看，这个定义是分布式系统实践的第一性原理，分布式系统都是围绕着集群状态表来进行编程的，集群状态表是分布式系统的核心功能中的核心。因此本系列分布式系统文章都是依据理论结合实践的原则，从工程交付的角度来看待分布式系统的。</p><h2 id="设计哲学"><a href="#设计哲学" class="headerlink" title="设计哲学"></a><font color="#FF8C00">设计哲学</font></h2><p>什么是分布式系统的设计哲学？首先这里的设计哲学不是产品的设计哲学，它是一种工程哲学，是分布式系统架构设计原则以及设计方法论的指导思想，是架构师的内功。其目的是为了指导架构设计的过程，克服架构设计难题从而达到最终的架构设计目标。不同的架构师有自己不同的设计哲学观，这里我提出分布式系统架构设计哲学9式，即：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs undefined">抽象 分层  解耦 拆分 聚合 治理 模型 取舍 质量、边界 演化<br></code></pre></td></tr></table></figure><p>这9个词每个词展开来讲都可以是一篇大论，不同的架构设计师有自己不同的设计哲学观，也就形成了不同的架构设计原则以及设计方法论，并不存在一个普适的、统一的架构设计哲学，适合自己的才是最好的，每个人的领悟不同，因此这里也就不展开来讲。</p><h2 id="设计原则"><a href="#设计原则" class="headerlink" title="设计原则"></a><font color="#FF8C00">设计原则</font></h2><p>同设计哲学一样，不同的架构设计师有着自己不同的设计原则观，在这里，我认为最合适的分布式系统的架构设计原则有二，即：</p><ul><li><strong>最佳物种原则</strong></li><li><strong>功能非功能原则</strong></li></ul><h4 id="最佳物种原则"><a href="#最佳物种原则" class="headerlink" title=" 最佳物种原则"></a><font color="#00CED1"> 最佳物种原则</font></h4><p>最佳物种原则其来源是生物的物种进化理论，讲的是产品原则，其可以一分为二：</p><p>1，最佳原则，做产品架构设计的时候要挖掘不同的业务特性以及其业务本质，从而设计出与业务最为匹配的架构。天上飞的是鸟儿，地上奔跑的是走兽，水里游的是鱼儿。架构设计由大及小，由外及内也是如此。比如计算用的是分布式计算、存储用的是分布式存储，调度用的是分布式调度，其负责的领域各不相同，不存在一个全能的分布式中间件可以最佳的完成计算、存储、调度三合一的功能。从小处来讲也是如此，比如分布式系统内部的注册、路由、成员管理、服务提供、复制、安全、算法模型、存储等各有其自己最佳的设计方案，再依据这些最佳组件、最佳方案组合出一个最佳分布式中间件，从而计算的归计算、存储的归存储、调度的归调度。</p><p>2，进化原则，万物由微而显，由简而繁，物竞天择，优胜劣汰，好的架构是根据业务演化而来，而不是一开始就完美的设计好的。但是不管是微还是显，其最本质的功能还是不变的，一个产品从POC到MVP再到企业级达标其最核心的功能是不变的，比如计算、存储与调度。</p><h4 id="功能非功能原则"><a href="#功能非功能原则" class="headerlink" title=" 功能非功能原则"></a><font color="#00CED1"> 功能非功能原则</font></h4><p>功能非功能原则，讲的是技术原则，<strong>架构的目的是提供该领域的功能，然而功夫却是体现在非功能。</strong>比如常见的几个深度学习框架在功能上都具有深度学习训练与推理的能力，但是让用户决定是否选择这个框架的主要决定性因素却体现在其非功能，比如性能、可用性、可靠性、易用性、服务支持以及版权等。</p><p>从大体上来说，分布式系统的架构设计都是围绕其功能与非功能的<strong>量化</strong>设计来进行的，非功能又可以一分为二，即：质量与约束，比如：</p><p>客户对产品质量的需求一般可以用四个字概括，即”多、快、好、省“，然而客户在产品交付的时间、质量与成本上的取舍，客户原来遗留的系统，当前国家的法律法规，市场上的技术趋势以及竞争对手与行业标准等都属于当前客户需要考虑的约束条件。</p><p>用户的产品质量需求一般称为使用质量需求，其一般包括：合适的性能（Performant）、可用性(Availability)、可靠性(Reliability)、可伸缩性(Scalability)、韧性(resilience)、可观测性(Observability)、可服务性（Serviceability）、安全性（security）、易用性（usability）、可运维性（operability）等，而用户的约束需求包括 用户的业务环境、用户的能力以及用户群的特征等。</p><p>团队的质量需求指的是产品开发周期内的质量需求，高质量的代码几个最重要的要素有：可测试性（ testability）、可维护性（Maintainability）、可扩展性（ extensibility）、可读性（ readability）等，而团队的约束需求有：资源预算、上级要求、开发团队的能力、产品规划、此外还有信息安全以及产品运行环境 的约束等。</p><h2 id="设计方法论"><a href="#设计方法论" class="headerlink" title="设计方法论"></a><font color="#FF8C00">设计方法论</font></h2><p>同设计哲学与设计原则一样，不同的架构设计师有着自己不同的设计方法论，在这里，我认为分布式系统的架构设计方法论可以总结成以下口诀，即<strong>分布式9法10功能口诀</strong>，如下：</p><h4 id="分布式9法："><a href="#分布式9法：" class="headerlink" title="分布式9法："></a>分布式9法：</h4><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs undefined">少读少写少依赖<br>业务拆业务合<br>功能拆性能聚<br>时空换同异换<br>硬件顺天性<br>服务需治理<br>数据保一致<br>哪都不可靠<br>事事慎权衡<br></code></pre></td></tr></table></figure><h4 id="分布式10项"><a href="#分布式10项" class="headerlink" title="分布式10项:"></a>分布式10项:</h4><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs undefined">提供 注册 配置 调用 路由<br>观测 治理 编排 质量 边界<br></code></pre></td></tr></table></figure><p>在分布式系统里几乎所有的功能与设计思路都可以用这个<strong>“9法10项”</strong>口诀来解读，例如：</p><p>1，“业务拆业务合”，其理论依据来源于“康威定律”，即：</p><blockquote><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs undefined">&gt; 设计系统的组织其产生的设计等价于组织间的沟通结构。<br>&gt;<br></code></pre></td></tr></table></figure></blockquote><p>软件架构的拆合关系来源于团队的组织结构。</p><p>2，“功能拆性能聚”，在分布式系统里有拆有合，那么拆与合的取舍依据在哪里？这句话讲的就是这个拆与合的取舍关系：依据功能进行拆分，但是也要依据性能进行聚合，拆开后会影响性能的地方最好不拆。</p><p>3，“时空换同异换”， 讲的是性能优化的路数，解读开来说即是：时间换空间、空间换时间、同步换异步、异步换同步。例如：采用cache的功能可以减少计算的时间，这是存储空间换时间从而提升性能；采用批处理的方式提升性能，这是减少计算时间；采用异步换同步的方式提升性能也是减少计算时间；减少IO的数据量从而提升性能，这是存储空间换时间；减少IO路径提升性能，这也是网络空间换时间；采用最新的硬件提升性能，这可以是计算换时间，也可以是存储或网络空间换时间。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font color="#FF8C00">小结</font></h2><p>本文讲述了分布式系统架构设计总决，其可分为设计哲学、设计原则以及设计方法论，从而可以依据这三个方面量化人的设计理念。日拱一卒，功不唐捐，分享是最好的学习，与其跟随不如创新，希望这个知识点对大家有用。另作者能力与认知都有限，”我讲的，可能都是错的“，欢迎大家拍砖留念。</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中科大硕，DELL EMC 资深首席工程师，曾就职于Marvell、AMD，主要从事Linux内核以及分布式产品的交付、架构设计以及开发工作。</p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>分布式系统架构设计 – 第13式 - 产品交付之双轮驱动思维模型</title>
      <link href="/2020/01/21/distributed-ideamodel-cicd-toowheel/"/>
      <url>/2020/01/21/distributed-ideamodel-cicd-toowheel/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a><font color="#FF8C00">前言</font></h2><p>日拱一卒，功不唐捐，一个知识领域里的 “道 法 术 器” 这四个境界需要从 微观、中观以及宏观 三个角度来把握。微观是实践，中观讲套路，宏观靠领悟。本系列文章我把它命名为《分布式系统架构设计36式》，讲诉分布式系统里最重要的三十六个的中观套路，而微服务的本质也是分布式，因此搞明白这三十六个最重要的知识点也就同时能搞明白微服务。</p><p><strong>“兵者，国之大事，死生之地，存亡之道，不可不察也”</strong>，这句话对企业来讲，兵即产品，国即企业，察即研究探讨，产品关系到企业的存亡，所以不可以不慎重地加以研究探讨。本文提出toB产品交付双轮驱动思维模型以探讨toB软件产品的交付方法论。</p><h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a><font color="#FF8C00">动机</font></h2><p>架构设计人员是业务与技术之间的桥梁，其既需要保证产品需求合理，也要保证产品交付的功能是对客户、用户有用、有价值的。为了能够准确的落地业务需求同时又能保证产品按时交付，架构设计人员就需要一个可以量化执行的产品业务需求与产品交付的思维模型。</p><h2 id="双轮驱动思维模型"><a href="#双轮驱动思维模型" class="headerlink" title="双轮驱动思维模型"></a><font color="#FF8C00">双轮驱动思维模型</font></h2><p>受 《持续交付2.0》的启发这里提出toB产品交付之双轮驱动思维模型。双轮驱动思维模型以业务需求为出发点，探索业务真实有用的价值，以最节约的成本和最可控的风险，通过持续的业务价值探索和产品迭代交付快速交付价值与市场锲合的产品，其思维模型如下图所示：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/ideamodel/idea-model-cicd-twoWheel.PNG" alt="双轮驱动模型"></p><h4 id="总则"><a href="#总则" class="headerlink" title="总则"></a><font color="#00CED1">总则</font></h4><p>产品的交付的是价值，因此双轮驱动思维模型是一个产品价值交付模型，总的理念是以“真北业务价值”为导向，以“产品快速交付”为动力，将“业务价值”与“产品交付”双个环节紧密结合，前轮业务价值把握方向，后轮产品交付提供动力，从而驱动业务与产品一起前进。它以“产品价值与市场锲合”为指导思想，以“以客户为中心”为工作理念，以“指北需求”，“精简过滤”、“量化分解”、“快速反馈”和“演化迭代”为工作原则，是一套持续集成持续交付产品的思维模型。</p><ul><li><p><strong>产品价值与市场锲合</strong>，指的是客户需要什么以及你能提供什么的从而获得产品商业成功的问题。朴素的说法就是产品的价值是市场需要的，是客户的痛点、恐惧点、难点以及挑战点，是客户要什么你就给什么，而不是从自己的角度出发，自我感觉良好地强塞给客户什么，是自身提供的产品能否准确满足市场真实需求的问题，度量的指标是<strong>”客户是否愿意快速的为你的产品买单“</strong>。</p></li><li><p><strong>以客户为中心</strong>，指的是“以客户需求为导向、为客户提供高质量低价格的产品、为客户提供满意的服务以及快速响应客户需求”，以客户为中心不是没有底线的跪添客户或者一些违法的行为，而是走正道为客户提供优质低价的产品或服务，快速响应客户的需求，帮助客户取得商业上的成功的问题。</p></li><li><p><strong>“指北需求”，“精简过滤”、“量化分解”、“快速反馈”和“演化迭代”</strong>，指的是挖掘客户的真需求，需要对客户的需求精简过滤、去伪存真，再通过量化分解客户的需求为可落地执行的行为，这样才能快速交付产品、快速验证、迭代演进。</p></li></ul><h4 id="价值轮"><a href="#价值轮" class="headerlink" title=" 价值轮 "></a><font color="#00CED1"> 价值轮 </font></h4><p>价值轮是一个理解真北需求、去伪存真的过程，具体包括以下四个环节：</p><ul><li><p>需求：通过”客户、用户、团队“三个维度收集需求，将收集到的业务需求信息输入到价值轮；</p></li><li><p>确定：针对输入的需求去伪存真、去粗存精确定真北需求，识别客户的痛点、难点、恐惧点以及挑战点；</p></li><li><p>探讨：团队讨论，深入理解需求，拿出可行的解决方案以及实现方案；</p></li><li><p>精炼：为了节约团队资源，不是所有的方案都需要传递给产品交付环去执行，因此需要精炼过滤这些方案，有些通过常识就可以判断不合理的方案就不需要往交付轮传递，其次要进行价值优先级评估，筛选出最有价值的需求与方案，以作为交付轮的输入，并等待交付轮的交付与反馈。</p></li></ul><h4 id="交付轮"><a href="#交付轮" class="headerlink" title="交付轮"></a><font color="#00CED1">交付轮</font></h4><p>产品或服务在被客户买单之前都是成本，只有被客户采购并且最终能够买单或者被用户使用并且最终兑现，才能证明其价值的存在。因此在价值轮达成共识后要借助“交付轮”快速交付，才能将其传递到客户或用户手中，从而得到真实且可靠的反馈以验证之。</p><p>交付轮它也包含四个环节，分别是（1）开发；（2）测试；（3）运维；（4）反馈：</p><ul><li><p>开发：指以及价值轮的输入需求以及精简过的方案，依据质量要求进行软件架构设计以及进行软件开发并且达到可运行要求；</p></li><li><p>测试：指的是测试以及验证设计开发阶段交付的软件是否达到功能、质量与约束的要求；</p></li><li><p>运维：指的是将开发以及测试好的软件包部署到生产环境中运行或交付给客户为客户提供生产服务；</p></li><li><p>反馈：指的是监测生产运行情况以及收集用户使用情况与反馈的信息，再将收集到的信息反馈给价值轮，作为业务参考以便做出下一步的业务决策与判断。</p></li></ul><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font color="#FF8C00">小结</font></h2><p>本文讲述”toB产品交付双轮驱动思维模型“，日拱一卒，功不唐捐，分享是最好的学习，与其跟随不如创新，希望这几个思维模型对大家有用。另作者能力与认知都有限，”我讲的，可能都是错的“[1]，欢迎大家拍砖留念。</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中科大硕，DELL EMC 资深首席工程师，主要从事分布式产品的交付、架构设计以及开发工作。</p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a><font color="#FF8C00">参考资料</font></h2><p>[1]《持续交付2.0 - 业务引领的DevOps精要》 乔梁著</p>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>分布式计算中间件 - 信息分析基础</title>
      <link href="/2019/12/21/distributed-product-info-analysis-basic-knowledge/"/>
      <url>/2019/12/21/distributed-product-info-analysis-basic-knowledge/</url>
      
        <content type="html"><![CDATA[<h3 id="分布式计算中间件之信息分析基础"><a href="#分布式计算中间件之信息分析基础" class="headerlink" title="分布式计算中间件之信息分析基础"></a><font color="#FF8C00">分布式计算中间件之信息分析基础</font></h3><h4 id="构建与领域设计"><a href="#构建与领域设计" class="headerlink" title="构建与领域设计"></a><font color="#00CED1">构建与领域设计</font></h4><p>通常分布式计算中间件可以从两个层面进行划分：</p><p>1，构建与运维 ： 分布式功能的设计与实现</p><p>2，领域设计 ： 具体领域相关功能的设计与实现</p><ul><li>数据计算与分析中间件，实现数据计算与分析领域功能，比如 Flink, Spark, elasticsearch等</li><li>深度学习计算中间件， 实现深度学习领域功能，比如 tensorflow, caffe等；</li></ul><h4 id="信息分析基础"><a href="#信息分析基础" class="headerlink" title="信息分析基础"></a><font color="#00CED1">信息分析基础</font></h4><p>信息分析基础：下图从功能，质量、模型、定义、本质、视角、职责、相关性、难题以及Lucene 等方面归纳了检索与分析技术领域基础10项。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/analysis/distributed-infomation-analysis-basic-knowledge.PNG" alt="信息检索模型"></p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中科大硕，DELL EMC 资深首席工程师，主要从事分布式产品的交付、架构设计以及开发工作。</p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a><font color="#FF8C00">参考资料</font></h2><p>[1]《信息检索导论》 </p>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>分布式系统架构设计 – 第12式- 需求分析思维模型</title>
      <link href="/2019/12/21/distributed-ideamodel-requirement/"/>
      <url>/2019/12/21/distributed-ideamodel-requirement/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a><font color="#FF8C00">前言</font></h2><p>日拱一卒，功不唐捐，一个知识领域里的 “道 法 术 器” 这四个境界需要从 微观、中观以及宏观 三个角度来把握。微观是实践，中观讲套路，宏观靠领悟。本系列文章我把它命名为《分布式系统架构设计36式》，讲诉分布式系统里最重要的三十六个的中观套路，而微服务的本质也是分布式，因此搞明白这三十六个最重要的知识点也就同时能搞明白微服务。</p><p>实现一个分布式系统通常会面临只见“点与线”而不见“面与体”的难题 。本系列中的思维模型章节主要是为了解决分布式系统设计中的“面与体”的难题，它包括：需求分析思维模型、 技术思维模型、产品思维模型、创新思维模型以及商业思维模型，依据这些模型往上套就可以从“点、线、面、体”这四个层面系统性的设计一个分布式系统。</p><p>如果说技术是分布式系统工程师的一根DNA螺旋线，那么“产品、创新、商业”等就是DNA的另外一根螺旋线，只有两根螺旋线俱全并且不停的演化才能进化出新物种，本文将讲述思维模型里的 “需求分析思维” 模型。</p><h2 id="需求分析思维模型"><a href="#需求分析思维模型" class="headerlink" title="需求分析思维模型"></a><font color="#FF8C00">需求分析思维模型</font></h2><p>架构师是业务需求与产品落地之间的桥梁，因此准确地理解业务需求也是架构师必备的一个基本能力，准确地理解业务需求需要从理解业务愿景、策略与执行以及软件需求开始。理解业务愿景需要理清楚业务目标与产品的技术目标，理解策略与执行需要看清楚企业的战略方针、团队定位以及执行方法论，再次才是理解软件的产品需求。</p><h4 id="业务愿景"><a href="#业务愿景" class="headerlink" title=" 业务愿景"></a><font color="#00CED1"> 业务愿景</font></h4><p>1，业务目标</p><p>业务目标是很粗略的业务描述，比如需要提供物联网数据的存储服务或者比如给深度学习框架提供专门的训练芯片等.</p><p>2，技术目标</p><p>技术目标分为功能目标与非功能目标，功能目标是跟业务需求强相关的软件功能需求，比如提供原生的时序数据存储功能，还比如分布式计算功能。非功能目标可以分为质量目标与约束目标，比如性能质量、可用质量以及系统硬件规格约束等，对于产品来说质量与约束都需要可度量化、可验证化。</p><h4 id="策略与执行"><a href="#策略与执行" class="headerlink" title=" 策略与执行"></a><font color="#00CED1"> 策略与执行</font></h4><p>1, 战略方针</p><p>产品的战略意味着方向、资源以及取舍，方针是如何打造出这么一款产品的策略，一开始从全方位复制再处处差异化竞争也是一个思路，比如全面复制市场上已有的产品，再从产品、技术、销售、服务、运营、客户定位等方面处处差异化竞争。</p><p>2, 团队定位</p><p>团队文化即产品文化，打造一款产品需要一个团队，组织文化也深刻的影响着产品，团队不同意味着不同。国内一些企业团队复制国外产品的时候，往往有其形而无其神，原因之一往往是团队定位以及企业文化的不同。</p><p>通常来讲团队可以用四种类型来类比：海盗、特种兵、军队以及警察。海盗团队求生存，特种作战团队求根据地，军队团队求统一全国，警察团队求维稳。采用不愁吃喝的警察维稳的思路开发一款新产品又怎么能跟需要打下根据地的特种作战部队一样呢，跟需要求生存的海盗部队更不一样。</p><p>3, 执行策略</p><p>执行策略是指产品落地的方法论，持续交付2.0的方法论就很类似火箭思维，采用火箭思维意味着先开工再在过程中矫正，先确保大方向正确，开工过程中矫正直至准确命中目标。</p><h4 id="软件需求"><a href="#软件需求" class="headerlink" title=" 软件需求"></a><font color="#00CED1"> 软件需求</font></h4><p>架构师需要能准确理解业务愿景、产品策略，将抽象的愿景、目标、策略等分解成可量化的、可执行的具体任务，从而准确实现业务到产品的落地。</p><p>从业务到产品的过程中，能够准确的理解业务的软件需求也是一个非常重要的思维能力，这样可以保证大方向的正确性，这里提出一种从业务到产品的需求分析模型，以准确的理解软件需求，从而保证软件产品的落地方向的准确性。这里我提出一个公式：</p><p><strong><font color="#00CE00">软件需求 = [客户，用户，团队] x [功能，质量，约束]</font></strong></p><p>依据这个公式我提出<strong><font color="#00CE00">“三三制需求分析思维模型”</font></strong>以抛砖引玉，如下图：</p><table><thead><tr><th style="text-align:center">需求分析</th><th style="text-align:center">功能</th><th style="text-align:center">质量</th><th style="text-align:center">约束</th></tr></thead><tbody><tr><td style="text-align:center">“大”客户</td><td style="text-align:center">业务目标</td><td style="text-align:center">多、快、好、省</td><td style="text-align:center">时间、质量、成本<br>遗留系统，法律法规<br>技术趋势，竞争对手<br>行业标准等</td></tr><tr><td style="text-align:center">“大”用户</td><td style="text-align:center">业务需求</td><td style="text-align:center">性能，可用性<br>可靠性，可伸缩性<br>可观测性，可运维性<br>易用性，安全性，韧性</td><td style="text-align:center">业务环境<br>用户能力<br>用户群特征</td></tr><tr><td style="text-align:center">“大”团队</td><td style="text-align:center">基本功能 ，核心功能 <br>增值功能 ，可有可无功能 <br>有害无益功能</td><td style="text-align:center">可扩展<br>可读性<br>可测试性<br>可维护性</td><td style="text-align:center">资源预算，上级要求<br>开发团队能力<br>产品规划，信息安全<br>运行环境</td></tr></tbody></table><h5 id="“大”客户"><a href="#“大”客户" class="headerlink" title="“大”客户"></a><font color="#00CE00">“大”客户</font></h5><p>这里的“大”字有两个层面的意思，首先是范围上的”大“，三三制模型里的客户不只是狭义上的产品的客户，还包括整个产品利益链上的客户，比如客户的客户，因此这里称之为 “大“客户。第二这里的”大“字是规模上的大，从商业的角度来看大订单客户理应获得更大的关注。</p><p><strong>功能</strong></p><p>客户关注的功能即为业务目标，比如获取商业上的成功、业务难点、恐惧点、挑战点以及压力点等。对架构师来说 “以客户为中心”导向的业务功能目标不只是提供“高质量、低成本、服务好、响应及时”的基本产品或服务需求，还包括帮助客户获取商业上的成功，帮助客户解决难点、痛点、恐惧点、挑战点以及压力点。</p><p><strong>质量</strong></p><p>客户对产品质量的需求一般可以用四个字概括，即”多、快、好、省“，当然从软件工程的角度来说，四个方面全满足是极其困难的，因此应该根据实际情况合理取舍，对客户的需求需要进行合理的”过滤“，去粗存精，去伪纯真。</p><p><strong>约束</strong></p><p>对于客户的需求只关注功能和质量而忽视约束也是不够全面的。客户在产品交付的时间、质量与成本上需要取舍，客户原来遗留的系统以及资产，当前国家的法律法规，市场上的技术趋势，以及竞争对手与行业标准等都属于当前需要考虑的约束需求。</p><h5 id="”大“用户"><a href="#”大“用户" class="headerlink" title="”大“用户"></a><font color="#00CE00">”大“用户</font></h5><p>这里的”大“用户的”大“字，也分为两个层面的意思，一是范围”大“，不只是当前产品的用户，还包括用户的用户以及整个产品使用链上的所有用户，二是规模”大“，主流用户的需求更应该第一时间满足，有限的资源应该在第一时间满足主流用户的需求。</p><p><strong>功能</strong></p><p> 功能需求指的是满足用户对业务的需求，用户需要什么就提供什么，而不是我有什么就非要给用户什么，以”用户“为中心的思路也是正确的。    </p><p><strong>质量</strong></p><p>用户的产品质量需求一般称为使用质量需求，可以从以下几个维度进行分析：</p><ul><li><p>合适的性能（Performant），性能指标一般包括 TPS,  QPS,  Latency, IOPS， response time等，这里用”合适的性能“作为表达，指的是性能合适即可、够用即可，高性能当然好，但是高性能也意味着更高的成本，有些场景高性能反而是一种浪费行为，性能需求需要理解业务场景适可而止；</p></li><li><p>可用性(Availability)，可用性指的是系统长时间可对外提供服务的能力，通常采用小数点后的9的个数作为度量指标，按照这种约定“五个九”等于0.99999（或99.999％）的可用性，默认企业级达标的可用性为6个9。但是当前从时间维度来度量可用性已经没有太大的意义，因为设计得好的系统可以在系统出现故障得情况下也能保证对外提供得服务不中断，因此，当前更合适得可用性度量指标 是请求失败率；</p></li><li><p>可靠性(Reliability)，可靠性一般指系统在一定时间内、在一定条件下可以无故障地执行指定功能的能力或可能性， 也是采用小数点后的9的个数作为度量指标，通常5个9的可靠性就可以满足企业级达标；</p></li><li><p>可伸缩性(Scalability)，是指通过向系统添加资源来处理越来越多的工作并且维持高质量服务的能力；</p></li><li><p>韧性(resilience)，通常也叫容错性（fault-tolerant），也就是健壮和强壮的意思，指的是系统的对故障与异常的处理能力，比如在软件故障、硬件故障、认为故障这样的场景下，系统还能保持正常工作的能力；</p></li><li><p>可观测性(Observability)，是一种设计理念，包括告警、监控、日志与跟踪，可以实时地更深入地观测系统内部的工作状态；</p></li><li><p>安全性（security），指的是阻止非授权使用，阻止非法访问以及使用，保护合法用户的资产的能力；</p></li><li><p>易用性（usability），指的是软件的使用难易程度，对于产品的易用性来说，  易用性不仅仅 是软件使用角度的易用，还包括安装、部署、升级上的易用,升值还包括硬件层面的易用，比如产品的外观，形状等；</p></li><li><p>可运维性（operability），可运维性指的是运维人员对系统进行运维操作的难易程度，主要包含以下几个方面的难以程度： 系统的部署、升级、修改、监控以及告警等。</p></li></ul><p><strong>约束</strong></p><p>用户的约束需求包括 用户的业务环境，用户的能力以及用户群的特征等。</p><h5 id="”大“团队"><a href="#”大“团队" class="headerlink" title="”大“团队"></a><font color="#00CE00">”大“团队</font></h5><p>这里的大团队的”大“指的是范围上的大，不只是直接开发人员，还包括跨职级、跨部门的利益相关人员。</p><p><strong>功能</strong></p><p>软件功能需求从产品的角度来说可以分为五种，即：</p><ul><li>基本功能，这是在产品概念阶段就必须实现的功能也是在产品的第一个发布版本中必须提供的功能，比如数据处理产品的”读与写“；</li><li><p>核心功能，核心功能是产品的主要功能，扩展了基本功能的外延，比如为了保证性能达标的缓存功能、分布式功能等；</p></li><li><p>增值功能，这里指的是一些产品差异化的能力，比如安全、监控、告警、日志、升级、部署等；</p></li><li><p>可有可无功能，有些特性存在还是不存在不影响产品的使用也不会带来产品的优势，只起到锦上添花的作用，因此属于可有可无的功能；</p></li><li>有害无益功能，指的一些功能不只没用还有害，没有识别出来消耗了团队资源不说还对产品有拉后腿的作用。</li></ul><p><strong>质量</strong></p><p>团队的质量需求，指的是产品开发周期内的质量需求，高质量的代码几个最重要的要素有：</p><ul><li><p>可测试性（ testability），指的是单元测试，集成测试，打桩测试等的难易；</p></li><li><p>可维护性（Maintainability）， 指的是代码升级，部署，定位bug，添加功能的难易；</p></li><li><p>可扩展性（ extensibility）， 指的是未来增加新的功能与模块的难易；</p></li><li><p>可读性（ readability），指的是代码的易理解程度。</p></li></ul><p><strong>约束</strong></p><p>几个中药得团队的约束需求有：</p><ul><li><p>资源预算，产品的质量与功能以及发布周期受限于预算；</p></li><li><p>上级要求，上级的要求相当于客户要求也是非常重要的约束条件；</p></li><li><p>开发团队的能力，开发团队的能力组成、知识结构组成决定了产品是否能够交付以及能否高质量的交付；</p></li><li><p>产品规划，产品规划得进度是产品的交付周期以及开发进度得约束条件；</p></li><li><p>此外还有信息安全以及产品运行环境 的约束。</p></li></ul><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font color="#FF8C00">小结</font></h2><p>本系列文章讲述了五个思维模型： “需求分析思维模型、技术思维模型、创新思维模型、商业思维模型以及产品思维模型”，再结合分布式流存储做了简单的举例分析。本文讲述”需求思维模型“，日拱一卒，功不唐捐，分享是最好的学习，与其跟随不如创新，希望这几个思维模型对大家有用。另作者能力与认知都有限，”我讲的，可能都是错的“[1]，欢迎大家拍砖留念。</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中科大硕，DELL EMC 资深首席工程师，主要从事分布式产品的交付、架构设计以及开发工作。</p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a><font color="#FF8C00">参考资料</font></h2><p>[1]《软件架构设计》 温昱著</p>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>进EMC马上两年，里程碑两件</title>
      <link href="/2019/12/21/person-emc-codeline-and-awarded/"/>
      <url>/2019/12/21/person-emc-codeline-and-awarded/</url>
      
        <content type="html"><![CDATA[<p>进EMC马上两年，12月份里程碑两件。</p><p>一是硬技能，项目里个人提交的代码突破6万行，产品第一个版本月底发布；</p><p>二是软技能，专利公司内过审3个，写文章推广产品以及提升团队的技术影响力获得公司副总裁认可给了个奖。</p><h2 id="代码行数突破6万行"><a href="#代码行数突破6万行" class="headerlink" title="代码行数突破6万行"></a>代码行数突破6万行</h2><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/person/emc-20191220-codeline.png" alt="codeline"></p><h4 id="专利过三"><a href="#专利过三" class="headerlink" title="专利过三"></a>专利过三</h4><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/person/emc-2019-patent-1.PNG" alt="patent"></p><h4 id="GEEK-BANG-技术文章活动奖"><a href="#GEEK-BANG-技术文章活动奖" class="headerlink" title="GEEK BANG 技术文章活动奖"></a>GEEK BANG 技术文章活动奖</h4><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/person/emc-201912-award-1.JPG" alt="award"></p>]]></content>
      
      
      <categories>
          
          <category> person </category>
          
      </categories>
      
      
        <tags>
            
            <tag> person </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>分布式系统架构设计 – 第11式 - 产品思维模型</title>
      <link href="/2019/11/20/distributed-ideamodel-product/"/>
      <url>/2019/11/20/distributed-ideamodel-product/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a><font color="#FF8C00">前言</font></h2><font color="#FF8C00">注：本思维模型系列文章已被infoq采纳并推荐至首页：<a href="https://www.infoq.cn/article/JjycubQz3YTBgozaZ4G9" target="_blank" rel="noopener">https://www.infoq.cn/article/JjycubQz3YTBgozaZ4G9</a></font><p>日拱一卒，功不唐捐，一个知识领域里的 “道 法 术 器” 这四个境界需要从 微观、中观以及宏观 三个角度来把握。微观是实践，中观讲套路，宏观靠领悟。本系列文章我把它命名为《分布式系统架构设计36式》，讲诉分布式系统里最重要的三十六个的中观套路，而微服务的本质也是分布式，因此搞明白这三十六个最重要的知识点也就同时能搞明白微服务。</p><p><strong>“兵者，国之大事，死生之地，存亡之道，不可不察也”</strong>，这句话对企业来讲，兵即产品，国即企业，察即研究探讨，产品关系到企业的存亡，所以不可以不慎重地加以研究探讨。</p><p>我们知道一个产品的成功不只是技术的成功，它还包括商业、创新、管理、资本、运营以及销售等的成功。当打造一个产品的时候，通常来说工程人员往往会比较关注技术层面的东西： 方案、功能、难点、亮点以及如何实现等，深度有余但高度与广度往往不足 。一般有点经验的工程人员都可以从点或线的层面考虑一个产品的实现，但往往缺乏从面及体的层面看待一个产品的能力。</p><p>因此，如果说技术思维是架构师的一根DNA螺旋线，那么产品思维、创新思维以及商业思维等就是架构师的另外一根DNA螺旋线，只有两根DNA螺旋线俱全才能有机会进化出新物种。</p><h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a><font color="#FF8C00">动机</font></h2><p>人的知识与能力可以从“时空”这两个角度进行评价，其可分为四个维度：深度、广度、高度以及跨度。空间角度指的是深度、广度、高度，时间角度指的是跨度。深度靠专研，广度靠学习，高度靠抽象，而跨度靠长久地积累经验。这四个维度组合成了一个人的知识与能力的时空度。</p><p>万事万物逃脱不出<strong>“不易、简易、变易”</strong>这三个层次，金庸先生的《天龙八部》里少林寺有72技，其每一技又千变万化，想要样样精通，今生无望，然而练就“小无相功”却可以以这功法催动不同的“技”，甚至可以比原版更具威力，以“不易 简易”之功施展“变易”之术。那么对于技术开发人员来说技术也是“变易”的，更新快，领域多，复杂度高，样样精通也是今生无望，那么需要的就是找出适合自己的“功”，技术思维模型、产品思维模型、创新思维模型、商业思维模型就是这样的“功”。</p><p>因此本系列文章提出了技术、产品、创新与商业这四个思维模型，这一系列文章不是为了解决具体的某个分布式系统设计里的难题，它提出了一种思维框架，从技术、产品、创新以及商业的角度，给工程人员以一种系统性的分析分布式系统设计难题的模型，这也是一种系统思维的体现。</p><h2 id="产品思维模型"><a href="#产品思维模型" class="headerlink" title="产品思维模型"></a><font color="#FF8C00">产品思维模型</font></h2><p>最后一个思维模型是产品思维模型，它是以上三个思维模型的组合与新生，如下图：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/ideamodel/idea-model-product.PNG" alt="产品思维模型"></p><p>产品思维模型灵感来自于阿基米德的一句话:”给我一个支点,我可以撬起地球。“，因此定义它为阿基米德产品思维模型。</p><p>如上图所示，在产品思维模型里产品被看作是一个圆，在圆之外还有一个杠杆、一个支点以及一个作用力。在产品圆里除了技术火箭六元组、产品创新奇点、五看三定六要素之外还补充了 产品价值网，企业文化、企业制度以及组织结构这三个要素。</p><h4 id="价值网"><a href="#价值网" class="headerlink" title=" 价值网"></a><font color="#00CED1"> 价值网</font></h4><p>产品价值网指的是产品所在的市场，是产品需要去匹配的市场，也是产品的市场天花板，市场空间的大小意味着产品的增长局限性，它可以是10倍增长的、缓缓增长的或者存量市场等。一个自我快速膨胀的市场空间里往往可以事半功倍，比如2000年后的互联网市场。</p><p>价值网是产品所在的市场，通常采用三个指标来描述产品是否适合价值网：<font color="#00CED1">技术-产品匹配，产品-市场匹配以及价值-市场匹配</font>。</p><h5 id="技术-产品匹配（Technology-Product-Fit）"><a href="#技术-产品匹配（Technology-Product-Fit）" class="headerlink" title="技术-产品匹配（Technology-Product Fit）"></a><font color="#00CED1">技术-产品匹配（Technology-Product Fit）</font></h5><p>TPF这个概念是我新提出的，做工程不同做研究，工程当中技术取舍的关键在于适合即可，技术超前于产品是优势但是也是成本，技术落后于产品，缺乏创新，也容易被市场淘汰。技术于产品锲合度的度量在于满足客户需求即可，包括核心需求与增值需求。</p><h5 id="产品-市场匹配（Product-Market-Fit）"><a href="#产品-市场匹配（Product-Market-Fit）" class="headerlink" title="产品-市场匹配（Product-Market Fit）"></a><font color="#00CED1">产品-市场匹配（Product-Market Fit）</font></h5><p>产品-市场匹配的意思指的是产品确定是可以满足市场真正的需求的，并且产品可以从客户那边获取生存下来。</p><p>产品-市场匹配度的度量标准有： 客户的下载数量、客户付费数量、客户求购的数量、客户愿意付钱。</p><h5 id="价值-市场匹配（Value-Market-Fit）"><a href="#价值-市场匹配（Value-Market-Fit）" class="headerlink" title="价值-市场匹配（Value-Market Fit）"></a><font color="#00CED1">价值-市场匹配（Value-Market Fit）</font></h5><p>价值-市场匹配指的是产品所提供的价值是真正满足市场需求的，从软件的角度来说可以匹配的价值有：产品质量、性能、可扩展性、可靠性、可视化、安全、审计、辅助工具以及各种插件等。                                                                                                                                                                                                                                                                                                                </p><h4 id="企业文化、企业制度以及组织结构"><a href="#企业文化、企业制度以及组织结构" class="headerlink" title=" 企业文化、企业制度以及组织结构"></a><font color="#00CED1"> 企业文化、企业制度以及组织结构</font></h4><p>产品也是受企业文化、企业制度以及企业组织结构影响的，对于”这三要素如何影响产品？“这一主题没有研究过，这里不敢展开讲。但是可以确定的是“诚信 以人为本”的企业比“KPI导向 利益驱动”的企业更能出现优秀的作品。</p><h4 id="支点"><a href="#支点" class="headerlink" title=" 支点"></a><font color="#00CED1"> 支点</font></h4><p>支点即关键着力点，它是撬动产品的着力点，它也可以是”以客户为中心，为客户创造价值“的理念，也可以是关键资源、战略投入等，最适合自己的、自己最拿手的要素就是支点。</p><h4 id="杠杆"><a href="#杠杆" class="headerlink" title=" 杠杆"></a><font color="#00CED1"> 杠杆</font></h4><p>杠杆可以是创新，也可以是资本，是撬动产品从而获得10倍增长效应的关键要素，关键时刻需要对产品启动杠杆效应以获取大规模爆发机会。</p><h4 id="关键能力"><a href="#关键能力" class="headerlink" title=" 关键能力"></a><font color="#00CED1"> 关键能力</font></h4><p>一个企业的能力包括：技术，产品，渠道、市场、资源，资本，管理，运营，人力，销售，财务等，这里的关键能力，指的是最拿手的一个或几个能力， 选出最适合自己的， 比如技术领先的能力、打造产品的能力等，当然也可以认为是管理能力或财务能力，然后作为驱动产品的杠杆作用力。</p><p>分布式流存储所在的市场是物联网以及IT运维这样的高速增长市场，产品的支点是”以客户为中心，为客户创造价值“这样的理念，同时在关键能力上，团队组成、企业的存储基因等都是关键能力。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font color="#FF8C00">小结</font></h2><p>本系列文章讲述了四个思维模型： “技术思维模型、创新思维模型、商业思维模型以及产品思维模型”，再结合分布式流存储做了简单的举例分析。本文讲述”产品思维模型“，日拱一卒，功不唐捐，分享是最好的学习，与其跟随不如创新，希望这几个思维模型对大家有用。另作者能力与认知都有限，”我讲的，可能都是错的“[1]，欢迎大家拍砖留念。</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中科大硕，DELL EMC 资深首席工程师，主要从事分布式产品的交付、架构设计以及开发工作。</p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a><font color="#FF8C00">参考资料</font></h2><p>[1]《第二曲线创新》 李善友</p><p>[2]《如何在一分钟内用5个问题讲清你的商业模式》 中欧商业评论，关苏哲 </p><p>[3] Pravega.io</p>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>分布式系统架构设计 – 第10式 - 商业思维模型</title>
      <link href="/2019/11/20/distributed-ideamodel-business/"/>
      <url>/2019/11/20/distributed-ideamodel-business/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a><font color="#FF8C00">前言</font></h2><font color="#FF8C00">注：本思维模型系列文章已被infoq采纳并推荐至首页：<a href="https://www.infoq.cn/article/JjycubQz3YTBgozaZ4G9" target="_blank" rel="noopener">https://www.infoq.cn/article/JjycubQz3YTBgozaZ4G9</a></font><p>日拱一卒，功不唐捐，一个知识领域里的 “道 法 术 器” 这四个境界需要从 微观、中观以及宏观 三个角度来把握。微观是实践，中观讲套路，宏观靠领悟。本系列文章我把它命名为《分布式系统架构设计36式》，讲诉分布式系统里最重要的三十六个的中观套路，而微服务的本质也是分布式，因此搞明白这三十六个最重要的知识点也就同时能搞明白微服务。</p><p><strong>“兵者，国之大事，死生之地，存亡之道，不可不察也”</strong>，这句话对企业来讲，兵即产品，国即企业，察即研究探讨，产品关系到企业的存亡，所以不可以不慎重地加以研究探讨。</p><p>我们知道一个产品的成功不只是技术的成功，它还包括商业、创新、管理、资本、运营以及销售等的成功。当打造一个产品的时候，通常来说工程人员往往会比较关注技术层面的东西： 方案、功能、难点、亮点以及如何实现等，深度有余但高度与广度往往不足 。一般有点经验的工程人员都可以从点或线的层面考虑一个产品的实现，但往往缺乏从面及体的层面看待一个产品的能力。</p><p>因此，如果说技术思维是架构师的一根DNA螺旋线，那么产品思维、创新思维以及商业思维等就是架构师的另外一根DNA螺旋线，只有两根DNA螺旋线俱全才能有机会进化出新物种。</p><h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a><font color="#FF8C00">动机</font></h2><p>人的知识与能力可以从“时空”这两个角度进行评价，其可分为四个维度：深度、广度、高度以及跨度。空间角度指的是深度、广度、高度，时间角度指的是跨度。深度靠专研，广度靠学习，高度靠抽象，而跨度靠长久地积累经验。这四个维度组合成了一个人的知识与能力的时空度。</p><p>万事万物逃脱不出<strong>“不易、简易、变易”</strong>这三个层次，金庸先生的《天龙八部》里少林寺有72技，其每一技又千变万化，想要样样精通，今生无望，然而练就“小无相功”却可以以这功法催动不同的“技”，甚至可以比原版更具威力，以“不易 简易”之功施展“变易”之术。那么对于技术开发人员来说技术也是“变易”的，更新快，领域多，复杂度高，样样精通也是今生无望，那么需要的就是找出适合自己的“功”，技术思维模型、产品思维模型、创新思维模型、商业思维模型就是这样的“功”。</p><p>因此本系列文章提出了技术、产品、创新与商业这四个思维模型，这一系列文章不是为了解决具体的某个分布式系统设计里的难题，它提出了一种思维框架，从技术、产品、创新以及商业的角度，给工程人员以一种系统性的分析分布式系统设计难题的模型，这也是一种系统思维的体现。</p><h2 id="商业思维模型"><a href="#商业思维模型" class="headerlink" title="商业思维模型"></a><font color="#FF8C00">商业思维模型</font></h2><p>IBM有个商业战略思维模型叫做”五看三定“， 经过很多家企业的验证，表示效果很好。这里扩充”五看三定“思维模型为“五看三定六要素”思维模型，作为产品的商业模式思维模型。”五看三定六要素“即：五看：看趋势、看市场、看对手、看自己、看机会，三定：定目标、定策略、定执行，六要素：客户、产品、供给、盈利、创新及风险。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/ideamodel/idea-model-business.PNG" alt="商业思维模型"></p><h4 id="五看"><a href="#五看" class="headerlink" title=" 五看"></a><font color="#00CED1"> 五看</font></h4><p>1，五看，首先要看的是趋势，属于宏观的范畴，行业趋势、行业风向，国家政策，经济周期，技术趋势，资源方向等，从而判断出正确的资源投入方向；</p><p>2，接着看市场，看看市场需求在哪里？客户的真实需求在哪里？客户愿意买单的点在哪里？产品与市场的最佳适配点在哪里？从而输出正确的客户目标；</p><p>3，再看对手，可以从三个方面进行看对手：</p><ul><li><p>赚得到钱，如果有对手已经验证过了这个市场可以获取高额利润，那么就可以确定这个方向的正确性；</p></li><li><p>赚不到钱，如果对手正在介入的市场领域属于赚不到钱的领域，那么自己去做赚不到钱的概率也一样非常的大，现在新介入的话就需要非常非常的谨慎；- </p></li><li>没有对手，如果是一个没有对手的领域，要么是新开拓的市场空白机会，要么根本就是没有真实的客户需求的伪需求市场，这也是需要非常谨慎介入方向。</li></ul><p>4，看完对手就要看自己，看自己说的是，看看自己的优势在哪里，劣势在哪里，有什么关键资源能力，自己能做什么不能做什么，介入这个市场领域的话，对比其他对手有什么优势胜出，如果没有胜出优势就需要谨慎介入。</p><p>5，最后看机会，判断真机会的依据是：行业趋势正确，有真实的客户需求，对手有钱赚，自己团队有优势，那么这样的机会输出点就是”真机会“。</p><h4 id="三定"><a href="#三定" class="headerlink" title=" 三定"></a><font color="#00CED1"> 三定</font></h4><p>五看后就要三定，看好机会后，需要定目标，定策略以及定执行。</p><p>1，首先定好需要达到的市场目标，比如3年利润1个小目标（1亿￥）；</p><p>2，然后开始着手制定如何达到这个目标的策略，比如：1）分解这个目标，1年到什么阶段、2年到什么阶段、3年到什么阶段等；2）是先单点突破最佳盈利点，再以此为树干长出树枝？还是借助资源优势全面铺开？</p><p>3，再就是定执行，定策略是如何做的范畴，而定执行是让谁做，什么时候做出来的问题，属于生成资料、生成工具分配的范畴。</p><h4 id="六要素"><a href="#六要素" class="headerlink" title=" 六要素"></a><font color="#00CED1"> 六要素</font></h4><p>”五看三定“分析完后，更进一步需要进行商业模型六要素的分析[2]。</p><p>1，客户，客户指的是市场定位，是想赚谁的钱、不想赚谁的钱的问题，是客户是谁、又不是谁的问题，是客户如何取舍的问题。</p><p>2，产品，产品指的是打算用什么东西去赚钱，是卖产品还是卖服务，是提供的满客户需求的价值是什么又不是什么的问题。</p><p>3，供应，供应指的是如何生产出好产品以及怎么样把产品卖出去。如何打造与市场最佳适配的产品？如何保证技术与产品的最佳适配，如何交付出这样的好产品？然后又准备怎么把这样的产品卖出去？渠道在哪? 价格怎么定义？然后自己又有哪些强力的资源优势？这也是产品成败的一个非常关键的点。</p><p>4，盈利，盈利讲的是如何赚钱的问题，是做产品？还是做平台？或者做生态？然后又怎么保证可以持续地赚钱？做产品离钱近，一手交钱一手交货；做平台，投入大、但是空间也大；做生态，投入巨大、周期长，但是如果成了，那么收益也巨大。</p><p>5，创新，创新指的是以上四点如何创新，如何持续的创新，可以从寻找差异化入手，也可以从先同质化模仿再处处差异化创新入手，可以是 ”更好“，也可以是”不同“，还可以是”新生“。</p><p>6，风险，风险指的是风险管理，居安思危，失败风险是否在可承受的范围之内？以上五点的风险在哪里，方方面面是否都考虑周全？</p><p>依据以上近乎穷举的系统分析法，可以发现，为物联网以及IT运维市场专门设计一个存储系统是值得投入的一个机会点。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font color="#FF8C00">小结</font></h2><p>本系列文章讲述了四个思维模型： “技术思维模型、创新思维模型、商业思维模型以及产品思维模型”，再结合分布式流存储做了简单的举例分析。本文讲述”商业思维模型“，日拱一卒，功不唐捐，分享是最好的学习，与其跟随不如创新，希望这几个思维模型对大家有用。另作者能力与认知都有限，”我讲的，可能都是错的“[1]，欢迎大家拍砖留念。</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中科大硕，DELL EMC 资深首席工程师，主要从事分布式产品的交付、架构设计以及开发工作。</p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a><font color="#FF8C00">参考资料</font></h2><p>[1]《第二曲线创新》 李善友</p><p>[2]《如何在一分钟内用5个问题讲清你的商业模式》 中欧商业评论，关苏哲 </p><p>[3] Pravega.io</p>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>分布式系统架构设计 – 第9式- 创新思维模型</title>
      <link href="/2019/11/20/distributed-ideamodel-innovation/"/>
      <url>/2019/11/20/distributed-ideamodel-innovation/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a><font color="#FF8C00">前言</font></h2><font color="#FF8C00">注：本思维模型系列文章已被infoq采纳并推荐至首页：<a href="https://www.infoq.cn/article/JjycubQz3YTBgozaZ4G9" target="_blank" rel="noopener">https://www.infoq.cn/article/JjycubQz3YTBgozaZ4G9</a></font><p>日拱一卒，功不唐捐，一个知识领域里的 “道 法 术 器” 这四个境界需要从 微观、中观以及宏观 三个角度来把握。微观是实践，中观讲套路，宏观靠领悟。本系列文章我把它命名为《分布式系统架构设计36式》，讲诉分布式系统里最重要的三十六个的中观套路，而微服务的本质也是分布式，因此搞明白这三十六个最重要的知识点也就同时能搞明白微服务。</p><p><strong>“兵者，国之大事，死生之地，存亡之道，不可不察也”</strong>，这句话对企业来讲，兵即产品，国即企业，察即研究探讨，产品关系到企业的存亡，所以不可以不慎重地加以研究探讨。</p><p>我们知道一个产品的成功不只是技术的成功，它还包括商业、创新、管理、资本、运营以及销售等的成功。当打造一个产品的时候，通常来说工程人员往往会比较关注技术层面的东西： 方案、功能、难点、亮点以及如何实现等，深度有余但高度与广度往往不足 。一般有点经验的工程人员都可以从点或线的层面考虑一个产品的实现，但往往缺乏从面及体的层面看待一个产品的能力。</p><p>因此，如果说技术思维是架构师的一根DNA螺旋线，那么产品思维、创新思维以及商业思维等就是架构师的另外一根DNA螺旋线，只有两根DNA螺旋线俱全才能有机会进化出新物种。</p><h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a><font color="#FF8C00">动机</font></h2><p>人的知识与能力可以从“时空”这两个角度进行评价，其可分为四个维度：深度、广度、高度以及跨度。空间角度指的是深度、广度、高度，时间角度指的是跨度。深度靠专研，广度靠学习，高度靠抽象，而跨度靠长久地积累经验。这四个维度组合成了一个人的知识与能力的时空度。</p><p>万事万物逃脱不出<strong>“不易、简易、变易”</strong>这三个层次，金庸先生的《天龙八部》里少林寺有72技，其每一技又千变万化，想要样样精通，今生无望，然而练就“小无相功”却可以以这功法催动不同的“技”，甚至可以比原版更具威力，以“不易 简易”之功施展“变易”之术。那么对于技术开发人员来说技术也是“变易”的，更新快，领域多，复杂度高，样样精通也是今生无望，那么需要的就是找出适合自己的“功”，技术思维模型、产品思维模型、创新思维模型、商业思维模型就是这样的“功”。</p><p>因此本系列文章提出了技术、产品、创新与商业这四个思维模型，这一系列文章不是为了解决具体的某个分布式系统设计里的难题，它提出了一种思维框架，从技术、产品、创新以及商业的角度，给工程人员以一种系统性的分析分布式系统设计难题的模型，这也是一种系统思维的体现。</p><h2 id="创新思维模型"><a href="#创新思维模型" class="headerlink" title="创新思维模型"></a><font color="#FF8C00">创新思维模型</font></h2><p>受李善友老师的《第二曲线创新》的启发，这里提出“奇点破界”创新思维模型，如下图：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/ideamodel/idea-model-creative.PNG" alt="创新思维模型"></p><h4 id="创新三重境：”更好、不同、新生“"><a href="#创新三重境：”更好、不同、新生“" class="headerlink" title=" 创新三重境：”更好、不同、新生“"></a><font color="#00CED1"> 创新三重境：”更好、不同、新生“</font></h4><ul><li><p><strong>更好，</strong>指的是市场是明确存在需求的，但是提供的新产品在质量、功能、渠道、价格等方面比原有产品更具优势，是用更好的体验来满足客户的真需求；</p></li><li><p><strong>不同，</strong>指的是差异化竞争，”与其更好不如不同”[1]，不同不只是技术面的不同，而是处处差异化不同，理念、技术、渠道，运营，销售等处处差异化竞争；</p></li><li><p><strong>新生，</strong>指的是 从0到1，从无到有的创造一个新物种，是指用凭空创造出一个新产品来满足客户需求，这种形态的产品要么是颠覆式的创造带来巨大的商业上的成功，要么就是没有真实客户需求的新事物，商业上完全失败。</p></li></ul><p>这里，分布式流存储采用的是“<strong>更好与不同”</strong>这两个产品创新方法论，组合原有的技术开拓出新产品，规避风险，满足客户真实的需求。</p><h4 id="奇点破界"><a href="#奇点破界" class="headerlink" title=" 奇点破界"></a><font color="#00CED1"> 奇点破界</font></h4><p>物理学认为宇宙从无到有始于一个点，这个点叫做“奇点”，它积聚了形成现有宇宙中所有物质的势能，当这一个点的能量平衡被破坏后，宇宙大爆炸发生，从而生成我们现在的宇宙。如果把宇宙比作我们的产品，奇点就是这个产品赖以出现与存在的关键点，“奇点破界”创新思维模型的理论依据是奇点创新三部曲：“破坏，外延，重生”，即：</p><p>1，破坏，找到产品奇点并加以破坏。产品缺点不是奇点，奇点是产品赖以出现与存在的点，找到它，然后破坏它，类似于使得宇宙奇点能量失去平衡；</p><p>2，外延，产品奇点下移，产品边界外延，类似于宇宙大爆炸从而造成宇宙边界外延；</p><p>3，重生，重构产品奇点，形成新的产品体系，类似于新宇宙的形成。</p><p>以分布式流存储的创新为例，这里只涉及技术面的创新，销售、渠道、运营、管理、商业模式等方面的创新不在本文范围。可以知道的是目前市面上的分布式流存储的最大竞争对手是Kafka，对其应用奇点创新思维模型的步骤有：</p><p>1， 破坏，找出产品奇点，然后破坏它的奇点。例如，我们知道Kafka的赖以依存的关键点有：提供消息服务语义；分布式的；依赖于代理中心的横向扩展以及依赖于分区的数据冗余；依据初代版本时间点的硬件特性进行软件的设计；</p><p>2，外延，产品奇点下移，破界，新的产品边界外延。针对以上Kafka的四条关键点，提出分布式流存储的新奇点：提供存储语义服务而不是消息语义；依据云原生、微服务的理念进行产品架构，扩展分布式系统外延；软件定义，抽象1层存储与2层存储，平衡高性能与无限扩容的问题；抓住技术进步的福利，依据当前最新的硬件特性进行产品软件设计；</p><p>3， 重生，最后更新的、更具有技术竞争力的、针对流式数据而实现的新产品”分布式流存储“诞生。</p><p>这一套创新思维模型的关键点在于找出原有的产品赖以出现以及存在的“奇点”，然后破界重生。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font color="#FF8C00">小结</font></h2><p>本系列文章讲述了四个思维模型： “技术思维模型、创新思维模型、商业思维模型以及产品思维模型”，再结合分布式流存储做了简单的举例分析。本文讲述”创新思维模型“，日拱一卒，功不唐捐，分享是最好的学习，与其跟随不如创新，希望这几个思维模型对大家有用。另作者能力与认知都有限，”我讲的，可能都是错的“[1]，欢迎大家拍砖留念。</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中科大硕，DELL EMC 资深首席工程师，主要从事分布式产品的交付、架构设计以及开发工作。</p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a><font color="#FF8C00">参考资料</font></h2><p>[1]《第二曲线创新》 李善友</p><p>[2]《如何在一分钟内用5个问题讲清你的商业模式》 中欧商业评论，关苏哲 </p><p>[3] Pravega.io</p>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>分布式系统架构设计 – 第8式 - 技术思维模型</title>
      <link href="/2019/11/20/distributed-ideamodel-technology/"/>
      <url>/2019/11/20/distributed-ideamodel-technology/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a><font color="#FF8C00">前言</font></h2><font color="#FF8C00">注：本思维模型系列文章已被infoq采纳并推荐至首页：<a href="https://www.infoq.cn/article/JjycubQz3YTBgozaZ4G9" target="_blank" rel="noopener">https://www.infoq.cn/article/JjycubQz3YTBgozaZ4G9</a></font><p>日拱一卒，功不唐捐，一个知识领域里的 “道 法 术 器” 这四个境界需要从 微观、中观以及宏观 三个角度来把握。微观是实践，中观讲套路，宏观靠领悟。本系列文章我把它命名为《分布式系统架构设计36式》，讲诉分布式系统里最重要的三十六个的中观套路，而微服务的本质也是分布式，因此搞明白这三十六个最重要的知识点也就同时能搞明白微服务。</p><p><strong>“兵者，国之大事，死生之地，存亡之道，不可不察也”</strong>，这句话对企业来讲，兵即产品，国即企业，察即研究探讨，产品关系到企业的存亡，所以不可以不慎重地加以研究探讨。</p><p>我们知道一个产品的成功不只是技术的成功，它还包括商业、创新、管理、资本、运营以及销售等的成功。当打造一个产品的时候，通常来说工程人员往往会比较关注技术层面的东西： 方案、功能、难点、亮点以及如何实现等，深度有余但高度与广度往往不足 。一般有点经验的工程人员都可以从点或线的层面考虑一个产品的实现，但往往缺乏从面及体的层面看待一个产品的能力。</p><p>因此，如果说技术思维是架构师的一根DNA螺旋线，那么产品思维、创新思维以及商业思维等就是架构师的另外一根DNA螺旋线，只有两根DNA螺旋线俱全才能有机会进化出新物种。</p><h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a><font color="#FF8C00">动机</font></h2><p>人的知识与能力可以从“时空”这两个角度进行评价，其可分为四个维度：深度、广度、高度以及跨度。空间角度指的是深度、广度、高度，时间角度指的是跨度。深度靠专研，广度靠学习，高度靠抽象，而跨度靠长久地积累经验。这四个维度组合成了一个人的知识与能力的时空度。</p><p>万事万物逃脱不出<strong>“不易、简易、变易”</strong>这三个层次，金庸先生的《天龙八部》里少林寺有72技，其每一技又千变万化，想要样样精通，今生无望，然而练就“小无相功”却可以以这功法催动不同的“技”，甚至可以比原版更具威力，以“不易 简易”之功施展“变易”之术。那么对于技术开发人员来说技术也是“变易”的，更新快，领域多，复杂度高，样样精通也是今生无望，那么需要的就是找出适合自己的“功”，技术思维模型、产品思维模型、创新思维模型、商业思维模型就是这样的“功”。</p><p>因此本系列文章提出了技术、产品、创新与商业这四个思维模型，这一系列文章不是为了解决具体的某个分布式系统设计里的难题，它提出了一种思维框架，从技术、产品、创新以及商业的角度，给工程人员以一种系统性的分析分布式系统设计难题的模型，这也是一种系统思维的体现。</p><h2 id="技术思维模型"><a href="#技术思维模型" class="headerlink" title="技术思维模型"></a><font color="#FF8C00">技术思维模型</font></h2><p>技术思维模型很多，适合自己的才是最好的，这里提出“火箭技术思维模型”以抛砖引玉，如下图：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/ideamodel/idea-model-technology.PNG" alt="技术思维模型"></p><h4 id="火箭思维"><a href="#火箭思维" class="headerlink" title=" 火箭思维"></a><font color="#00CED1"> 火箭思维</font></h4><p>在这个技术思维模型里，产品被看作一个圆，技术是一个三角形火箭，它包括“势 道 法 术 器 界”这六个要素。其中技术只是产品当中的一个子集，在产品圆内还有企业文化、企业制度以及组织关系，这也是影响产品的几个非常重要的因素。</p><p>在这个技术思维模型中的火箭也体现了一种产品开发思维，开发产品的时候应该先确定好大概的方向（趋势），这时并不需要非常精确但是方向一定要对，然后发射（开工），在过程中不断矫正迭代更新，使得短期目标与长期目标相符合，在这个火箭模型中每一级都都是上一级的动力，一级一级地推动，直至最终命中目标（产品满足市场需求，从而获取商业上的成功）。</p><h4 id="技术与产品匹配-TPF-Technology-Product-Fit"><a href="#技术与产品匹配-TPF-Technology-Product-Fit" class="headerlink" title=" 技术与产品匹配(TPF: Technology-Product Fit)"></a><font color="#00CED1"> 技术与产品匹配(TPF: Technology-Product Fit)</font></h4><p>在做产品的时候第一步讲的是产品需要与市场匹配 (PMF: Product-Market Fit)，找出与市场匹配的产品，然后进行最小可行性验证(MVP:  Minimal Viable Product)。同样在做技术的时候，技术需要与产品匹配，这里提出一个新的概念TPF：Technology-Product Fit, 即技术与产品匹配。在技术思维模型里，当技术三角大于产品圆时，技术领先与产品需求，当技术三角小于圆时，技术落后于产品需求，但技术三角的三个点与圆刚好相交时，技术与产品达到最佳匹配，匹配合适度的评判标准是看是否符合下面的“五看三定六要素”的商业思维模型里的输出。</p><h4 id="“势、道、法、术、器、界“-六元组"><a href="#“势、道、法、术、器、界“-六元组" class="headerlink" title=" “势、道、法、术、器、界“ 六元组"></a><font color="#00CED1"> “势、道、法、术、器、界“ 六元组</font></h4><p>狭义上的技术通常指的是技能属于“术”的范畴，而广义的技术则是市场趋势、自己的优势与劣势、产品设计理念、工程方法论、技术技能、工程工具以及约束限制这几个方面的组合体，抽象成工程哲学即“势、道、法、术、器、界”这六个字 ，简称技术思维六元组。</p><h5 id="势：时势，是市场趋势、是产品定位同时也是自我的优势与劣势"><a href="#势：时势，是市场趋势、是产品定位同时也是自我的优势与劣势" class="headerlink" title=" 势：时势，是市场趋势、是产品定位同时也是自我的优势与劣势"></a><font color="#00CED1"> 势：时势，是市场趋势、是产品定位同时也是自我的优势与劣势</font></h5><p>“天时、地利、人和”，打造的产品必须符合市场趋势、准确定位客户需求，同时也要看看自己团队的优势与劣势。例如：依据市场的趋势判断，未来IOT 以及 IT运维市场是处于快速增长状态的，这可以成为为这两个市场提供数据存储服务的决策支持。同时，也要看清自我团队的优势与劣势，是否有能力打造这样的产品。</p><h5 id="道：本质，是“不变”的范畴，是一个产品的灵魂、设计理念以及价值观"><a href="#道：本质，是“不变”的范畴，是一个产品的灵魂、设计理念以及价值观" class="headerlink" title=" 道：本质，是“不变”的范畴，是一个产品的灵魂、设计理念以及价值观"></a><font color="#00CED1"> 道：本质，是“不变”的范畴，是一个产品的灵魂、设计理念以及价值观</font></h5><p>“能工摹其形，巧匠摄其魂”，代码本身是没有灵魂、没有设计理念、没有价值观的，由打造它的人铸其形而赋其神。如同雕塑与画画一般，好的匠人与宗师可以赋予作品以灵魂。同样的产品由不同的人打造，不同的设计理念体现了不同的产品灵魂，这跟打造它的人相关、也跟企业制度、企业文化、组织结构等相关。</p><p>分布式流存储从工程哲学以及设计理念的角度定义了自己的产品灵魂，工程哲学体现在“Best of Breed” 即“最佳物种”这句话，专门为物联网以及日志场景下的流式数据而设计，产品与市场适配，技术与产品适配。而它的设计理念又涵盖了：可度量化的高质量，云原生、微服务架构，软件定义存储，资源自动伸缩，消除数据冗余，数据无限存储，开箱即用，安全等。</p><h5 id="法：方法论，是”简变“的范畴，是工程的套路方法"><a href="#法：方法论，是”简变“的范畴，是工程的套路方法" class="headerlink" title=" 法：方法论，是”简变“的范畴，是工程的套路方法"></a><font color="#00CED1"> 法：方法论，是”简变“的范畴，是工程的套路方法</font></h5><p>方法论体现在产品的设计原则、产品创新、产品交付以及功能与非功能特性的定义。 分布式流存储的设计原则是最佳物种的工程哲学方法论以及以客户为中心的设计理念，产品创新依据是 ”奇点创新“三部曲：破坏、下移、重生，这一点在”奇点创新思维模型”这一章里会讲述。产品交付依从“持续交付2.0” ，探索环与验证环互补互利、互为驱动。功能特性：分布式流存储系统的核心功能就一个：提供分布式流存储服务，而非功能特性可以一分为二：质量与约束。</p><h5 id="术：技能，是”易变”的范畴，狭义上的技术，通常指的就是这一点"><a href="#术：技能，是”易变”的范畴，狭义上的技术，通常指的就是这一点" class="headerlink" title=" 术：技能，是”易变”的范畴，狭义上的技术，通常指的就是这一点"></a><font color="#00CED1"> 术：技能，是”易变”的范畴，狭义上的技术，通常指的就是这一点</font></h5><p>术，指的是技术上的设计方案与实现，在产品里占据了最大的一块版图。分布式流存储里的术可分为：</p><ul><li><p>架构视图：通常架构可以分为场景、物理、逻辑、数据处理以及开发这五个架构视图。分布式流存储最为朴素的数据处理架构视图即为抽象缓存与2层存储资源为流资源，实时性的读和写都在缓存里，数据恢复采用分布式日志系统，而长期存储采用了2层分布式文件存储系统，这也是分布式流存储最重要的一个设计理念。</p></li><li><p>控制面：分布式流存储的控制面最重要的两个工作就是：流管理与集群管理。流管理负责流的抽象、流的生命周期管理，而集群管理体现在集群状态管理以及集群的可服务管理。</p></li><li><p>数据面：数据面最重要的职责是数据“段“的抽象与管理：创建、删除、修改、使用。</p></li><li><p>高级企业特性：分布式流存储也提供了多租户、安全、监控告警、事务、读群组、状态同步器以及保序等企业级特性。</p></li></ul><h5 id="器：工具，也是”易变”的范畴-“工欲善其事-必先利其器”"><a href="#器：工具，也是”易变”的范畴-“工欲善其事-必先利其器”" class="headerlink" title=" 器：工具，也是”易变”的范畴, “工欲善其事,必先利其器”"></a><font color="#00CED1"> 器：工具，也是”易变”的范畴, “工欲善其事,必先利其器”</font></h5><p>工具的使用对人类的进化起到至关重要的作用，生产工具是人类进步的一大要素，用好“器”可以事半功倍。在分布式流存储里采用的器可分为：</p><ul><li><p>构建与运维工具：k8s、Docker, 部署，版本回滚、升级、发布，监控、告警等组件；</p></li><li><p>测试验证工具：集成测试的Jenkins, 单元测试的 Mock ， 以及A/B测试的方法论等；</p></li><li><p>此外企业平台提供的资源支持也可以属于器的范畴。</p></li></ul><h4 id="界：是约束，也是限制"><a href="#界：是约束，也是限制" class="headerlink" title=" 界：是约束，也是限制"></a><font color="#00CED1"> 界：是约束，也是限制</font></h4><p>技术思维模型里的三角形的三条边代表着“界” ，是技术边界也是技术约束与技术限制，对市场来说它是技术壁垒，对产品来说它是法律法规、是功能约束，对团队来说它是资源约束、是自我能力约束。分布式流存储的最大的技术优势也是最大的技术约束就是它是为 物联网、IT日志这样的数据格式而设计的，不是所有的数据类型存储都适用。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font color="#FF8C00">小结</font></h2><p>本系列文章讲述了四个思维模型： “技术思维模型、创新思维模型、商业思维模型以及产品思维模型”，再结合分布式流存储做了简单的举例分析。本文讲述”技术思维模型“，日拱一卒，功不唐捐，分享是最好的学习，与其跟随不如创新，希望这几个思维模型对大家有用。另作者能力与认知都有限，”我讲的，可能都是错的“[1]，欢迎大家拍砖留念。</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中科大硕，DELL EMC 资深首席工程师，主要从事分布式产品的交付、架构设计以及开发工作。</p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a><font color="#FF8C00">参考资料</font></h2><p>[1]《第二曲线创新》 李善友</p><p>[2]《如何在一分钟内用5个问题讲清你的商业模式》 中欧商业评论，关苏哲 </p><p>[3] Pravega.io</p>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>产品思维奇点图</title>
      <link href="/2019/10/21/distributed-product-architecture-daoist/"/>
      <url>/2019/10/21/distributed-product-architecture-daoist/</url>
      
        <content type="html"><![CDATA[<h2 id="产品思维奇点图"><a href="#产品思维奇点图" class="headerlink" title="产品思维奇点图"></a>产品思维奇点图</h2><p>理解技术、产品与商业是产品架构师的基本职责，架构思维、产品思维与商业思维是架构师的底层思维，就个人领悟来说技术与产品是其实不分家的，二者互补互利。</p><p>这里先放出一张我自己用的产品思维图（如下），接下来会写一篇文章详细解读这个产品思维模型，这张图我称之为产品思维奇点图，结合了“第一性原理”、“奇点理论”以及中国古朴的哲学，口诀是“四点一线五元组”。</p><p>四点分为“产品定位点、价值点、业务点以及奇点”，一线是指“能力线”，五元组是指 “势、道、法、术、器”，对应产品的“趋势、优势、劣势”，“本质、灵魂、规律、价值”，“方法论”，“技能”，“工具”。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/product/daoist/product-architecture-daoist.PNG" alt="产品架构奇点图"></p>]]></content>
      
      
      <categories>
          
          <category> product </category>
          
      </categories>
      
      
        <tags>
            
            <tag> product </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>重构工业物联网大数据处理平台的存储栈</title>
      <link href="/2019/06/23/bigdata-streaming-refactor-iot-platform/"/>
      <url>/2019/06/23/bigdata-streaming-refactor-iot-platform/</url>
      
        <content type="html"><![CDATA[<p>本文为《下一个分布式存储系统，为万物互联的智能世界而发》升级版。</p><h2 id="导言"><a href="#导言" class="headerlink" title="导言"></a><font color="#FF8C00">导言</font></h2><p>纵观人类历史，各种技术变革都是以人类活动为中心，然后发明各种工具。石器时代，原始人发明了石器以及用火从而提升了生活品质和社会文明。现代社会，人类为了解决各种寂寞空虚冷吃穿住用行、生理和心理上的各种需求从而发明了各种社交空间、社交工具、网络购物、生活服务APP等，为了更好的服务这些应用场景，挖掘这些场景所生产的数据的价值，从而有了今天的各种大数据技术。</p><p>在互联网时代，数据主要来源于网页、APP以及一些相应的日志系统，而在万物互联的世界，数据还可以来源于有各种传感器、工业设备、监控设备、检测设备、智能家居、自动驾驶等。大数据的四个特征：数据量、时效性、多样性、价值密度在万物互联的场景下被进一步的深化，这就意味着商业成本以及技术成本的增加。</p><p>理论奠定技术的基础，业务驱使技术的变革。在万物互联的智能时代，我们有一个愿景：<font color="#FF0000"> <strong>能够将万物互联下生成的海量原始数据转化为可用的信息以及行为决策，并且这个转换的时间差需要能够接近于零。</strong></font>通过现有技术的组合，技术人员打造了工业物联网平台从而希望能达成这个愿景。</p><h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a><font color="#FF8C00">动机</font></h2><p>现有的工业物联网大数据处理平台很多是基于开源的技术<font color="#00CED1"><strong>“D-I-Y”</strong></font>而来，它是一个”DIY“系统，往往为了一个功能而引入一个复杂的组件，这就容易造成平台只关注功能而忽略“质量与约束”，在复杂之上堆积复杂，致使客户商业成本、技术成本以及运维成本高昂。</p><p>从商业角度来说，在构建物联网大数据处理平台的时候，大家都用的开源的技术，构建出来的平台同质化严重，那么有个问题需要回答的就是：“大家都用的同样的开源技术，客户凭什么需要买单你的？”</p><p>从产品的角度来看，一个好的产品既能<font color="#00CED1"><strong>“顶天”</strong></font>，还能<font color="#00CED1"><strong>“立地”</strong></font>，它除了能有自己独到的灵魂与创新，还能将自己扎根于用户，替客户解决实际的生产问题，而不是又给客户带来新的问题。然而现有的工业物联网大数据处理平台除了给客户解决了一部分的生产问题，但是又引入了新的问题：成本高昂以及平台质量还往往难以达标。</p><font color="#00CED1"><strong>新的技术不仅可以来源于已有技术的组合与进化，还可以来自于对现有现象的理解与征服。</strong></font>因此，出于对现有的工业物联网平台的理解以及降低客户的商业成本、技术成本以及运维成本的目的，这里提出了重构工业物联网大数据平台存储栈的理念。<br><br><font> </font><h2 id="工业物联网平台"><a href="#工业物联网平台" class="headerlink" title="工业物联网平台"></a><font color="#FF8C00">工业物联网平台</font></h2><p>如下图所示，通常一个工业物联网平台是以<font color="#FF0000"> <strong>“云-管-端”</strong></font>三部分组成的，类似x86服务器主板南桥北桥的叫法，工业物联网平台也是如此，在“管”的左边跟外设传感器之类打交道的地方我们称之为“南向”，跟数据处理相关“管”的右边我们称之为“北向”。南向由各种传感器以及SCADA/PLC/HMI组成，负责数据的采集，然后数据再经过RTU、DTU、网关或路由传输到云端的工业大数据处理平台进行处理，从而完成监控、告警、预测性维护、分析等功能。</p><p>​                             </p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/streaming/iot_platform.PNG" alt="工业物联网平台"></p><h5 id="流数据-时序数据"><a href="#流数据-时序数据" class="headerlink" title="流数据/时序数据"></a><font color="#FF00FF">流数据/时序数据</font></h5><p>如下表所示，工业物联网平台南向传感器采集的数据，具有时间属性并且自带标签与数值，每条数据代表一个监测指标并且反应数值的变化，同时这些数据又随时间延续而无限增长，因此被称之为流数据或时序数据。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/streaming/iot_data_format.PNG" alt="时序数据"></p><p> 南向采集数据的设备虽然多种多样，然而本质上它们的数据格式是一样的，都由“timestamp,tags,metrics”这三部分组成。数据格式看上去是很简单的，但是对于数据处理系统来说复杂度的来源在于：</p><ol><li>数据自带时间戳具有时间有效性，这意味着数据处理的实时性;</li><li>数据都是小数据，这意味着数据存储系统需要对此进行专门的高性能设计；</li><li>数据随时间延续而无限增长，这意味着数据的无限性；</li><li>数据到达的速度有快有慢、负载有高有低，这意味着灵活又细粒度的资源弹性需求；</li><li>数据有序、无序、持久化以及复杂的传输环境而又要保证数据处理结果的唯一正确性。</li></ol><p>这是几个特性转换成存储技术的语义对应着：<font color="#FF0000"> <strong>实时性、高性能、无限性、可伸缩性以及恰好一次：持久化、有序、一致性以及事务。</strong></font>从<font color="#FF0000"> <strong>存储的视角</strong></font>来说，每种类型的数据都有其原生的属性和需求，对应有最佳的适用场景以及最合适的存储系统。那么目前又有哪种存储系统最适合用于<font color="#FF0000"> <strong>“流数据”</strong></font>呢？正如当前技术条件下最适合<font color="#FF0000"> <strong>“流数据”</strong></font>计算的是类似Flink这样的分布式流计算应用，最适合“流数据”的我们认为应当是专门针对流数据而设计的<font color="#00CED1"><strong>分布式流存储系统。</strong></font> </p><h5 id="工业大数据处理"><a href="#工业大数据处理" class="headerlink" title="工业大数据处理"></a><font color="#FF00FF">工业大数据处理</font></h5><p>工业物联网平台北向负责大数据的处理，万物互联场景下无限量的数据给数据处理技术带来巨大的挑战与压力，不同的应用场景意味着不同的数据处理要求与复杂度，要把这些不同的甚至矛盾的数据处理要求都很好的综合在一个大数据处理系统里，对现有的大数据处理技术来说是个非常大的挑战，比如无人车的处理要求毫秒甚至纳秒级的数据处理实时性、而有些工业设备数据只需要分析历史数据，要让一个大数据处理系统既能能处理历史数据又能提供毫秒级甚至纳秒级的实时性处理能力还能应对各种不同格式不同传输场景的数据，而且每种数据处理都能达到这些应用场景原生指标的处理需求，相信这样的场景对工程技术人员来说是个很大的挑战。为了解决上述问题，按照现有的成熟的技术能力，通常开发人员采用类似Lambda架构（如下图）这样的大数据处理平台组合了各种复杂的中间件来达成这个数据处理的目标。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/streaming/streaming-bigdata-lambda-arch.PNG" alt="Lambda架构"></p><p>Lambda架构即支持批处理也支持实时处理，能应对数据的多样性、具有容错功能、复杂性分离、能处理流式数据也能处理历史数据等优点，但是缺点也很明显：批处理一套独立的数据处理路径，实时处理又一套数据处理路径，然后还要合并结果再输出展示，同时系统里同样的数据存在存储多份的问题，比如同样的数据在Elasticsearch里有、HDFS里有、ceph里有、Kafka里也有，除了这些甚至还存在其他一些复杂的存储组件，而且同样的数据还都是多份冗余的，因此存储成本太高太过于复杂。Lambda架构里为了提供一个功能却引入一个组件，在复杂之上堆积复杂，存储成本、开发与运维成本都太过于复杂。</p><p>那么应当如何解决Lambda架构带来的这些缺点？<font color="#FF0000"><strong>以数据流向为核心</strong></font>重构大数据处理平台是一个比较好的方案，它具体包括数据的采集、聚合、传输、处理、展示等。依据这种设计理念我们可以推出一个端到端的原生的流式大数据处理平台：原生的流式计算加上一个原生的流式存储并且可以平衡商业成本与技术成本。</p><p>流式计算可以采用Flink，然而并没有发现当前有合适的流式存储可以使用，因此，综合思考万物互联场景下的数据处理场景也需要一个原生的分布式流存储系统，<font color="#FF0000"><strong>重构Lambda架构里的存储栈</strong></font>，使得分布式流计算加上分布式流存储即为原生的流式大数据处理系统，同时还能很好的平衡商业成本与技术成本之间的关系。</p><h2 id="设计思路"><a href="#设计思路" class="headerlink" title="设计思路"></a><font color="#FF8C00">设计思路</font></h2><h3 id="数据中台"><a href="#数据中台" class="headerlink" title="数据中台"></a><font color="#00CED1">数据中台</font></h3><p>通常数据中台的目标是：<font color="#FF0000"><strong>“治理与聚合数据，将数据抽象封装成服务提供给前台业务使用”</strong></font>，因此，数据的治理、聚合以及抽象是数据中台的关键点。当前的大数据处理平台，不管是Kappa架构还是lambda架构，数据的存储都是多组件化、多份化的。比如同样的数据在Kafka里有、在HDFS里有、在Elasticsearch里又有，有些用户还使用了更多的存储中间件，而且这些数据还是多份冗余的。这一方面增加了数据的存储成本，另一方面也降低了数据的可信性、可靠性、合规性，给数据标准化以及数据的重复利用带来了困难，不利于数据的分享、合规、降低成本以及安全可靠地支持业务和决策。因此需要对数据进行治理、聚合以及抽象。通过使用分布式流存储，大数据处理平台的架构可以进化成<font color="#FF0000"><strong>”分布式流计算+ 分布式流存储“</strong></font>这样的原生流式数据处理平台架构，这也体现了<font color="#FF0000"><strong>“数据中台”</strong></font>的理念。</p><h3 id="流原生架构"><a href="#流原生架构" class="headerlink" title="流原生架构"></a><font color="#00CED1">流原生架构</font></h3><p>依据<font color="#FF0000"> <strong>“流原生”</strong> </font>的架构设计哲学以及数据中台的理念，这里提出<font color="#FF0000"><strong>”分布式流计算+ 分布式流存储“</strong></font>这样的原生流式工业大数据处理平台的架构理念，不同于Lambda架构与Kappa架构，流原生架构最主要的工作是对数据进行了治理、聚合与抽象，使得工业大数据平台的计算层通过统一的数据API接口调用底层的流存储系统。如下图所示，Spark,Flink以及检索系统等都调用统一的流存储接口，从而减少了平台复杂度以及降低数据存储成本和运维成本。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/streaming/stream_native_platform.PNG" alt="流原生架构"></p><h3 id="算子编排"><a href="#算子编排" class="headerlink" title="算子编排"></a><font color="#00CED1">算子编排</font></h3><p>工业大数据处理平台虽然很复杂，然而抽象到最后就一个简单的数学公式：<font color="#FF0000"><strong>“Y = F(X)”</strong></font>，输入数据x，经过F算子计算再输出结果Y，数学表达式并不复杂，如同质能方程E=mc²，但是从理论到落地还有一个浩大的工程，Y=F(x)其复杂度主要来源于：</p><ol><li><p>每个数据算子都认为是一个Y=F(x)，需要对无数个这样的算子进行高性能的计算，算子无限性；</p></li><li><p>需要对无限个随时可能乱序的Y=F(x)算子进行编排、组合、拆分，算子编排。</p></li><li>需要对无限个Y=F(x)算子的中间结果进行持久化、保序，以及保证计算结果的正确性，算子结果确定性；</li></ol><p>因此需要一个专门的数据处理架构来解决这些复杂度。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/streaming/stream_platform.PNG" alt="流式架构"></p><p>如上图所示，“流原生”的Flink计算加上“流原生”的存储管道组成了“流原生”的大数据处理平台。数据从分布式流存储输入经过map算子计算，输出中间计算结果到分布式流存储里，数据又从分布式流存储里读入到Filter算子里，再经过计算，中间结果放到了分布式流存储里，再最后的计算结果经过Apply算子的计算放到了目的地的分布式流存储里。这个过程体现了算子编排和管道式编程的设计哲学，在这里分布式流存储起了大数据处理平台里的管道的作用。</p><h2 id="分布式流存储"><a href="#分布式流存储" class="headerlink" title="分布式流存储"></a><font color="#FF8C00">分布式流存储</font></h2><p>分布式流存储的产品定位是给万物互联这样的应用场景服务的，从技术角度来看它具有自身的特点，正如标题里提到的三个关键词：<font color="#FF8C00"> <strong>“分布式”、“流”、“存储”</strong></font>。首先是分布式的，它具有分布式系统本身所具有的一切能力，接着表示是专门给流式数据设计和实现的，最后的存储表示的是一个原生的存储解决方案，它讲究数据的<font color="#FF8C00"> <strong>可靠性、持久化、一致性、资源隔离等</strong></font>，它从<font color="#FF0000"> <strong>存储的视角</strong></font>处理流数据。分布式流存储针对 <strong>“流数据”</strong> 的自身属性以及相应的特殊的业务需求场景做了专门的设计与实现，下面从<font color="#FF8C00"> <strong>命名空间、业务场景、无限性、可伸缩性、恰好一次、字节流、数据管道、租户隔离、海量小文件</strong></font>的角度依据 <strong>最佳实践原则</strong> 讲述了为什么需要专门设计和实现一个流式存储系统。</p><h3 id="命名空间"><a href="#命名空间" class="headerlink" title="命名空间"></a><font color="#00CED1">命名空间</font></h3><p>通常，块存储系统以<font color="#FF0000"><strong>分区、目录、文件</strong></font>，文件存储系统以<font color="#FF0000"><strong>目录、文件</strong></font>，以及对象存储以<font color="#FF0000"><strong>租户、桶、对象</strong></font>来定义数据的存储路径以及命名空间，而流存储系统则以<font color="#FF0000"><strong>范围(scope)、流(stream)、段(segment)、事件(event)</strong></font>来描述数据的存储路径以及命名空间。</p><div align="center"> <table><thead><tr><th>类型</th><th>命名空间</th></tr></thead><tbody><tr><td>块存储</td><td>分区、目录、文件</td></tr><tr><td>文件存储</td><td>目录、文件</td></tr><tr><td>对象存储</td><td>租户、桶、对象</td></tr><tr><td>流存储</td><td>范围、流、段、事件</td></tr></tbody></table><div align="left"> <p>在流存储系统里，如下图所示，数据的组织形式被抽象成范围、流、段和事件，范围由流组成，流由段组成，段由事件组成，事件由字节(bytes)组成。</p><div align="center"> <p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/pravega-infoq-scope-stream.png" alt="流的组成"></p><div align="left"> <h3 id="业务场景"><a href="#业务场景" class="headerlink" title="业务场景"></a><font color="#00CED1">业务场景</font></h3><p>在自动驾驶的场景里采用分布式流存储，我们可以这样处理自动驾驶的数据：给每一辆无人车定义一个1TB存储空间的范围，车上的每个传感器都归属于一个流，传感器上报的事件都在段内持久化。再假设每辆车都有1000个传感器（实际情况只多不少），那么10万辆车就需要定义1亿个流，可以想象要进行这种规模的隔离也就只有这种专门针对流数据而设计的流存储系统能够支持。</p><p>在工业厂房的场景下，还可以这样定义工业设备的数据：给一个厂房里的每台设备定义一个范围，每台设备里的每个传感器都对应一个流，传感器上传的事件数据保存在流内的段里，这样就很方便的对工业设备进行了大规模的租户数据隔离。</p><p>因此，以<font color="#FF0000"><strong>“范围、流、段、事件”</strong></font>的方式很方便的进行了大规模的租户隔离保证了用户信息安全同时又进行了存储资源配额的隔离。</p><h3 id="数据无限性"><a href="#数据无限性" class="headerlink" title="数据无限性"></a><font color="#00CED1">数据无限性</font></h3><p>无限性是分布式流存储最为重要的设计原则。从流数据的角度来看，数据是大量、快速、连续而又无限的，这就给流存储系统的设计与实现带来极大的困难，无限的数据使得存储系统必须能支持连续且无限规模的数据流，光这一点就对存储系统的可扩展性要求非常的高，同时还要求存储系统能够根据到达的数据量动态而又优雅地进行扩容与缩容。从技术与成本的角度来看，数据无限性意味着冷热数据分离，长期不用的数据淘汰到长期存储系统里，热点数据需要缓存，同时还需要能支持历史数据的读取与实时数据的读取与写入。</p><h3 id="可伸缩性"><a href="#可伸缩性" class="headerlink" title="可伸缩性"></a><font color="#00CED1">可伸缩性</font></h3><p>可伸缩性也是分布式流存储最为重要的设计原则之一，而且流存储里的可伸缩性要求还是自动化的资源细粒度的可伸缩。通常，在云原生的场景下，资源的缩放是以主机、虚机或容器为单位的，这样的缩放对流存储来说粒度太大。在流存储的场景下需要能够以数据的<strong>“流段”</strong>为单位，比如一个流段2MB，那么就需要能支持一次自动扩容或缩容2MB的存储空间。另外在流存储里还要求写入与读取对数据子集的操作是解耦分离的，并且写入与读取二者之间跟数据流段还要有一个合理的平衡。</p><h3 id="恰好一次"><a href="#恰好一次" class="headerlink" title="恰好一次"></a><font color="#00CED1">恰好一次</font></h3><p>恰好一次也是分布式流存储最为重要的设计原则之一，恰好一次意味着数据的可持久化、有序、一致性以及事务性的支持。持久性意味着一旦得到确认，即使存储组件发生故障，写入的数据也不会丢失。有序意味着读客户端将严格按照写入的顺序处理数据。一致性意味着所有的读客户端即使面对存储故障、网络故障也都会看到相同的有序数据视图。事务性写入对于保证Flink这样的计算应用处理结果的完全正确是非常必要的。</p><h3 id="字节流"><a href="#字节流" class="headerlink" title="字节流"></a><font color="#00CED1">字节流</font></h3><p>分布式流存储里采用字节流的格式组织数据而不是像消息系统里采用消息报文的方式，这意味着接口的通用性。二进制的字节流是与数据格式无关的，字节流可以组成事件封装在分布式存储的流段里。而消息系统里数据是消息头消息体的格式封装的，在兼容性上不如字节流。</p><h3 id="数据管道"><a href="#数据管道" class="headerlink" title=" 数据管道"></a><font color="#00CED1"> 数据管道</font></h3><p>在存储界通常喜欢用跑车、卡车、渡轮来比喻块存储、文件存储以及对象存储，打个比方来说块存储类似跑车：极快、极稳、装的人少、成本高；文件存储类似卡车：快、稳、装的人比跑车多，但是没跑车那么快；对象存储类似渡轮：可以装非常多的货，讲究量大、成本低；那么分布式流存储像什么呢？ 在我们的定义里它就像管道：<font color="#FF0000"><strong>数据如同流水一般流过管道，又快又稳源源不断而又永无止境</strong>。</font></p><h3 id="租户隔离"><a href="#租户隔离" class="headerlink" title="租户隔离"></a><font color="#00CED1">租户隔离</font></h3><p>分布式流存储从一开始设计的时候就将”租户隔离“作为其基本特性进行实现，”隔离“是分布式流存储的最基本的特性之一，在分布式流存储里租户隔离不只是租户B绝对不能看的到租户A的任何信息这样的信息安全层面的隔离，它支持范围、流、段、事件层面的隔离还将支持的租户规模作为设计的目标之一，在分布式流存储里单集群需要能支持千万量级起的租户数，另外还有资源、命名、可视空间、权限以及服务质量层面的隔离。</p><h3 id="海量小文件"><a href="#海量小文件" class="headerlink" title="海量小文件"></a><font color="#00CED1">海量小文件</font></h3><p>对巨量小文件的支持是分布式流存储的设计原则之一。正如前面提到的，万物互联下的海量数据来源于传感器，而传感器上传的数据都是类似温度、地理位置、告警信息这样的几个字节几个字节的小数据，这就意味着在万物互联的场景下会有巨量的小数据上传，而且90%以上的数据操作行为都是写入。为了保证数据写入的性能以及可靠性、正确性、持久性以及保证介质的使用寿命降低成本，这也需要存储系统针对这种业务场景进行专门的设计。</p><p>在分布式流存储里每个事件第一步是被仅附加写入一个缓存的段内进行封装的，在段达到一定的尺寸（比如64MB）后会被封闭不再写入，这时再将整个段写入下一级的持久化存储里。通过这样的设计，实现小数据在缓存里封装成大块的数据，再将大块数据写入持久化存储设备的方式保证了存储系统整体的性能。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font color="#FF8C00">小结</font></h2><p>电影《一代宗师》里提到习武之人有三个境界：<font color="#00CED1"><strong>“见自己，见天地，见众生”</strong></font>。做技术做产品也同样如是，“三见”如同一体三面不可分割，认知上从关注自己到关注格局创新，再扎根到用户当中替用户解决有价值的实际问题。现有的工业物联网大数据处理平台有创新也有替客户解决了部分工业数据处理的难题，但是还是属于一个”DIY“的系统，离产品化还有距离，因此需要我们继续扎根下去替客户解决新的实际问题。</p><p>综上所述，在万物互联的智能世界里，为了实现将海量数据近实时转化成信息和决策的愿景，除了流式计算应用还需要一个流式存储系统，未来已来，已有开源的分布式流存储系统正走在这条路上。另本文仅为作者愚见，与任何组织机构无关，作者能力也很有限，如有不足之处欢迎留言批评指正。</p><h2 id="问题思考"><a href="#问题思考" class="headerlink" title="问题思考"></a><font color="#FF8C00">问题思考</font></h2><p>最后给大家留一个思考题：<font color="#00CED1"><strong>如果让你来设计一个工业物联网平台产品，你会如何定义它的产品灵魂？</strong></font></p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中科大硕，10年+数据相关经验，主要工作背景为分布式系统、存储、缓存、微服务、云计算以及工业物联网大数据，现就职于DELL EMC。个人技术博客：<a href="https://changping.me" target="_blank" rel="noopener">https://changping.me</a></p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a> ，可以自由阅读、分享、转发、复制、分发等，限制是需署名、非商业使用（以获利为准）以及禁止演绎。</p></div></div></div></div>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>下一个分布式存储系统，为万物互联的智能世界而发</title>
      <link href="/2019/05/24/bigdata-streaming-the-next-storage/"/>
      <url>/2019/05/24/bigdata-streaming-the-next-storage/</url>
      
        <content type="html"><![CDATA[<p>如果说互联网和云计算使得对象存储在存储市场上与块存储、文件存储三分天下，相应的业务需求直接奠定了对象存储与块存储、文件存储并列存储江湖一哥的地位，那么接下来也许我们需要为下一场数据变革的大事做好准备 – <font color="#00CED1"><strong>万物互联这样的商业场景将给数据存储带来极大的商业挑战和技术挑战。</strong></font></p><h2 id="万物互联下的数据"><a href="#万物互联下的数据" class="headerlink" title="万物互联下的数据"></a><font color="#FF8C00">万物互联下的数据</font></h2><p>纵观人类历史，各种技术变革都是以人类活动为中心，然后发明各种工具。石器时代，原始人发明了石器以及用火从而提升了生活品质和社会文明。现代社会，人类为了解决各种寂寞空虚冷吃穿住用行、生理和心理上的各种需求从而发明了各种社交空间、社交工具、网络购物、生活服务APP等，为了更好的服务这些应用场景，挖掘这些场景所生产的数据的价值，从而有了今天的各种大数据技术。</p><p>在互联网时代，数据主要来源于网页、APP以及一些相应的日志系统，而在万物互联的世界，数据还可以来源于有各种传感器、工业设备、监控设备、检测设备、智能家居、自动驾驶等。大数据的四个特征：数据量、时效性、多样性、价值密度在万物互联的场景下被进一步的深化，这就意味着商业成本以及技术成本的增加。</p><p>理论奠定技术的基础，业务驱使技术的变革。在万物互联的智能时代，我们有一个愿景：<font color="#FF0000"> <strong>能够将万物互联下生成的海量原始数据转化为可用的信息以及行为决策，并且这个转换的时间差需要能够接近于零。</strong></font>而需要实现这个愿景，从技术角度来看，需要有计算层面的解决方案也需要有存储层面的，如今在计算层面已经有Flink、Spark等这类成熟的分布式计算应用，然而在存储层面还没有。</p><h2 id="流数据与流存储"><a href="#流数据与流存储" class="headerlink" title="流数据与流存储  "></a><font color="#FF8C00">流数据与流存储  </font></h2><p>在万物互联的场景下，各种传感器以及设备生成的数据有其原生的属性，这种数据自带时间戳、实时性要求高，而且是<font color="#FF0000"> <strong>“流数据”</strong></font>。</p><p>首先流数据在百度百科里是这样被定义的：</p><blockquote><p>流数据是一组顺序、大量、快速、连续到达的数据序列，一般情况下，数据流可被视为一个随时间延续而无限增长的动态数据集合。应用于网络监控、传感器网络、航空航天、气象测控和金融服务等领域。</p></blockquote><p>从数据的生产与传输场景来看流数据具有几个与众不同的带有破坏性的特性：</p><ol><li>数据随时间延续而无限增长，这意味着数据的无限性；</li><li>数据到达的速度有快有慢、负载有高有低，这意味着灵活又细粒度的资源弹性需求；</li><li>数据有序、无序、持久化以及复杂的传输环境而又要保证数据处理结果的唯一正确性。</li></ol><p>这是三个特性转换成存储技术的语义对应着：<font color="#FF0000"> <strong>无限性、可伸缩性以及恰好一次：持久化、有序、一致性以及事务。</strong></font></p><p>从<font color="#FF0000"> <strong>存储的视角</strong></font>来说，每种类型的数据都有其原生的属性和需求，对应有最佳的适用场景以及最合适的存储系统。跑在数据库里的数据对实时性和可靠性要求非常的高，因此适合采用块存储系统。文件共享场景下需要向用户共享文件，多个用户可以共享读取一个文件，因此适合采用文件存储系统。而互联网网页与APP里的文件、图像、视频可以看作一个个的数据对象又需要租户隔离以及无限扩展，因此又非常适合采用对象存储系统。那么目前又有哪种存储系统最适合用于<font color="#FF0000"> <strong>“流数据”</strong></font>呢？</p><p>正如当前技术条件下最适合<font color="#FF0000"> <strong>“流数据”</strong></font>计算的是类似Flink这样的分布式流计算应用，最适合“流数据”的应当是<font color="#00CED1"><strong>分布式流存储系统。</strong></font> </p><h2 id="分布式流存储系统"><a href="#分布式流存储系统" class="headerlink" title="分布式流存储系统"></a><font color="#FF8C00">分布式流存储系统</font></h2><h3 id="产品定位"><a href="#产品定位" class="headerlink" title="产品定位"></a><font color="#00CED1">产品定位</font></h3><p>分布式流存储系统的产品定位是给万物互联这样的应用场景服务的，从技术角度来看它具有自身的特点，正如标题里提到的三个关键词：<font color="#FF8C00"> <strong>“分布式”、“流”、“存储”</strong></font>。首先是分布式的，它具有分布式系统本身所具有的一切能力，接着表示是专门给流式数据设计和实现的，最后的存储表示的是一个原生的存储解决方案，它讲究数据的<font color="#FF8C00"> <strong>可靠性、持久化、一致性、资源隔离等</strong></font>，它从<font color="#FF0000"> <strong>存储的视角</strong></font>处理流数据。分布式流存储针对 <strong>“流数据”</strong> 的自身属性以及相应的特殊的业务需求场景做了专门的设计与实现，下面从<font color="#FF8C00"> <strong>命名空间、业务场景、无限性、可伸缩性、恰好一次、字节流、数据管道、租户隔离、海量小文件、数据治理、流式架构</strong></font>的角度依据 <strong>最佳实践原则</strong> 讲述了为什么需要专门设计和实现一个流式存储系统。</p><h3 id="命名空间"><a href="#命名空间" class="headerlink" title="命名空间"></a><font color="#00CED1">命名空间</font></h3><p>通常，块存储系统以<font color="#FF0000"><strong>分区、目录、文件</strong></font>，文件存储系统以<font color="#FF0000"><strong>目录、文件</strong></font>，以及对象存储以<font color="#FF0000"><strong>租户、桶、对象</strong></font>来定义数据的存储路径以及命名空间，而流存储系统则以<font color="#FF0000"><strong>范围(scope)、流(stream)、段(segment)、事件(event)</strong></font>来描述数据的存储路径以及命名空间。</p><div align="center"> <table><thead><tr><th>类型</th><th>命名空间</th></tr></thead><tbody><tr><td>块存储</td><td>分区、目录、文件</td></tr><tr><td>文件存储</td><td>目录、文件</td></tr><tr><td>对象存储</td><td>租户、桶、对象</td></tr><tr><td>流存储</td><td>范围、流、段、事件</td></tr></tbody></table><div align="left"> <p>在流存储系统里，如下图所示，数据的组织形式被抽象成范围、流、段和事件，范围由流组成，流由段组成，段由事件组成，事件由字节(bytes)组成。</p><div align="center"> <p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/pravega-infoq-scope-stream.png" alt="流的组成"></p><div align="left"> <h3 id="业务场景"><a href="#业务场景" class="headerlink" title="业务场景"></a><font color="#00CED1">业务场景</font></h3><h5 id="可穿戴设备、自动驾驶与工业厂房"><a href="#可穿戴设备、自动驾驶与工业厂房" class="headerlink" title=" 可穿戴设备、自动驾驶与工业厂房"></a><font color="#FF00ff"> 可穿戴设备、自动驾驶与工业厂房</font></h5><p>可以想象一下这样的业务场景：某个商家销售了几千万个智能手表，这些智能手表可以记录每个用户每天走了多少步，同时还可以分析过往的历史数据，用柱状图给用户展示历史数据，如下图所示：</p><div align="center"> <p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/pravega-infoq-watch.png" alt="步数分析"></p><div align="left">  <p>考虑到信息安全，用户A是不能看到用户B的数据的，那么就需要按智能手表为单位进行租户隔离，这种的场景下就有几千万个租户，同时每个租户还有自己的存储空间配额，比如给每个智能手表分配5GB 存储空间。光是这样的租户隔离场景，依据<strong>最佳实践</strong>的系统设计原则，不管是块存储系统、文件存储系统、对象存储系统还是Kafka这样的消息系统，按他们本身的隔离特性以及支持的租户规模都是难以在单个系统里支持这样的租户隔离场景。但是用流存储来实现就很方便，比如以智能手表的业务场景为例：</p><ul><li>默认分配5GB存储空间给一个智能手表，然后定义一个智能手表类型的命名空间用于与其他智能设备进行隔离，给每个智能手表分配一个流，每个智能手表上报的字节数据以事件为单位存储在流内的段里。</li><li>也可以这样来定义：给每个智能手表分配一个5GB 存储空间的命名空间，手表里的每个传感器都对应一个流，每个传感器以事件为单位上报字节数据存储到流的段里。</li></ul><p>还可以想象一下这样的业务场景：自动驾驶。采用分布式流存储的话，我们可以这样处理自动驾驶的数据：给每一辆无人车定义一个1TB存储空间的范围，车上的每个传感器都归属于一个流，传感器上报的事件都在段内持久化。再假设每辆车都有1000个传感器（实际情况只多不少），那么10万辆车就需要定义1亿个流，可以想象要进行这种规模的隔离也就只有这种专门针对流数据而设计的流存储系统能够支持。</p><p>在工业互联网的场景下，还可以这样定义工业设备的数据：给一个厂房里的每台设备定义一个范围，每台设备里的每个传感器都对应一个流，传感器上传的事件数据保存在流内的段里，这样就很方便的对工业设备进行了大规模的租户数据隔离。</p><p>因此，以<font color="#FF0000"><strong>“范围、流、段、事件”</strong></font>的方式很方便的进行了大规模的租户隔离保证了用户信息安全同时又进行了存储资源配额的隔离。</p><h5 id="大数据处理平台"><a href="#大数据处理平台" class="headerlink" title=" 大数据处理平台"></a><font color="#FF00FF"> 大数据处理平台</font></h5><p>万物互联场景下无限量的数据给数据处理技术带来巨大的挑战与压力，不同的应用场景意味着不同的数据处理要求与复杂度，要把这些不同的甚至矛盾的数据处理要求都很好的综合在一个大数据处理系统里，对现有的大数据处理技术来说是个非常大的挑战，比如无人车的处理要求毫秒甚至纳秒级的数据处理实时性、而有些工业设备数据只需要分析历史数据，要让一个大数据处理系统既能能处理历史数据又能提供毫秒级甚至纳秒级的实时性处理能力还能应对各种不同格式不同传输场景的数据，而且每种数据处理都能达到这些应用场景原生指标的处理需求。相信这样的场景对工程技术人员来说是个很大的挑战。为了解决上述问题，按照现有的成熟的技术能力，通常开发人员采用类似Lambda架构（如下图）这样的大数据处理平台来处理大数据。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/streaming/streaming-bigdata-lambda-arch.PNG" alt="Lambda架构"></p><p>Lambda架构即支持批处理也支持实时处理，能应对数据的多样性、具有容错功能、复杂性分离、能处理流式数据也能处理历史数据等优点，但是缺点也很明显：<strong>批处理一套独立的数据处理路径，实时处理又一套数据处理路径，然后还要合并结果再输出展示，同时系统里同样的数据存在存储多份的问题，比如同样的数据在Elasticsearch里有、HDFS里有、ceph里有、Kafka里也有，除了这些甚至还存在其他一些复杂的存储组件，而且同样的数据还都是多份冗余的，因此存储成本太高太过于复杂。Lambda架构里为了提供一个功能却引入一个组件，在复杂之上堆积复杂，存储成本、开发与运维成本都太过于复杂。</strong></p><p>那么应当如何解决Lambda架构带来的这些缺点？<font color="#FF0000"><strong>以数据流向为核心</strong></font>重构大数据处理平台是一个比较好的方案，它具体包括数据的采集、聚合、传输、缓存、持久化、处理、展示等。依据这种设计理念我们可以推出一个端到端的原生的流式大数据处理平台：原生的流式计算加上一个原生的流式存储并且可以平衡商业成本与技术成本。</p><p>流式计算可以采用Flink，然而并没有发现当前有合适的流式存储可以使用，如果采用Flink加上传统的文件存储或者块存储、对象存储的方式，也只能认为是半原生的大数据处理平台：<font color="#FF0000"><strong>计算是原生的流式计算而存储却不是原生的流式存储</strong></font>。</p><p>因此，综合思考万物互联场景下的数据处理场景也需要一个原生的分布式流存储系统，<font color="#FF0000"><strong>重构Lambda架构里的存储栈</strong></font>，使得分布式流计算加上分布式流存储即为原生的流式大数据处理系统，同时还能很好的平衡商业成本与技术成本之间的关系。</p><h3 id="数据无限性"><a href="#数据无限性" class="headerlink" title="数据无限性"></a><font color="#00CED1">数据无限性</font></h3><p>无限性是分布式流存储最为重要的设计原则。从流数据的角度来看，数据是大量、快速、连续而又无限的，这就给流存储系统的设计与实现带来极大的困难，无限的数据使得存储系统必须能支持连续且无限规模的数据流，光这一点就对存储系统的可扩展性要求非常的高，同时还要求存储系统能够根据到达的数据量动态而又优雅地进行扩容与缩容。从技术与成本的角度来看，数据无限性意味着冷热数据分离，长期不用的数据淘汰到长期存储系统里，热点数据需要缓存，同时还需要能支持历史数据的读取与实时数据的读取与写入。</p><h3 id="可伸缩性"><a href="#可伸缩性" class="headerlink" title="可伸缩性"></a><font color="#00CED1">可伸缩性</font></h3><p>可伸缩性也是分布式流存储最为重要的设计原则之一，而且流存储里的可伸缩性要求还是自动化的资源细粒度的可伸缩。通常，在云原生的场景下，资源的缩放是以主机、虚机或容器为单位的，这样的缩放对流存储来说粒度太大。在流存储的场景下需要能够以数据的<strong>“流段”</strong>为单位，比如一个流段2MB，那么就需要能支持一次自动扩容或缩容2MB的存储空间。另外在流存储里还要求写入与读取对数据子集的操作是解耦分离的，并且写入与读取二者之间跟数据流段还要有一个合理的平衡。</p><h3 id="恰好一次"><a href="#恰好一次" class="headerlink" title="恰好一次"></a><font color="#00CED1">恰好一次</font></h3><p>恰好一次也是分布式流存储最为重要的设计原则之一，恰好一次意味着数据的可持久化、有序、一致性以及事务性的支持。持久性意味着一旦得到确认，即使存储组件发生故障，写入的数据也不会丢失。有序意味着读客户端将严格按照写入的顺序处理数据。一致性意味着所有的读客户端即使面对存储故障、网络故障也都会看到相同的有序数据视图。事务性写入对于保证Flink这样的计算应用处理结果的完全正确是非常必要的。</p><h3 id="字节流"><a href="#字节流" class="headerlink" title="字节流"></a><font color="#00CED1">字节流</font></h3><p>分布式流存储里采用字节流的格式组织数据而不是像消息系统里采用消息报文的方式，这意味着接口的通用性。二进制的字节流是与数据格式无关的，字节流可以组成事件封装在分布式存储的流段里。而消息系统里数据是消息头消息体的格式封装的，在兼容性上不如字节流。</p><h3 id="数据管道"><a href="#数据管道" class="headerlink" title=" 数据管道"></a><font color="#00CED1"> 数据管道</font></h3><p>在存储界通常喜欢用跑车、卡车、渡轮来比喻块存储、文件存储以及对象存储，打个比方来说块存储类似跑车：极快、极稳、装的人少、成本高；文件存储类似卡车：快、稳、装的人比跑车多，但是没跑车那么快；对象存储类似渡轮：可以装非常多的货，讲究量大、成本低；那么分布式流存储像什么呢？ 在我们的定义里它就像管道：<font color="#FF0000"><strong>数据如同流水一般流过管道，又快又稳源源不断而又永无止境</strong>。</font></p><h3 id="租户隔离"><a href="#租户隔离" class="headerlink" title="租户隔离"></a><font color="#00CED1">租户隔离</font></h3><p>分布式流存储从一开始设计的时候就将”租户隔离“作为其基本特性进行实现，”隔离“是分布式流存储的最基本的特性之一，在分布式流存储里租户隔离不只是租户B绝对不能看的到租户A的任何信息这样的信息安全层面的隔离，它支持范围、流、段、事件层面的隔离还将支持的租户规模作为设计的目标之一，在分布式流存储里单集群需要能支持千万量级起的租户数，另外还有资源、命名、可视空间、权限以及服务质量层面的隔离。</p><h3 id="海量小文件"><a href="#海量小文件" class="headerlink" title="海量小文件"></a><font color="#00CED1">海量小文件</font></h3><p>对巨量小文件的支持是分布式流存储的设计原则之一。正如前面提到的，万物互联下的海量数据来源于传感器，而传感器上传的数据都是类似温度、地理位置、告警信息这样的几个字节几个字节的小数据，这就意味着在万物互联的场景下会有巨量的小数据上传，而且90%以上的数据操作行为都是写入。为了保证数据写入的性能以及可靠性、正确性、持久性以及保证介质的使用寿命降低成本，这也需要存储系统针对这种业务场景进行专门的设计。</p><p>在分布式流存储里每个事件第一步是被仅附加写入一个缓存的段内进行封装的，在段达到一定的尺寸（比如64MB）后会被封闭不再写入，这时再将整个段写入下一级的持久化存储里。通过这样的设计，实现小数据在缓存里封装成大块的数据，再将大块数据写入持久化存储设备的方式保证了存储系统整体的性能。</p><h3 id="数据治理"><a href="#数据治理" class="headerlink" title="数据治理"></a><font color="#00CED1">数据治理</font></h3><p>当前的大数据处理平台，不管是Kappa架构还是lambda架构，数据的存储都是多组件化、多份化的。比如同样的数据在Kafka里有、在HDFS里有、在Elasticsearch里又有，有些用户还使用了更多的存储中间件，而且这些数据还是多份冗余的。这一方面增加了数据的存储成本，另一方面也降低了数据的可信性、可靠性、合规性，给数据标准化以及数据的重复利用带来了困难，不利于数据的分享、合规、降低成本以及安全可靠地支持业务和决策。数据治理也是分布式流存储的基本设计原则之一，通过使用分布式流存储，大数据处理平台的架构可以进化成<font color="#FF0000"><strong>”分布式流计算+ 分布式流存储“</strong></font>这样的原生流式数据处理平台架构。</p><h3 id="流式架构"><a href="#流式架构" class="headerlink" title="流式架构"></a><font color="#00CED1">流式架构</font></h3><p>下图体现了<font color="#FF0000"><strong>”分布式流计算+ 分布式流存储“</strong></font>这样的原生流式大数据处理平台的架构理念。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/streaming/streaming-bigdata-processor.PNG" alt="流式架构"></p><p>这个架构体现了<font color="#FF0000"> <strong>“流原生”(stream native)式</strong> </font>的设计哲学，“流原生”的计算加上“流原生”的存储管道组成了“流原生”的大数据处理平台。数据从分布式流存储输入经过map算子计算，输出中间计算结果到分布式流存储里，数据又从分布式流存储里读入到Filter算子里，再经过计算，中间结果放到了分布式流存储里，再最后的计算结果经过聚合算子的计算放到了目的地的分布式流存储里。这个过程体现了算子编排和管道式编程的设计哲学，在这里分布式流存储起了大数据处理平台里的管道的作用。</p><p>同时，在分布式流存储里数据的存储单位是流段，当输入的数据速率或者负载增加时，流段就会自动扩容，通过流协议联动，流计算应用的算子也相应扩容。相应的，如果输入的数据速率或负载降低，流段就自动收缩，通过流协议联动，流计算应用的算子也相应的缩容，所有这些行为都是自动完成的，无需人工干预，这种行为体现了分布式流存储的细粒度可伸缩性。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font color="#FF8C00">小结</font></h2><p>综上所述，在万物互联的智能世界里，为了实现将海量数据近实时转化成信息和决策的愿景，除了流式计算应用还需要一个流式存储系统，未来已来，已有开源的分布式流存储系统正走在这条路上。另本文仅为作者愚见，与任何组织机构无关，作者能力也很有限，如有不足之处欢迎留言批评指正。</p><h2 id="问题思考"><a href="#问题思考" class="headerlink" title="问题思考"></a><font color="#FF8C00">问题思考</font></h2><p>最后给大家留一个思考题：<font color="#00CED1"><strong>如果让你来设计一个分布式流存储产品，你会如何定义它的产品灵魂？</strong></font></p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中科大硕，10年+数据相关经验，主要工作背景为分布式系统、存储、缓存、微服务、云计算以及大数据，现就职于DELL EMC。个人技术博客：<a href="https://changping.me" target="_blank" rel="noopener">https://changping.me</a></p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a> ，可以自由阅读、分享、转发、复制、分发等，限制是需署名、非商业使用（以获利为准）以及禁止演绎。</p></div></div></div></div></div></div>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>分布式系统架构设计 – 第7式 - 服务治理之系统自适应模式</title>
      <link href="/2019/04/21/distributed-servicegovernance-systemadaptive/"/>
      <url>/2019/04/21/distributed-servicegovernance-systemadaptive/</url>
      
        <content type="html"><![CDATA[<h2 id="导读"><a href="#导读" class="headerlink" title="导读"></a><font color="#FF8C00">导读</font></h2><p>日拱一卒，功不唐捐，分享是最好的学习，一个知识领域里的 <font color="#00CED1"> <strong>“道 法 术 器”</strong> </font> 这四个境界需要从 <font color="#00CED1"> <strong>微观、中观以及宏观</strong> </font>三个角度来把握。微观是实践，中观讲套路，宏观靠领悟。本系列文章我把它命名为《分布式系统架构设计三十六式》，讲诉分布式系统里最重要的三十六个虚数的中观套路，而微服务的本质也是分布式，因此搞明白这三十六个最重要的知识点也就同时能搞明白微服务。</p><p>实现一个分布式系统通常会面临三大难题： <font color="#00CED1"> <strong>故障传播性、业务拆分与聚合以及分布式事务</strong> </font>。本系列中的服务治理章节主要是为了解决故障传播性的难题，它包括： <font color="#00CED1"> <strong>隔离、熔断、降级、限流、容错以及资源管控-系统自适应算法</strong> </font>，本文将讲述服务治理里的 <font color="#00CED1"> <strong>“系统自适应模式”</strong> </font>模式。</p><h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a><font color="#FF8C00">动机</font></h2><font color="#00CED1"> <strong>分布式系统的灵魂</strong>  </font>：从产品思维的角度来看，好的产品都是有自己灵魂的。比如微信的产品灵魂被定位成“善良”，善有大善、上善、小善。《道德经》有言：“上善若水，水善利万物而不争，处众人之所恶（wù），故几于道。”，水善利万物而不与万物争，水无处不在，万物感觉不到水的存在又离不开水，不争故天下莫能与之争。每种好的产品背后都隐藏着自己的设计哲学，有自己的灵魂。而一个分布式系统的灵魂又应该怎么定义呢？认知层次不同，对分布式系统的理解也不同，度量一个分布式系统的灵魂，在我看来可以采用分布式系统的SLO图形指标来表达。好的分布式系统SLO指标也是很有规律很漂亮的，如下图所示，左图波形上跳下串，很明显不如右边波形来的漂亮。<br><br><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/systemadaptive/system-jitter.PNG" alt="系统抖动"><br><br>波形上跳下串带来的后果是什么呢？想象一下在高速路开车的场景，如果一辆车一会快，一会慢，后面的车会发生什么事？这样开车是很容易出事故的，而开得很稳的车出故障的概率就较小。波形上跳下串，说明该系统里头没有解决好资源竞用性以及服务治理的问题。<br><br><font color="#00CED1"> <strong>可靠性与高性能的平衡</strong>  </font>：我们知道要让一个水管里的水流的又快又多，一是给水管灌满水，二是水管通畅同时保证不炸裂水管。同样的道理，在分布式系统里要让系统跑出最好的性能和最可靠的效果，一方面压榨整个系统的资源，另一方面又要保证系统不出故障，在系统不出故障的前提下，尽量榨尽系统资源。<br><br>因此为了解决以上问题，这里提出了系统自适应模式。<br><br><font></font><h2 id="系统自适应模式设计思路"><a href="#系统自适应模式设计思路" class="headerlink" title="系统自适应模式设计思路"></a><font color="#FF8C00">系统自适应模式设计思路</font></h2><h3 id="资源平衡"><a href="#资源平衡" class="headerlink" title="资源平衡"></a><font color="#00CED1">资源平衡</font></h3><p>服务治理与其说是分布式下的套路，不如说是控制论下的套路，其本质是资源的细粒度管控，精巧的平衡整个系统里的资源竞用，从而保证分布式系统对外提供高质量的服务。如下图《一根羽毛的力量》所示，其将平衡的思想用到极致，我们也希望在分布式系统里体现有限资源下的平衡。</p><div align="center"> <p> <img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/systemadaptive/balance.jpg" alt=" 图片来源于网络版权归原作者所有"></p><div align="left"> <p>我们将平衡的思想融入分布式系统，在系统健康的前提下，极致的压榨系统的能力(capacity)，同时又保证不会主动造成系统故障，如果发现系统内部出现故障，又会自动调整下发的压力，这就是系统自适应保护。</p><h3 id="最佳衡量指标"><a href="#最佳衡量指标" class="headerlink" title="最佳衡量指标"></a><font color="#00CED1"><strong>最佳衡量指标</strong></font></h3><p>如何确定最佳的衡量指标？通常比较的原始情况下，是以工作负载比如1分钟、5分钟、15分钟的CPU负载作为系统衡量指标，但是这并不大正确。比如假设 CPU load &gt; 2 就 触发一个系统保护，如果这个 时候系统的CPU load是在下降的，它虽然此时刻大于2， 但是趋势却是下降，因此没必要触发系统保护。还有就是干扰性，比如 按 1分钟负载&amp;&amp; 5分钟负载&amp;&amp;15分钟负载，全都是满足大于2的条件就触发系统保护。但是实际上，也许 5分钟负载是不大于2的，因此这个条件就不成立，并不会触发系统过载保护， 这种行为我称之为负载干扰性。</p><p>参考水管的流量算法只依赖于管的截面大小以及流速，我们定义系统的自适应算法依赖的参数为系统入口处的 QPS或TPS ，以及请求的返回时间（RT），这里我将这个公式定义为 System Balance Capacity = QPS * RT。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/systemadaptive/qps-and-rt.PNG" alt="最佳值"></p><p>如上图，最好的情况就是即满足 最大的QPS 又满足最小的RT，通过一个时间窗口计算QPS 和 RT ，自适应调整整个系统。</p><h3 id="系统自适应算法"><a href="#系统自适应算法" class="headerlink" title="系统自适应算法"></a><font color="#00CED1"><strong>系统自适应算法</strong></font></h3><p>下图表示了一个自适应算法，造成系统负载过高以及故障传播的因素很多，比如不合适的线程数、TPS或QPS过大、返回时间过长都有可能，通过合适的算法可以自动调整下发的压力从而保持系统的内部资源平衡。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/systemadaptive/systemadaptive.PNG" alt="自适应算法"></p><p>通过采用系统自适应算法在系统的入口处，实时采集QPS/TPS 以及RT， 然后跟最佳样本值进行比较，依据调节系数进行计算，再调节发送的请求量，发送请求后又采集造成的影响，再反馈在系统入口处。其中，样本值可以在系统启动时按动态采样的方式计算，逐渐增加QPS ，当发现时延发生转折时，我们就确定这个转折点为分布式系统自适应最佳平衡点，记下该值作为当前样本。 </p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font color="#FF8C00">小结</font></h2><p>本文讲诉了服务治理里的 <font color="#00CED1"><strong>“系统自适应”</strong></font>模式，在前一篇《分布式系统架构设计三十六式之服务治理-5F容错模式》里讲诉了分布式系统服务治理的容错模式。另作者能力与认知都有限，欢迎大家拍砖留念。</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中科大硕，10年+数据相关经验，主要工作背景为分布式系统、存储、缓存、微服务、云计算以及大数据，现就职于DELL EMC。个人技术博客：<a href="https://changping.me" target="_blank" rel="noopener">https://changping.me</a></p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a> ，可以自由阅读、分享、转发、复制、分发等，限制是需署名、非商业使用（以获利为准）以及禁止演绎。</p></div></div>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>黑客马拉松 2019</title>
      <link href="/2019/04/12/person-emc-hackson-2019/"/>
      <url>/2019/04/12/person-emc-hackson-2019/</url>
      
        <content type="html"><![CDATA[<p>参加公司的hackathson 2019 获奖了。。。。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/person/hackson-2019.png" alt="hackson"></p>]]></content>
      
      
      <categories>
          
          <category> person </category>
          
      </categories>
      
      
        <tags>
            
            <tag> person </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>分布式系统架构设计 – 第6式 - 服务治理之5F容错模式</title>
      <link href="/2019/04/06/distributed-servicegovernance-failure-handling/"/>
      <url>/2019/04/06/distributed-servicegovernance-failure-handling/</url>
      
        <content type="html"><![CDATA[<h2 id="导读"><a href="#导读" class="headerlink" title="导读"></a><font color="#FF8C00">导读</font></h2><p>日拱一卒，功不唐捐，分享是最好的学习，一个知识领域里的 <font color="#00CED1"> <strong>“道 法 术 器”</strong> </font> 这四个境界需要从 <font color="#00CED1"> <strong>微观、中观以及宏观</strong> </font>三个角度来把握。微观是实践，中观讲套路，宏观靠领悟。本系列文章我把它命名为《分布式系统架构设计三十六式》，讲诉分布式系统里最重要的三十六个虚数的中观套路，而微服务的本质也是分布式，因此搞明白这三十六个最重要的知识点也就同时能搞明白微服务。</p><p>实现一个分布式系统通常会面临三大难题： <font color="#00CED1"> <strong>故障传播性、业务拆分与聚合以及分布式事务</strong> </font>。本系列中的服务治理章节主要是为了解决故障传播性的难题，它包括： <font color="#00CED1"> <strong>隔离、熔断、降级、限流、容错以及资源管控</strong> </font>，本文将讲诉服务治理里的 <font color="#00CED1"> <strong>“5F容错”</strong> </font>模式，下一篇将讲诉<font color="#00CED1"> <strong>“关联资源管控”</strong> </font>模式。</p><h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a><font color="#FF8C00">动机</font></h2><font color="#00CED1"> <strong>出错重试</strong>  </font>：在分布式系统里，系统里出现故障时需要进行出错处理，当执行熔断或降级处理策略时，通常也需要有相应的重试处理策略，而这些策略又需要根据不同的业务场景进行设计。<br><br><font color="#00CED1">  <strong>超时处理</strong>  </font>：在分布式系统里，为了保证高可用以及高可靠性，也需要相应的超时处理策略，比如超时后怎么重试？超时后重试几次还是失败应该怎么处理？超时处理是让用户感知还是不让用户感知?<br><br><br><br><font></font><h2 id="5F容错模式设计思路"><a href="#5F容错模式设计思路" class="headerlink" title="5F容错模式设计思路"></a><font color="#FF8C00">5F容错模式设计思路</font></h2><p>这里借用Dubbo里的概念讲述5种容错处理策略，我定义它们为5F容错法，下图是一个简单的分布式系统逻辑架构图。</p><div align="center"> <p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/failurehandling/failure-handling-five-solution.PNG" alt="容错模式"></p><div align="left"> <h3 id="Failover-失败切换"><a href="#Failover-失败切换" class="headerlink" title="Failover 失败切换"></a><font color="#00CED1">Failover 失败切换</font></h3><p>在分布式系统里，为了保证高可用性以及高可靠性，通常会对服务或者设备进行冗余，当一个服务或者设备出现故障时，就直接切换到另外一个服务或设备上，这种设计模式叫做 故障切换。</p><p>如上图所示，服务10本来是路由到服务20的，当服务20出现故障时，从服务10路由到服务20的请求，服务20并没办法处理，这时候服务10收到一个请求超时的返回，发现服务20没法处理这个请求，为了保证高可用性，服务10的请求就被路由到服务21，从而保证了服务的高可用与可靠性，这个过程用户是不感知的</p><h3 id="Failfast-快速失败"><a href="#Failfast-快速失败" class="headerlink" title="Failfast  快速失败"></a><font color="#00CED1">Failfast  快速失败</font></h3><p>快速失败是指当发现服务请求调用失败时，就立即上报故障，快速失败的一个重要目的是用于检测错误以便降低出错成本为系统提供足够的信息来保证高可用与高可靠，这个过程用户是感知的。</p><p>比如上图中服务20出现故障就快速上报故障给服务10，然后服务10就可以采用Failover策略将服务请求切换到服务21，从而避免更多的不可用时间。</p><h3 id="Failback-失败恢复"><a href="#Failback-失败恢复" class="headerlink" title="Failback 失败恢复"></a><font color="#00CED1">Failback 失败恢复</font></h3><p>Failback跟Failover有点类似，但是Failover是发现故障时就把请求切换到别的服务或设备上去，而Failback是在发现下游的故障后，把请求扔到一个临时的设备或者服务或者组件（比如队列）上，然后待下游故障修复后，重新同步数据以及请求，把这些数据或者请求还原到原来的服务或者设备上。比如上图所示，在服务20出现故障后，服务10发过来的请求被放到一个临时的队列里，然后在服务20在一定的时间内被恢复后，又把这些请求从队列中恢复发到服务20，这个过程用户时不感知的。</p><h3 id="Failsafe-失败安全"><a href="#Failsafe-失败安全" class="headerlink" title="Failsafe 失败安全"></a><font color="#00CED1">Failsafe 失败安全</font></h3><p>FailSafe 是指系统出现故障时可以直接忽略这个故障，不进行相应的故障处理，在Failsafe的场景下，故障不会给系统带来伤害，对服务质量也不会有什么影响，简单的处理方式就是把故障的信息写到日志里保存。</p><h3 id="Forking-请求分叉"><a href="#Forking-请求分叉" class="headerlink" title="Forking 请求分叉"></a><font color="#00CED1">Forking 请求分叉</font></h3><p>在Forking策略下，将请求进行裂变下发，只要一个请求处理成功整体请求就成功。比如上图所示，一个读请求到网关后被分裂成同样的请求三份，然后这三个请求被下发到服务10，11，12，只要有一个请求处理成功就返回成功。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font color="#FF8C00">小结</font></h2><p>本文讲诉了服务治理里的 <font color="#00CED1"><strong>“5F容错”</strong></font>模式，内容也没有多少，但是需要应用合适保证服务质量却并不容易，在应用的时候一般会根据实际的业务场景进行策略组合使用，在前一篇《分布式系统架构设计三十六式之服务治理-横向限流模式》里讲诉了分布式系统服务治理的横向限流模式。另作者能力与认知都有限，欢迎大家拍砖留念。</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中科大硕，10年+数据相关经验，主要工作背景为分布式系统、存储、缓存、微服务、云计算以及大数据，现就职于DELL EMC。个人技术博客：<a href="https://changping.me" target="_blank" rel="noopener">https://changping.me</a></p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a> ，可以自由阅读、分享、转发、复制、分发等，限制是需署名、非商业使用（以获利为准）以及禁止演绎。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a><font color="#FF8C00">参考资料</font></h2><p>[1]<a href="http://dubbo.apache.org/zh-cn/docs/source_code_guide/cluster.html" target="_blank" rel="noopener">http://dubbo.apache.org/zh-cn/docs/source_code_guide/cluster.html</a></p></div></div>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>分布式系统架构设计 – 第5式 - 服务治理之横向限流模式</title>
      <link href="/2019/03/30/distributed-servicegovernance-flowcontrol-2/"/>
      <url>/2019/03/30/distributed-servicegovernance-flowcontrol-2/</url>
      
        <content type="html"><![CDATA[<h2 id="导读"><a href="#导读" class="headerlink" title="导读"></a><font color="#FF8C00">导读</font></h2><p>日拱一卒，功不唐捐，分享是最好的学习，一个知识领域里的 <font color="#00CED1"> <strong>“道 法 术 器”</strong> </font> 这四个境界需要从 <font color="#00CED1"> <strong>微观、中观以及宏观</strong> </font>三个角度来把握。微观是实践，中观讲套路，宏观靠领悟。本系列文章我把它命名为《分布式系统架构设计三十六式》，讲诉分布式系统里最重要的三十六个虚数的中观套路，而微服务的本质也是分布式，因此搞明白这三十六个最重要的知识点也就同时能搞明白微服务。</p><p>实现一个分布式系统通常会面临三大难题： <font color="#00CED1"> <strong>故障传播性、业务拆分与聚合以及分布式事务</strong> </font>。本系列中的服务治理章节主要是为了解决故障传播性的难题，它包括： <font color="#00CED1"> <strong>隔离、熔断、降级、限流、容错以及资源管控</strong> </font>，本文将讲诉服务治理里的 <font color="#00CED1"> <strong>“限流-横向限流”</strong> </font>模式，下一篇将讲诉<font color="#00CED1"> <strong>“容错”</strong> </font>模式。</p><h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a><font color="#FF8C00">动机</font></h2><p>上一篇文章讲诉了纵向限流，那么为什么还需要横向限流呢？如下图所示：</p><div align="center"> <p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/flowcontrol/flow-control-distributed-qos-0.png" alt="流量控制"></p><div align="left"> <font color="#00CED1"> <strong>解决限流不均匀问题</strong> </font>: 如上图所示纵向限流只解决了网关-服务1，网关-服务2，网关-服务N的纵向路径的限流问题，但是并没有解决 这几个服务路径的限流是否均匀的问题，比如在某些情况下，网关-服务1 QPS 是 200，网关-服务2 QPS是 500,网关-服务N QPS 是 20，但是服务1-服务N的配置都是一样的，很明显，这里的限流并不均匀。<br><br><font color="#00CED1"> <strong>更细粒度的用户/租户的限流问题</strong> </font>: 如上图所示，用户1-用户N都发请求到网关，但是想限制每个用户可以进入系统的请求的个数，这里纵向限流并没有办法统计并控制每个用户的可以进入系统的请求数，纵向限流只能限制整体的进入网关的请求数，因此需要一个计数中心用于登记每个用户的请求数，从而进行更细粒度的流量控制，控制每个用户的请求数。<br><br><br><font></font><h2 id="横向限流模式"><a href="#横向限流模式" class="headerlink" title=" 横向限流模式 "></a><font color="#FF8C00"> 横向限流模式 </font></h2><p>如下图，通常采用一个类似配置中心或分布式事务中心的方式实现横向限流。</p><div align="center"> <p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/flowcontrol/flow-control-distributed-qos-3.png" alt="限流中心"></p><div align="left"> <ul><li><p>如左图所示，将集群限流服务中心实现在一个网关实例里，与网关一起提供服务，好处是无需再独立部署一个限流实例，缺点是网关如果挂掉，那么限流服务也会一起挂掉，而且无法对网关进行横向限流，只实现了网关底下的服务的横向限流；</p></li><li><p>如右图所示，独立拉起一个集群限流服务中心实例，用于提供全局限流计数服务，好处是与业务解耦，缺点是在集群内增加了一个额外的服务实例，增加了系统复杂度。</p></li></ul><h2 id="横向限流模式设计思路"><a href="#横向限流模式设计思路" class="headerlink" title="横向限流模式设计思路"></a><font color="#FF8C00">横向限流模式设计思路</font></h2><p>常用的横向限流算法有计数算法以及时间标签算法。</p><h3 id="计数算法"><a href="#计数算法" class="headerlink" title=" 计数算法 "></a><font color="#00CED1"> 计数算法 </font></h3><p>如图所示，独立的限流服务中心，拉起一个独立的分布式配置中心/事务中心，在里头实现限流算法，比如固定窗口算法、滑动窗口算法、漏桶算法、令牌桶算法等用于全局计数，而且保证这个计数是全局唯一的，不管集群规模多大，保证每个服务所使用的计数器和计时器都是唯一的，服务拿到这个计数ID后在进行限流调度。</p><p><div align="center"><br> <img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/flowcontrol/flow-control-distributed-qos-1.png" alt="全局限流算法"></div></p><div align="left"> <ul><li><p>CP模式：采用独立的限流中心，如果每个用户进入系统的请求都需要去远程的限流服务中心取一个计数返回，这就多了一个远程读取限流计数值的过程，很明显增加的这一步会影响请求的性能，但是在某些对限流可靠性比较苛刻的场景里，这是以牺牲请求性能的方式换取限流的可靠性；</p></li><li><p>AP模式：计数还是在限流服务中心，但在本地维护了一个限流计数的缓存，这样每个用户进来的请求并不是去远程读取计数值，而是直接在本地获取限流计数，而这个限流计数是通过一个独立的调度线程维护着的，这里这个本地的限流计数与远程限流服务中心的限流计数是不保证一致性的，这种方式牺牲了限流的可靠性，但是保证了请求的性能，在对限流要求不是很苛刻的场景下比较合适，而且配合纵向限流，还是可以解决绝大部分的系统的限流调度问题的。</p></li></ul><h3 id="时间标签算法"><a href="#时间标签算法" class="headerlink" title=" 时间标签算法 "></a><font color="#00CED1"> 时间标签算法 </font></h3><p>计数算法只是实现了限制用户或者服务请求量的最大值，并不能提供最小值保障，因此基于时间标签的算法被提出，例如DMCLOCK算法[1]。<br>在dmclock算法里，不只实现了限流，还实现了用户权重的划分以及最小值的预留。</p><p>例如在云服务里，用户1与用户2，付费不一样，因此给提供的最大限流上限是不一样的，但是采用计数限流算法，并不能保证付费多的用户就一定能得到最低的服务质量保证，在系统负载高的时候，付费高的用户与付费低的用户一样难以得到服务资源保底，这是不合理的，因此需要一个可以预留资源的算法。如下图所示，系统里流量资源的调度可以按<font color="#00CED1"> <strong>“预留、权重、上限”</strong> </font>这三个维度进行调度。</p><p><div align="center"><br> <img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/flowcontrol/flow-control-distributed-qos-2.png" alt="流量预留"></div></p><div align="left"> <p>例如，在时间标签算法里， 有三个用户：user1, user2,user3 根据付费的高低，给他们分别分配了不同的权重与预留值。如果系统里最大的QPS资源量是 4000，用户1与拥护2的QPS预留值是 1000，权重比例是 1：2：3.那么应当如何分配这些QPS资源？ 按dmclock算法可以这样计算：</p><p>用户1 ： (4000/(1+2+3)) <em> 1 =  667 &lt; 1000,但是保底的QPS是1000，因此分配了1000 QPS 给用户1.<br>用户2：( (4000-800) / (2+3)) </em> 2 = 1200 QPS<br>用户 3：4000-1200 – 667 = 2133 QPS        </p><p>基本的计算思路是，先保证最低的预留值，再根据权重划分剩下的资源，并且保证不要超过最大值。</p><h2 id="算法实践"><a href="#算法实践" class="headerlink" title="算法实践"></a><font color="#FF8C00">算法实践</font></h2><ul><li><p>通常如非必要或者业务场景要求苛刻，纵向限流就够，实现横向限流会引入新的组件，增加复杂度，同时还影响系统性能；</p></li><li><p>如果必须实现横向限流，那么性能要求高就采用AP模式，限流可靠性要求高就采用 CP模式；</p></li><li><p>权衡利弊，根据业务场景合理组合纵向限流与横向限流，才是最佳实践。</p></li></ul><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font color="#FF8C00">小结</font></h2><p>本文讲诉了服务治理里的 <font color="#00CED1"><strong>“横向限流”</strong></font>模式，在前一篇《分布式系统架构设计三十六式之服务治理-纵向限流模式》里讲诉了分布式系统服务治理的纵向限流模式。另作者能力与认知都有限，欢迎大家拍砖留念。</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中科大硕，10年+数据相关经验，主要工作背景为分布式系统、存储、缓存、微服务、云计算以及大数据，现就职于DELL EMC。个人技术博客：<a href="https://changping.me" target="_blank" rel="noopener">https://changping.me</a></p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a> ，可以自由阅读、分享、转发、复制、分发等，限制是需署名、非商业使用（以获利为准）以及禁止演绎。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a><font color="#FF8C00">参考资料</font></h2><p>[1]<a href="https://github.com/ceph/dmclock" target="_blank" rel="noopener">https://github.com/ceph/dmclock</a></p></div></div></div></div></div></div>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>分布式系统架构设计 – 第4式 - 服务治理之纵向限流模式</title>
      <link href="/2019/03/24/distributed-servicegovernance-flowcontrol-1/"/>
      <url>/2019/03/24/distributed-servicegovernance-flowcontrol-1/</url>
      
        <content type="html"><![CDATA[<h2 id="导读"><a href="#导读" class="headerlink" title="导读"></a><font color="#FF8C00">导读</font></h2><p>日拱一卒，功不唐捐，分享是最好的学习，一个知识领域里的 <font color="#00CED1"> <strong>“道 法 术 器”</strong> </font> 这四个境界需要从 <font color="#00CED1"> <strong>微观、中观以及宏观</strong> </font>三个角度来把握。微观是实践，中观讲套路，宏观靠领悟。本系列文章我把它命名为《分布式系统架构设计三十六式》，讲诉分布式系统里最重要的三十六个虚数的中观套路，而微服务的本质也是分布式，因此搞明白这三十六个最重要的知识点也就同时能搞明白微服务。</p><p>实现一个分布式系统通常会面临三大难题： <font color="#00CED1"> <strong>故障传播性、业务拆分与聚合以及分布式事务</strong> </font>。本系列中的服务治理章节主要是为了解决故障传播性的难题，它包括： <font color="#00CED1"> <strong>隔离、熔断、降级、限流、容错以及资源管控</strong> </font>，本文将讲诉服务治理里的 <font color="#00CED1"> <strong>“限流-纵向限流”</strong> </font>模式，下一篇将讲诉<font color="#00CED1"> <strong>“限流-横向限流”</strong> </font>模式。</p><h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a><font color="#FF8C00">动机</font></h2><font color="#00CED1"> <strong>可靠性</strong> </font>： 在分布式系统里，每个系统都有自己的容量限制，它所能处理的业务请求能力是有限的，如果不控制这些输入的请求数，突发输入过多的请求量会造成过度的资源竞争从而引发系统故障降低系统的可靠性。<br><br><font color="#00CED1"> <strong>可用性</strong> </font>： 限流有利于控制系统资源的消耗速率有利于过载保护，有利于保护业务资源不被耗尽。例如，当服务A所依赖的下游服务B由于某种原因不稳定、响应增加、延迟增加，对于调用者服务A意味着吞吐量下降和更多的资源占用，极端情况下甚至导致资源耗尽造成服务可用性故障。<br><br><font color="#00CED1"> <strong>流量监管</strong> </font>： 流量监管就是对输入的请求流量进行细粒度的控制，通过监管输入的请求量速率，对超出的部分进行”惩罚”， 比如直接丢弃，使得进入系统里的请求量被限制在一个系统所能承受的合理的范围之内，流量监管比较适合对延时要求较高的业务。<br><br><font color="#00CED1"> <strong>流量整形</strong> </font>： 流量整形就是控制最大输出请求速率提供可能，以确保请求量符合系统容量配置的最大传输速率规定。请求的流量被整形，以使它符合下游服务的速率需求，流量整形比较适合可靠性要求较高的业务。<br><br><font></font><h2 id="限流限的是什么"><a href="#限流限的是什么" class="headerlink" title=" 限流限的是什么 "></a><font color="#FF8C00"> 限流限的是什么 </font></h2><p>限流其原理是监控输入的请求量，当达到指定的阈值时对量进行控制，以避免系统被瞬时的请求量高峰冲垮，从而保障系统的高可用、高可靠。因此，限流的限的自然是“流”，对于不同的场景“流”是不同的：</p><ul><li>网络限流，流指的是带宽、流量；</li><li>I/O限流的“流”指的是TPS或QPS；</li><li>并发限流的“流”指的是并发请求数；</li><li>线程资源限流的“流”指的是线程数。</li></ul><p>这些“流” 通常具有资源竞用性、延迟性、抖动性以及不可靠性的特征。资源竞用性以及不可靠性需要控制流的资源使用，延迟性、抖动性需要对“流”进行整形，削峰填谷，控制请求的指标波形图。</p><h2 id="限流处理策略"><a href="#限流处理策略" class="headerlink" title="限流处理策略"></a><font color="#FF8C00">限流处理策略</font></h2><ul><li><p>直接拒绝：当请求量超过阈值后，新的请求就会被直接拒绝，方式为直接返回或者抛出异常。这种方式比较适合于对分布式系统的负载容量已知的情况下，比如通过全链路压测已经确定了准确的系统处理能力及系统容量，对应固定窗口、滑动窗口算法。</p></li><li><p>冷启动：当分布式系统长期处于低负载的情况下，请求量突发时，会把系统负载很快拉到很高的水准，这样就可能瞬间就把系统击垮。通过”冷启动”方式，让输入的请求量缓慢增加，在一个时间段内慢慢增加到系统所能承载的阈值上限，给冷系统一个预热的时间，避免系统被压垮，对应令牌桶算法。</p></li><li><p>匀速排队：匀速排队的方式也就是控制请求以均匀的速率通过，对应的是漏桶算法。</p></li></ul><h2 id="限流模式设计思路"><a href="#限流模式设计思路" class="headerlink" title="限流模式设计思路"></a><font color="#FF8C00">限流模式设计思路</font></h2><p>如下图所示，在分布式系统里，限流通常可以按空间维度划分为纵向限流以及横向限流，本文讲述纵向限流，下一篇将讲诉 横向限流。</p><div align="center"> <p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/flowcontrol/flow-control.png" alt="流量控制"></p><div align="left"> <p>常用的纵向限流算法有两窗算法：固定窗口、滑动窗口以及两桶算法：令牌桶算法、漏桶算法，按其工作原理又可以划分为 保险丝模式以及变压器模式。</p><h2 id="保险丝模式"><a href="#保险丝模式" class="headerlink" title="保险丝模式"></a><font color="#FF8C00">保险丝模式</font></h2><p>在电路中保险丝主要是起电流过载保护作用，当电路中的电流过载时，保险丝自身就会烧坏从而切断电流，保护后续电路的安全运行，但是保险丝有个问题就是在切断电流后，需要人工或者自动更换保险丝后，电路才能继续运行。</p><p>限流算法里的固定窗口算法以及滑动窗口算法应用原理与此类似，在拒绝请求后，需要重新设置计数，因此我定义它们为限流保险丝模式。</p><h3 id="固定窗口"><a href="#固定窗口" class="headerlink" title="固定窗口"></a><font color="#00CED1">固定窗口</font></h3><p>固定窗口算法类似人工保险丝模式，在切断流量后需要等很久才能重新工作。固定窗口算法将时间线划分成一个个固定大小的时间窗口，并且每个窗口都有一个计数器用于统计这一时间窗口内的访问次数，如果访问的次数超过了一个预先定义的阈值，则拒绝接下来的请求直到下一个时间窗口开始重新计数，又超过则继续拒绝，再在下一个时间窗口重新设置计数器继续计数，依次类推。</p><div align="center"> <p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/flowcontrol/flow-control-fixedwindow.png" alt="固定窗口"></p><div align="left"> <p>如上图所示，如果我们将时间线的窗口大小设置为5秒，上图里的窗口有[0, 5), [5, 10), …。假设限制是每5秒500个请求，如果在这个5秒内 计数器没超过 500就继续，超过500就拒绝后续的请求进入，直到下一个[5,10]的时间窗口内计数器被重新置0 再继续开始计数服务，再超过500，就继续拒绝服务，依次类推。</p><p>很明显，固定窗口的优点很明确，那就是实现很简单，一个计数器就可以实现。但是缺点也很明显，例如：</p><ol><li><p>边界场景，在第一个[0,5]的时间窗口内，第1秒就把计数器打到超过500，则后续的4秒将无法服务，得等到下一个[5,10]的时间窗口内计数器被重新置0，才可以对外提供服务。</p></li><li><p>跨窗口场景，当在第一个时间窗口的 [4,5]计数器的计数是300，没有超过阈值，然后第二个时间窗口的[5,6]计数器是320，也没超过阈值，但是 在 [4,6]的时间窗口内计数器的计数是 300+320=620,很明显超过阈值，因此，固定窗口的缺陷也很明显。</p></li></ol><h3 id="滑动窗口"><a href="#滑动窗口" class="headerlink" title="滑动窗口"></a><font color="#00CED1">滑动窗口</font></h3><p>滑动窗口算法类似自动保险丝模式，在切断流量不像固定窗口那样需要等较长的时间才能重新工作。滑动窗口的计数器也类似固定窗口的计数器，但是将时间线做了进一步的细分，每次往后移动一个细分单元，再每一次都对一个小的窗口进行计数统计实现流量控制，这种方法可以很好的解决之前的固定窗口的跨窗口问题。</p><div align="center"> <p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/flowcontrol/flow-control-slidewindow.png" alt="滑动窗口"></p><div align="left"> <p>如上图所示，还是定义请求的阈值为500，我们将[0,5]划分为5个窗口，则每个窗口对应1s。假设还是在[4,5]有300个请求和下一秒的[5,6]有320个突发请求，按照滑动窗口的原理，此时统计的将是[1,6]窗口，很明显 300+320=620 &gt; 500，超出了阈值，从而触发拒绝服务，避免了固定窗口算法的请求量突增的问题。</p><p>但是对于边界场景，例如[0,5]秒的窗口内，因为是按1s的时间单元进行窗口划分的，假设在第1ms的时间内，请求就超过500，然后就拒绝服务，然后需要等到下一个1s才可以继续出发服务，这很明显有59ms的时间窗式不能提供服务的，因此体现出来请求的指标也不大平滑。</p><h2 id="变压器模式"><a href="#变压器模式" class="headerlink" title="变压器模式"></a><font color="#FF8C00">变压器模式</font></h2><p>因为保险丝模式都不能解决请求的边界问题，因此引出变压器模式，变压器是电路中将某一等级的电压或电流转换成另外一种同频率的电压或电流的设备，有利于稳流稳压。限流算法里的漏桶算法以及令牌桶算法工作原理与此类似，因此我定义它们为变压器模式。</p><h3 id="漏桶"><a href="#漏桶" class="headerlink" title="漏桶"></a><font color="#00CED1">漏桶</font></h3><div align="center"> <p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/flowcontrol/flow-control-leakybucket-1.png" alt="漏桶算法"></p><div align="left"> <p>上图显示了漏桶算法在流量整形和速率限制中的用法，突发的不均匀的请求到达后被扔到一个桶里，这个桶底下有个固定大小的孔，请求按固定大小稳定的输出。</p><div align="center"> <p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/flowcontrol/flow-control-leakybucket-2.png" alt="漏桶算法"></p><div align="left"> <p>如上图所示，漏桶算法工作步骤：</p><ul><li>请求随意的被输入，有突发的请求量也有比较小的请求量，有快的请求也有慢的请求，然后这些请求进入系统后不是立马被处理，而是被扔到一个桶里；</li><li>当桶里缓冲的请求超过设定的水位时，输入的请求将被拒绝进入，从而丢失的后续请求</li><li>这个桶以恒定的速率将输入的请求输出；</li><li>对比窗口算法，漏桶算法多了一个缓冲。</li></ul><p>优点：</p><ul><li>漏桶算法里，桶的存在有利于削峰填谷，且输出总是按恒定的速率输出的，因此有利于流量整形，从而平滑了突发的请求量。</li></ul><p>缺点：</p><ul><li><p>很明显，漏桶里的请求超过水位后，后续请求会被丢弃，在需要保证幂等性请求的场景不适合使用。</p></li><li><p>漏桶总是按恒定速率输出请求，这是在假设后续的服务能承接这个速率的前提下的，它无法保证这些输出的请求能够稳定地在一个固定的时间内处理完，假如后续的服务出现资源抢用，或者故障，那么将无法处理这个很定的输出速率，从而引发更大的级联故障。</p></li></ul><p>如上图所示，如果服务2变慢，就会一直占用线程资源不释放，从而导致无法响应服务1的请求，而服务1还是以恒定的速率处理漏桶的请求，而其下游资源不够，因此也会引起级联故障。</p><h3 id="令牌桶"><a href="#令牌桶" class="headerlink" title="令牌桶"></a><font color="#00CED1">令牌桶</font></h3><p>下图显示了令牌桶的主要工作步骤：</p><div align="center"> <p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/flowcontrol/flow-control-tockenbucket.png" alt="令牌桶算法"></p><div align="left"> <p>如上图所示，令牌桶算法工作步骤：</p><ul><li>在这个桶中有按一定时间周期定期生成的令牌，令牌按预先定义的时间周期进行填充；</li><li>令牌桶有最大的令牌个数限制；</li><li>如果请求到来时，必须从令牌桶中取得令牌，之后才可以对这个请求进行处理，并且从令牌桶中删除这个被获取的令牌；</li><li>如果令牌桶中没有令牌，则无法发送请求，请求必须稍后重试。</li></ul><p>优点</p><ul><li>如果令牌桶中令牌已满，则丢令牌而不是丢请求。</li><li>可以支持突发的请求。</li></ul><p>缺点</p><ul><li>令牌被耗光后需要等下一次令牌填充，这意味着需要等待一段时间令牌填充后后续请求才可以使用。</li><li>对请求的处理速率没做限制，这意味着输入的请求处理速率有可能高过设置的阈值从而引发故障。</li></ul><h3 id="漏桶VS令牌桶-3"><a href="#漏桶VS令牌桶-3" class="headerlink" title="漏桶VS令牌桶[3]"></a><font color="#00CED1">漏桶VS令牌桶[3]</font></h3><ul><li><p>漏桶算法控制输出的请求量，输入的请求量可以变化，但输出的请求量保持恒定不变。令牌桶算法控制输入的令牌量，但不限制输出的请求量，输出的请求量可以根据突发的大小而变化。</p></li><li><p>漏桶算法不依赖令牌。令牌桶算法是令牌依赖的。</p></li><li><p>在漏桶算法中，如果桶已满，则丢弃请求。在令牌桶中，如果桶已满，则丢弃令牌但不会丢弃该请求。</p></li><li><p>在漏桶中，请求不断被输出。在令牌桶中，只有在拿到令牌时请求才能通过。</p></li><li><p>漏桶以恒定速率发送请求。令牌桶允许在恒定速率之后以更快的速率发送突发请求。</p></li></ul><h2 id="算法实践"><a href="#算法实践" class="headerlink" title="算法实践"></a><font color="#FF8C00">算法实践</font></h2><ul><li><p>固定窗口与滑动窗口实现都比较简单，性能较好，但是在超出限流阈值后，请求都会被直接拒绝，因此适用于非幂等性的请求场景；</p></li><li><p>漏桶算法，有利于控制输出的请求速率，但是在超出桶的水位后请求也会被丢失，也不适用于幂等性请求的场景;</p></li><li><p>令牌算法，可以支持突发的请求量，但是不控制输出的请求速率，在超出阈值后，只丢失令牌但不丢失请求，因此可以结合在幂等性请求的场景使用;</p></li><li><p>权衡利弊，根据业务场景合理组合以上4个算法，才是最佳实践。</p></li></ul><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font color="#FF8C00">小结</font></h2><p>本文讲诉了服务治理里的 <font color="#00CED1"><strong>“纵向限流”</strong></font>模式，在前一篇《分布式系统架构设计三十六式之服务治理-降级模式》里讲诉了分布式系统服务治理的降级模式。另作者能力与认知都有限，欢迎大家拍砖留念。</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中科大硕，10年+数据相关经验，主要工作背景为分布式系统、存储、缓存、微服务、云计算以及大数据，现就职于DELL EMC。个人技术博客：<a href="https://changping.me" target="_blank" rel="noopener">https://changping.me</a></p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a> ，可以自由阅读、分享、转发、复制、分发等，限制是需署名、非商业使用（以获利为准）以及禁止演绎。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a><font color="#FF8C00">参考资料</font></h2><p>[1]<a href="https://tech.domain.com.au/2017/11/protect-your-api-resources-with-rate-limiting" target="_blank" rel="noopener">https://tech.domain.com.au/2017/11/protect-your-api-resources-with-rate-limiting</a><br>[2]<a href="https://github.com/alibaba/Sentinel/wiki/%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6" target="_blank" rel="noopener">https://github.com/alibaba/Sentinel/wiki/%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6</a><br>[3]<a href="https://www.quora.com/What-is-the-difference-between-token-bucket-and-leaky-bucket-algorithms" target="_blank" rel="noopener">https://www.quora.com/What-is-the-difference-between-token-bucket-and-leaky-bucket-algorithms</a><br>[4]<a href="https://en.wikipedia.org/wiki/Rate_limiting" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Rate_limiting</a><br>[5]<a href="https://en.wikipedia.org/wiki/Bandwidth_throttling" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Bandwidth_throttling</a><br>[6]<a href="https://en.wikipedia.org/wiki/Bandwidth_management" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Bandwidth_management</a><br>[7]<a href="https://en.wikipedia.org/wiki/Token_bucket" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Token_bucket</a><br>[8]<a href="https://en.wikipedia.org/wiki/Leaky_bucket" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Leaky_bucket</a></p></div></div></div></div></div></div></div></div></div></div></div></div>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>分布式系统架构设计 – 第3式 -  服务治理之降级模式</title>
      <link href="/2019/03/21/distributed-servicegovernance-degraded/"/>
      <url>/2019/03/21/distributed-servicegovernance-degraded/</url>
      
        <content type="html"><![CDATA[<h2 id="导读"><a href="#导读" class="headerlink" title="导读"></a><font color="#FF8C00">导读</font></h2><p>日拱一卒，功不唐捐，分享是最好的学习，一个知识领域里的 <font color="#00CED1"> <strong>“道 法 术 器”</strong> </font> 这四个境界需要从 <font color="#00CED1"> <strong>微观、中观以及宏观</strong> </font>三个角度来把握。微观是实践，中观讲套路，宏观靠领悟。本系列文章我把它命名为《分布式系统架构设计三十六式》，讲诉分布式系统里最重要的三十六个虚数的中观套路，而微服务的本质也是分布式，因此搞明白这三十六个最重要的知识点也就同时能搞明白微服务。</p><p>实现一个分布式系统通常会面临三大难题： <font color="#00CED1"> <strong>故障传播性、业务拆分与聚合以及分布式事务</strong> </font>。本系列中的服务治理章节主要是为了解决故障传播性的难题，它包括： <font color="#00CED1"> <strong>隔离、熔断、降级、限流、容错以及资源管控</strong> </font>，本文将讲诉服务治理里的 <font color="#00CED1"> <strong>“降级”</strong> </font>模式。</p><h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a><font color="#FF8C00">动机</font></h2><ol><li><p>某些时候系统会遇到负载过高的问题，当系统外来的或内部的负载过高超过预先定义的阈值，为了保证更重要的更紧急的业务的服务质量，希望将一些非核心的、不紧急的业务降低服务质量，从而释放一些额外的资源给紧急业务使用。比如一个分布式系统里的读、写、数据校验、空间回收都比较消耗资源，在白天为了保证读和写的服务质量，可以把数据校验的服务通过限流或减少线程数之类的方式使得可以调用的资源配额减少，从而释放部分资源给读和写使用，保证读写的服务质量。同样在读和写业务不繁忙的时候，降低读和写的资源配额，从而释放资源给空间回收使用，通过这种方式动态调整局部业务的服务质量从而保证关键业务的服务质量，提升用户体验。</p></li><li><p>在云服务里“可用性”指标是一个非常重要的SLA指标，在可用性出现不达标的情况下需要根据SLA进行赔偿，因此，我们希望分布式系统不管出现怎么样的故障，比如服务器故障，磁盘故障，网络故障都能保持可用性，起码要保证单点故障不会造成系统故障，比如，在系统出现严重故障的时候，可以停止负载较高的写操作从而保证“读”或者“查询“服务。</p></li></ol><h2 id="降级模式"><a href="#降级模式" class="headerlink" title="降级模式"></a><font color="#FF8C00">降级模式</font></h2><p>从故障处理角度来讲，服务降级简单来说就是这一功能或服务直接不能用，而在动态调整系统整体的服务质量的时候，降级是降低某些当前非重要或非核心业务的资源，从而释放部分资源给重要的或紧急的业务使用。</p><p>在故障处理的时候，对比“熔断”，降级是更严重的故障处理方式，最后拿来兜底用的。比如某个功能出故障，“熔断”是不管怎么样，都希望这个功能还能救活，降级是发现试着救了几次发现还是救不活，就下狠心砍掉这个部分，断臂求生，起码要保证整体是活的，这样整体还有救活的希望。</p><p>从系统的角度来说降级有 读功能降级，写功能降级以及级联组件降级，还有自动降级或者人工降级。比如，在云服务里，为了保证高可用性，在出现系统级的故障后，可以把写功能降级，就是这个服务只能读，只能查询不能写了，因此在设计的比较好的云服务里，按时间的维度来度量可用性已经没有太大的意义，因为不管怎么样它都是服务可用的，系统都是活着的，起码部分服务可用，因此在云服务里更合理的新的衡量可用性的指标方式是请求失败比率。</p><h2 id="降级模式设计思路"><a href="#降级模式设计思路" class="headerlink" title="降级模式设计思路"></a><font color="#FF8C00">降级模式设计思路</font></h2><h3 id="降级触发策略"><a href="#降级触发策略" class="headerlink" title="降级触发策略"></a><font color="#00CED1">降级触发策略</font></h3><ul><li>超时降级：在超时重试的次数达到一个阈值后就触发降级；</li><li>失败比率降级：当某个服务的失败的比率达到一定比率后就开始降级；</li><li>系统故障降级：比如网络故障，硬盘故障，电源故障，服务器故障，数据中心故障等；</li><li>限流降级：某些访问量太大的场景会触发限流，当达到限流阈值后，请求也会被降级；</li><li>重要业务救急降级：比如为了保证读或者查询的功能，降低写或者数据校验的资源配额，从而实现读服务的质量保证。</li></ul><h3 id="降级处理措施"><a href="#降级处理措施" class="headerlink" title="降级处理措施"></a><font color="#00CED1">降级处理措施</font></h3><ul><li>资源配额调度，调度不紧急的业务支援紧急的重要的业务；</li><li>抛出异常，直接抛出异常，打印出出错日志，然后就不管了，请求会丢失，这在需要保证幂等性的请求里不合适；</li><li>直接返回， 直接返回拒绝服务，这里请求也会丢失，这在需要保证幂等性的请求里不合适；</li><li>调用回退方法，调用出现服务降级时对应的业务处理逻辑，不同场景降级处理的逻辑不同，比如可以把请求再挂到等待队列里继续重试之类，这里需要根据业务场景合理设计回退方法；</li></ul><h3 id="降级分级策略"><a href="#降级分级策略" class="headerlink" title="降级分级策略"></a><font color="#00CED1">降级分级策略</font></h3><p>一般可以把降级的等级分为几个层次，比如P0级，P1级，P2级，P3级，级别越高表示问题越严重， 比如：</p><ol><li>重要业务救急降级可以定义为P0级降级，只是调度次要的资源去救急，并不会出现故障；</li><li>限流降级可以定义为P1级降级，只是为了保证服务质量，而且如果不限流可能会出现系统负载过高从而出现故障；</li><li>超时降级以及失败比率降级可以定义为P2级降级，出现小范围故障，触发P2级降级，保证小故障不蔓延不传播从而造成大范围的故障；</li><li>系统故障降级可以定义为P3级降级，系统出现大范围故障，从而触发P3级降级，比如，此时可以只保证最低资源的的读请求服务，写和其他业务全部被禁止。</li></ol><h3 id="配置中心"><a href="#配置中心" class="headerlink" title="配置中心"></a><font color="#00CED1">配置中心</font></h3><p>如下图所示是一个简单的配置中心物理架构图：</p><div align="center"> <p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/distributed-degraded-config-center.png" alt="配置中心"></p><div align="left"> <p>在分布式系统里每个服务的配置信息会给保存在一个配置中心里，这个配置中心里有每个服务的开关信息以及一些重要的资源配置信息。通过动态调整服务的配置信息，比如降级触发策略、降级处理措施、降级分级策略或者开关信息可以实现服务降级功能。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font color="#FF8C00">小结</font></h2><p>本文讲诉了服务治理里的 <font color="#00CED1"><strong>“降级”</strong></font>模式，在前一篇《分布式系统架构设计三十六式之服务治理-熔断模式》里讲诉了分布式系统服务治理的熔断模式。另作者能力与认知都有限，欢迎大家拍砖留念。</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中科大硕，10年+数据相关经验，主要工作背景为分布式系统、存储、缓存、微服务、云计算以及大数据，现就职于DELL EMC。</p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a><font color="#FF8C00">参考资料</font></h2><p>[1] <a href="https://medium.com/@felipedutratine/microservices-should-be-design-for-failure-b58bccdce0b6" target="_blank" rel="noopener">https://medium.com/@felipedutratine/microservices-should-be-design-for-failure-b58bccdce0b6</a></p><p>[2] <a href="https://blog.risingstack.com/designing-microservices-architecture-for-failure" target="_blank" rel="noopener">https://blog.risingstack.com/designing-microservices-architecture-for-failure</a></p></div></div>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>分布式系统架构设计 – 第2式 - 服务治理之熔断模式</title>
      <link href="/2019/03/16/distributed-servicegovernance-circuitbreaker/"/>
      <url>/2019/03/16/distributed-servicegovernance-circuitbreaker/</url>
      
        <content type="html"><![CDATA[<h2 id="导读"><a href="#导读" class="headerlink" title="导读"></a><font color="#FF8C00">导读</font></h2><p>日拱一卒，功不唐捐，分享是最好的学习，一个知识领域里的 <font color="#00CED1"> <strong>“道 法 术 器”</strong> </font> 这四个境界需要从 <font color="#00CED1"> <strong>微观、中观以及宏观</strong> </font>三个角度来把握。微观是实践，中观讲套路，宏观靠领悟。本系列文章我把它命名为《分布式系统架构设计三十六式》，讲诉分布式系统里最重要的三十六个虚数的中观套路，而微服务的本质也是分布式，因此搞明白这三十六个最重要的知识点也就同时能搞明白微服务。</p><p>实现一个分布式系统通常会面临三大难题： <font color="#00CED1"> <strong>故障传播性、业务拆分与聚合以及分布式事务</strong> </font>。本系列中的服务治理章节主要是为了解决故障传播性的难题，它包括：<font color="#00CED1"> <strong>隔离、熔断、降级、限流、容错以及资源管控</strong> </font>，本文将讲诉服务治理里的 <font color="#00CED1"> <strong>“熔断”</strong> </font>模式。</p><h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a><font color="#FF8C00">动机</font></h2><p>在分布式系统里经常会遇到这样的场景：</p><ol><li><p>系统负载突然过高，比如突发的访问量、过多的请求并发数以及过多的IO等都会造成某个节点故障，比如节点A，然后节点A挂了，又把负载转给节点B，然后节点B又负载过高，接着B又挂了，就这样一连串的挂过去从单点故障造成系统级的级联故障。</p></li><li><p>当一个服务出现故障时，希望这个服务能在一个时间段内恢复，在请求被拒绝后隔一段时间再自动的去探测服务的可服务性。</p></li></ol><p>对应这两个场景，我们希望在分布式系统里能避免级联故障、提供快速失败快速恢复服务的能力，因此，这里引出 <font color="#00CED1"><strong>“熔断模式”</strong></font> 。</p><h2 id="熔断模式"><a href="#熔断模式" class="headerlink" title="熔断模式"></a><font color="#FF8C00">熔断模式</font></h2><p>熔断模式也称之为断路器模式，英文单词是“circuit breaker”，“circuit breaker”是一个电路开关，其基本功能是检测到电流过载就中断电路，在检测到电流正常时又能自动或手动恢复工作，从而保护断路器背后的电源设备安全。这里需要将”断路器“与 “保险丝”进行区分，断路器可以通过手动或自动的复位从而恢复正常工作，而保险丝是运行一次必须更换。</p><p>实现一个分布式系统通常会面临三大难题： <font color="#00CED1"><strong>业务拆分与聚合，分布式事务以及故障传播性</strong></font>。本系列中的服务治理章节主要是为了解决故障传播性的难题，它包括：隔离、熔断、降级、限流、容错以及资源管控，本文将讲诉服务治理里的 <font color="#00CED1"><strong>“熔断”</strong></font>模式。</p><p>在分布式系统里 <font color="#00CED1"><strong>“熔断模式”</strong></font>的设计思想来源于此，当系统里响应时间或者异常比率或者异常数超过某个阈值时，比如超时次数或重试次数超过某个阈值就会触发熔断，接着所有的调用都快速失败，从而保证下游系统的负载安全，在断开一段时间后，熔断器又打开一点试着让部分请求负载通过，如果这些请求成功那么断路器就恢复正常工作，如果继续失败，则继续关闭服务走快速失败通道，接着继续这个过程直到重试的次数超过一定的阈值从而触发更为严重的<font color="#00CED1"><strong>“降级模式”</strong></font>。</p><h3 id="熔断模式设计思路"><a href="#熔断模式设计思路" class="headerlink" title="熔断模式设计思路"></a><font color="#00CED1">熔断模式设计思路</font></h3><p>下图是一个熔断模式的设计思路：</p><div align="center"> <p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/distributed-circuitbreaker.png" alt="熔断器"></p><p>图片来源于引文[2]，版权归原作者所有</p><div align="left"> <ol><li><p>首先熔断器是处于闭合（closed）状态的，如果请求超时次数，异常数或者异常比率超过一定的阈值则熔断器会被打开；</p></li><li><p>接着熔断器处于打开（Open）状态，所有走到这个路径里的请求会走快速失败通道从而避免负载下行，但是这里不会一直都是打开的，过一个时间周期会自动切换到半打开（Half-open）状态；</p></li><li><p>在接下来是半打开（half-open）状态，在这里认为之前的错误可能被修复了，因此允许通过部分请求试着看看能不能处理成功，如果这些请求处理成功，那么就认为之前导致失败的错误已被修复，此时熔断器就切换到闭合状态并且将错误计数器重置。如果这些试着发送的请求还是处理失败，则认为导致之前失败的问题仍然存在，熔断器切回到打开方式，然后开始重置计时器给系统一定的时间来修复错误。半打开状态能够有效防止正在恢复中的服务被突然而来的大量请求再次打挂；</p></li><li><p>接着重复以上过程，直到半打开状态重复的次数达到一定的阈值发现故障还没被修复，从而触发”降级“状态</p></li></ol><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font color="#FF8C00">小结</font></h2><p>本文讲诉了服务治理里的 <font color="#00CED1"><strong>“熔断”</strong></font>模式，在前一篇《分布式系统架构设计三十六式之服务治理-隔板模式》里讲诉了分布式系统服务治理的隔板模式。另作者能力与认知都有限，欢迎大家拍砖留念。</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中科大硕，10年+数据相关经验，主要工作背景为分布式系统、存储、缓存、微服务、云计算以及大数据，现就职于DELL EMC。</p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a><font color="#FF8C00">参考资料</font></h2><p>[1] <a href="https://en.wikipedia.org/wiki/Circuit_breaker" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Circuit_breaker</a></p><p>[2] <a href="https://martinfowler.com/bliki/CircuitBreaker.html" target="_blank" rel="noopener">https://martinfowler.com/bliki/CircuitBreaker.html</a></p></div></div>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>分布式系统架构设计 – 第1式 - 隔板模式</title>
      <link href="/2019/03/10/distributed-servicegovernance-bulkhead/"/>
      <url>/2019/03/10/distributed-servicegovernance-bulkhead/</url>
      
        <content type="html"><![CDATA[<h2 id="导读"><a href="#导读" class="headerlink" title="导读"></a><font color="#FF8C00">导读</font></h2><p>日拱一卒，功不唐捐，分享是最好的学习，一个知识领域里的 <font color="#00CED1"> <strong>“道 法 术 器”</strong> </font> 这四个境界需要从 <font color="#00CED1"> <strong>微观、中观以及宏观</strong> </font>三个角度来把握。微观是实践，中观讲套路，宏观靠领悟。本系列文章我把它命名为《分布式系统架构设计三十六式》，讲诉分布式系统里最重要的三十六个虚数的中观套路，而微服务的本质也是分布式，因此搞明白这三十六个最重要的知识点也就同时能搞明白微服务。</p><p>实现一个分布式系统通常会面临三大难题： <font color="#00CED1"> <strong>故障传播性、业务拆分与聚合以及分布式事务</strong> </font>。本系列中的服务治理章节主要是为了解决故障传播性的难题，它包括： <font color="#00CED1"> <strong>隔离、熔断、降级、限流、容错以及资源管控</strong> </font>，本文将讲诉服务治理里的 <font color="#00CED1"> <strong>“隔板”</strong> </font>模式。</p><h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a><font color="#FF8C00">动机</font></h2><p>在分布式系统里通常将进程容器化以进行资源隔离，然后在同一个进程里的各种业务都共享线程池对外提供服务，这就经常会遇到这样的问题：</p><ol><li>业务A负载较高，抢占了线程池里的大部分线程资源，从而造成其他业务的服务质量下降；</li><li>同一个进程内新加入一个业务，这个业务会抢占其他业务的资源，从而造成系统的不稳定，比如业务性能抖动；</li><li>难以调试，比如同一个进程里的10个业务共享同一个线程池，当出现故障时难以通过简单的日志判断是哪个业务出了问题。</li></ol><p>因此，我们希望找出一个机制解决这样的问题。</p><h2 id="隔板模式"><a href="#隔板模式" class="headerlink" title="隔板模式"></a><font color="#FF8C00">隔板模式</font></h2><p>首先我来看一个英文单词“Bulkhead”，翻译成中文就是“舱壁”‘或“隔板”，在分布式系统里有个资源隔离的设计模式叫做”舱壁模式”或者“隔板模式”。</p><font color="#00CED1"><strong>模式来源:</strong></font> 通过万能的Wiki百科我们可以了解到轮船里的两个舱位之间的挡板就是隔板/舱壁（Bulkhead），如下图：<br><div align="center"><br><br><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/distributed-resource-isolation-1.jpg" alt="bulkhead"><br><br>图片来源于引文[1]，版权归原作者所有<br><br><div align="left"><br><br><br>在造船的时候，<font color="#FF0000">”船农们“（对应码农）</font>通常会把一个大的船舱用隔板分成N个小的空间，以便万一船体破裂或着火的时候，只有这个被分割开的小船舱受到影响，而其他的船舱是被隔离而不受影响的，从而提高整个船只的安全度。<br><br>同样这种隔板模式可以应用在分布式系统的资源隔离设计里，在分布式系统里，资源隔离通常按业务分为进程级别的隔离和线程级别的隔离，某些简单的服务质量要求不高的业务场景下实现进程级别的隔离就够了，但是在某些对服务质量要求较高的分布式场景下需要线程级别的细粒度隔离。<br><br><br><font></font><h3 id="进程隔离"><a href="#进程隔离" class="headerlink" title="进程隔离"></a><font color="#00CED1">进程隔离</font></h3><p>进程级别隔离通常指的是容器化隔离，比如通过使用docker实现业务进程之间的资源隔离。</p><h3 id="线程隔离"><a href="#线程隔离" class="headerlink" title="线程隔离"></a><font color="#00CED1">线程隔离</font></h3><p>线程级别隔离是指给每个跑在进程里的业务都按业务类型创建一个线程池，从而实现线程级别细粒度的资源隔离，线程隔离具有以下优势：</p><ol><li>提高业务可靠性，减少业务受其他业务影响的程度，当一个业务耗尽自身的线程资源后也不会影响另外一个业务的服务质量；</li><li>降低新加入的业务的给系统带来的风险，比如当前系统的一个进程用例中有10个业务。当新加入一个业务时，必然会抢占此前10个业务的线程资源，从而给系统带来不稳定，比如性能抖动；</li><li>利于调试，给每一个业务都分配一个线程池名称，当业务出故障时，通过线程池名称可以很方便地定位是哪个业务出了故障，并且通过监控线程池的请求失败次数、超时次数、拒绝请求次数等可以实时的反应当前业务服务质量。</li></ol><p>事物都有二元性，线程池隔离，有利自然也有弊，线程池隔离也会引入额外的一些开销，开销类型有：</p><ol><li>对象分配，每个调用都会实例化一个新的线程对象及其中的关联对象，占用系统资源；</li><li>并发，共享数据结构，计数器等，也占用系统资源；</li><li>线程的执行开销：切换，调度，执行，同样也占用资源。</li></ol><p>因此，线程池的隔离带来了好处但是也会引起一些顾虑，比如给每个业务都创建一个线程池是否会给系统带来太大的开销。通过Hystrix的数据分析可以得出结论是：<font color="#FF0000"><strong> “开销是有的，但是对比好处，通过权衡，其开销在一些要求不苛刻的场景可以忽略。”</strong></font></p><h2 id="线程池的开销分析"><a href="#线程池的开销分析" class="headerlink" title="线程池的开销分析"></a><font color="#FF8C00">线程池的开销分析</font></h2><p>Hystrix官网[3]，统计了线程池带来的开销成本，如下图表示在单个API实例上以60个请求/秒执行一个HystrixCommand：</p><div align="center"> <p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/distributed-resource-isolation-2.png" alt="Hystrix"></p><p>图片来源于引文[3]，版权归原作者所有</p><div align="left"> <p>通过分析这个统计图（注意不同的颜色），我们可以看到：</p><ol><li>中位数（P50）和更低的场景下，对比不使用线程池隔离模式，隔离线程池基本没有成本开销。</li><li>在P90的场景下，对比不使用线程池隔离模式，隔离线程池的耗时差距为3毫秒。</li><li>在P99的场景下，对比不使用线程池隔离模式，隔离线程池的耗时差距为9毫秒。</li></ol><p>但是从上图可以看出，成本增加的幅度远小于单独一个线程的执行时间增加的幅度，当未使用线程池隔离的线程执行时间从2ms跳到28ms时，线程池隔离的耗时成本从0ms跳到9ms。</p><p>因此，对于大多数的使用场景而言，在P90及以上的线程池隔离带来的开销被认为是可接受的，从而获得资源隔离带来的好处。</p><p>但是在某些场景这样的开销可能过高，比如缓存场景，在这种情况下，可以选用信号量来进行隔离，缺点是信号量不允许设置超时，难以实现熔断、降级之类的服务治理行为。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font color="#FF8C00">小结</font></h2><p>本文讲诉了服务治理里的 <font color="#00CED1"><strong>“隔板”</strong></font>模式，在下一篇将讲诉分布式系统服务治理的熔断模式。另作者能力与认知都有限，欢迎大家拍砖留念。</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中科大硕，10年+数据相关经验，主要工作背景为分布式系统、存储、缓存、微服务、云计算以及大数据，现就职于DELL EMC。</p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a></p><p>在遵循署名、非商业使用（以获利为准）以及禁止演绎的前提下可以自由阅读、分享、转发、复制、分发等。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a><font color="#FF8C00">参考资料</font></h2><p>[1] <a href="https://en.wikipedia.org/wiki/Bulkhead_(partition)" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Bulkhead_(partition)</a></p><p>[2] <a href="http://writing.engr.psu.edu/uer/bassett.html" target="_blank" rel="noopener">http://writing.engr.psu.edu/uer/bassett.html</a></p><p>[3] <a href="https://github.com/Netflix/Hystrix/wiki/FAQ%20:%20General" target="_blank" rel="noopener">https://github.com/Netflix/Hystrix/wiki/FAQ%20:%20General</a></p></div></div></div></div>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ceph fileStore与blueStore架构简单对比</title>
      <link href="/2019/03/09/distributed-ceph-bluestore-filestore/"/>
      <url>/2019/03/09/distributed-ceph-bluestore-filestore/</url>
      
        <content type="html"><![CDATA[<h2 id="ceph逻辑架构图"><a href="#ceph逻辑架构图" class="headerlink" title=" ceph逻辑架构图  "></a><font color="#FF8C00"> ceph逻辑架构图  </font></h2><p>ceph后端支持多种存储引擎，以插件化的形式来进行管理使用，目前支持filestore，kvstore，memstore以及bluestore，目前默认使用的是filestore，但是目前bluestore也可以上生产。下图是ceph的逻辑架构图：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/ceph/distributed-ceph-blusetore-1.png" alt="ceph-bluestore"></p><p><strong>Firestore存在的问题是：</strong></p><ol><li><p>在写数据前需要先写journal，会有一倍的写放大；</p></li><li><p>若是另外配备SSD盘给journal使用又增加额外的成本；</p></li><li><p>filestore一开始只是对于SATA/SAS这一类机械盘进行设计的，没有专门针对SSD这一类的Flash介质盘做考虑。</p></li></ol><p><strong>而Bluestore的优势在于：</strong></p><ol><li><p>减少写放大；</p></li><li><p>针对FLASH介质盘做优化；</p></li><li><p>直接管理裸盘，进一步减少文件系统部分的开销。</p></li></ol><p>但是在机械盘场景Bluestore与firestore在性能上并没有太大的优势，bluestore的优势在于flash介质盘。</p><h2 id="FileStore逻辑架构"><a href="#FileStore逻辑架构" class="headerlink" title=" FileStore逻辑架构 "></a><font color="#FF8C00"> FileStore逻辑架构 </font></h2><p>下图为ceph filestore逻辑架构图：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/ceph/distributed-ceph-blusetore-2.png" alt="ceph-bluestore"></p><ol><li><p>首先，为了提高写事务的性能，FileStore增加了fileJournal功能，所有的写事务在被FileJournal处理以后都会立即callback(上图中的第2步)。日志是按append only的方式处理的，每次都是被append到journal文件末尾，同时该事务会被塞到FileStore op queue；</p></li><li><p>接着，FileStore采用多个thread的方式从op queue 这个 thread pool里获取op，然后真正apply事务数据到disk（文件系统pagecache）。当FileStore将事务落到disk上之后，后续的读请求才会继续(上图中的第5步)。</p></li><li><p>当FileStore完成一个op后，对应的Journal才可以丢弃这部分Journal。对于每一个副本都有这两步操作，先写journal，再写到disk，如果是3副本，就涉及到6次写操作，因此性能上体现不是很好。</p></li></ol><h2 id="Bluestore逻辑架构"><a href="#Bluestore逻辑架构" class="headerlink" title=" Bluestore逻辑架构 "></a><font color="#FF8C00"> Bluestore逻辑架构 </font></h2><p>下图为ceph bluestore逻辑架构图：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/ceph/distributed-ceph-blusetore-3.png" alt="ceph-bluestore"></p><ol><li><p>Bluestore实现了直接管理裸设备的方式，抛弃了本地文件系统，BlockDevice实现在用户态下使用linux aio直接对裸设备进行I/O操作，去除了本地文件系统的消耗，减少系统复杂度，更有利于Flash介质盘发挥性能优势；</p></li><li><p>为了惯例裸设备就需要一个磁盘的空间管理系统，Bluestore采用Allocator进行裸设备的空间管理，目前支持StupidAllocator和BitmapAllocator两种方式；</p></li><li><p>Bluestore的元数据是以KEY-VALUE的形式保存到RockDB里的，而RockDB又不能直接操作裸盘，为此，bluestore实现了一个BlueRocksEnv，继承自EnvWrapper，来为RocksDB提供底层文件系统的抽象接口支持；</p></li><li><p>为了对接BlueRocksEnv，Bluestore自己实现了一个简洁的文件系统BlueFS，只实现RocksDB Env所需要的接口，在系统启动挂在这个文件系统的时候将所有的元数据都加载到内存中，BluesFS的数据和日志文件都通过BlockDevice保存到底层的裸设备上；</p></li><li><p>BlueFS和BlueStore可以共享裸设备，也可以分别指定不同的设备，比如为了获得更好的性能Bluestore可以采用 SATA SSD 盘，BlueFS采用 NVMe SSD 盘。</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>新公司一年里程碑</title>
      <link href="/2019/02/11/person-emc-one-year/"/>
      <url>/2019/02/11/person-emc-one-year/</url>
      
        <content type="html"><![CDATA[<p>2018年2月12日到2019年2月11日，刚好满一年，不知不觉间居然写了35770行代码，</p><p>2018-02-12 ~ 2019-02-11， 刚好入职EMC满一年，里程碑两件：</p><p>1，个人代码量突破3万5千行，排列第一；</p><p>2，专利公司内部通过且美国专利局审核中2个。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/person/emc-201902-codeline.png" alt="codeline"></p><div align="left"> </div>]]></content>
      
      
      <categories>
          
          <category> person </category>
          
      </categories>
      
      
        <tags>
            
            <tag> person </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>重构大数据平台的存储栈</title>
      <link href="/2019/01/25/pravega-arch-refactor-bigdata-storage-stack/"/>
      <url>/2019/01/25/pravega-arch-refactor-bigdata-storage-stack/</url>
      
        <content type="html"><![CDATA[<h2 id="当前大数据处理平台存在的问题"><a href="#当前大数据处理平台存在的问题" class="headerlink" title="当前大数据处理平台存在的问题"></a><font color="#FF8C00">当前大数据处理平台存在的问题</font></h2><p>如图1是目前大数据处理平台最常见的Lambda架构，它的优势在于实时处理与批处理统一，但是它的缺点也很明显：</p><ol><li>实时处理一条路径，批处理另外一条路径，不同的路径采用了不同的计算组件，这就增加了系统的复杂度；</li><li>数据存储多组件化、多份化，如下图，同样的数据会被存储在ElasticSearch 里、S3对象存储系统里、Kafka里、HDFS里以及Cassandra里，而且考虑到数据的可靠性，数据还都是多份冗余的，这就极大的增加了用户的存储成本；</li><li>系统里组件太多太复杂，也增加了用户的运维成本。</li></ol><div align="center"> <p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/pravega-infoq-arch-lambda.png" alt="lambda架构"></p><p>​图1.  Lambda架构</p><div align="left"> <p>因此，为了解决Lambda架构的以上三大缺点，流式架构被提出。在流式架构里，流计算一般选用<strong>Flink</strong>作为计算组件，那么对于存储来说又意味着什么呢？为了<strong>降低系统复杂度、减少用户的存储成本与运维成本</strong>，我们推出了<font color="#FF0000"> <strong>流存储</strong></font>，目的之一就是为了重构Lambda架构里的存储栈，这样流式架构就可以由<font color="#FF0000"><strong>”流计算+流存储“</strong></font>组成。</p><h2 id="第4种存储类型-流存储"><a href="#第4种存储类型-流存储" class="headerlink" title="第4种存储类型 - 流存储 "></a><font color="#FF8C00">第4种存储类型 - 流存储 </font></h2><p>首先，流式大数据处理平台里的数据一般被称之为“流数据”，流数据在百度百科里是这样被定义的：</p><blockquote><p>流数据是一组顺序、大量、快速、连续到达的数据序列，一般情况下，数据流可被视为一个随时间延续而无限增长的动态数据集合。应用于网络监控、传感器网络、航空航天、气象测控和金融服务等领域。</p></blockquote><p>那么目前又有哪种存储系统最适合用于<strong>“流数据”</strong>呢？正如当前技术条件下最适合“流数据”计算的是类似Flink这样的流计算应用，最适合“流数据”存储的应当是流存储系统。</p><p>如图2所示，从<font color="#FF0000"> <strong>存储的视角</strong></font>来说，每种类型的数据都有其原生的属性和需求，对应有最佳的适用场景以及最合适的存储系统。</p><div align="center"> <p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/pravega-infoq-storage-type.png" alt="存储类型"></p><p>​                                                                       图2.  4大存储类型</p><div align="left"> <p>简单来说就是传统数据库这类对于IOPS要求高的业务需要块存储系统。文件共享场景下需要在用户间共享文件进行读写操作，因此适合采用分布式文件存储系统。而互联网业务文件以及图片、视频等适合采用对象存储系统。</p><p>流数据存储具有性能要求高、严格次序保证、连续而又无限、大规模租户隔离等特点，而目前市面上又没有这样一个专门针对流数据进行设计的存储系统。因此，为了满足业务需求、平衡商业成本与技术成本，也为了给流数据提供最佳最合适的存储系统，分布式流存储Pravega被推出。</p><div align="center"> <p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/pravega-infoq-arch-6.png" alt="I/O路径隔离"></p><p>​                                                                       图3.  日志结构</p><div align="left"> <p>如图3所示：在Pravega里，日志是作为共享存储原语而存在的。Pravega被推出的目的之一就是为了<font color="#FF0000"> <strong>重构Lambda架构里的存储栈：流批统一、降低存储成本以及运维成本。</strong></font> 一般数据的批处理对应于处理历史数据，因此Pravega支持高吞吐量的追赶读；数据的流处理对应于处理实时数据，因此Pravega又支持低时延的尾部读取以及写入；同时Pravega通过分层存储以及资源自动伸缩降低了用户的存储成本以及运维成本。</p><h2 id="Pravega关键架构"><a href="#Pravega关键架构" class="headerlink" title="Pravega关键架构"></a><font color="#FF8C00">Pravega关键架构</font></h2><h3 id="架构目标"><a href="#架构目标" class="headerlink" title="架构目标"></a><font color="#00CED1">架构目标</font></h3><ul><li>持久化：在客户端确认写入前，数据被复制并且写入磁盘；</li><li>严格的顺序保证以及恰好一次语义：支持追赶读、尾部读以及从中间任意位置读，支持事务</li><li>轻量级：一个流就如同一个文件，可以在单集群里创建千万量级起的流；</li><li>可弹性：可基于负载和吞吐量智能地动态扩展或者收缩流；</li><li>无限性：存储空间大小不受单个节点的容量限制；</li><li>高性能：写入延迟低于10ms，吞吐量仅受网络带宽限制，读模式（例如：追赶读）不影响写性能;</li></ul><h3 id="逻辑架构"><a href="#逻辑架构" class="headerlink" title=" 逻辑架构"></a><font color="#00CED1"> 逻辑架构</font></h3><blockquote><p>”技术在某种程度上一定是来自此前已有技术的新的组合“  – 《技术的本质》，布莱恩·阿瑟</p></blockquote><p>Pravega为连续而又无限的数据提供了一种新的存储原语 - 流存储，然而Pravega也并不是凭空发明出来的，它是以前成熟技术与新技术的组合，例如Pravega的 范围、流、段、事件就跟Kafka的主题、分区、段、消息对应，而一层存储又用了Bookkeeper，协调器用了Zookeeper等，如图4 ：Pravega的逻辑架构。</p><div align="center"> <p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/pravega-infoq-arch.png" alt="逻辑架构图"></p><p>​                                                                       图4.  逻辑架构</p><div align="left"> <ol><li>Pravega提供了一个用Java编写的客户端库，抽象出了流协议层接口，用于支持客户端应用，例如Flink、Spark以及一些检索系统等；</li><li>Pravega实现了一个流数据抽象层，用于事件流和字节流的抽象；</li><li>Pravega遵循软件定义存储的设计规则，其控制面与数据面分离，控制实例组成控制面，实现了检索流信息、监控集群、收集相关指标等功能，同时为了实现高可用，通常有多个（建议至少3个）控制实例同时对外提供服务；</li><li>Pravega采用Zookeeper作为集群中的协调组件；</li><li>Pravega的第1层存储系统由bookkeeper实现，第2层存储系统由开源的HDFS、Ceph、GlusterFS、Swift或者商业存储产品组成。</li></ol><h3 id="流批统一-降低系统复杂度"><a href="#流批统一-降低系统复杂度" class="headerlink" title="流批统一 - 降低系统复杂度"></a><font color="#00CED1">流批统一 - 降低系统复杂度</font></h3><p>通过使用Pravega，实现了流批统一的大数据处理架构，重构了大数据处理平台的存储栈，有效降低了系统复杂度.</p><h3 id="存储分层-降低存储成本"><a href="#存储分层-降低存储成本" class="headerlink" title="存储分层 - 降低存储成本"></a><font color="#00CED1">存储分层 - 降低存储成本</font></h3><p>如图4所示，在Pravega里，底层存储系统由两部分组成：第1层为低时延存储层，主要关注性能，用于存储热点数据，由bookkeeper实现，保证了存储系统的低时延、高性能。第2层为长期存储层，主要关注低成本、高吞吐量以及高可扩展性，提供数据的长期存储，由开源的或者商业的存储产品组成。随着数据的老化，第1层中的数据将自动分层流入第2层。通过这种方式，冷热数据分离有效降低了数据存储成本。</p><h3 id="资源自动缩放-减少运维成本"><a href="#资源自动缩放-减少运维成本" class="headerlink" title="资源自动缩放 - 减少运维成本"></a><font color="#00CED1">资源自动缩放 - 减少运维成本</font></h3><p>在Pravega里，当流中的负载上升或下降时，流中段的数量会随着负载自动增长或收缩，此特性被称之为“自动缩放”，该特性无需人工干预自动完成，有效减少了系统的运维成本。当创建流时，可以使用缩放策略配置流，该策略确定流如何响应其负载变化，目前支持三种策略：1）固定，流段的数量不随负载而变化；2）基于写入的字节数，当每秒写入流的数据字节数增量超过某个目标速率时，流段的数量增加，相应的如果它低于某个流速时，流段数量减少；3）基于事件的个数，与基于字节数的扩展策略类似，不同之处在于它使用事件的个数而不是字节数。</p><h2 id="Pravega的一些关键概念与特性"><a href="#Pravega的一些关键概念与特性" class="headerlink" title="Pravega的一些关键概念与特性"></a><font color="#FF8C00">Pravega的一些关键概念与特性</font></h2><p>本章节将简要介绍一些Pravega的关键特性。</p><font color="#00CED1"><strong>范围（scope）：</strong></font>在Pravega里，范围是流的命名空间，例如可以把一台机器命名为一个范围，也可以把一个无人车命名为一个范围，还可以把整个工厂命名为一个范围。<br><br><font color="#00CED1"><strong>流（stream）：</strong></font>在同一个范围内流具有命名唯一性，所有流的名称在同一个范围内都是唯一的。在pravega里数据被组织到流中的，流是一种可持久化、可伸缩、仅附加、字节大小无限制的序列，具有高性能和强一致性的特性。<br><br><font color="#00CED1"><strong>段（segment）：</strong></font>流由段组成，段是流的分片。<br><br><font color="#00CED1"><strong>事件（event）：</strong></font> 段由事件组成，事件存储在段里，事件是流中的可以表示为一组字节的任何事物。例如：来自温度传感器的读数，它包含少量的字节且由时间戳，度量标识符和温度值组成。另外事件也可以是与用户点击网站或APP相关联的日志数据等。<br><br><font color="#00CED1"><strong>写客户端（writers）：</strong></font>写客户端是一个可以创建事件并将事件写入流中的应用，所有的事件数据都可以通过附加到流的尾部来写入。<br><br><font color="#00CED1"><strong>读客户端（readers）：</strong></font>读客户端是一个可以从流中读取事件的应用，读客户端可以从流中的任何一点读取，比如头部、尾部、中间任何一点。<br><br><font color="#00CED1"><strong>读者组（readerGroups）：</strong></font>读者组由读客户端组成，读者组本质上是为了实现同一个组内读客户端的平衡以及不同组的扇出。同一个读者组内的读客户端可以一起并行读取给定的一组流段内的事件，比如一个读客户端对应一个段。不同的应用可以定义不同的读者组实现扇出，比如定义一个Flink读者组，再定义一个检索读者组，这样二者互不影响，互不干涉，可以优雅而又和谐地一起读取同一个流段内的事件。<br><br><font color="#00CED1"><strong>顺序保证：</strong></font>流是由段组成的，写入流的事件被写入单个段，在同一个段内的事件具有顺序性。对于读客户端来说，可以分配多个可并行读取的段，从多个段读取的也许是交错的事件，但在同一个段内读取的数据是有严格有序的。<br><br><font color="#00CED1"><strong>检查点：</strong></font>Pravega为应用提供了在读者组上初始化检查点的功能，使用检查点的意图是通过使用检查点事件来确保每个读客户端能保存原来的使用状态。<br><br><font color="#00CED1"><strong>事务：</strong></font> Pravega提供了事务功能，事务是写客户端可以“批处理”一堆事件并将它们作为一个处理单元原子性地提交到流中。这一堆事件要么所有都处理成功，要么所有都处理失败。在提交事务之前，发布到事务中的事件永远不会被读客户端看到。<br><br><font color="#00CED1"><strong>状态同步器：</strong></font> Pravega也提供了在分布式计算环境中作为协调器的功能，类似Zookeeper、ETCD这样的提供分布式共识和领导者选举能力。这样的组件在Pravega里被称作“状态同步器”。状态同步器为在集群中运行的多个进程之间的共享状态提供同步机制，使用户可以轻松地构建高级服务，从而使用户更加的容易构建分布式应用。<br><br><font color="#00CED1"><strong>恰好一次：</strong></font> Pravega确保每个事件只被处理一次，即使客户端、服务器或网络出现故障也能保证精确的处理顺序。<br><br><font color="#00CED1"><strong>性能：</strong></font> Pravega的延迟目标为毫秒级(&lt;10ms)；<br><br><font color="#00CED1"><strong>永久保留：</strong></font> Pravega将流的抽象与实际数据存储分离，这使得Pravega可以透明地将数据从低延迟、持久的存储层移到云存储服务层。<br><br><font color="#00CED1"><strong>高效存储：</strong></font> Pravega统一了流（有序）数据和批量（并行）数据的访问，可以将批量和实时应用程序结合起来而无需为流式计算流水线（比如Flink）的每个步骤复制数据从而有效的提高了数据的存储效率。<br><br><br><br>## <font color="#FF8C00">与kafka对比</font><p>前面我们已经提到过Pravega是从<font color="#FF0000"> <strong>存储的视角</strong></font>来看待流数据，而Kafka本身的定位是消息系统而不是存储系统，它是从<font color="#FF0000"> <strong>消息的视角</strong></font>来看待流数据。消息系统与存储系统的定位是不同的，简单来说，消息系统是消息的传输系统，关注的是数据传输与生产消费的过程。而存储系统除了关注存储用的物理媒介，数据的持久化、安全、可靠性、一致性、隔离等都是它的原生属性，它关注数据的生产、传输、存放、访问等整个数据的生命周期。</p><p>这里我们把Pravega与Kafka做了对比，大体在功能上的差异如下表所示。功能上的差异也只是说明各个产品针对的业务场景不同，看待数据的视角不同，并不是说明这个产品不好，另外每个产品自身也在演进，因此本对比仅供参考。</p><table><thead><tr><th>名称</th><th style="text-align:center">Kafka 2.1.0</th><th style="text-align:right">Pravega GA</th></tr></thead><tbody><tr><td>自动扩容缩容</td><td style="text-align:center">部分支持</td><td style="text-align:right">支持</td></tr><tr><td>完全不丢数据</td><td style="text-align:center">不支持</td><td style="text-align:right">支持</td></tr><tr><td>多协议可入</td><td style="text-align:center">支持</td><td style="text-align:right">支持</td></tr><tr><td>无限个流</td><td style="text-align:center">不支持</td><td style="text-align:right">支持</td></tr><tr><td>事务</td><td style="text-align:center">支持</td><td style="text-align:right">支持</td></tr><tr><td>恰好一次</td><td style="text-align:center">支持</td><td style="text-align:right">支持</td></tr><tr><td>顺序保证</td><td style="text-align:center">支持</td><td style="text-align:right">支持</td></tr><tr><td>兼容Kafka API</td><td style="text-align:center">支持</td><td style="text-align:right">支持</td></tr><tr><td>数据链接与汇聚</td><td style="text-align:center">支持</td><td style="text-align:right">部分支持</td></tr><tr><td>多种二层存储支持（ECS,HDFS,S3,etc）</td><td style="text-align:center">不支持</td><td style="text-align:right">支持</td></tr><tr><td>安全与加密</td><td style="text-align:center">支持</td><td style="text-align:right">支持</td></tr><tr><td>无限多租户</td><td style="text-align:center">不支持</td><td style="text-align:right">部分支持</td></tr><tr><td>服务质量保证</td><td style="text-align:center">部分支持</td><td style="text-align:right">部分支持</td></tr><tr><td>流计算应用集成</td><td style="text-align:center">支持</td><td style="text-align:right">支持</td></tr><tr><td>数据治理</td><td style="text-align:center">不支持</td><td style="text-align:right">支持</td></tr></tbody></table><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a><font color="#FF8C00">总结</font></h2><p>本文讲述了推出分布式流存储Pravega的原因，介绍了一些Pravega的关键架构以及关键特性，另外还与Kafka做了简要对比。有关Pravega的更多详细信息，请参阅官方网站以及关注我们的后续文章。另作者能力有限，如有不足之处欢迎留言批评指正。</p><h2 id="问题思考"><a href="#问题思考" class="headerlink" title="问题思考"></a><font color="#FF8C00">问题思考</font></h2><p>最后给大家留一个问题：<font color="#00CED1"><strong>一般来说从开源项目到商业产品还是有一段距离的（注意这里的用词：开源的“项目”，商业的“产品”），那么对于设计开发人员来说应该如何弥补这段距离，从而使得开源项目产品化？</strong></font> </p></div></div></div></div></div></div></div></div>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>分布式流存储 - 架构、自动缩放、IO隔离与事务</title>
      <link href="/2019/01/25/pravega-arch-IO-transaction-autoscaling/"/>
      <url>/2019/01/25/pravega-arch-IO-transaction-autoscaling/</url>
      
        <content type="html"><![CDATA[<h2 id="Pravega架构"><a href="#Pravega架构" class="headerlink" title=" Pravega架构  "></a><font color="#FF8C00"> Pravega架构  </font></h2><blockquote><p> ”技术在某种程度上一定是来自此前已有技术的新的组合“  – 《技术的本质》，布莱恩·阿瑟</p></blockquote><p>Pravega为连续而又无限的数据提供了一种新的存储原语 - 流存储，然而Pravega也并不是凭空发明出来的，它是以前成熟技术与新技术的组合，例如Pravega的 范围、流、段、事件就跟Kafka的主题、分区、段、消息对应，而一层存储又用了Bookkeeper，协调器用了Zookeeper等。</p><h3 id="设计原则与目标"><a href="#设计原则与目标" class="headerlink" title=" 设计原则与目标"></a><font color="#00CED1"> 设计原则与目标</font></h3><ul><li><p>持久化：在客户端确认写入前，数据被复制并且写入磁盘；</p></li><li><p>保序：段内严格保序；</p></li><li><p>恰好一次：支持恰好一次语义；</p></li><li><p>轻量级：一个流就如同一个文件，可以在单集群里创建千万量级起的流；</p></li><li><p>可弹性：可基于负载和吞吐量智能地动态扩展或者收缩流；</p></li><li><p>无限性：存储空间大小不受单个节点的容量限制；</p></li><li><p>高性能：写入延迟低于10ms，吞吐量仅受网络带宽限制，读模式（例如：追赶读）不影响写性能;</p></li></ul><h3 id="Pravega设计创新"><a href="#Pravega设计创新" class="headerlink" title="Pravega设计创新"></a><font color="#00CED1">Pravega设计创新</font></h3><ol><li><p>支持“无限流”分层</p></li><li><p>零接触动态缩放</p><ul><li><p>根据负载和SLO自动调整读/写并行度</p></li><li><p>没有服务中断</p></li><li>无需手动重新配置客户端</li><li>无需手动重新配置服务资源</li></ul></li><li><p>智能工作负载分配</p><ul><li>无需为峰值负载过度配置服务器</li></ul></li><li><p>I / O路径隔离</p><ul><li>支持尾部写入</li><li>支持尾部读</li><li>支持追赶读</li></ul></li><li><p>支持“恰好一次”事务</p></li></ol><h3 id="逻辑架构"><a href="#逻辑架构" class="headerlink" title="  逻辑架构"></a><font color="#00CED1">  逻辑架构</font></h3><p>下图为Pravega的逻辑架构图：</p><p><div align="center"><br><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/pravega-infoq-arch.png" alt="逻辑架构图"></div></p><div align="left"> <ol><li>首先，Pravega提供了一个用Java编写的客户端库，抽象出了流协议层接口，用于支持客户端应用，例如Flink、Spark以及一些检索系统等；</li><li>其次，Pravega实现了一个流数据抽象层，用于事件流和字节流的抽象；</li><li>再者，从整体架构上来讲Pravega符合软件定义存储的设计规则，其控制面与数据面分离，数据面的集合统称为段存储层，控制实例组成控制面，实现了检索流信息、监控集群、收集相关指标等功能，同时为了实现高可用，通常有多个（建议至少3个）控制实例同时对外提供服务。 </li><li>Pravega采用Zookeeper作为集群中的协调组件。 </li><li>Pravega的存储系统由两部分组成：第1层为短期存储层，主要关注性能，用于存储热点数据，由bookkeeper实现，保证了存储系统的低时延、高性能。第2层为长期存储层，主要关注成本，提供数据的持久性以及长期存储，由开源的或者商业的存储产品组成。第1层保留热点数据，随着第1层中数据的老化，数据将自动分层流入第2层。</li></ol><h3 id="数据架构"><a href="#数据架构" class="headerlink" title=" 数据架构"></a><font color="#00CED1"> 数据架构</font></h3><p>下图展示了Pravega的数据架构图以及数据流分层：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/pravega-infoq-data-path.png" alt="数据架构图"></p><ol><li>Pravega客户端可以通过调用控制器接口管理流的创建、删除和缩放以及进行事务管理：启动事务、创建事务、跟踪事务状态；</li><li>所有的数据对读来说都是透明的，客户端的读写操作直接与段存储（数据面）进行交互，而不通过控制器；</li><li>段存储里有缓存组件保证了读写的高性能，热点数据放在bookkeeper里作为一层存储；</li><li>数据老化后会自动流转到长期存储（例如：对象存储系统，文件存储系统，HDFS等）里以便降低存储成本；</li></ol><h3 id="关键子功能-零接触缩放"><a href="#关键子功能-零接触缩放" class="headerlink" title="关键子功能 - 零接触缩放"></a><font color="#00CED1">关键子功能 - 零接触缩放</font></h3><h4 id="零接触缩放：段的动态拆分与合并"><a href="#零接触缩放：段的动态拆分与合并" class="headerlink" title="零接触缩放：段的动态拆分与合并"></a>零接触缩放：段的动态拆分与合并</h4><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/pravega-infoq-arch-2.png" alt="段的拆分与合并"></p><p>如上图所示，1）拆分：在t1时刻系统负载加大，段0被拆分成段1和段2，同时段0封装不再写入；t2时刻系统负载继续加大，段2被拆分成段3与段4，同时段2被封装不再写入；t3时刻系统负载又继续加大，段1被拆分成段5和段6，同时段1被封装不再写入；2）合并：t4时刻系统负载降低，段6与段3被合并成段7，同时段6与段3被封装不再写入。而且所有的这些行为都是Pravega里自动完成的无需人工干预。</p><h4 id="零接触缩放：写并行-与Kafka比较"><a href="#零接触缩放：写并行-与Kafka比较" class="headerlink" title="零接触缩放：写并行 - 与Kafka比较"></a>零接触缩放：写并行 - 与Kafka比较</h4><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/pravega-infoq-arch-3.png" alt="写并行"></p><p>当并行写入的时候：</p><ol><li><p>在Pravega里流段的数量会根据负载和服务质量目标而动态变化，并且段的拆分与合并都是自动进行的无需人工干预，同时拆分或合并流段是，写客户端的配置是静态不变的；</p></li><li><p>在Kafka里主题分区数（写并行性）是静态的，添加或删除分区时需要手动配置服务并且当分区数更改时，必须手动更新生产者配置。</p></li></ol><h4 id="零接触缩放：读并行-与Kafka比较"><a href="#零接触缩放：读并行-与Kafka比较" class="headerlink" title="零接触缩放：读并行 - 与Kafka比较"></a>零接触缩放：读并行 - 与Kafka比较</h4><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/pravega-infoq-arch-4.png" alt="读并行"></p><p>并行读取时：</p><ol><li>在Pravega里，当拆分或者合并流段时，读客户端通过流协议获得通知从而使得读并行与流段缩放保持同步；</li><li>在Kafka里，当分区数更改时，必须手动更改使用者配置。</li></ol><h4 id="关键子功能-智能工作负载分配"><a href="#关键子功能-智能工作负载分配" class="headerlink" title="关键子功能 - 智能工作负载分配 "></a><font color="#00CED1">关键子功能 - 智能工作负载分配 </font></h4><h4 id="智能工作负载分配-与Kafka比较"><a href="#智能工作负载分配-与Kafka比较" class="headerlink" title="智能工作负载分配 - 与Kafka比较"></a>智能工作负载分配 - 与Kafka比较</h4><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/pravega-infoq-arch-5.png" alt="智能工作负载分配"></p><p>在Pravega里，热点段会自动拆分，子段在整个集群中重新分配缓解热点，同时最大限度地利用集群的可用IOPS能力；而在Kafka里没有减轻“热点”分区的机制，其强制部署并且过度配置资源以获得处理其“峰值负载”的能力。</p><h3 id="关键子功能-I-O路径隔离"><a href="#关键子功能-I-O路径隔离" class="headerlink" title="关键子功能 - I/O路径隔离"></a><font color="#00CED1">关键子功能 - I/O路径隔离</font></h3><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/pravega-infoq-arch-6.png" alt="I/O路径隔离"></p><p>流存储的基础数据结构为仅附加写入的日志结构。考虑到高吞吐量，Pravega支持追赶读，同时为了保证低时延，Pravega还支持尾部读取以及尾部写入，从而进行了IO路径的隔离。</p><h3 id="关键子功能-事务"><a href="#关键子功能-事务" class="headerlink" title="关键子功能 - 事务"></a><font color="#00CED1">关键子功能 - 事务</font></h3><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/pravega-infoq-arch-7.png" alt="智能工作负载分配"></p><p>Pravega提供了事务功能，事务是写客户端可以“批处理”一堆事件并将它们作为一个处理单元原子性地提交到流中。这一堆事件要么所有都处理成功，要么所有都处理失败。在提交事务之前，发布到事务中的事件永远不会被读客户端看到。如上图所示，第一步，先将一堆事件封装在一个事务里；第二步，提交这个事务。这个事务里所有的事件要么全部都处理成功要么全部都处理失败。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a><font color="#FF8C00">总结</font></h2><p>本文分析了物联网场景下的数据存储商业现状以及技术现状，为平衡商业成本与技术成本推出了分布式流存储系统Pravega，同时本文还介绍了流存储的特殊需求点以及与Kafka做了简要对比，此外还介绍了一些Pravega的关键架构以及一些关键特性。有关Pravega的更多详细信息，请参阅官方网站。另作者能力有限，如有不足之处欢迎留言批评指正。</p></div>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>flink handbook - Flink分布式运行时</title>
      <link href="/2018/09/26/flink-concepts-distributed-runtime/"/>
      <url>/2018/09/26/flink-concepts-distributed-runtime/</url>
      
        <content type="html"><![CDATA[<h2 id="任务和算子链"><a href="#任务和算子链" class="headerlink" title="任务和算子链"></a>任务和算子链</h2><p>对于分布式执行，Flink将算子子任务链接到任务中。每个任务由一个线程执行。将算子链接到任务中是一项有用的优化：它可以减少线程到线程切换和缓冲的开销，并在降低延迟的同时提高整体吞吐量。可以配置链接行为; 有关详细信息，请参阅链接文档。</p><p>下图中的示例数据流由五个子任务执行，因此具有五个并行线程。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/flink/tasks_chains.svg" alt="算子链接到任务"></p><h2 id="作业管理器，任务管理器，客户端"><a href="#作业管理器，任务管理器，客户端" class="headerlink" title="作业管理器，任务管理器，客户端"></a>作业管理器，任务管理器，客户端</h2><p>Flink运行时包含两种类型的进程：</p><ul><li>JobManagers（也称为主作业）协调分布式执行。他们调度任务，协调检查点，协调故障恢复等。</li></ul><p>总是至少有一个Job Manager。高可用性配置将具有多个JobManagers，其中一个始终是领导者，其他人则是备用者。</p><ul><li>TaskManagers（也叫工作者）执行数据流的任务（或者更具体地说，子任务），并且缓冲和交换数据流。</li></ul><p>必须至少有一个TaskManager。</p><p>JobManagers和TaskManagers可以通过多种方式启动：直接作为独立集群、在容器中、或由YARN或Mesos等资源框架管理。TaskManagers连接到JobManagers，宣布它们自己是可用，并被分配工作。</p><p>客户端不是运行时和程序执行的一部分，而是被用来准备和发送的数据流的JobManager。之后，客户端可以断开连接或保持连接以接收进度报告。客户端既可以作为触发执行的Java / Scala程序的一部分运行，也可以在命令行进程中运行./bin/flink run …。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/flink/processes.svg" alt="执行Flink数据流所涉及的过程"></p><h2 id="任务槽和资源"><a href="#任务槽和资源" class="headerlink" title="任务槽和资源"></a>任务槽和资源</h2><p>每个worker（TaskManager）都是一个JVM进程，可以在不同的线程中执行一个或多个子任务。为了控制worker接受的任务数量，worker有所谓的任务槽（至少一个）。</p><p>每个任务槽代表TaskManager的固定资源子集。例如，具有三个插槽的TaskManager将其托管内存的1/3专用于每个插槽。对资源进行分隔意味着子任务不会与来自其他作业的子任务竞争托管内存，而是具有一定数量的保留托管内存。请注意，此处不会发生CPU隔离; 当前插槽只分离任务的托管内存。</p><p>通过调整任务槽的数量，用户可以定义子任务如何相互隔离。每个TaskManager有一个插槽意味着每个任务组在一个单独的JVM中运行（例如，可以在一个单独的容器中启动）。拥有多个插槽意味着更多子任务共享同一个JVM。同一JVM中的任务共享TCP连接（通过多路复用）和心跳消息。它们还可以共享数据集和数据结构，从而减少每任务开销。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/flink/tasks_slots.svg" alt="具有任务槽和任务的TaskManager"></p><p>默认情况下，Flink允许子任务共享插槽，即使它们是不同任务的子任务，只要它们来自同一个作业。结果是一个槽可以容纳整个作业的管道。允许此插槽共享有两个主要好处：</p><p>Flink集群需要与作业中使用的最高并行度一样多的任务槽。无需计算程序总共包含多少任务（具有不同的并行性）。</p><p>更容易获得更好的资源利用率。如果没有插槽共享，非密集型源/ map（）子任务将阻止与资源密集型窗口子任务一样多的资源。通过插槽共享，将示例中的基本并行性从2增加到6可以充分利用插槽资源，同时确保繁重的子任务在TaskManagers之间公平分配。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/flink/slot_sharing.svg" alt="具有共享任务槽的TaskManagers"></p><p>API还包括可用于防止不期望的插槽共享的资源组机制。</p><p>根据经验，一个好的默认任务槽数就是CPU核心数。使用超线程，每个插槽然后需要2个或更多硬件线程上下文。</p><h2 id="状态后端"><a href="#状态后端" class="headerlink" title="状态后端"></a>状态后端</h2><p>存储键/值索引的确切数据结构取决于所选的状态后端。一个状态后端将数据存储在内存中的哈希映射中，另一个状态后端使用RocksDB作为键/值存储。除了定义保存状态的数据结构之外，状态后端还实现逻辑以获取键/值状态的时间点快照，并将该快照存储为检查点的一部分逻辑。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/flink/checkpoints.svg" alt="检查点和快照"></p><h2 id="保存点"><a href="#保存点" class="headerlink" title="保存点"></a>保存点</h2><p>用Data Stream API编写的程序可以从保存点恢复执行。保存点允许更新程序和Flink群集，而不会丢失任何状态。</p><p>保存点是手动触发的检查点，它将程序的快照写入状态后端。他们依赖于常规的检查点机制。在执行期间，程序会周期性地在工作节点上创建快照并生成检查点。对于恢复，仅需要最后完成的检查点，并且一旦新的检查点完成，就可以安全地丢弃旧的检查点。</p><p>保存点与这些定期检查点类似，不同之处在于它们由用户触发，并且在完成较新的检查点时不会自动过期。可以从命令行或通过REST API取消作业时创建保存点。</p>]]></content>
      
      
      <categories>
          
          <category> flink </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flink </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>flink handbook - flink数据流编程模型</title>
      <link href="/2018/09/26/flink-concepts-programming-model/"/>
      <url>/2018/09/26/flink-concepts-programming-model/</url>
      
        <content type="html"><![CDATA[<h2 id="抽象层次"><a href="#抽象层次" class="headerlink" title="抽象层次"></a>抽象层次</h2><p>Flink提供不同级别的抽象来开发流/批处理应用程序。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/flink/levels_of_abstraction.svg" alt="抽象层次"></p><ul><li><p>最低级抽象只提供有状态流。它通过Process Function嵌入到DataStream API中。它允许用户自由处理来自一个或多个流的事件，并使用一致的容错状态。此外，用户可以注册事件时间和处理时间回调，允许程序实现复杂的计算。</p></li><li><p>实际上，大多数应用不需要上述低级抽象，而是针对Core API编程， 如DataStream API（有界/无界流）和DataSet API （有界数据集）。这些流动的API提供了用于数据处理的通用构建块，例如各种形式的用户指定的转换，连接，聚合，窗口，状态等。在这些API中处理的数据类型在相应的编程语言中表示为类。</p></li></ul><p>低级Process Function与DataStream API集成，因此只能对某些操作进行低级抽象。DataSet API提供的有限数据集的其他原语，如循环/迭代。</p><ul><li>Table API是以表为中心的声明性DSL，其可以是动态地改变的表（表示流时）。Table API遵循（扩展）关系模型：表附加了一个模式（类似于在关系数据库中的表），API提供了类似的操作，如选择，项目，连接，分组依据，聚合等。Table API程序以声明方式定义应该执行的逻辑操作，而不是准确指定 操作代码的外观。虽然Table API可以通过各种类型的用户定义函数进行扩展，但它的表现力不如Core API，但使用更简洁（编写的代码更少）。此外，Table API程序还会通过优化程序，在执行之前应用优化规则。</li></ul><p>可以在表和DataStream / DataSet之间无缝转换，允许程序混合Table API以及DataStream 和DataSet API。</p><ul><li>Flink提供的最高级抽象是SQL。这种抽象在语义和表达方面类似于Table API，但是将程序表示为SQL查询表达式。在SQL抽象与 Table API紧密地相互作用，和SQL查询可以在Table API中定义的表上执行。</li></ul><h2 id="程序和数据流"><a href="#程序和数据流" class="headerlink" title="程序和数据流"></a>程序和数据流</h2><p>Flink程序的基本构建块是流和转换。（请注意，Flink的DataSet API中使用的DataSet也是内部流 - 稍后会详细介绍。）从概念上讲，流是（可能永无止境的）数据记录流，而转换是将一个或多个流作为输入，并产生一个或多个流输出的结果。</p><p>执行时，Flink程序映射到流数据流，由流和转换运算符组成。每个数据流都以一个或多个源开头，并以一个或多个接收器结束。数据流类似于任意有向无环图 （DAG）。尽管通过迭代结构允许特殊形式的循环 ，但为了简单起见，我们将在大多数情况下对此进行掩饰。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/flink/program_dataflow.svg" alt="DataStream程序及其数据流"></p><p>通常，程序中的转换与数据流中的运算符之间存在一对一的对应关系。但是，有时一个转换可能包含多个转换运算符。</p><p>源流和接收器记录在流连接器和批处理连接器文档中。DataStream运算符和DataSet转换中记录了转换。</p><h2 id="并行数据流"><a href="#并行数据流" class="headerlink" title="并行数据流"></a>并行数据流</h2><p>Flink中的程序本质上是并行和分布式的。在执行期间，流具有一个或多个流分区，并且每个运算符具有一个或多个运算符子任务。运算符子任务彼此独立，并且可以在不同的线程中执行，并且可能在不同的机器或容器上执行。</p><p>运算符子任务的数量是该特定运算符的并行度。流的并行性始终是其生成运算符的并行性。同一程序的不同运算符可能具有不同的并行级别。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/flink/parallel_dataflow.svg" alt="并行数据流"></p><p>流可以以一对一（或转发）模式或以重新分发模式在两个算子之间传输数据：</p><ul><li><p>一对一流（例如，在上图中的Source和map（）算子之间）保留元素的分区和排序。这意味着map（）算子的subtask [1] 将以与Source算子的subtask [1]生成的顺序相同的顺序看到相同的元素。</p></li><li><p>重新分配流（在上面的map（）和keyBy / window之间，以及 keyBy / window和Sink之间）重新分配流。每个算子子任务将数据发送到不同的目标子任务，具体取决于所选的转换。实例是 keyBy（） （其通过散列密钥重新分区），广播（） ，或重新平衡（） （其重新分区随机地）。在重新分配交换中，元素之间的排序仅保留在每对发送和接收子任务中（例如，map（）的子任务[1] 和子任务[2]keyBy / window）。因此，在此示例中，保留了每个密钥内的排序，但并行性确实引入了关于不同密钥的聚合结果到达接收器的顺序的非确定性。</p></li></ul><p>有关配置和控制并行性的详细信息，请参阅并行执行的文档。</p><h2 id="视窗"><a href="#视窗" class="headerlink" title="视窗"></a>视窗</h2><p>聚合事件（例如，计数，总和）在流上的工作方式与批处理方式不同。例如，不可能计算流中的所有元素，因为流通常是无限的（无界）。相反，流上的聚合（计数，总和等）由窗口限定，例如“在最后5分钟内计数”或“最后100个元素的总和”。</p><p>Windows可以是时间驱动的（例如：每30秒）或数据驱动（例如：每100个元素）。一个典型地区分不同类型的窗口，例如翻滚窗口（没有重叠）， 滑动窗口（具有重叠）和会话窗口（由不活动的间隙打断）。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/flink/windows.svg" alt="时间和计数Windows"></p><p>更多窗口示例可以在此博客文章中找到。更多详细信息在窗口文档中。</p><h2 id="时间"><a href="#时间" class="headerlink" title="时间"></a>时间</h2><p>当在流程序中引用时间（例如定义窗口）时，可以参考不同的时间概念：</p><ul><li><p>事件时间是创建事件的时间。它通常由事件中的时间戳描述，例如由生产传感器或生产服务附加。Flink通过时间戳分配器访问事件时间戳。</p></li><li><p>摄取时间是事件在源操作员处输入Flink数据流的时间。</p></li><li><p>处理时间是执行基于时间的操作的每个算子的本地时间。</p></li></ul><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/flink/event_ingestion_processing_time.svg" alt="事件时间，摄取时间和处理时间"></p><p>有关如何处理时间的更多详细信息，请参阅<a href="https://ci.apache.org/projects/flink/flink-docs-master/dev/event_time.html" target="_blank" rel="noopener">事件时间文档</a>。</p><h2 id="有状态的操作"><a href="#有状态的操作" class="headerlink" title="有状态的操作"></a>有状态的操作</h2><p>虽然数据流中的许多操作只是一次查看一个单独的事件（例如事件解析器），但某些操作会记住多个事件（例如窗口操作符）的信息。这些操作称为有状态。</p><p>状态操作的状态保持在可以被认为是嵌入式键/值存储的状态中。状态被分区并严格地与有状态算子读取的流一起分发。因此，只有在keyBy（）函数之后才能在键控流上访问键/值状态，并且限制为与当前事件的键相关联的值。对齐流和状态的密钥可确保所有状态更新都是本地操作，从而保证一致性而无需事务开销。此对齐还允许Flink重新分配状态并透明地调整流分区。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/flink/state_partitioning.svg" alt="状态和分区"></p><p>有关更多信息，请参阅有关状态的文档。</p><h2 id="容错检查点"><a href="#容错检查点" class="headerlink" title="容错检查点"></a>容错检查点</h2><p>Flink使用流重放和检查点的组合实现容错。检查点与每个输入流中的特定点以及每个算子的对应状态相关。通过恢复算子的状态并从检查点重放事件，可以从检查点恢复流数据流，同时保持一致性（恰好一次处理语义）。</p><p>检查点间隔是在执行期间用恢复时间（需要重放的事件的数量）来折衷容错开销的手段。</p><p><a href="https://ci.apache.org/projects/flink/flink-docs-master/internals/stream_checkpointing.html" target="_blank" rel="noopener">容错内部</a>的描述提供了有关Flink如何管理检查点和相关主题的更多信息。有关启用和配置检查点的详细信息，请参阅检查点API文档。</p><h2 id="批处理流"><a href="#批处理流" class="headerlink" title="批处理流"></a>批处理流</h2><p>Flink执行<a href="https://ci.apache.org/projects/flink/flink-docs-master/dev/batch/index.html" target="_blank" rel="noopener">批处理程序</a>作为流程序的特殊情况，其中流是有界的（有限数量的元素）。数据集做为数据流在内部处理。因此，上述概念以适用于流程序相同的方式应用于批处理程序，只是少数例外：</p><ul><li><p><a href="https://ci.apache.org/projects/flink/flink-docs-master/dev/batch/fault_tolerance.html" target="_blank" rel="noopener">批处理程序的容错</a>不使用检查点。而是通过完全重放流来恢复。这是可能的，因为输入是有界的。这会使成本更多高，但却使常规处理更便宜，因为它避免了检查点。</p></li><li><p>DataSet API中的有状态操作使用简化的内存/核外数据结构，而不是键/值索引。</p></li><li><p>DataSet API引入了特殊的同步（基于超前的）迭代，这在有界流上是可行的。有关详细信息，请查看<a href="https://ci.apache.org/projects/flink/flink-docs-master/dev/batch/iterations.html" target="_blank" rel="noopener">迭代文档</a>。</p></li></ul><h2 id="下一步"><a href="#下一步" class="headerlink" title="下一步"></a>下一步</h2><p>Flink的Distributed Runtime。</p>]]></content>
      
      
      <categories>
          
          <category> flink </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flink </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Flink handbook - Apache Flink的文档</title>
      <link href="/2018/09/24/flink-apache-flink-home/"/>
      <url>/2018/09/24/flink-apache-flink-home/</url>
      
        <content type="html"><![CDATA[<h2 id="Apache-Flink文档"><a href="#Apache-Flink文档" class="headerlink" title="Apache Flink文档"></a>Apache Flink文档</h2><p>本文档适用于Apache Flink master版。</p><p>Apache Flink是一个用于分布式流和批处理数据处理的开源平台。Flink的核心是流数据流引擎，为数据流上的分布式计算提供数据分发，通信和容错。Flink在流引擎之上构建批处理，涵盖原生的迭代支持，受管理的内存和程序优化。</p><h2 id="第一步"><a href="#第一步" class="headerlink" title="第一步"></a>第一步</h2><p><strong>概念：</strong>从Flink的<a href="https://ci.apache.org/projects/flink/flink-docs-master/concepts/programming-model.html" target="_blank" rel="noopener">数据流编程模型</a>和<a href="https://ci.apache.org/projects/flink/flink-docs-master/concepts/runtime.html" target="_blank" rel="noopener">分布式运行时环境</a>的基本概念开始。这将有助于您了解文档的其他部分，包括配置和编程指南。我们建议您先阅读这部分内容。</p><p><strong>教程：</strong></p><ul><li><a href="https://ci.apache.org/projects/flink/flink-docs-master/tutorials/datastream_api.html" target="_blank" rel="noopener">实现并运行DataStream应用</a></li><li><a href="https://ci.apache.org/projects/flink/flink-docs-master/tutorials/local_setup.html" target="_blank" rel="noopener">配置本地Flink群集</a></li></ul><p><strong>编程指南：</strong>您可以阅读我们关于<a href="https://ci.apache.org/projects/flink/flink-docs-master/dev/api_concepts.html" target="_blank" rel="noopener">基本API概念</a>和<a href="https://ci.apache.org/projects/flink/flink-docs-master/dev/datastream_api.html" target="_blank" rel="noopener">DataStream API</a>或<a href="https://ci.apache.org/projects/flink/flink-docs-master/dev/batch/index.html" target="_blank" rel="noopener">DataSet API</a>的指南，以了解如何编写您的第一个Flink程序。</p><h2 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h2><p>在将Flink作业投入生产之前，请阅读<a href="https://ci.apache.org/projects/flink/flink-docs-master/ops/production_ready.html" target="_blank" rel="noopener">生产准备清单</a>。</p><h2 id="发行说明"><a href="#发行说明" class="headerlink" title="发行说明"></a>发行说明</h2><p>发行说明涵盖了Flink版本之间的重要更改。如果您计划将Flink升级到更高版本，请仔细阅读这些说明。</p><ul><li><a href="https://ci.apache.org/projects/flink/flink-docs-master/release-notes/flink-1.6.html" target="_blank" rel="noopener">Flink 1.6发行说明</a></li><li><a href="https://ci.apache.org/projects/flink/flink-docs-master/release-notes/flink-1.5.html" target="_blank" rel="noopener">Flink 1.5的发行说明</a></li></ul><h2 id="外部资源"><a href="#外部资源" class="headerlink" title="外部资源"></a>外部资源</h2><ul><li><p>Flink Forward：<a href="http://flink-forward.org/" target="_blank" rel="noopener">Flink Forward网站</a>和<a href="https://www.youtube.com/channel/UCY8_lgiZLZErZPF47a2hXMA" target="_blank" rel="noopener">YouTube</a>上提供了以往会议的讲座。<a href="http://2016.flink-forward.org/kb_sessions/robust-stream-processing-with-apache-flink/" target="_blank" rel="noopener">使用Apache Flink进行可靠的流处理</a>，那这些资料是一个很好的起点。</p></li><li><p>培训：data Artisans的<a href="http://training.data-artisans.com/" target="_blank" rel="noopener">培训材料</a>包括幻灯片，练习和示例。</p></li><li><p>博客：<a href="https://flink.apache.org/blog/" target="_blank" rel="noopener">Apache Flink</a>和<a href="https://data-artisans.com/blog/" target="_blank" rel="noopener">data Artisans</a>博客会比较频繁的发布flink相关的、深入的技术文章。</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> flink </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flink </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Flink handbook - flink常见问题</title>
      <link href="/2018/09/24/flink-faq/"/>
      <url>/2018/09/24/flink-faq/</url>
      
        <content type="html"><![CDATA[<p>关于Flink项目，一般会经常被问到以下问题。</p><h2 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h2><h2 id="Apache-Flink仅用于（近）实时处理用例吗？"><a href="#Apache-Flink仅用于（近）实时处理用例吗？" class="headerlink" title="Apache Flink仅用于（近）实时处理用例吗？"></a>Apache Flink仅用于（近）实时处理用例吗？</h2><p>Flink是一个非常通用的系统，用于数据处理和数据驱动的应用程序，数据流作为核心构建块。这些数据流可以是实时数据流,也可以是存储的历史数据流。例如，在Flink的视图中，文件是存储的字节流。因此，Flink支持实时数据处理和应用，以及批处理应用。</p><p>流可以是无界的（没有结束，事件不断发生）或受限制（流有开始和结束）。例如，来自消息队列的Twitter馈送或事件流通常是无界流，而来自文件的字节流是有界流。</p><h2 id="如果一切都是流，为什么Flink中有DataStream和DataSet-API？"><a href="#如果一切都是流，为什么Flink中有DataStream和DataSet-API？" class="headerlink" title="如果一切都是流，为什么Flink中有DataStream和DataSet API？"></a>如果一切都是流，为什么Flink中有DataStream和DataSet API？</h2><p>有界流通常比无界流更有效。在（近）实时处理无限事件流需要系统能够立即对事件起作用并产生中间结果（通常具有低延迟）。处理有界流通常不需要产生低延迟结果，因为无论如何数据都是旧的（相对而言）。这允许Flink以简单且更有效的方式处理数据。</p><p>DataStream API通过支持低延时的结果和对事件和时间（包括事件时间）灵活反应的模型捕获无界流和有界流的连续处理，</p><p>DataSet API具有加快有界数据流的处理的技术。将来，社区计划将这些优化与DataStream API中的技术相结合。</p><h2 id="Flink如何与Hadoop堆栈相关？"><a href="#Flink如何与Hadoop堆栈相关？" class="headerlink" title="Flink如何与Hadoop堆栈相关？"></a>Flink如何与Hadoop堆栈相关？</h2><p>Flink独立于Apache Hadoop，并且在没有任何Hadoop依赖性的情况下运行。</p><p>但是，Flink与许多Hadoop组件集成得非常好，例如HDFS，YARN或HBase。与这些组件一起运行时，Flink可以使用HDFS读取数据，或写入结果和检查点/快照。Flink可以通过YARN轻松部署，并与YARN和HDFS Kerberos安全模块集成。</p><h2 id="Flink运行的其他堆栈是什么？"><a href="#Flink运行的其他堆栈是什么？" class="headerlink" title="Flink运行的其他堆栈是什么？"></a>Flink运行的其他堆栈是什么？</h2><p>Flink可以在Kubernetes，Mesos， Docker上运行 ，甚至作为独立服务运行。</p><h2 id="使用Flink有哪些先决条件？"><a href="#使用Flink有哪些先决条件？" class="headerlink" title="使用Flink有哪些先决条件？"></a>使用Flink有哪些先决条件？</h2><p>您需要Java 8来运行Flink作业/应用。<br>Scala API（可选）依赖于Scala 2.11。<br>Apache ZooKeeper需要高度可用且没有单点故障的设置。<br>对于可以从故障中恢复的高可用流处理设置，Flink需要某种形式的分布式存储用于检查点（HDFS / S3 / NFS / SAN / GFS / Kosmos / Ceph / …）。</p><h2 id="Flink支持多大的规模？"><a href="#Flink支持多大的规模？" class="headerlink" title="Flink支持多大的规模？"></a>Flink支持多大的规模？</h2><p>用户在非常小的设置（少于5个节点）和1000个节点以及状态的TB上运行Flink作业。</p><h2 id="Flink是否仅限于内存数据集？"><a href="#Flink是否仅限于内存数据集？" class="headerlink" title="Flink是否仅限于内存数据集？"></a>Flink是否仅限于内存数据集？</h2><p>对于DataStream API，Flink支持大于内存的状态来配置RocksDB状态后端。</p><p>对于DataSet API，所有操作（delta迭代除外）都可以扩展到主内存之外。</p><h2 id="常见错误消息"><a href="#常见错误消息" class="headerlink" title="常见错误消息"></a>常见错误消息</h2><p>“ 获得帮助”页面上列出了常见错误消息。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1].<a href="https://flink.apache.org/faq.html" target="_blank" rel="noopener">https://flink.apache.org/faq.html</a></p>]]></content>
      
      
      <categories>
          
          <category> flink </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flink </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Flink handbook - flink用例</title>
      <link href="/2018/09/23/flink-use-cases/"/>
      <url>/2018/09/23/flink-use-cases/</url>
      
        <content type="html"><![CDATA[<h2 id="用例"><a href="#用例" class="headerlink" title="用例"></a>用例</h2><p>Apache Flink因其丰富的功能集而成为开发和运行多种不同类型应用程序的绝佳选择。Flink的功能包括对流和批处理的支持，复杂的状态管理，事件时间处理语义以及状态的恰好一次一致性保证。此外，Flink可以部署在各种资源管理集群（如YARN，Apache Mesos和Kubernetes）上，也可以部署为裸机硬件上的单个群集。Flink配置为高可用性，没有单点故障。Flink已经被证明可以扩展到数千个核心和万亿字节的应用状态，提供高吞吐量和低延迟，并为世界上一些最苛刻的流处理应用程序提供支持。</p><p>下面，我们将探讨由Flink提供支持的最常见类型的应用程序，并指出实际示例。</p><ul><li>事件驱动的应用</li><li>数据分析应用</li><li>数据管道应用</li></ul><h2 id="事件驱动的应用"><a href="#事件驱动的应用" class="headerlink" title="事件驱动的应用"></a>事件驱动的应用</h2><h3 id="什么是事件驱动的应用？"><a href="#什么是事件驱动的应用？" class="headerlink" title="什么是事件驱动的应用？"></a>什么是事件驱动的应用？</h3><p>事件驱动的应用程序是一个有状态的应用程序，它从一个或多个事件流中提取事件，并通过触发计算，状态更新或外部操作对传入事件做出响应。</p><p>事件驱动的应用程序是传统应用程序设计的演变，具有分离的计算和数据存储层。在传统应用的体系结构中，应用从远程事务数据库中读取数据并将数据持久化到远程事务数据库。</p><p>相比之下，事件驱动的应用程序基于有状态流处理应用程序。在这种设计中，数据和计算是共同定位的，这产生了本地（内存或磁盘）数据访问。通过定期将检查点写入远程持久存储来实现容错。下图描绘了传统应用程序体系结构和事件驱动应用程序之间的差异。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/flink%2Fusecases-eventdrivenapps.png" alt=""></p><h3 id="事件驱动的应用有哪些优点？"><a href="#事件驱动的应用有哪些优点？" class="headerlink" title="事件驱动的应用有哪些优点？"></a>事件驱动的应用有哪些优点？</h3><p>事件驱动的应用程序不是查询远程数据库，而是在本地访问其数据，从而在吞吐量和延迟方面发挥更好的性能。远程持久存储的定期检查点可以异步和递增完成。因此，检查点对常规事件处理的影响非常小。但是，事件驱动的应用程序设计提供的不仅仅是本地数据访问。在分层体系结构中，多个应用程序共享同一数据库是很常见的。因此，需要协调数据库的任何更改，例如由于应用程序更新或扩展服务而更改数据布局。由于每个事件驱动的应用程序都负责自己的数据，因此对数据表示的更改或扩展应用程序需要较少的协调。</p><h3 id="Flink如何支持事件驱动的应用？"><a href="#Flink如何支持事件驱动的应用？" class="headerlink" title="Flink如何支持事件驱动的应用？"></a>Flink如何支持事件驱动的应用？</h3><p>事件驱动应用程序的限制由流处理器处理时间和状态的程度来定义。Flink的许多杰出功能都围绕着这些概念。Flink提供了一组丰富的状态原语，可以管理非常大的数据量（最多几TB），并且具有恰好一次的一致性保证。此外，Flink支持事件时间，高度可定制的窗口逻辑，以及通过ProcessFunction实现高级业务逻辑提供的细粒度时间控制。此外，Flink还提供了一个用于复杂事件处理（CEP）的库，用于检测数据流中的模式。</p><p>但是，Flink针对事件驱动应用程序的突出特点是保存点功能。保存点是一致的状态图像，可用作兼容应用程序的起点。给定保存点，可以更新应用程序或调整其规模，或者可以启动应用程序的多个版本以进行A / B测试。</p><h3 id="什么是典型的事件驱动应用？"><a href="#什么是典型的事件驱动应用？" class="headerlink" title="什么是典型的事件驱动应用？"></a>什么是典型的事件驱动应用？</h3><ul><li>欺诈识别</li><li>异常检测</li><li>基于规则的警报</li><li>业务流程监控</li><li>Web应用程序（社交网络）</li></ul><h2 id="数据分析应用"><a href="#数据分析应用" class="headerlink" title="数据分析应用"></a>数据分析应用</h2><h3 id="什么是数据分析应用？"><a href="#什么是数据分析应用？" class="headerlink" title="什么是数据分析应用？"></a>什么是数据分析应用？</h3><p>分析工作从原始数据中提取信息和洞察力。传统上，分析是在有记录事件的有界数据集上作为批查询或应用程序来执行的。为了将最新数据合并到分析结果中，必须将其添加到分析的数据集中，并重新运行查询或应用程序。结果将写入存储系统或作为报告发出。</p><p>借助先进的流处理引擎，还可以实时地执行分析。流式查询或应用程序不是读取有限数据集，而是摄取实时事件流，并在消耗事件时不断生成和更新结果。结果要么写入外部数据库，要么保持为内部状态。仪表板应用程序可以从外部数据库读取最新结果或直接查询应用程序的内部状态。</p><p>Apache Flink支持流式和批量分析应用程序，如下图所示。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/flink%2Fusecases-analytics.png" alt=""></p><h3 id="流式分析应用有哪些优势？"><a href="#流式分析应用有哪些优势？" class="headerlink" title="流式分析应用有哪些优势？"></a>流式分析应用有哪些优势？</h3><p>与批量分析相比，连续流分析的优势不仅限于因消除定期导入和查询执行而从事件到洞察的低得多的延迟。与批量查询相比，流式查询不必处理输入数据中的人为边界，这些边界是由定期导入和输入的有界性质引起的。</p><p>另一方面是更简单的应用程序架构。批量分析管道由若干独立组件组成，以周期性地调度数据提取和查询执行。可靠地操作这样的管道并非易事，因为一个组件的故障会影响管道的后续步骤。相比之下，在像Flink这样的复杂流处理器上运行的流分析应用程序包含从数据摄取到连续结果计算的所有步骤。因此，它可以依赖于引擎的故障恢复机制。</p><h3 id="Flink如何支持数据分析应用？"><a href="#Flink如何支持数据分析应用？" class="headerlink" title="Flink如何支持数据分析应用？"></a>Flink如何支持数据分析应用？</h3><p>Flink为连续流式传输和批量分析提供了非常好的支持。具体来说，它具有符合ANSI标准的SQL接口，具有用于批处理和流式查询的统一语义。无论是在记录事件的静态数据集上还是在实时事件流上运行，SQL查询都会计算相同的结果。对用户定义函数的丰富支持可确保在SQL查询中执行自定义代码。如果需要更多的自定义逻辑，Flink的DataStream API或DataSet API提供更多的低级控制。此外，Flink的Gelly库为批量数据集上的大规模和高性能图形分析提供算法和构建块。</p><h3 id="什么是典型的数据分析应用？"><a href="#什么是典型的数据分析应用？" class="headerlink" title="什么是典型的数据分析应用？"></a>什么是典型的数据分析应用？</h3><ul><li>电信网络的质量监控</li><li>分析移动应用程序中的产品更新和实验评估</li><li>对消费者技术中的实时数据进行特别分析</li><li>大规模图分析</li></ul><h2 id="数据管道应用"><a href="#数据管道应用" class="headerlink" title="数据管道应用"></a>数据管道应用</h2><h3 id="什么是数据管道？"><a href="#什么是数据管道？" class="headerlink" title="什么是数据管道？"></a>什么是数据管道？</h3><p>提取 - 转换 - 加载（ETL）是在存储系统之间转换和移动数据的常用方法。通常会定期触发ETL作业，以便将数据从事务数据库系统复制到分析数据库或数据仓库。</p><p>数据管道与ETL作业具有相似的用途。它们可以转换和丰富数据，并可以将数据从一个存储系统移动到另一个存储系统 但是，它们以连续流模式运行，而不是周期性地触发。因此，他们能够从连续生成数据的源中读取记录，并以低延迟将其移动到目的地。例如，数据管道可能会监视文件系统目录中的新文件并将其数据写入事件日志。另一个应用程序可能会将事件流实现到数据库，或者逐步构建和优化搜索索引。</p><p>下图描述了定期ETL作业和连续数据管道之间的差异。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/flink%2Fusecases-datapipelines.png" alt=""></p><h3 id="数据管道有哪些优势？"><a href="#数据管道有哪些优势？" class="headerlink" title="数据管道有哪些优势？"></a>数据管道有哪些优势？</h3><p>连续数据流水线优于周期性ETL作业的显著优势是减少了将数据移动到目的地的延迟。此外，数据管道更加通用，可用于更多用例，因为它们能够连续消耗和发送数据。</p><h3 id="Flink如何支持数据管道？"><a href="#Flink如何支持数据管道？" class="headerlink" title="Flink如何支持数据管道？"></a>Flink如何支持数据管道？</h3><p>Flink的SQL接口（或表API）可以解决许多常见的数据转换或丰富任务，并支持用户定义的函数。通过使用更通用的DataStream API，可以实现具有更高级要求的数据管道。Flink为各种存储系统（如Kafka，Kinesis，Elasticsearch和JDBC数据库系统）提供了丰富的连接器。它还具有连续的文件系统源，用于监视以时间分区方式写入文件的目录和接收器。</p><h3 id="什么是典型的数据管道应用？"><a href="#什么是典型的数据管道应用？" class="headerlink" title="什么是典型的数据管道应用？"></a>什么是典型的数据管道应用？</h3><ul><li>电子商务中的实时搜索索引构建</li><li>电子商务中持续的ETL</li></ul><h2 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h2><p>[1].<a href="https://flink.apache.org/usecases.html" target="_blank" rel="noopener">https://flink.apache.org/usecases.html</a></p>]]></content>
      
      
      <categories>
          
          <category> flink </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flink </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Flink handbook - 什么是Apache Flink？</title>
      <link href="/2018/09/23/flink-what-is-apache-flink/"/>
      <url>/2018/09/23/flink-what-is-apache-flink/</url>
      
        <content type="html"><![CDATA[<p>Apache Flink是一个框架和分布式处理引擎，用于对无界和有界数据流进行有状态计算。Flink设计为在所有常见的集群环境中运行，以内存速度和任何规模执行计算。</p><p>在这里，我们解释了Flink架构的重要方面。</p><h2 id="无界和有界数据的处理"><a href="#无界和有界数据的处理" class="headerlink" title="无界和有界数据的处理"></a>无界和有界数据的处理</h2><p>任何类型的数据都是作为事件流产生的。信用卡交易，传感器测量，机器日志或网站或移动应用程序上的用户交互，所有这些数据都作为流生成。</p><p>数据可以作为无界或有界流处理。</p><ol><li><p><strong>无界流</strong> 有一个开始，但没有定义的结束。它们不会终止并提供其生成的数据。无界流必须持续处理，即必须在摄取事件后立即处理事件。不可能等待所有的输入数据都到达，因为输入是无界的，并且在任何时间点都不会结束。处理无界数据通常要求以特定顺序（例如事件发生的顺序）摄取事件，以便能够推断结果的完整性。</p></li><li><p><strong>有界流</strong>具有定义的开始和结束。可以在执行任何计算之前，通过摄取所有数据来处理有界流。有界数据集是可以被排序的，因此处理有界流不需要有序摄取。有界流的处理也称为批处理。</p></li></ol><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/flink%2Fbounded-unbounded.png" alt=""></p><p><strong>Apache Flink擅长处理无界和有界数据集</strong>。精确控制时间和状态使Flink的运行时能够在无界流上运行任何类型的应用程序。有界流由算法和数据结构在内部处理，这些算法和数据结构专门针对固定大小的数据集而设计，从而发挥出性能优势。</p><h2 id="随处部署应用"><a href="#随处部署应用" class="headerlink" title="随处部署应用"></a>随处部署应用</h2><p>Apache Flink是一个分布式系统，需要计算资源才能执行的应用程序。Flink可以与所有常见的集群资源管理器（如Hadoop YARN，Apache Mesos和Kubernetes）集成，但也可以设置为独立的集群运行。</p><p>Flink旨在很好地适用于之前列出的每个资源管理器，这是通过特定于资源管理器的部署模式实现的，这些模式允许Flink以其惯用的方式与每个资源管理器进行交互。</p><p>部署Flink应用程序时，Flink会根据应用程序配置的并行性自动识别所需资源，并从资源管理器里申请它们。如果发生故障，Flink会通过申请新资源来替换发生故障的容器。所有提交或控制应用程序的通信都是通过REST调用来进行，这简化了Flink在许多环境中的集成。</p><h2 id="以任何规模运行应用"><a href="#以任何规模运行应用" class="headerlink" title="以任何规模运行应用"></a>以任何规模运行应用</h2><p>Flink旨在以任何规模运行有状态的流应用，应用程序可以并行化为数千个在集群中分布和同时执行的任务。因此，应用程序可以利用几乎无限量的CPU、主内存、磁盘和网络IO。而且，Flink可以轻松维护数据量非常大的应用状态。其异步和增量检查点算法确保对处理的延迟影响最小，同时保证恰好一次状态的一致性。</p><p>用户报告了在其生产环境中运行的Flink集群的规模，这样的规模有点令人印象深刻，例如</p><ul><li>应用程序每天处理数万亿个事件，</li><li>应用程序维护多个TB的状态，以及</li><li>应用程序在数千个内核的运行。</li></ul><h2 id="内存的性能优势"><a href="#内存的性能优势" class="headerlink" title="内存的性能优势"></a>内存的性能优势</h2><p>有状态Flink应用针对本地状态的访问进行了优化。任务状态始终保留在内存中，或者，如果状态大小超过可用内存，则保存在可高效访问的磁盘上的数据结构中。因此，任务通过访问本地（通常是内存中）状态来执行所有计算，从而产生非常低的处理延迟。Flink通过定期并且异步地把本地状态打检查点并持久化到存储设备来保证在出现故障时的恰好一次状态的一致性。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/flink%2Flocal-state.png" alt=""></p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1].<a href="https://flink.apache.org/flink-architecture.html" target="_blank" rel="noopener">https://flink.apache.org/flink-architecture.html</a></p>]]></content>
      
      
      <categories>
          
          <category> flink </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flink </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>微服务-微服务解惑</title>
      <link href="/2018/09/23/distributed-microservice-weifuwunaxieshier/"/>
      <url>/2018/09/23/distributed-microservice-weifuwunaxieshier/</url>
      
        <content type="html"><![CDATA[<h2 id="微服务解惑"><a href="#微服务解惑" class="headerlink" title="微服务解惑"></a>微服务解惑</h2><h3 id="微服务与容器"><a href="#微服务与容器" class="headerlink" title="微服务与容器"></a>微服务与容器</h3><p>微服务又指的是在传统应用架构的基础上，按照业务能力将系统拆分成多个服务，每个服务都是一个独立的应用，对外提供一些列的公共服务API，服务之间以轻量的方式互相调用。<br>微服务里的每个服务都是一个组件，通过编排组合从而达到独立、解耦、组件化、易维护、可复用、可替换、高可用的设计原则。微服务后，自动化部署以及运维是比较头疼的事，容器技术解决了这个问题。</p><ul><li>好的架构需要考虑后面的扩展以及修改</li><li>好的架构是解耦的，需改一个地方不会影响另外一个地方</li><li>好的架构是轻便灵活的，一个应用最好只解决一个问题，而不是叠加功能</li></ul><h3 id="微服务的标签"><a href="#微服务的标签" class="headerlink" title="微服务的标签"></a>微服务的标签</h3><ul><li>单一职责</li><li>微</li><li>面向服务</li><li>自治</li><li>易扩展</li><li>流程化</li></ul><h3 id="微服务的不足"><a href="#微服务的不足" class="headerlink" title="微服务的不足"></a>微服务的不足</h3><ul><li>时效性·服务间的调用延时可能导致系统相应慢的问题</li><li>一致性·微服务在保证一致性上需要做更多的工作</li></ul><h3 id="微服务的价值"><a href="#微服务的价值" class="headerlink" title="微服务的价值"></a>微服务的价值</h3><ul><li>资源价值，资源不足是自动扩容，资源过量时自动缩容；</li><li>业务价值，工作量、人员数量、交付质量、交付周期；</li><li>技术价值，技术是为业务来服务的（个人标注：技术也是业务的一部分而不只是为业务而服务）</li><li>用户价值，用户体验好，服务上线快</li><li>未来价值，技术不成为业务的瓶颈</li></ul><h3 id="微服务的小目标"><a href="#微服务的小目标" class="headerlink" title="微服务的小目标"></a>微服务的小目标</h3><ul><li>持续交付</li><li>业务敏捷</li><li>独立演进</li><li>高可用</li><li>高性能</li></ul><h3 id="微服务的拆与不拆"><a href="#微服务的拆与不拆" class="headerlink" title="微服务的拆与不拆"></a>微服务的拆与不拆</h3><p>依据：数据模型、业务模型、关键指标，粒度平衡，边界合理</p><h3 id="DevOPS"><a href="#DevOPS" class="headerlink" title="DevOPS"></a>DevOPS</h3><p>开发与运维是一个整体，devops是一种思维方式，微服务与devops是天生一对</p><h3 id="SpringCloud特点"><a href="#SpringCloud特点" class="headerlink" title="SpringCloud特点"></a>SpringCloud特点</h3><ul><li>功能齐全</li><li>标准化</li><li>简单方便</li><li>按需取用</li><li>轻量</li><li>易扩展、易维护</li><li>可复用性</li></ul><h3 id="分布式系统组件及操作"><a href="#分布式系统组件及操作" class="headerlink" title="分布式系统组件及操作"></a>分布式系统组件及操作</h3><p>配置管理（Spring cloud config）、服务发现/调用(Feign)、断路器、智能路由（ZUUL）、微代理、控制总线、一次性Token、全局锁、决策竞选、分布式会话、集群状态。</p><p>注册中心(Eureka)、负载均衡(Ribbon)、断路器（Hystrix）、服务追踪（Sleuth，zipkin）、权限（string security）、接口可视化（Swagger）。</p><p>以上内容为《微服务那些事儿》读书笔记。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1]. 微服务那些事儿，纪晓峰著</p>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>打造“流原生”式大数据处理平台</title>
      <link href="/2018/09/22/bigdata-streaming-native-platform/"/>
      <url>/2018/09/22/bigdata-streaming-native-platform/</url>
      
        <content type="html"><![CDATA[<h1 id="开篇-马斯克们的Hyperloop"><a href="#开篇-马斯克们的Hyperloop" class="headerlink" title="开篇,马斯克们的Hyperloop"></a>开篇,马斯克们的Hyperloop</h1><p>我们先来看张图，下图上部分是现在的高铁，它是跑在露天的轨道上的，下图是Elon Musk’s 在正吹的<a href="https://hyperloop-one.com" target="_blank" rel="noopener">hyperloop</a>，类似于跑在真空管道里的未来高铁。相比跑在露天轨道里的高铁，跑真空管道里的高铁好处多了：快，节能，安全，比飞机便宜。。。<br>技术是可以自己进化的，相信类似hyperloop的”高铁+真空管道”的模式就是未来的一种交通出行方式。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/streaming%2Fstreaming-native-platform-0.jpg" alt="hyperloop"></p><p>那么HYPERLOOP跟本文又有什么关系呢？ 是不是有点扯远了？其实本文讲的就是类似给高铁加上真空管道的活，二者本质上是相同的。</p><h2 id="管道-Unix-Linux的设计哲学"><a href="#管道-Unix-Linux的设计哲学" class="headerlink" title="管道,Unix/Linux的设计哲学"></a>管道,Unix/Linux的设计哲学</h2><p>在Linux或者Unix系统里,有时候我们为了查询某个信息，会输入类似如下的命令行：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs undefined">#cat *.log | grep –v ‘pipeline’ | sort –nr | head –n 10 | tail -5 | awk ‘&#123;print $2&#125;’ | wc –l  &gt; /dev/stdout<br></code></pre></td></tr></table></figure><p>这个命令行通过“|”来分隔多个命令，前面命令的输出是紧接着的后面命令的输入，命令之间通过“|”彼此相连，并且一个命令只做一件事情。这里的“|”就是管道，把一个程序的输出和另一个程序的输入连起来的一根管子。</p><p>在Unix/Linux里存在这样的管道命令设计哲学：</p><ul><li>程序是个过滤器</li><li>一个程序只做一件事并且做到最好</li><li>一个程序的输入是另外一个程序的输出</li></ul><p>下图体现了这样的管道设计哲学，应用之间通过管道相连相互作用：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/streaming%2Fstreaming-native-platform-1.PNG" alt="Uniux/linux pipeline"></p><p>管道所要解决的问题是：<code>高内聚，低耦合</code>。它以一种“链”的方式将这些程序组合起来，让这些程序组成一条工作流，而每个程序又只作一件事情，给定输入，经过各个程序的先后处理，最终得到输出结果，如下图所示：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/streaming%2Fstreaming-native-platform-2.PNG" alt="Uniux/linux pipeline"></p><p>Unix/Linux在<code>&quot;每个程序只做一件事并且做好，每个程序的输出是对另一个程序的输入，可组合性&quot;</code>方面是做的非常成功的。但是，UNIX/Linux也存在一些局限性，比如：<code>&quot;仅单机，只支持一对一通信，无容错，仅字节流,数据处理能力有限等&quot;</code>。意思是说 linux/unix的这些管道命令只能在一台机器上跑，没有分布式，并且只能支持一个命令和另外一个命令之间的一对一的输入输出，无法一对多或多对一；无容错，假如管道坏了数据就出错不能恢复；只支持字节流，不支持数据格式的多样性；处理的数据量有限。</p><p>因此，我们希望可以找到一个数据处理解决方案，这个方案在保留这些Unix/linux管道的设计哲学优点的同时还能克服其缺点。 幸运的是，我们通过Flink+Pravega打造的第三代“流原生”(stream native)式的大数据处理平台实现了这种设计思想。</p><h2 id="流原生-第三代大数据处理平台"><a href="#流原生-第三代大数据处理平台" class="headerlink" title="流原生,第三代大数据处理平台"></a>流原生,第三代大数据处理平台</h2><p>下图体现了“流原生”(stream native)式的设计哲学，Flink是“流原生”的计算，Pravega是“流原生”的存储管道，Flink + pravega 是“流原生”的大数据处理平台。数据从pravega管道输入经过map算子计算，输出中间计算结果到pravega的管道里，数据又从pravega的管道里读入到filter算子里，再经过计算，中间结果放到了pravega管道里，再最后的计算结果经过聚合算子的计算放到了目的地的pravega的管道里。这个过程体现了算子编排和管道式编程的设计哲学。在这里pravega起了大数据处理平台里的管道的作用。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/streaming%2Fstreaming-native-platform-3.PNG" alt="Stream processing pipeline"></p><p>在Unix/Linux中，系统提供管道和命令，用于从一个进程到另一个进程获取字节流。</p><p>在“流原生”处理平台上，Flink提供流处理服务，pravega提供流存储服务，数据源自pravega，被Flink算子们处理后输出到pravega，这是一种将事件从一个流处理作业转移到另一个流处理作业的机制。 Flink和Pravega 所遵循的流处理平台设计哲学是：</p><ul><li>每个算子都只做一件事，并且做到最好</li><li>每个算子的输出是另一个算子的输入</li><li>可组合</li><li>流式传输：数据是动态的，算子是静态的</li><li>算子可编排</li><li>Pravega是最好的Flink搭档</li><li>分布式，扩展到多台机器</li><li>可进化的编码/解码</li></ul><p>当前的流式处理平台一般是 Flink 加传统的存储类型，这种是”半流原生“式的大数据处理平台，计算是原生的流计算而存储却不是原生的流存储。<br>而Pravega就是专门给Flink们设计的原生流存储，它的数据传输方式类似于“管道”，不同于传统的块存储，文件存储以及对象存储，它是一个”管道式流存储“。</p><p>通过Flink + Pravega的组合可以实现 “流原生”(stream native)式的第三代大数据处理平台，未来已来。。。。。</p><h2 id="思考题"><a href="#思考题" class="headerlink" title="思考题"></a>思考题</h2><p>最后给大家留个思考题，“流原生”(stream native)的概念有了，Flink + Pravega 也有了，而且二者的代码都是开源的（flink.apache.org, pravega.io），那么怎么把这些开源的东西产品化？ 或者这个问题太伤脑筋，我们换个简单的问题：“今天中午吃什么？”</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a>作者简介</h2><p>常平，毕业于中国科学技术大学，获硕士研究生学历学位，10年+ 存储、布式系统、云计算以及大数据经验，曾就职于Marvell、AMD等，现就职于EMC，资深首席工程师，主要负责流式大数据处理平台的架构设计、编码及产品交付等。</p>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>算命先生的阴阳五行学说与码农们的分布式系统设计理论</title>
      <link href="/2018/09/22/distributed-tradeoff/"/>
      <url>/2018/09/22/distributed-tradeoff/</url>
      
        <content type="html"><![CDATA[<h2 id="阴阳五行"><a href="#阴阳五行" class="headerlink" title="阴阳五行"></a>阴阳五行</h2><p>一说到阴阳五行就容易让人想到大街上的算命先生，然而阴阳五行学说却是中国古代解释世间万物的起源和多样性的哲学理论依据，是中国古代朴素的唯物论和自发的辩证法思想。</p><p>中国古代哲学的核心思想之一用“老子”的话来说就是：</p><blockquote><p>“道生一、一生二、二生三、三生万物，万物负阴而抱阳，冲气以为和。”。</p></blockquote><p>而五行学说讲的是:<code>“金 木 水 火 土”</code>这五行,五行相生又相克。<code>木头烧火——木生火；火烧木头成灰——火生土，土长期聚在一起生石头、石头里炼金——土生金，金销水——金生水，水又生土。</code>,<code>水克火，火克金，金克木，木克土，土克水。</code></p><p>但是如下图,五行虽然相生相克但都是为“和”字而服务的，即平衡：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed%2Fdistributed-tradeoff-1.PNG" alt="五行"></p><p>解读开来就是：</p><p><code>“天道生阴阳，阴阳成五行，五行变化成万物，而万物的存在方式和相互关系一直在追求一种“和谐”。</code>“道”在阴阳的相互作用下，产生五行，五行之间相互作用产生世间万物的无穷变化，并且阴阳之间对立消长，五行之间相生相克，自此万物得以和谐发展。借助于阴阳五行的核心要素以及由此而生的非核心要素关系把宇宙看成一个统一的整体，这样的整体：<code>循环平衡、相生相克、有刚有柔、和谐统一</code>。</p><p>那么这些玄乎的哲学理论跟码农又有什么关系呢？对于本人这么个靠技术混饭吃卖身又卖艺的码农来说，这实在太重要，归纳成一个字就是”和”，对应到技术实现体系里就是一个理念 ”权衡“，英文叫<code>tradeoff</code>。<code>“tradeoff”</code>这词实在是太妙了，啥都可以往上套，比如你十一准备到哪旅游啦，中午到哪吃饭啦，买哪里的房子啦，准备追哪个姑娘做老婆啦…….，都需要 <code>tradeoff</code>。技术如此人生又何尝不如是。</p><h2 id="分布式系统"><a href="#分布式系统" class="headerlink" title="分布式系统"></a>分布式系统</h2><p>通常来讲设计分布式系统的时候需要考虑的最重要的<code>核心要素</code>有五个，这里不是说其他要素就不重要，这是指经过<code>tradeoff</code>过的五个最重要的核心要素，如下图：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed%2Fdistributed-tradeoff-2.PNG" alt="分布式系统要素"></p><ol><li><p><code>Capacity</code>，容量，其实这个词翻译成”能力“会更合适，指的是分布式系统里的CPU，内存，硬盘，网络，文件描述符，socket连接数，老板的预期，开发周期，成本预算之类的限制条件,以下所有的要素都受 “容量”的限制，这是前提条件，就比如一辆车最多能跑多快，一个人最多能跳多高都是受自身“容量/能力”的限制的；</p></li><li><p><code>Performant</code>, performance + conformant, performant这词也是造的，指的是合适的性能，分布式系统的IOPS，TPS, QPS，Latency,Jitter之类的性能指标要求，性能受限于容量，性能同时又影响了可靠性以及可用性；</p></li><li><p><code>Availability</code>，可用性，可用性通常指的是产品或服务在随机时间内调用时处于可服务状态的概率，通常被定义为正常运行时间除以总时间（正常运行时间加停机时间），比如 5个9，6个9，还有个厂家都喜欢的号称的9个9之类的，可用性受容量的限制同时也受可伸缩性的影响，可用性又影响了性能；</p></li><li><p><code>Reliability</code>，可靠性，一般指的是出保证不出故障的概率，比如，企业级产品 5个9是保底，可测试性和可维护性通常被定义为可靠性当中的一部分，可伸缩性影响了可靠性，而可靠性又影响了可用性，同时性能又影响了可靠性，可靠性也影响着性能。</p></li><li><p><code>Scalability</code>，可伸缩性，这里很容易跟“可扩展性”混淆，可伸缩性可以指的是集群处理越来越多或越来越少的工作的能力，或者是为了适应这种增长或减少而扩大或缩小其能力的能力。可伸缩性影响了可用性，也影响了性能与可靠性，受限于容量。</p></li></ol><p>当然还有另外一些由此而衍生的非核心要素，就不多做详细解释了，比如：</p><ul><li>Testability，可测试性</li><li>Security，安全性</li><li>Observability，可观测性</li><li>Predictability，可预测性</li><li>Extensibility，可扩展性</li><li>Maintainability，可维护性</li><li>Serviceability， 可服务性</li></ul><p>这些非核心要素虽然是非核心但是也不是说就不重要，是<code>开源产品与商业产品</code>差异的关键，关键在如何<code>tradeoff</code>。</p><h2 id="阴阳五行与分布式系统"><a href="#阴阳五行与分布式系统" class="headerlink" title="阴阳五行与分布式系统"></a>阴阳五行与分布式系统</h2><p>将阴阳五行理论与分布式系统设计理论结合起来解读就是：</p><p><code>分布式系统里的“道”就是“产品”，“阴阳“ 就是 ”功能“ 与 “非功能”，五行就是 ”容量、性能、可用性、可伸缩性以及可靠性“，阴阳五行衍生的一些其他关系对应分布式系统五要素衍生的一些其他要素。</code></p><p>用人话来讲就是 开发产品的时候需要考虑功能与非功能两个方面，而要保证产品质量又需要考虑”容量、性能、可用性、可伸缩性以及可靠性“这些核心要素，但是也不能忽略由此而生的一些非核心要素。</p><p>那么从这些理论到产品又需要怎么做才能落地呢？ 那自然是需要 <code>懂得如何把从这些概念性的、功能的、非功能的、这些核心的、非核心的要素进行设计实现成代码</code>，这就涉及到 “术”的层面了，“道”的层面可以通过看书看论文获得，而<code>“术”</code>的获得除了自身努力还得靠机会，而且每个人的悟性还不一样，这些个”术“以后有空慢慢讲。</p><h2 id="思考题"><a href="#思考题" class="headerlink" title="思考题"></a>思考题</h2><p>最后给大家留一个思考题： 前面提过老子曰：<code>”道生一、一生二、二生三、三生万物，万物负阴而抱阳，冲气以为和。“</code>， 三之后就是万物，为什么不是 五、不是六、不是七之类的呢？为什么三之后就是万物了？</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a>作者简介</h2><p>常平，毕业于中国科学技术大学，获硕士研究生学历学位，10年+ 存储、布式系统、云计算以及大数据经验，曾就职于Marvell、AMD等，现就职于EMC，资深首席工程师，主要负责流式大数据处理平台的架构设计、编码及产品交付等。</p><hr><h4 id="注："><a href="#注：" class="headerlink" title="注："></a>注：</h4><ol><li>这个用五行解释分布式系统的观点，以前在一个业内微信群里提出并且聊过，所以这个解读的方式为本人原创非COPY.</li><li>个人愚钝，悟性有限，欢迎拍砖，砖多了我就拿回去砌墙。</li></ol><h3 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h3><p>[1]. <a href="https://baike.sogou.com/v7556185.htm" target="_blank" rel="noopener">https://baike.sogou.com/v7556185.htm</a></p>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Flink handbook - flink集群与部署之kubernetes篇</title>
      <link href="/2018/09/20/flink-deployment-kubernetes/"/>
      <url>/2018/09/20/flink-deployment-kubernetes/</url>
      
        <content type="html"><![CDATA[<p>本页介绍如何在Kubernetes上部署Flink作业和会话群集。</p><h2 id="设置Kubernetes"><a href="#设置Kubernetes" class="headerlink" title="设置Kubernetes"></a>设置Kubernetes</h2><p>请参照<a href="https://kubernetes.io/docs/setup/" target="_blank" rel="noopener">Kubernetes的设置指南</a>来部署Kubernetes集群。如果您想在本地运行Kubernetes，我们建议使用<a href="https://kubernetes.io/docs/setup/minikube/" target="_blank" rel="noopener">MiniKube</a>来部署集群。</p><blockquote><p>注意：如果使用MiniKube，请确保<code>minikube ssh &#39;sudo ip link set docker0 promisc on&#39;</code>在部署Flink群集之前执行。否则，Flink组件无法通过Kubernetes服务自行引用。</p></blockquote><h2 id="Kubernetes上的Flink会话群集"><a href="#Kubernetes上的Flink会话群集" class="headerlink" title="Kubernetes上的Flink会话群集"></a>Kubernetes上的Flink会话群集</h2><p>Flink会话群集作为长期运行的Kubernetes部署来执行，请注意，可以在会话群集上运行多个Flink作业。在部署了集群之后，每个作业都需要提交到群集。</p><p>一个基本的部署在Kubernetes上的Flink会话群集一般会有三个组件：</p><ul><li>一个运行JobManager的deployment或job</li><li>一个TaskManagers池 deployment</li><li>一个公开JobManager的REST和UI端口的service</li></ul><h2 id="在Kubernetes上部署Flink会话群集"><a href="#在Kubernetes上部署Flink会话群集" class="headerlink" title="在Kubernetes上部署Flink会话群集"></a>在Kubernetes上部署Flink会话群集</h2><p>使用会话群集的资源定义，采用kubectl命令启动群集：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs undefined">kubectl create -f jobmanager-service.yaml<br>kubectl create -f jobmanager-deployment.yaml<br>kubectl create -f taskmanager-deployment.yaml<br></code></pre></td></tr></table></figure><p>然后，您可以通过kubectl proxy按以下方式访问Flink UI ：</p><p>第一步，保证kubectl proxy在终端中运行</p><p>第二步，在浏览器里输入 <code>http://localhost:8001/api/v1/namespaces/default/services/flink-jobmanager:ui/proxy</code></p><p>如果要终止Flink会话群集，可以使用如下命令：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs undefined">kubectl delete -f jobmanager-deployment.yaml<br>kubectl delete -f taskmanager-deployment.yaml<br>kubectl delete -f jobmanager-service.yaml<br></code></pre></td></tr></table></figure><h2 id="Kubernetes上的Flink作业集群"><a href="#Kubernetes上的Flink作业集群" class="headerlink" title="Kubernetes上的Flink作业集群"></a>Kubernetes上的Flink作业集群</h2><p>Flink作业集群是运行单个作业的专用集群，这项作业是打包在flink镜像里的，因此，不需要提交额外的作业对象，步骤如下：</p><h3 id="创建特定于作业的镜像"><a href="#创建特定于作业的镜像" class="headerlink" title="创建特定于作业的镜像"></a>创建特定于作业的镜像</h3><p>Flink作业集群镜像需要包含启动集群的作业的用户代码jar。因此，需要为每个作业构建专用的容器镜像。请按照这些<a href="https://github.com/apache/flink/blob/master/flink-container/docker/README.md" target="_blank" rel="noopener">说明</a>构建Docker镜像。</p><h3 id="在Kubernetes上部署Flink作业集群"><a href="#在Kubernetes上部署Flink作业集群" class="headerlink" title="在Kubernetes上部署Flink作业集群"></a>在Kubernetes上部署Flink作业集群</h3><p>要在Kubernetes上部署作业集群，请按照这些<a href="https://github.com/apache/flink/blob/master/flink-container/kubernetes/README.md#deploy-flink-job-cluster" target="_blank" rel="noopener">说明</a>进行操作。</p><h2 id="高级群集部署"><a href="#高级群集部署" class="headerlink" title="高级群集部署"></a>高级群集部署</h2><p>GitHub上提供了早期版本的<a href="https://github.com/docker-flink/examples" target="_blank" rel="noopener">Flink Helm chart</a>。</p><h1 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h1><h2 id="会话群集资源定义"><a href="#会话群集资源定义" class="headerlink" title="会话群集资源定义"></a>会话群集资源定义</h2><p>部署使用的最新镜像 <code>flink:latest</code> 可在<a href="https://hub.docker.com/r/_/flink/" target="_blank" rel="noopener">Docker Hub</a>上找到。该镜像是用这个工具 <code>https://github.com/docker-flink/docker-flink</code> 构建的</p><p>jobmanager-deployment.yaml</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs undefined">&quot;<br>apiVersion: extensions/v1beta1<br>kind: Deployment<br>metadata:<br>  name: flink-jobmanager<br>spec:<br>  replicas: 1<br>  template:<br>    metadata:<br>      labels:<br>        app: flink<br>        component: jobmanager<br>    spec:<br>      containers:<br>      - name: jobmanager<br>        image: flink:latest<br>        args:<br>        - jobmanager<br>        ports:<br>        - containerPort: 6123<br>          name: rpc<br>        - containerPort: 6124<br>          name: blob<br>        - containerPort: 6125<br>          name: query<br>        - containerPort: 8081<br>          name: ui<br>        env:<br>        - name: JOB_MANAGER_RPC_ADDRESS<br>          value: flink-jobmanager<br>&quot;<br></code></pre></td></tr></table></figure><p>taskmanager-deployment.yaml</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs undefined">&quot;<br>apiVersion: extensions/v1beta1<br>kind: Deployment<br>metadata:<br>  name: flink-taskmanager<br>spec:<br>  replicas: 2<br>  template:<br>    metadata:<br>      labels:<br>        app: flink<br>        component: taskmanager<br>    spec:<br>      containers:<br>      - name: taskmanager<br>        image: flink:latest<br>        args:<br>        - taskmanager<br>        ports:<br>        - containerPort: 6121<br>          name: data<br>        - containerPort: 6122<br>          name: rpc<br>        - containerPort: 6125<br>          name: query<br>        env:<br>        - name: JOB_MANAGER_RPC_ADDRESS<br>          value: flink-jobmanager<br>&quot;<br></code></pre></td></tr></table></figure><p>jobmanager-service.yaml</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs undefined">&quot;<br>apiVersion: v1<br>kind: Service<br>metadata:<br>  name: flink-jobmanager<br>spec:<br>  ports:<br>  - name: rpc<br>    port: 6123<br>  - name: blob<br>    port: 6124<br>  - name: query<br>    port: 6125<br>  - name: ui<br>    port: 8081<br>  selector:<br>    app: flink<br>    component: jobmanager<br>&quot;<br></code></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> flink </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flink </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Flink handbook - flink 集群与部署之docker篇</title>
      <link href="/2018/09/20/flink-deployment-docker/"/>
      <url>/2018/09/20/flink-deployment-docker/</url>
      
        <content type="html"><![CDATA[<h2 id="作者标注"><a href="#作者标注" class="headerlink" title="作者标注"></a>作者标注</h2><p>经过验证， 到当前版本为止 flink-1.7 snapshot，构建 flink docker镜像需要采用这个flink docker 构建工具 <code>https://github.com/docker-flink/docker-flink</code>，按照<a href="https://github.com/apache/flink/tree/master/flink-container" target="_blank" rel="noopener">flink官方代码库</a>里的构建出来的flink镜像有些功能不能用，比如 flink-standalone模式，report metrics等。</p><h2 id="Docker设置"><a href="#Docker设置" class="headerlink" title="Docker设置"></a>Docker设置</h2><p>Docker Hub上有关于Apache Flink的Docker镜像，可用于部署flink群集。Flink镜像库还包含用于创建容器映像以部署flink工作集群的一些工具以及说明。</p><h2 id="Flink-session群集"><a href="#Flink-session群集" class="headerlink" title="Flink session群集"></a>Flink session群集</h2><p>Flink会话群集可用于运行多个业务。在部署后，每个业务都需要提交到集群才能跑起来。</p><h2 id="Docker镜像"><a href="#Docker镜像" class="headerlink" title="Docker镜像"></a>Docker镜像</h2><p>该<a href="https://hub.docker.com/_/flink/" target="_blank" rel="noopener">Flink镜像库</a>托管在docker hub，提供了flink1.2.1以及之后的版本镜像。</p><p>注意： Docker镜像是由个人提供的社区项目，它们并不是Apache Flink PMC的官方版本（作者标注：所以需要用这个个人的<a href="https://github.com/docker-flink/docker-flink" target="_blank" rel="noopener">构建工具</a>，而不是官方代码库里的构建工具）。</p><h2 id="Flink作业集群"><a href="#Flink作业集群" class="headerlink" title="Flink作业集群"></a>Flink作业集群</h2><p>Flink作业集群是运行单个作业的专用集群，这是镜像内容的一部分，因此，不需要额外的工作。</p><h2 id="Docker镜像-1"><a href="#Docker镜像-1" class="headerlink" title="Docker镜像"></a>Docker镜像</h2><p>Flink作业集群镜像需要包含启动集群的作业的用户代码jar。因此，需要为每个作业构建专用的容器镜像。该flink-container模块包含一个build.sh脚本，可用于创建此类镜像。有关详细信息，请参阅<a href="https://github.com/apache/flink/blob/master/flink-container/docker/README.md" target="_blank" rel="noopener">说明</a>。（作者注：这个是官方的构建方式，试过有问题，比如跑 flink-standalone再 report metrics）</p><h2 id="Flink与Docker-Compose"><a href="#Flink与Docker-Compose" class="headerlink" title="Flink与Docker Compose"></a>Flink与Docker Compose</h2><p>Docker Compose是一种很方便的用于在本地启动一组Flink Docker容器的方式。</p><p>GitHub上提供了<a href="https://github.com/docker-flink/examples/blob/master/docker-compose.yml" target="_blank" rel="noopener">集群部署实例</a>和<a href="https://github.com/apache/flink/blob/master/flink-container/docker/docker-compose.yml" target="_blank" rel="noopener">作业群集示例</a>的配置文件。</p><h2 id="用法"><a href="#用法" class="headerlink" title="用法"></a>用法</h2><p>启动集群</p><p><code>$docker-compose up</code></p><p>以deamon的方式启动集群</p><p> <code>$docker-compose up -d</code></p><p>集群扩展 N 个 TaskManagers</p><p><code>$docker-compose scale taskmanager=&lt;N&gt;</code></p><p>销毁集群</p><p><code>$docker-compose kill</code></p><p>当拉起一个Flink群集后，您可以访问 <code>http：// localhost：8081</code>的Web UI ，在界面里您还可以将作业提交到群集。</p><p>如果要通过命令行将作业提交到会话群集，必须将JAR复制到JobManager容器里并从那里执行作业。</p><p>例如：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs undefined">$ JOBMANAGER_CONTAINER=$(docker ps --filter name=jobmanager --format=&#123;&#123;.ID&#125;&#125;)<br>$ docker cp path/to/jar &quot;$JOBMANAGER_CONTAINER&quot;:/job.jar<br>$ docker exec -t -i &quot;$JOBMANAGER_CONTAINER&quot; flink run /job.jar<br></code></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> flink </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flink </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>分布式系统中DHT算法改进</title>
      <link href="/2018/09/16/distributed-dht-update/"/>
      <url>/2018/09/16/distributed-dht-update/</url>
      
        <content type="html"><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>通常，分布式存储系统以及分布式缓存系统习惯采用分布式哈希（DHT）算法来实现数据的分区分配（路由）以及负载均衡，普通的分布式hash算法通过增添虚拟节点，对物理的热点区间进行划分，将负载分配至其他节点，从而达到负载均衡的状态，但是这并不能保证集群的负载就一定很是的均衡。</p><p>而一种改进过的一致性Hash算法，即带边界因子的一致性Hash算法，其严格控制每个节点的负载从而能获得更好的负载均衡效果[1][2]。</p><h2 id="普通的DHT算法"><a href="#普通的DHT算法" class="headerlink" title="普通的DHT算法"></a>普通的DHT算法</h2><p>假设有8个Object，通过下图的DHT算法:</p><ol><li>object 0,1,2映射到了虚拟节点vNode0 ： object 0,1,2 –&gt; vNode0</li><li>Object 3,4,5 映射到了vNode1：object 3,4,5 –&gt; vNode1</li><li>Object 6映射到 vNode2：object 6 –&gt; vNode2</li><li>Object 7映射到 vNodeN：object 7 –&gt; vNodeN</li></ol><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed%2Fdistributed-DHT-1.png" alt="distributed-DHT-1"></p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed%2Fdistributed-DHT-2.png" alt="distributed-DHT-2"></p><p>很明显，Vnode0和vNode1 都落了三个 object，而 vNode2和vNodeN 都只落了 1个Object，这里的DHT算法负债均衡因子并不是很好。</p><h2 id="带负载边界因子的DHT算法"><a href="#带负载边界因子的DHT算法" class="headerlink" title="带负载边界因子的DHT算法"></a>带负载边界因子的DHT算法</h2><p>假设有8个Object，通过如下图的DHT with bounded loads算法:</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed%2Fdistributed-DHT-3.png" alt="distributed-DHT-3"></p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed%2Fdistributed-DHT-4.png" alt="distributed-DHT-4"></p><p>第一轮映射：</p><ol><li>object 0,1,2 需要映射到了虚拟节点vNode0，但是vNode0的权重因子是 2，因此只完成了 object 0,1 –&gt; vNode0， object 2不能映射到节点 vNode0；</li><li>Object 3,4,5 需要映射到了虚拟节点vNode1：但是vNode1的权重因子是 2，因此只完成了 object 3,4 –&gt; vNode1， object 5不能映射到节点 vNode1；</li><li>Object 6映射到 vNode2：object 6 –&gt; vNode2</li><li>Object 7映射到 vNodeN：object 7 –&gt; vNodeN</li></ol><p>第二轮映射：</p><ol><li>Object 2 映射到 vNode1，但是vNode1权重因子=0， 不能被接收，继续往下一个节点走，发现vNode2 权重因子是2,还剩权重因子1，可以被映射，因此 object 2–&gt;vNode2</li><li>Object 5 映射到 vNode2，但是vNode2现在的权重因子=0， 不能被接收，继续往下一个节点走，发现vNodeN 权重因子是2,还剩权重因子1，可以被映射，因此 object 5–&gt;vNodeN</li></ol><p>最终的映射结果是:</p><ol><li>object 0,1映射到了虚拟节点vNode0 ： object 0,1 –&gt; vNode0</li><li>Object 3,4 映射到了vNode1：object 3,4 –&gt; vNode1</li><li>Object 2,6映射到 vNode2：object 2,6 –&gt; vNode2</li><li>Object 5,7映射到 vNodeN：object 5,7 –&gt; vNodeN</li></ol><p>很明显，Vnode0，vNode1，vNode2, vNodeN 每个节点都分到2个 object，<br>显然带负载边界因子的DHT算法负债均衡比普通的DHT算法来的好。</p><p>这些节点的负载因子可以从IO，CPU，MEM，Disk，Network等输入因子计算出来。</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a>作者简介</h2><p>常平，毕业于中国科学技术大学，获硕士研究生学历学位，10年+ 存储、布式系统、云计算以及大数据经验，曾就职于Marvell、AMD等，现就职于EMC，资深首席工程师，主要负责流式大数据处理平台的架构设计、编码及产品交付等。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1] <a href="https://research.googleblog.com/2017/04/consistent-hashing-with-bounded-loads.html" target="_blank" rel="noopener">https://research.googleblog.com/2017/04/consistent-hashing-with-bounded-loads.html</a></p><p>[2] <a href="https://medium.com/vimeo-engineering-blog/improving-load-balancing-with-a-new-consistent-hashing-algorithm-9f1bd75709ed" target="_blank" rel="noopener">https://medium.com/vimeo-engineering-blog/improving-load-balancing-with-a-new-consistent-hashing-algorithm-9f1bd75709ed</a></p>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>下一个分布式存储系统，为万物互联的智能世界而发</title>
      <link href="/2018/09/16/distributed-streaming-storage/"/>
      <url>/2018/09/16/distributed-streaming-storage/</url>
      
        <content type="html"><![CDATA[<p>如果说互联网和云计算使得对象存储在存储市场上与块存储、文件存储三分天下，相应的业务需求直接奠定了对象存储与块存储、文件存储并列存储江湖一哥的地位，那么接下来也许我们需要为下一场数据变革的大事做好准备 – <font color="#00CED1"><strong>万物互联这样的商业场景将给数据存储带来极大的商业挑战和技术挑战。</strong></font></p><h2 id="万物互联下的数据"><a href="#万物互联下的数据" class="headerlink" title="万物互联下的数据"></a><font color="#FF8C00">万物互联下的数据</font></h2><p>纵观人类历史，各种技术变革都是以人类活动为中心，然后发明各种工具。石器时代，原始人发明了石器以及用火从而提升了生活品质和社会文明。现代社会，人类为了解决各种寂寞空虚冷吃穿住用行、生理和心理上的各种需求从而发明了各种社交空间、社交工具、网络购物、生活服务APP等，为了更好的服务这些应用场景，挖掘这些场景所生产的数据的价值，从而有了今天的各种大数据技术。</p><p>在互联网时代，数据主要来源于网页、APP以及一些相应的日志系统，而在万物互联的世界，数据还可以来源于有各种传感器、工业设备、监控设备、检测设备、智能家居、自动驾驶等。大数据的四个特征：数据量、时效性、多样性、价值密度在万物互联的场景下被进一步的深化，这就意味着商业成本以及技术成本的增加。</p><p>理论奠定技术的基础，业务驱使技术的变革。在万物互联的智能时代，我们有一个愿景：<font color="#FF0000"> <strong>能够将万物互联下生成的海量原始数据转化为可用的信息以及行为决策，并且这个转换的时间差需要能够接近于零。</strong></font>而需要实现这个愿景，从技术角度来看，需要有计算层面的解决方案也需要有存储层面的，如今在计算层面已经有Flink、Spark等这类成熟的分布式计算应用，然而在存储层面还没有。</p><h2 id="流数据与流存储"><a href="#流数据与流存储" class="headerlink" title="流数据与流存储  "></a><font color="#FF8C00">流数据与流存储  </font></h2><p>在万物互联的场景下，各种传感器以及设备生成的数据有其原生的属性，这种数据自带时间戳、实时性要求高，而且是<font color="#FF0000"> <strong>“流数据”</strong></font>。</p><p>首先流数据在百度百科里是这样被定义的：</p><blockquote><p>流数据是一组顺序、大量、快速、连续到达的数据序列，一般情况下，数据流可被视为一个随时间延续而无限增长的动态数据集合。应用于网络监控、传感器网络、航空航天、气象测控和金融服务等领域。</p></blockquote><p>从数据的生产与传输场景来看流数据具有几个与众不同的带有破坏性的特性：</p><ol><li>数据随时间延续而无限增长，这意味着数据的无限性；</li><li>数据到达的速度有快有慢、负载有高有低，这意味着灵活又细粒度的资源弹性需求；</li><li>数据有序、无序、持久化以及复杂的传输环境而又要保证数据处理结果的唯一正确性。</li></ol><p>这是三个特性转换成存储技术的语义对应着：<font color="#FF0000"> <strong>无限性、可伸缩性以及恰好一次：持久化、有序、一致性以及事务。</strong></font></p><p>从<font color="#FF0000"> <strong>存储的视角</strong></font>来说，每种类型的数据都有其原生的属性和需求，对应有最佳的适用场景以及最合适的存储系统。跑在数据库里的数据对实时性和可靠性要求非常的高，因此适合采用块存储系统。文件共享场景下需要向用户共享文件，多个用户可以共享读取一个文件，因此适合采用文件存储系统。而互联网网页与APP里的文件、图像、视频可以看作一个个的数据对象又需要租户隔离以及无限扩展，因此又非常适合采用对象存储系统。那么目前又有哪种存储系统最适合用于<font color="#FF0000"> <strong>“流数据”</strong></font>呢？</p><p>正如当前技术条件下最适合<font color="#FF0000"> <strong>“流数据”</strong></font>计算的是类似Flink这样的分布式流计算应用，最适合“流数据”的应当是<font color="#00CED1"><strong>分布式流存储系统。</strong></font> </p><h2 id="分布式流存储系统"><a href="#分布式流存储系统" class="headerlink" title="分布式流存储系统"></a><font color="#FF8C00">分布式流存储系统</font></h2><h3 id="产品定位"><a href="#产品定位" class="headerlink" title="产品定位"></a><font color="#00CED1">产品定位</font></h3><p>分布式流存储系统的产品定位是给万物互联这样的应用场景服务的，从技术角度来看它具有自身的特点，正如标题里提到的三个关键词：<font color="#FF8C00"> <strong>“分布式”、“流”、“存储”</strong></font>。首先是分布式的，它具有分布式系统本身所具有的一切能力，接着表示是专门给流式数据设计和实现的，最后的存储表示的是一个原生的存储解决方案，它讲究数据的<font color="#FF8C00"> <strong>可靠性、持久化、一致性、资源隔离等</strong></font>，它从<font color="#FF0000"> <strong>存储的视角</strong></font>处理流数据。分布式流存储针对 <strong>“流数据”</strong> 的自身属性以及相应的特殊的业务需求场景做了专门的设计与实现，下面从<font color="#FF8C00"> <strong>命名空间、业务场景、无限性、可伸缩性、恰好一次、字节流、数据管道、租户隔离、海量小文件、数据治理、流式架构</strong></font>的角度依据 <strong>最佳实践原则</strong> 讲述了为什么需要专门设计和实现一个流式存储系统。</p><h3 id="命名空间"><a href="#命名空间" class="headerlink" title="命名空间"></a><font color="#00CED1">命名空间</font></h3><p>通常，块存储系统以<font color="#FF0000"><strong>分区、目录、文件</strong></font>，文件存储系统以<font color="#FF0000"><strong>目录、文件</strong></font>，以及对象存储以<font color="#FF0000"><strong>租户、桶、对象</strong></font>来定义数据的存储路径以及命名空间，而流存储系统则以<font color="#FF0000"><strong>范围(scope)、流(stream)、段(segment)、事件(event)</strong></font>来描述数据的存储路径以及命名空间。</p><div align="center"> <table><thead><tr><th>类型</th><th>命名空间</th></tr></thead><tbody><tr><td>块存储</td><td>分区、目录、文件</td></tr><tr><td>文件存储</td><td>目录、文件</td></tr><tr><td>对象存储</td><td>租户、桶、对象</td></tr><tr><td>流存储</td><td>范围、流、段、事件</td></tr></tbody></table><div align="left"> <p>在流存储系统里，如下图所示，数据的组织形式被抽象成范围、流、段和事件，范围由流组成，流由段组成，段由事件组成，事件由字节(bytes)组成。</p><div align="center"> <p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/pravega-infoq-scope-stream.png" alt="流的组成"></p><div align="left"> <h3 id="业务场景"><a href="#业务场景" class="headerlink" title="业务场景"></a><font color="#00CED1">业务场景</font></h3><h5 id="可穿戴设备、自动驾驶与工业厂房"><a href="#可穿戴设备、自动驾驶与工业厂房" class="headerlink" title=" 可穿戴设备、自动驾驶与工业厂房"></a><font color="#FF00ff"> 可穿戴设备、自动驾驶与工业厂房</font></h5><p>可以想象一下这样的业务场景：某个商家销售了几千万个智能手表，这些智能手表可以记录每个用户每天走了多少步，同时还可以分析过往的历史数据，用柱状图给用户展示历史数据，如下图所示：</p><div align="center"> <p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/pravega-infoq-watch.png" alt="步数分析"></p><div align="left">  <p>考虑到信息安全，用户A是不能看到用户B的数据的，那么就需要按智能手表为单位进行租户隔离，这种的场景下就有几千万个租户，同时每个租户还有自己的存储空间配额，比如给每个智能手表分配5GB 存储空间。光是这样的租户隔离场景，依据<strong>最佳实践</strong>的系统设计原则，不管是块存储系统、文件存储系统、对象存储系统还是Kafka这样的消息系统，按他们本身的隔离特性以及支持的租户规模都是难以在单个系统里支持这样的租户隔离场景。但是用流存储来实现就很方便，比如以智能手表的业务场景为例：</p><ul><li>默认分配5GB存储空间给一个智能手表，然后定义一个智能手表类型的命名空间用于与其他智能设备进行隔离，给每个智能手表分配一个流，每个智能手表上报的字节数据以事件为单位存储在流内的段里。</li><li>也可以这样来定义：给每个智能手表分配一个5GB 存储空间的命名空间，手表里的每个传感器都对应一个流，每个传感器以事件为单位上报字节数据存储到流的段里。</li></ul><p>还可以想象一下这样的业务场景：自动驾驶。采用分布式流存储的话，我们可以这样处理自动驾驶的数据：给每一辆无人车定义一个1TB存储空间的范围，车上的每个传感器都归属于一个流，传感器上报的事件都在段内持久化。再假设每辆车都有1000个传感器（实际情况只多不少），那么10万辆车就需要定义1亿个流，可以想象要进行这种规模的隔离也就只有这种专门针对流数据而设计的流存储系统能够支持。</p><p>在工业互联网的场景下，还可以这样定义工业设备的数据：给一个厂房里的每台设备定义一个范围，每台设备里的每个传感器都对应一个流，传感器上传的事件数据保存在流内的段里，这样就很方便的对工业设备进行了大规模的租户数据隔离。</p><p>因此，以<font color="#FF0000"><strong>“范围、流、段、事件”</strong></font>的方式很方便的进行了大规模的租户隔离保证了用户信息安全同时又进行了存储资源配额的隔离。</p><h5 id="大数据处理平台"><a href="#大数据处理平台" class="headerlink" title=" 大数据处理平台"></a><font color="#FF00FF"> 大数据处理平台</font></h5><p>万物互联场景下无限量的数据给数据处理技术带来巨大的挑战与压力，不同的应用场景意味着不同的数据处理要求与复杂度，要把这些不同的甚至矛盾的数据处理要求都很好的综合在一个大数据处理系统里，对现有的大数据处理技术来说是个非常大的挑战，比如无人车的处理要求毫秒甚至纳秒级的数据处理实时性、而有些工业设备数据只需要分析历史数据，要让一个大数据处理系统既能能处理历史数据又能提供毫秒级甚至纳秒级的实时性处理能力还能应对各种不同格式不同传输场景的数据，而且每种数据处理都能达到这些应用场景原生指标的处理需求。相信这样的场景对工程技术人员来说是个很大的挑战。为了解决上述问题，按照现有的成熟的技术能力，通常开发人员采用类似Lambda架构（如下图）这样的大数据处理平台来处理大数据。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/streaming/streaming-bigdata-lambda-arch.PNG" alt="Lambda架构"></p><p>Lambda架构即支持批处理也支持实时处理，能应对数据的多样性、具有容错功能、复杂性分离、能处理流式数据也能处理历史数据等优点，但是缺点也很明显：<strong>批处理一套独立的数据处理路径，实时处理又一套数据处理路径，然后还要合并结果再输出展示，同时系统里同样的数据存在存储多份的问题，比如同样的数据在Elasticsearch里有、HDFS里有、ceph里有、Kafka里也有，除了这些甚至还存在其他一些复杂的存储组件，而且同样的数据还都是多份冗余的，因此存储成本太高太过于复杂。Lambda架构里为了提供一个功能却引入一个组件，在复杂之上堆积复杂，存储成本、开发与运维成本都太过于复杂。</strong></p><p>那么应当如何解决Lambda架构带来的这些缺点？<font color="#FF0000"><strong>以数据流向为核心</strong></font>重构大数据处理平台是一个比较好的方案，它具体包括数据的采集、聚合、传输、缓存、持久化、处理、展示等。依据这种设计理念我们可以推出一个端到端的原生的流式大数据处理平台：原生的流式计算加上一个原生的流式存储并且可以平衡商业成本与技术成本。</p><p>流式计算可以采用Flink，然而并没有发现当前有合适的流式存储可以使用，如果采用Flink加上传统的文件存储或者块存储、对象存储的方式，也只能认为是半原生的大数据处理平台：<font color="#FF0000"><strong>计算是原生的流式计算而存储却不是原生的流式存储</strong></font>。</p><p>因此，综合思考万物互联场景下的数据处理场景也需要一个原生的分布式流存储系统，<font color="#FF0000"><strong>重构Lambda架构里的存储栈</strong></font>，使得分布式流计算加上分布式流存储即为原生的流式大数据处理系统，同时还能很好的平衡商业成本与技术成本之间的关系。</p><h3 id="数据无限性"><a href="#数据无限性" class="headerlink" title="数据无限性"></a><font color="#00CED1">数据无限性</font></h3><p>无限性是分布式流存储最为重要的设计原则。从流数据的角度来看，数据是大量、快速、连续而又无限的，这就给流存储系统的设计与实现带来极大的困难，无限的数据使得存储系统必须能支持连续且无限规模的数据流，光这一点就对存储系统的可扩展性要求非常的高，同时还要求存储系统能够根据到达的数据量动态而又优雅地进行扩容与缩容。从技术与成本的角度来看，数据无限性意味着冷热数据分离，长期不用的数据淘汰到长期存储系统里，热点数据需要缓存，同时还需要能支持历史数据的读取与实时数据的读取与写入。</p><h3 id="可伸缩性"><a href="#可伸缩性" class="headerlink" title="可伸缩性"></a><font color="#00CED1">可伸缩性</font></h3><p>可伸缩性也是分布式流存储最为重要的设计原则之一，而且流存储里的可伸缩性要求还是自动化的资源细粒度的可伸缩。通常，在云原生的场景下，资源的缩放是以主机、虚机或容器为单位的，这样的缩放对流存储来说粒度太大。在流存储的场景下需要能够以数据的<strong>“流段”</strong>为单位，比如一个流段2MB，那么就需要能支持一次自动扩容或缩容2MB的存储空间。另外在流存储里还要求写入与读取对数据子集的操作是解耦分离的，并且写入与读取二者之间跟数据流段还要有一个合理的平衡。</p><h3 id="恰好一次"><a href="#恰好一次" class="headerlink" title="恰好一次"></a><font color="#00CED1">恰好一次</font></h3><p>恰好一次也是分布式流存储最为重要的设计原则之一，恰好一次意味着数据的可持久化、有序、一致性以及事务性的支持。持久性意味着一旦得到确认，即使存储组件发生故障，写入的数据也不会丢失。有序意味着读客户端将严格按照写入的顺序处理数据。一致性意味着所有的读客户端即使面对存储故障、网络故障也都会看到相同的有序数据视图。事务性写入对于保证Flink这样的计算应用处理结果的完全正确是非常必要的。</p><h3 id="字节流"><a href="#字节流" class="headerlink" title="字节流"></a><font color="#00CED1">字节流</font></h3><p>分布式流存储里采用字节流的格式组织数据而不是像消息系统里采用消息报文的方式，这意味着接口的通用性。二进制的字节流是与数据格式无关的，字节流可以组成事件封装在分布式存储的流段里。而消息系统里数据是消息头消息体的格式封装的，在兼容性上不如字节流。</p><h3 id="数据管道"><a href="#数据管道" class="headerlink" title=" 数据管道"></a><font color="#00CED1"> 数据管道</font></h3><p>在存储界通常喜欢用跑车、卡车、渡轮来比喻块存储、文件存储以及对象存储，打个比方来说块存储类似跑车：极快、极稳、装的人少、成本高；文件存储类似卡车：快、稳、装的人比跑车多，但是没跑车那么快；对象存储类似渡轮：可以装非常多的货，讲究量大、成本低；那么分布式流存储像什么呢？ 在我们的定义里它就像管道：<font color="#FF0000"><strong>数据如同流水一般流过管道，又快又稳源源不断而又永无止境</strong>。</font></p><h3 id="租户隔离"><a href="#租户隔离" class="headerlink" title="租户隔离"></a><font color="#00CED1">租户隔离</font></h3><p>分布式流存储从一开始设计的时候就将”租户隔离“作为其基本特性进行实现，”隔离“是分布式流存储的最基本的特性之一，在分布式流存储里租户隔离不只是租户B绝对不能看的到租户A的任何信息这样的信息安全层面的隔离，它支持范围、流、段、事件层面的隔离还将支持的租户规模作为设计的目标之一，在分布式流存储里单集群需要能支持千万量级起的租户数，另外还有资源、命名、可视空间、权限以及服务质量层面的隔离。</p><h3 id="海量小文件"><a href="#海量小文件" class="headerlink" title="海量小文件"></a><font color="#00CED1">海量小文件</font></h3><p>对巨量小文件的支持是分布式流存储的设计原则之一。正如前面提到的，万物互联下的海量数据来源于传感器，而传感器上传的数据都是类似温度、地理位置、告警信息这样的几个字节几个字节的小数据，这就意味着在万物互联的场景下会有巨量的小数据上传，而且90%以上的数据操作行为都是写入。为了保证数据写入的性能以及可靠性、正确性、持久性以及保证介质的使用寿命降低成本，这也需要存储系统针对这种业务场景进行专门的设计。</p><p>在分布式流存储里每个事件第一步是被仅附加写入一个缓存的段内进行封装的，在段达到一定的尺寸（比如64MB）后会被封闭不再写入，这时再将整个段写入下一级的持久化存储里。通过这样的设计，实现小数据在缓存里封装成大块的数据，再将大块数据写入持久化存储设备的方式保证了存储系统整体的性能。</p><h3 id="数据治理"><a href="#数据治理" class="headerlink" title="数据治理"></a><font color="#00CED1">数据治理</font></h3><p>当前的大数据处理平台，不管是Kappa架构还是lambda架构，数据的存储都是多组件化、多份化的。比如同样的数据在Kafka里有、在HDFS里有、在Elasticsearch里又有，有些用户还使用了更多的存储中间件，而且这些数据还是多份冗余的。这一方面增加了数据的存储成本，另一方面也降低了数据的可信性、可靠性、合规性，给数据标准化以及数据的重复利用带来了困难，不利于数据的分享、合规、降低成本以及安全可靠地支持业务和决策。数据治理也是分布式流存储的基本设计原则之一，通过使用分布式流存储，大数据处理平台的架构可以进化成<font color="#FF0000"><strong>”分布式流计算+ 分布式流存储“</strong></font>这样的原生流式数据处理平台架构。</p><h3 id="流式架构"><a href="#流式架构" class="headerlink" title="流式架构"></a><font color="#00CED1">流式架构</font></h3><p>下图体现了<font color="#FF0000"><strong>”分布式流计算+ 分布式流存储“</strong></font>这样的原生流式大数据处理平台的架构理念。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/streaming/streaming-bigdata-processor.PNG" alt="流式架构"></p><p>这个架构体现了<font color="#FF0000"> <strong>“流原生”(stream native)式</strong> </font>的设计哲学，“流原生”的计算加上“流原生”的存储管道组成了“流原生”的大数据处理平台。数据从分布式流存储输入经过map算子计算，输出中间计算结果到分布式流存储里，数据又从分布式流存储里读入到Filter算子里，再经过计算，中间结果放到了分布式流存储里，再最后的计算结果经过聚合算子的计算放到了目的地的分布式流存储里。这个过程体现了算子编排和管道式编程的设计哲学，在这里分布式流存储起了大数据处理平台里的管道的作用。</p><p>同时，在分布式流存储里数据的存储单位是流段，当输入的数据速率或者负载增加时，流段就会自动扩容，通过流协议联动，流计算应用的算子也相应扩容。相应的，如果输入的数据速率或负载降低，流段就自动收缩，通过流协议联动，流计算应用的算子也相应的缩容，所有这些行为都是自动完成的，无需人工干预，这种行为体现了分布式流存储的细粒度可伸缩性。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font color="#FF8C00">小结</font></h2><p>综上所述，在万物互联的智能世界里，为了实现将海量数据近实时转化成信息和决策的愿景，除了流式计算应用还需要一个流式存储系统，未来已来，已有开源的分布式流存储系统正走在这条路上。另本文仅为作者愚见，与任何组织机构无关，作者能力也很有限，如有不足之处欢迎留言批评指正。</p><h2 id="问题思考"><a href="#问题思考" class="headerlink" title="问题思考"></a><font color="#FF8C00">问题思考</font></h2><p>最后给大家留一个思考题：<font color="#00CED1"><strong>如果让你来设计一个分布式流存储产品，你会如何定义它的产品灵魂？</strong></font></p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><font color="#FF8C00">作者简介</font></h2><p>常平，中科大硕，10年+数据相关经验，主要工作背景为分布式系统、存储、缓存、微服务、云计算以及大数据，现就职于DELL EMC。个人技术博客：<a href="https://changping.me" target="_blank" rel="noopener">https://changping.me</a></p><h2 id="版权申明"><a href="#版权申明" class="headerlink" title="版权申明"></a><font color="#FF8C00">版权申明</font></h2><p>本文的版权协议为 CC-BY-NC-ND license：<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="noopener">https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh</a> ，可以自由阅读、分享、转发、复制、分发等，限制是需署名、非商业使用（以获利为准）以及禁止演绎。</p></div></div></div></div></div></div>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Hello World</title>
      <link href="/2018/09/13/hello-world/"/>
      <url>/2018/09/13/hello-world/</url>
      
        <content type="html"><![CDATA[<h2 id="Hello-World"><a href="#Hello-World" class="headerlink" title="Hello World"></a>Hello World</h2><p><strong>启动新的技术网站:[<a href="http://www.changping.me]">www.changping.me]</a>, [<a href="http://www.yuncunchu.org]以及微信公众号上的文章将迁移到本站。" target="_blank" rel="noopener">www.yuncunchu.org]以及微信公众号上的文章将迁移到本站。</a></strong></p>]]></content>
      
      
      
    </entry>
    
  
  
    
    <entry>
      <title></title>
      <link href="/404.html"/>
      <url>/404.html</url>
      
        <content type="html"><![CDATA[<!DOCTYPE HTML><html><head>  <meta http-equiv="content-type" content="text/html;charset=utf-8;">  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">  <meta name="robots" content="all">  <meta name="robots" content="index,follow">  <link rel="stylesheet" type="text/css" href="https://qzone.qq.com/gy/404/style/404style.css"></head><body>  <script type="text/plain" src="http://www.qq.com/404/search_children.js" charset="utf-8" homepageurl="/" homepagename="�ص��ҵ���ҳ">  </script>  <script src="https://qzone.qq.com/gy/404/data.js" charset="utf-8"></script>  <script src="https://qzone.qq.com/gy/404/page.js" charset="utf-8"></script></body></html>]]></content>
      
    </entry>
    
    <entry>
      <title>about</title>
      <link href="/about/index.html"/>
      <url>/about/index.html</url>
      
        <content type="html"><![CDATA[<h2 id="关于作者"><a href="#关于作者" class="headerlink" title="关于作者"></a><font color="#FF8C00">关于作者</font></h2><ul><li>毕业于中国科学技术大学，获硕士研究生学历学位</li><li>主要工作背景：深度学习、Ai平台、系统调优、大数据、云计算以及Linux内核领域。</li><li>某AI芯片公司深度学习高级软件主管、架构师，前EMC资深首席工程师及中国区技术委员会成员，亦曾就职于AMD、Marvell等</li></ul><h2 id="联系方式"><a href="#联系方式" class="headerlink" title="联系方式"></a><font color="#FF8C00">联系方式</font></h2><ul><li>Email : <a href="mailto:wu@changping.me" target="_blank" rel="noopener">wu@changping.me</a></li><li>Blog : <a href="https://www.changping.me">https://www.changping.me</a></li><li>Github : <a href="https://github.com/wuchangping" target="_blank" rel="noopener">https://github.com/wuchangping</a></li><li>微信公众号 : 分布式系统架构设计师</li></ul><h2 id="网站声明"><a href="#网站声明" class="headerlink" title="网站声明"></a><font color="#FF8C00">网站声明</font></h2><p>文章内容仅为作者愚见，与任何组织机构无关，如有错误及不足之处欢迎发信批评指正。</p><h2 id="版权声明"><a href="#版权声明" class="headerlink" title="版权声明"></a><font color="#FF8C00">版权声明</font></h2><p>非商业用途在注明作者及本网站前提下无需授权即可转载。</p><h2 id="免责声明"><a href="#免责声明" class="headerlink" title="免责声明"></a><font color="#FF8C00">免责声明</font></h2><p>文章坚持原创，且仅供技术交流及研究使用，如有不小心侵犯您的版权， 请联系：<a href="mailto:wu@changping.me" target="_blank" rel="noopener">wu@changping.me</a>，会尽快删除。</p><p>–</p>]]></content>
      
    </entry>
    
    <entry>
      <title>archives</title>
      <link href="/archives/index.html"/>
      <url>/archives/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    <entry>
      <title>categories</title>
      <link href="/categories/index.html"/>
      <url>/categories/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    <entry>
      <title>tags</title>
      <link href="/tags/index.html"/>
      <url>/tags/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
  
</search>
