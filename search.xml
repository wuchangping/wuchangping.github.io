<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>pravega blog - streams in 与 streams out</title>
      <link href="/2018/11/17/pravega-blog-streams-in-and-out/"/>
      <url>/2018/11/17/pravega-blog-streams-in-and-out/</url>
      
        <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>读和写是Pravega提供的最基本的功能。应用程序通过写入一个或多个Pravega流来摄取数据，并通过从一个或多个流中读取数据来使用数据。但是，要使用Pravega正确实现应用程序，开发人员必须了解一些核心的写入和读取的附加功能。例如，写入可以是事务性的，reader可以被Group织成Group。</p><p>在本文中，我们将介绍开发人员在使用Pravega开发应用程序时必须注意的一些基本概念和功能，重点是读和写。我们鼓励reader在“开发Pravega应用程序”部分中另外查看Pravega文档站点，了解一些代码和更多细节。</p><h2 id="写入流"><a href="#写入流" class="headerlink" title="写入流"></a>写入流</h2><p>我们当前公开的用于编写的API使应用程序能够将事件附加到流中。事件是一个应用程序概念，应用程序可以定义事件是什么以及它代表什么。就Pravega而言，事件是字节序列，而Pravega并不试图理解事件。我们希望应用程序传递一个串行器，使  Pravega  能够接收任意类型的事件并将它们转换为字节序列。最终，  Pravega  在流段中存储字节序列，并且不知道事件类型。</p><p>存储字节序列而不是事件使得Pravega能够支持除API中的事件之外的抽象，例如，我们计划公开对读取和写入字节流的调用。当应用程序有其他包含不可变数据的大对象要存储时（例如Apache Flink中的检查点），此功能将非常有用。使用这样的API，应用程序能够直接在Pravega中存储这些对象，而不是依赖于单独的存储。<br>回想一下，Pravega流由段Group成，任何给定的流都可以在任何时间点打开许多并行段。为了将事件映射到段，应用程序会传递  路由键  以及事件本身。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/pravega-blog-streams-inout-1.png" alt="路由键到段图"></p><p>路由键是一个字符串，经过哈希处理以确定要将事件追加到哪个段。 Pravega  保证将路由密钥分配给段是一致的。请注意，由于流缩放，路由密钥到段的映射并不总是相同，但它是一致的。在两个缩放事件之间，写入具有相同路由密钥的流的所有事件都映射到同一个段。跨比例事件的分段根据缩放排序。为了使其具体化，例如示例，我们从一个区段S1向上扩展到区段S2和S3。S1的关键空间与S2和S3的关键空间重叠，但是S2和S3没有交集，所以可以简单地附加到S2和S3，但不要同时附加说S1和S2，因为具有相同路由键的事件可以转到两个不同的段。为了防止后一种情况发生，在S1被密封之前，S2和S3不会发生附加，这会在缩放事件之前和之后推广到任意数量的段。因此，一旦由于缩放事件而将段密封，则将未来事件附加到密封段的后继者，从而保留路由键顺序。</p><p>将事件写入流很简单，有两个选项：  常规 和  事务。通过常规写入，writer可以简单地触发写入事件的调用：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>// Set up a new scope and stream with a single segment (no scaling)<br>StreamManager streamManager = StreamManager.create(controllerURI);<br>StreamConfiguration streamConfig = StreamConfiguration.builder()<br>    .scope(scope).streamName(streamName)<br>    .scalingPolicy(ScalingPolicy.fixed(1))<br>    .build();<br>streamManager.createScope(scope);<br>streamManager.createStream(scope, streamName, streamConfig);<br> <br>// Create a client factory, a writer and append events<br>try(ClientFactory clientFactory = <br>      ClientFactory.withScope(scope, controllerURI) &#123;<br>    EventStreamWriter&lt;String&gt; writer = clientFactory<br>         .createEventWriter(streamName, <br>                            new JavaSerializer&lt;String&gt;(),<br>                            EventWriterConfig.builder().build()); <br>    writer.writeNext(&quot;Key 1&quot;, &quot;Hola&quot;); <br>    writer.writeNext(&quot;Key 2&quot;, &quot;Mundo!&quot;);<br>&#125;<br></code></pre></td></tr></table></figure><p>通过事务，writer开始一个事务并根据需要调用事件来进行多次调用：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>Transaction&lt;String&gt; txn = writer.beginTxn();<br>txn.writeEvent(&quot;Key 1&quot;, &quot;Hola&quot;);<br>txn.writeEvent(&quot;Key 2&quot;, &quot;Mundo!&quot;);<br>txn.commit();<br></code></pre></td></tr></table></figure><p>一旦完成，它就会提交事务，这使得事务中的写入可供读取。应用程序还可以选择中止事务，在这种情况下，作为事务的一部分编写的事件不可见。</p><p>关于writer的一些非常有趣的观点值得一提：重复和分段顺序。</p><h2 id="避免重复"><a href="#避免重复" class="headerlink" title="避免重复"></a>避免重复</h2><p>流中的重复可能是有问题的：它们通常会导致不正确的结果或不正确的行为。例如，重复可能导致实例的计数错误或状态机中的错误转换。一些应用程序对这种偏差非常敏感。</p><p>为避免重复，writer内部具有一个ID，用于确定重新连接时写入的最后一个事件。当writer有要追加的事件时，它会启动一个事件块的写入。一旦完成附加块，writer就会发送一个  块结束  命令，其中  包含写入  的事件数和  最后一个事件编号。writer附加块以便能够从批处理中受益。</p><p>段存储必须记住任何给定writerID的最后一个事件编号。否则，它无法发现重复。要记住给定writerID的最后一个事件编号，它会将writerID，事件编号对保留为该段的属性，作为处理追加请求的一部分。在writer断开连接并创建新连接的情况下，段存储将获取此属性并返回作为与客户端握手的一部分写入的最后一个事件编号。来自分段存储的响应使writer能够在其附加未完成的情况下从正确的事件中恢复。</p><p>但是，writer不会持久存在甚至暴露其writerID。如果writer崩溃并且实例化了新的writer，则新writer将使用新的writerID。尽管writer崩溃，为避免重复，我们需要将此writerID重复数据删除与事务相结合。通过事务性写入，如果写入程序在提交一批写入之前崩溃，那么它可以让事务超时并中止，在这种情况下，新写入程序可以从上一个写入程序停止的最后一个提交点恢复。</p><p>总而言之，  Pravega  通过检查与writerID相关联的事件编号以及使用事务写入来容忍writer崩溃来避免写入时的重复。在writer在事务中间崩溃的情况下，应用程序可以简单地让事务超时并中止。此类事务的部分写入不会向reader公开。</p><h2 id="段顺序"><a href="#段顺序" class="headerlink" title="段顺序"></a>段顺序</h2><p>流缩放导致流的段数随着时间而改变。流的段数的变化会导致随着时间的推移，路由关键字范围到段的映射发生变化。但是，如果映射发生变化，我们如何保证reader按照附加顺序接收具有相同路由键的事件？</p><p>为了保证具有相同路由密钥的事件的顺序，客户端与控制器一起根据它们的创建顺序读取段。例如，假设流以一个我们称为S1的段开始  。在时间  T1，段  S1  分成  S2  和  S3。因此，如缩放流的一部分，我们分离的键范围  S1  之间  S2  和  S3。为了简化讨论，让我们说我们将它分开，所以  S2  最终得到[0.0,0.5]，而  S3 以[0.5,1.0]结束。为了保证可以按附加顺序读取具有相同路由键的所有事件，我们需要确保在密封S1之前，writer不能附加到S2或S3。事实上，这正是writer的操作方式：当它发现一个段密封时，它会向控制器询问后继者。在这个例子中，当它到达S1的末尾   （表示段密封的返回代码）时，writer询问控制器并接收S2  和  S3  是后继者的响应  。下图说明了这种情况：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/pravega-blog-streams-inout-2.png" alt="读取和缩放"></p><p>在reader方，我们还必须遵循段的顺序，接下来当我们介绍reader和reader group时，我们将更详细地讨论它。</p><h2 id="从流中读取"><a href="#从流中读取" class="headerlink" title="从流中读取"></a>从流中读取</h2><p>流可以有多个段，writer可以并行追加。这种并行性不仅对于实现更高的摄取能力而且在读取和处理事件时实现并行性也很重要。</p><p>将事件附加到流时，我们可以让许多writer同时访问流的所有段。writer彼此独立，处理事件而无需进一步协调。我们也可以在读取方面有很多reader，但reader却不同。通常，事件只需要处理一次，因此一Groupreader需要协调段的工作负载分布，以便在整个Group中进行分割。</p><p>为了使reader能够有效地共享一个或多个流的工作负载，我们使用reader Group的概念  ：</p><p><strong>Reader Group</strong>：一reader Group是一Group RG 的  Pravega  reader和流S的一Group相关联，使得对于每个 ř ∈ RG，S（R）＆SubsetEqual; ⋃s∈ S C（S） 。在任何时间和任何两个不同的reader R，R ‘ ∈ RG ， S（R）∩ S（R’）是空的。</p><p>在该定义中，s（r）是分配给reader r的段的集合，并且c（s）是流的当前活动段的集合（用于读取的非密封段）。注意，这个定义并不意味着在所有的段 ⋃ 小号 ∈ 小号 C（S）在任何时间分配给一些reader。reader可能已经发布了一个片段，而其他人尚未获得该片段，或者尚未获得某些新片段。Reader Group的合约是，最终分配给⋃ 小号∈ 小号 C（S）中的任何段。因此，readerGroup不保证在任何时候 ⋃ 小号∈ 小号C（S）= ⋃ [R ∈ RG S（R） ，虽然我们保证了活性，所有 X ∈ ⋃ s∈ S C（S） ，最终x被分配到一些reader。 </p><p>每个reader都必须属于readerGroup。以下代码段说明了如何设置 reader：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>// Set up a new scope and stream with a single segment (no scaling)<br>StreamManager streamManager = StreamManager.create(controllerURI);<br>StreamConfiguration streamConfig = StreamConfiguration.builder()<br>    .scope(scope).streamName(streamName)<br>    .scalingPolicy(ScalingPolicy.fixed(1))<br>    .build();<br>streamManager.createScope(scope);<br>streamManager.createStream(scope, streamName, streamConfig);<br> <br>try (ReaderGroupManager manager =<br>              ReaderGroupManager.withScope(scope, controllerURI)) &#123;<br>    manager.createReaderGroup(readerGroup, <br>                              readerGroupConfig, <br>                              Collections.singleton(streamName));<br>&#125;<br> <br>try(ClientFactory clientFactory = <br>      ClientFactory.withScope(scope, controllerURI) &#123;<br>    EventStreamReader&lt;String&gt; reader = <br>             clientFactory.createReader(&quot;reader&quot;,<br>                                        readerGroup,<br>                                        new JavaSerializer&lt;String&gt;(),<br>                                        ReaderConfig.builder().build());<br>   while(!stop) &#123;<br>        EventRead&lt;String&gt; event = <br>                  reader.readNextEvent(READER_TIMEOUT_MS);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>将段分配给Group中的reader取决于使用我们在Pravega中称为stateSynchronizer的机制的reader的分布式协调  。stateSynchronizer使reader能够获得分布状态的一致视图，他们使用这些视图来协商Group状态的变化，  例如，分配了哪些分段以及分配给哪些分Group。我们用来确定分配的特定启发式算法很简单，但我们会对另一篇文章进行详细讨论。</p><p>reader和Group体有四个方面值得强调。</p><h2 id="段顺序-1"><a href="#段顺序-1" class="headerlink" title="段顺序"></a>段顺序</h2><p>为了保证reader在附加顺序中读取具有相同键的事件，reader遵循与writer类似的过程。当readerGroup 中的reader遇到密封段时，它会提取后继者，以便该Group可以从这些段中读取。如果后继者对应于分割密封片段的结果，那么reader可以立即开始阅读后继者。下图说明了这种情况：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/pravega-blog-streams-inout-3.png" alt="读取和缩放"></p><p>最初，流具有单个段  S1 ， 并且它最终扩展，导致S1分裂成  S2  和  S3。一旦reader 到达S1的末尾  ，它就会从控制器请求后继者，并开始从新的段中读取。</p><p>但是，如果密封段实际上与另一段合并而另一段尚未完全读取，该怎么办？让我们通过一个例子使这个方面更加具体。<br>假设我们有一个readerGroup  G，  有两个reader，  R1  和  R2。方案如下：</p><ul><li>Group  G  正在读取当前具有两个段  S1  和  S2的流。</li><li>R1  正在读取  S1，而  R2  正在读取  S2。</li><li>段合并为  S3  （S1  和  S2  是密封的，它们不接受进一步的附加）。</li><li>Reader  R1  命中S1结束   并请求其后继者。</li><li>reader  R1  回来说  S3  是S1的继承者  。</li><li>reader  R2  尚未完成  S2。</li></ul><p>如果  R1  或  R2  在R2  完成读取  S2之前   继续读取  S3，那么我们可能会违背我们在附加顺序中使用相同键读取事件的承诺。因此，为了满足我们的顺序属性，我们将  S3  置于保持状态，直到  R2标记它已完成  S2。只有这样   才能分配和读取S3。</p><p>为了协调分段的分配和顺序，我们再次依赖状态同步器。当reader获得段的后继者时，它会相应地更新状态，并且该状态将在ReaderGroup之间同步。具体到该示例，Reader  R1  将段S3添加   到未来 段的列表中  ，并且仅在完全读取S2的所有前任之后才分配段。</p><h2 id="检查点"><a href="#检查点" class="headerlink" title="检查点"></a>检查点</h2><p>我们目前不会通过reader GroupAPI向应用程序公开任何段信息。这是故意的。为了保证流的读取遵循正确的顺序，我们选择隐藏应用程序中后继者，前任和未来段的复杂性。即使应用程序没有明确地看到段，它仍然需要某种方式来确定流中在所有活动段中保持一致的点，并使应用程序从此点恢复。例如，如果应用程序想要从流中的较早点重新启动并恢复，则需要一种机制来引用此前一点。</p><p>检查点是我们提供的一种机制，使应用程序能够请求一个对象，该对象包含当前正在读取或可供读取的每个段的偏移量。检查点在内部使用状态同步器实现。一旦触发，reader就会协调生成一个不透明的检查点对象，该对象包含当前正在读取或可供读取的每个段的偏移量。</p><p>每个reader将其指定段的当前位置记录到状态一次：</p><p>1.它了解到有一个检查点在继续;<br>2.它已经发布了一个  检查点事件。</p><p>检查点事件通过reader 通知应用程序检查点正在进行中，并且应用程序应该采取任何适当的步骤（如果有的话）。例如，作为检查其状态的一部分，应用程序可能需要获取其输入的位置（  Pravega 流），为执行Reader的每个进程收集任何本地状态，并向下游刷新输出。因此，应用程序可能希望通过收集任何状态检查点信息并刷新下游的任何输出来对检查点事件作出反应，以避免重复。</p><p>如果需要，我们还利用检查点的机会重新平衡分段的分配。必须在检查点时执行此操作，以便应用程序有机会刷新任何挂起的状态更改，消息和事件，以避免任何重复。</p><h2 id="下游故障与重复"><a href="#下游故障与重复" class="headerlink" title="下游故障与重复"></a>下游故障与重复</h2><p>readerGroup使一组reader可以集中读取流。Reader Group逻辑以试图保持负载平衡的方式在Reader之间分配段。<br>一个重要的问题是当reader崩溃时会发生什么。具体来说，分配给该reader 的段会发生什么？显然，要在这些段存储取得进展，我们需要将它们重新分配给新的reader。在重新分配这些段时，我们需要从某个偏移量恢复。理想情况下，此偏移量是前一个Reader未读取的第一个偏移量。从第一个段偏移（偏移零）开始可能导致重复处理事件。如果应用程序对重复项敏感，则这是不可取的。</p><p>为了使应用程序在从Pravega读取时避免重复  ，我们执行以下操作。对于应用程序读取的每个事件，我们提供一个  位置 对象。position对象是一个可序列化的不透明对象，它包含reader当前分配的段的偏移量。此对象类似于检查点对象，但缩小为单个Reader。reader应该将此对象作为处理事件的一部分来持久化。如果Reader 崩溃，  Pravega  希望应用程序通过调用readerGroup API的方法并传递Reader 的最后一个位置对象来使Reader 脱机。此位置对象确定剩余Reader需要从指定段中的位置。</p><p>到目前为止，我们已选择将崩溃检测推送到应用程序。Reader Group API提供reader Offline调用，但它不提供任何检测崩溃的机制。因此，应用程序需要提供检测并相应地调用reader Offline。</p><p>请注意，使用位置对象背后没有任何魔力。我们要求应用程序合作：完全取决于应用程序持久保存这样的位置对象并在Reader崩溃时检索最新的位置对象。如果维护这些对象的成本很高或不合需要，那么根据所执行的处理的性质，应用程序在其输出中存在重复的风险。</p><h2 id="批读取"><a href="#批读取" class="headerlink" title="批读取"></a>批读取</h2><p>有时候应用程序想要简单地处理存储在流中的所有事件而不依赖于顺序。例如，假设应用程序想要收集流中的所有用户ID，事件中的单词，甚至执行经典的单词计数。在这种情况下，段的顺序并不重要。</p><p>对于这种情况，我们公开了一个批处理API，它使应用程序能够利用并行性并以任何顺序迭代流的各个段并使用它所需的任何程度的并行性。</p><p>要执行批量读取，应用程序会通过段请求迭代器：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>Iterator&lt;SegmentInfo&gt; segments = client.listSegments(stream);<br>SegmentInfo segmentInfo = segments.next();<br></code></pre></td></tr></table></figure><p>一旦它有了这个迭代器，它就可以继续单独遍历各个段：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>SegmentIterator&lt;T&gt; events = client.readSegment(segmentInfo.getSegment(),<br>                   deserializer);<br> <br>while (events.hasNext()) &#123;<br>    processEvent(events.next());<br>&#125;<br></code></pre></td></tr></table></figure><p>如果应用程序选择，它可以并行读取所有段。请注意，在撰写本文时，此API是实验性的，并且可能会发生变化。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>在这里，我们介绍了一些关于Pravega摄取和读的基本概念，和不是那么基本的一些概念  。这些是了解Pravega需要理解的一些主要概念 ， 基本功能易于使用和理解，但关于顺序和重复，在我们公开的属性中有一些细微差别，这对于开发人员来说是很重要的。更多的信息，我们建议读者们查看 Pravega.io网站  文档 和github上的代码库。</p><p><strong>原文</strong> ： <a href="http://blog.pravega.io/2018/02/12/streams-in-and-out-of-pravega/" target="_blank" rel="noopener">http://blog.pravega.io/2018/02/12/streams-in-and-out-of-pravega/</a></p>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>pravega blog - 流存储-重新设想流的世界</title>
      <link href="/2018/11/11/pravega-blog-storage-reimagined/"/>
      <url>/2018/11/11/pravega-blog-storage-reimagined/</url>
      
        <content type="html"><![CDATA[<p>将海量原始数据转换为有用的信息和行动所需的时间缩短为零的愿景的驱动下，流式传输看似简单：只需在数据到达时，快速地、连续且无限地处理和处理数据。</p><p>对于从工业物联网到联网汽车到实时欺诈检测等的用例，我们越来越多地寻求构建新的应用程序和客户体验，以快速响应客户的兴趣和行为，学习和适应不断变化的行为模式等。但实际情况是，我们大多数人还没有工具来处理生产级数据量、摄取率和故障弹性。因此，我们尽可能地利用定制系统在复杂性之上堆积复杂性。</p><p>复杂性是基本系统设计不匹配的症状：我们使用一个组件来完成它没有设计完成的任务，并且我们使用的机制不会从小到大进行扩展。</p><p>流式传输很难实现，因为它具有三种破坏性系统功能：</p><ul><li>能够将数据视为连续且无限的而不是有限的和静态的</li><li>能够通过与到达的数据量协调地动态扩展数据摄取、存储和处理能力来提供始终如一的快速结果的能力</li><li>即使是迟到或无序数据，也能够持续提供准确的结果处理数据</li></ul><p>在这里，它以一种好的方式变得有趣，甚至更具破坏性：事件驱动，连续和有状态数据处理的流式范例以及在许多情况下对时间的一致理解比传统的ETL&gt;Store&gt;Query， 即使对于没有实时要求的应用程序，查询方法也是如此！</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/Blog-Fig-1-1.png" alt=""></p><p>图1：流式处理的简单生命周期</p><p>流式传输迫使系统设计人员重新思考基本的计算和存储原理。作为充满激情的存储人员，我们正在通过设计一个新的存储原语（称为流，专门为流体系结构构建并在名为Pravega的新开源项目中实现）来完成我们的工作。</p><p>通过将Pravega流存储与像Apache Flink这样的有状态流处理器相结合，我们实现了一个系统，其中上图中的所有元素 - 写入器，处理器，读取器和存储 - 独立，弹性和动态可扩展，与数据到达使我们所有人都能够构建我们以前无法构建的流式应用程序，并无缝地将它们从原型扩展到生产。</p><h2 id="流式存储的要求"><a href="#流式存储的要求" class="headerlink" title="流式存储的要求"></a>流式存储的要求</h2><p>让我们看看流式系统的三个破坏性特征中的每一个，看看Pravega流如何以今天的存储无法实现的方式实现它们。</p><h3 id="将数据视为连续和无限"><a href="#将数据视为连续和无限" class="headerlink" title="将数据视为连续和无限"></a>将数据视为连续和无限</h3><p>附加到文件末尾并尾随其内容会模拟连续且无限的数据流，但文件并未针对此模式进行优化。它们也不是无限的。曾经轮换过日志文件的人都知道这一点。套接字或管道是连续数据的更好抽象，但它们不是持久化的。消息传递是连续数据的合理抽象 - 特别是像Kafka的仅附加日志 - 但它们并不是设计为无限、持久化的系统。并且它们使用信包和标题来构造数据结构，使它们不像字节序列那样通用。</p><p>将这些想法拼凑在一起，我们提出了Pravega将从数据的角度支持的特征，即连续和无限：</p><ul><li>Pravega流是一个有命名空间的、持久的、仅附加的、无限的字节序列</li><li>低延迟附加到序列的尾部并从中读取</li><li>通过序列的较老部分进行高通量追赶读取</li></ul><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/Blog-Fig-2-1.png" alt=""></p><p> 图2：在管道中使用流</p><h3 id="基于数据到达量的系统扩展"><a href="#基于数据到达量的系统扩展" class="headerlink" title="基于数据到达量的系统扩展"></a>基于数据到达量的系统扩展</h3><p>那么我们如何根据数据量弹性地、独立地缩放数据摄取、存储和数据处理？</p><p>我们通过将数据拆分为分区，并独立处理来获得并行性。例如，Hadoop通过HDFS和map-reduce实现了批处理。对于流式工作负载，我们今天要使用队列或Kafka分区。这两个选项都有同样的问题：分区会影响读者和写入者。连续处理的读/写缩放要求通常不同，并且链接它们会增加复杂性。此外，虽然可以添加队列或分区以进行扩展，但这需要手动协调地更新写入器、读取器和存储。这是很复杂，而不是动态缩放。</p><p>Pravega流，专为动态和独立扩展而设计，支持：</p><ul><li>许多写入者同时追加一个不相交的数据子集<ul><li>不相交的子集由用相同密钥写入的数据定义</li><li>为写入者分配密钥留给应用程序 </li><li>当密钥空间或编写器更改时，存储不得约束或不需要更改</li></ul></li><li>许多读者同时处理不相交的数据子集<ul><li>读取的数据分区必须独立于写入分区</li><li>读取分区必须由存储策略控制，例如将流分成足够的段以确保没有看到超过N字节/秒</li><li>每个传入数据卷的存储系统必须自动且不断地更新流中的段数</li></ul></li></ul><p>这些都是很苛刻的要求，我们来看看两种典型的分区方案。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/Blog-Fig-3-1.png" alt=""></p><p>图3：摄取率&lt;&lt;处理率</p><p>在图3中，处理时间比摄取时间更长。有一个写入器，但数据被分段用于读取：读取器＃1获取密钥k a … k c的数据，另一个获取密钥k d … k f。在图4中，处理比摄取更快，因此拓扑反转：多个写入器为写入分区密钥空间，但是一个读取器处理它。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/Blog-Fig-4-1.png" alt=""></p><p>图4：摄取率&gt;&gt;处理率</p><p>在现实生活中，我们最终介于两者之间 - 随着我们的数据源和应用程序的发展，可能会随着时间的推移而变化。虽然流将由多个段内部组成，但（a）写入者并不知道段拓扑，因为他们只知道键，以及（b）读者动态学习段拓扑 - 只需将它们指向流即可。</p><p>为了使整个系统（存储+处理）适应不断变化的数据量，Pravega不断监控流的传入数据速率，并确保存在适当数量的段以满足SLO合规性。图5显示了流的片段随时间动态变化。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/Blog-Fig-5-1.png" alt=""></p><p>图5：随时间动态缩放流段</p><p>在t 0，输入数据速率低于缩放SLO。所有数据都存储在段0中。在t 1，超过SLO。段0被密封，并且创建了段1和段2。k 0和k 1的新数据将转到段2。k 2和k 3 的新数据进入第1段。这是针对数量增加而分割的细分市场。分裂也发生在t 2和t 3。在t 4，速率减慢。段3和6被密封，并且段7被创建并将保持k 1 … k 2 的新数据。这是一个段合并以响应数量减少。</p><p>Pravega的分段缩放协议允许读者跟踪分段缩放并采取适当的措施，例如添加或删除读取器，使整个系统能够以协调的方式动态缩放。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/Blog-Fig-6-1.png" alt=""></p><p>图6：具有动态，协调的组件缩放的流式传输系统</p><h3 id="持续生成准确的结果处理数据"><a href="#持续生成准确的结果处理数据" class="headerlink" title="持续生成准确的结果处理数据"></a>持续生成准确的结果处理数据</h3><p>连续计算准确的结果意味着精确地进行一次处理，并且当关于该发生的数据被计算处理时，将事件时间——现实生活中发生的时间——与处理时间区分开。为此，我们向链式应用程序添加了一个要求，同时保留了一次将计算分成多个独立的应用程序。这是流式处理满足微服务。</p><p>与lambda架构相比，生成准确结果的流式系统可以节省大量成本，其中实时和批处理使用单独的基础架构。这不仅更简单、更便宜 - 它只是一个基础设施而不是两个 - 它简化了开发，因为您总共只需要编写一次代码而不是为每个 lambda 基础设施都编写一次。Tyler Akidau的O’Reilly博客中有一篇关于这些概念的精彩文章，名为“超越批量的世界：流式101”。</p><p>恰好一次的存储要求是明确的：流必须是持久的、有序的，一致的和事务性的。这些是关键属性，因为它们是存储系统设计中最困难的方面。如果没有重大的重新设计，您无法在以后更改它们。</p><p>持久性意味着一旦得到确认，即使面对组件故障，写入也不会丢失。持久性至关重要，因为如果数据丢失，则无法（重新）处理。大多数持久的数据并没有解决问题：要么你可以依靠存储持久性，要么你不能。不持久的系统不是记录系统，意味着数据的永久副本必须存储在其他地方 - 通常存储在对象存储或NAS等归档系统中。归档意味着ETL的应用程序代码和ETL过程的管理。这种复杂性被消除了，因为Pravega流式存储是一个持久的永久存储，您可以永久地可靠地保存您的流数据。</p><p>排序意味着读者将按照写入的顺序处理数据。对于具有密钥分区写入的流的系统，排序仅对具有相同密钥的数据有意义。在拥有数百万设备生成传感器指标的物联网系统中，sensor-ID.metric可能是关键。流保证读取密钥的数据将按其编写的顺序进行。对于许多计算（例如使用增量更新计算的聚合度量），排序是必不可少的。</p><p>一致性意味着所有读者都会看到给定密钥的相同有序数据视图 - 即使面对组件故障 - 无论是从流的尾部读取数据还是通过追加读取。与持久性一样，大多数情况并不一致：要么存储是一致的，要么是不一致的。从恰好一次的要求来看，存储一致性与区分计算层中的事件时间与处理时间同等重要。</p><p>事务性写入对于跨链接的应用程序一次完全正确是必要的。像Flink这样的有状态流处理器使用聪明的分布式检查点在单个应用程序中只有一次内部机制。跨多个应用程序精确扩展一次范围需要中间存储（在本例中为流）通过事务写入参与这些检查点方案。</p><h2 id="Pravega-Streams"><a href="#Pravega-Streams" class="headerlink" title="Pravega Streams"></a>Pravega Streams</h2><p>Pravega是一个实现流的开源分布式存储服务。流是可靠流式传输系统的基础：高性能、持久化，有弹性且无限附加的字节流，具有严格的排序和一致性。流是轻量级的。就像文件或对象一样，我们可以根据需要快速轻松地创建多个文件或对象 - 单个群集中的数百万。</p><p>通过对先前的内部日志和专有日志进行重构和外部化，流大大简化了新一代分布式中间件的开发和运行，这些中间件被重新构想为流式基础架构：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/Blog-Fig-7-1.png" alt=""></p><p> 图7：为流式世界重构堆栈</p><p>Pravega项目目前包括Pravega字节流原语以及分层摄取缓冲区和pub / sub机制，在概念上与Kafka类似，但具有性能、弹性、无限性、一致性和持久性的流特性。我们将在下一节讨论将Pravega的摄取缓冲区与Flink集成。</p><p>另外两个项目，都将通用中间件服务重新构想为流式基础设施，处于早期概念阶段：</p><ul><li>基于流的全文搜索：动态的、分布式的、实时的Lucene索引器，具有用于流数据的连续查询工具</li><li>流支持的持久数据结构：微服务原生主义者的框架，他们希望自己的微服务拥有自己的数据</li></ul><h2 id="Pravega架构"><a href="#Pravega架构" class="headerlink" title="Pravega架构"></a>Pravega架构</h2><p>Pravega的架构有三个主要组成部分。所述Pravega流服务是使用分布式软件服务执行流抽象语义，包括流控制和段存储的API，数据存储器缓存（Rocks DB）以及利用两个底层存储系统的数据放置和分层逻辑：低延迟存储Apache Bookkeeper，以及HDFS用于支持高吞吐量、大规模的存储。[此组件旨在可插拔，以支持具有适当强一致性语义的备用后备存储系统。]</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/Blog-Fig-8-1.png" alt=""></p><p> 图8：Pravega流式存储架构</p><p>Pravega的系统设计有许多创新，使其能够满足流的挑战性要求。I / O路径设计完全隔离了读写路径，从而实现了对尾部进行极低延迟的持久写入，从尾部进行低延迟读取以及从流的老的部分进行高吞吐量读取。Pravega架构的细节超出了本文的范围。更多信息可在Pravega Architecture Wiki中找到。</p><h2 id="流式存储-Apache-Flink-YEAH！"><a href="#流式存储-Apache-Flink-YEAH！" class="headerlink" title="流式存储+ Apache Flink = YEAH！"></a>流式存储+ Apache Flink = YEAH！</h2><p>让我们探索Pravega流如何与Flink集成，以实现一个动态和弹性的系统，提供快速和准确的计算结果，同时即使在数据速率变化很大的情况下也可以在恒定的时间内处理海量数据。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/Blog-Fig-9a.png" alt=""></p><p>系统的概念结构如图9所示。它包含一个典型的输入流，其中包含由一组写入者编写的原始数据，一个用于处理它的多工作者Flink应用程序，以及一个处理第一个输出的链式Flink应用程序。</p><p>这里是不同的地方：每个元素 – 写入者、输入流、读取器应用程序，输出流 - 独立，弹性和动态可伸缩，以响应数据量到达率随时间的变化。</p><p>两个集成点实现了这一点：Pravega的分段缩放驱动Flink的worker缩放，以及通过流将应用程序链接到整个系统，从而精确地保存一次。仅使用一个worker部署Flink应用程序，并根据流SLO动态缩放它。太好了！Pravega和Flink开发人员已经将流自动缩放功能整合到Flink中。</p><p>除了此之外，无限流还可以显著的简化许多操作用例。这里考虑推出一个新版本的Flink应用程序（真正的任何应用程序），首先根据历史数据对其进行测试。</p><p>图10展示了今天针对实时Flink应用程序的典型部署。信息被馈送到消息传送系统，由Flink应用程序处理，然后被转发到NOC或类似的框架以进行显示和/或动作。与此同时，ETL工作人员不断地将消息拉出并将其写入持久化的存储以进行历史访问。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/Blog-Fig-10-1.png" alt=""></p><p> 图10：测试没有流的新应用版本的复杂性</p><p>现在我们已经构建了一个新版本的应用程序“App”。准备在生产环境里对无中断部署之前，尝试针对历史数据集的新逻辑来验证正确性并确保没有回归的操作过程是什么？</p><p>首先，我们需要部署”App”来从归档而不是消息传递系统里获取其数据。因此，您的测试与生产不同：归档和消息传递之间的微妙行为差异可能会使测试不可靠。测试完成后，我们重新部署“App”以使用消息传递系统，并重新填充其缓存或从历史数据中派生的其他状态。如果一切正常，我们终于可以取代之前的版本了。结果是一个复杂的工作流程序列。复杂性意味着麻烦。</p><p>Pravega流如何改变？App’的部署与生产完全一样，因为历史数据是通过相同的流访问的- 只需回放它！消耗历史记录时，App’和App正在处理具有相同状态的相同数据。当我们确信App’很好时，请关闭App并重定向NOC。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/Blog-Fig-11-1.png" alt=""></p><p> 图11：使用流测试新的应用版本</p><h2 id="结束思考"><a href="#结束思考" class="headerlink" title="结束思考"></a>结束思考</h2><p>我们是充满激情的存储界人，我们喜欢流式的想法，我们觉得Flink这样的“原生的流式”计算非常的有意思。我们认为这个世界需要一种互补的存储技术。Pravega是我们贡献的开源流存储项目：pravega.io，我们相信它将进一步推动流式技术的发展.</p><p>请记住，当您考虑流式应用时，请将数据视为连续且无限的，而不是静态和有限的。想想企业存储的重要性，如持久性、一致性弹性、以及现在的：无限性。</p><p>另外我们鼓励您加入我们的社区！</p><blockquote><p>原文链接：<a href="http://blog.pravega.io/2017/04/09/storage-reimagined-for-a-streaming-world/" target="_blank" rel="noopener">http://blog.pravega.io/2017/04/09/storage-reimagined-for-a-streaming-world/</a></p></blockquote><blockquote><p>About the Author： Salvatore DeSimone – VP and CTO Advanced Software Division at Dell EMC</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>pravega blog - pravega的内部架构</title>
      <link href="/2018/11/02/pravega-blog-internals/"/>
      <url>/2018/11/02/pravega-blog-internals/</url>
      
        <content type="html"><![CDATA[<p>尾随数据流的一些困难归结为源和流处理器总是动态变化的。例如，如果源以非计划的方式增加其输出率，则读取系统必须能够适应这种变化。处理器下游遇到问题并努力跟上速率的变化也是如此。为了能够适应所有这些变化，用于存储流数据的系统（如Pravega）必须足够灵活，这一点至关重要。</p><p>Pravega的灵活性来自将数据流分解为段：仅附加的字节序列，这些字节序列被顺序和并行地组织成流。段支持重要的特性，例如并行读写，自动缩放和事务; 它们一开始就是按创建和维护成本低廉的理念而设计。当需要更多并行性，需要扩展或需要启动事务时，我们可以为给定流创建新的段。</p><p>Pravega中的控制面负责所有影响流的生命周期的所有操作，如创建、删除和缩放。数据面存储和服务段的数据。下图描绘了具有核心组件的高级Pravega架构。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/flavio_fig1.png" alt=" Pravega 架构图"></p><p>鉴于我们在之前的博客文章中讨论了客户端的概念，我们将在以下部分重点介绍控制器和段存储。</p><h2 id="控制器"><a href="#控制器" class="headerlink" title="控制器"></a>控制器</h2><p>控制器实现了Pravega的控制平面。它负责Pravega集群中的一些非常重要的任务，例如：</p><ol><li><p>流生命周期：管理流的创建，删除和缩放。</p></li><li><p>事务管理：它负责启动或创建事务并跟踪其状态，包括时间跟踪。</p></li></ol><h2 id="控制器服务"><a href="#控制器服务" class="headerlink" title="控制器服务"></a>控制器服务</h2><p>控制器主要负责编排所有流生命周期操作，如创建、更新、缩放和删除流。因此，控制器维护流元数据并响应客户端对流的查询。</p><p>创建和删除流是由用户请求触发的操作，但是控制器的某些操作由内部机制触发，例如缩放和保留。控制器实现工作流，使用户能够配置控制器以自动缩放流，并根据时间或大小截断流。此机制的配置基于策略，并且根据应用程序所期望的行为将策略配置为流配置的一部分。有关如何配置此类策略的示例，请参阅以下代码段：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>// Set up scaling and retention policies. <br>//<br>// In this example, the scaling policy sets the target rate to be<br>// of 10 events/second, with a scaling factor of 2, and a minimum<br>// of 2 segments.<br>//<br>// http://pravega.io/docs/latest/javadoc/javadoc/clients/io/pravega/client/stream/ScalingPolicy.html<br>//<br>// The retention policy sets it to an hour. With this policy, Pravega<br>// retains stream data for at least an hour and truncates eventually<br>// after the time has elapsed.<br>//<br>// http://pravega.io/docs/latest/javadoc/javadoc/clients/io/pravega/client/stream/RetentionPolicy.html<br>ScalingPolicy scalingPolicy = ScalingPolicy.byEventRate(10, 2, 2);<br>RetentionPolicy retentionPolicy = RetentionPolicy.byTime(Duration.ofMinutes(60);<br><br>// Configure the stream adding the policies<br>StreamConfiguration config = StreamConfiguration.builder().scope(&quot;myScope&quot;)<br>                                                          .streamName(&quot;myStream&quot;)<br>                                                          .scalingPolicy(scalingPolicy)<br>                                                          .retentionPolicy(retentionPolicy)<br>                                                          .build();<br><br>// Create scope and stream with the previously built configuration<br>StreamManager streamManager = StreamManager.create(controllerURI);<br>streamManager.createScope(&quot;myScope&quot;);<br>streamManager.createStream(&quot;myScope&quot;, &quot;myStream&quot;, config);<br></code></pre></td></tr></table></figure><h2 id="客户端交互"><a href="#客户端交互" class="headerlink" title="客户端交互"></a>客户端交互</h2><p>控制器在客户端交互中起着至关重要的作用。客户端与控制器交互以创建和删除scope和流。此交互通过Java或REST API进行。</p><p>创建和删除流是通过API调用直接触发的操作，但是对于客户端的来说，其他操作也很重要的，并且这些操作需要透明化。具体而言，客户端在其生命周期中需要与控制器交互，以了解段集以及它们所处的位置。回想一下，流执行自动缩放，因此，任何配置为自动缩放的流的段集都可以随时间改变。随着流的演进，客户端需要知道从控制器获得的这些段的拆分和合并。然而，了解当前的段集是不够的。客户端还需要知道对于给定的段，需要联系哪个段存储。控制器负责客户端和段存储之间的这种交集。</p><p>作为缩放流的一部分，控制器负责密封其部分片段。密封段是我们用来向客户端指示它需要从控制器获取新元数据的主要机制。在找到段的末尾（段密封）后，客户端从控制器请求后继段，包括联系用于新段的相应段存储所需的信息。此流程对于确保流的伸缩与应用程序无缝地互动至关重要，并且避免对应用程序的任何干扰。</p><h2 id="控制器实例"><a href="#控制器实例" class="headerlink" title="控制器实例"></a>控制器实例</h2><p>控制器服务包括许多控制器实例，这些实例当前依赖Apache ZooKeeper进行元数据协调。可以根据群集要求创建实例数。建议至少有两个实例能够容忍崩溃，并引入其他实例，既具有较高的崩溃容忍度，又能提高容量。只要有可能，控制器就会缓存ZooKeeper元数据以避免网络延迟。</p><p>随着控制器实例的数量随时间变化，系统必须能够适应对控制器集合的变化。在控制器实例崩溃或有意从系统中删除的情况下，我们实现了故障转移机制，以便其余实例接管已删除实例的工作。为了启用此类故障转移过程，控制器实例将向ZooKeeper注册并监视订阅的更改。在检测到实例已被移除时，每个控制器实例触发一组清扫任务争夺已删除实例的工作所有权。通过这种方式，我们可以自动响应控制平面中实例数量的变化。请注意，元数据是通过ZooKeeper存储和协调的，因此，控制器实例被视为无状态进程。目前正在努力将一些流元数据移出ZooKeeper fort可伸缩性。我们将在以后的文章中介绍它。</p><h2 id="事务管理"><a href="#事务管理" class="headerlink" title="事务管理"></a>事务管理</h2><p>控制器服务管理事务的生命周期。用户应用程序中的编写器请求控制器执行与事务有关的所有控制平面操作。在启动事务时，写入器需要使用控制器服务进行设置。控制器添加必要的元数据以跟踪事务的状态，并在需要更多时间才能完成的情况下将其设置为超时。</p><p>客户端针对单个流执行事务，因为Pravega当前不支持跨多个流的事务。当客户端开始事务处理时，控制器创建事务段，会为每个流段开放一个事务段。例如，假设客户端针对具有三个开放段s 1、s 2、s 3的流S启动事务。控制器创建事务TS i为每个打开的段SI，i∈{1，2，3} 。当客户端使用给定密钥k写入事件时要附加到段s i，该事件将附加到ts i。在提交事务的情况下，事务段被合并到流段上，并且事务事件变得可用于读取。</p><p>一旦写入器准备好，它就根据应用程序逻辑提交或中止事务，并且控制器负责命令段存储执行事务段的合并。它还负责更新事务相应的元数据。<br>当通过提交或中止事务来结束事务时，控制器需要确保事务的结果在确认操作后不会改变。接受提交事务并随后中止同一事务，或者反过来，是不可接受的方案。当它收到提交事务的请求时，控制器通过读取事务元数据（存储在ZooKeeper中）来检查事务的状态。如果事务仍处于打开状态，则控制器会更新元数据以反映其新状态。请注意，可以有多个控制器实例，并且元数据的更新需要以znode版本为条件，以避免因竞争条件导致的不一致。</p><p>事务元数据操作成功后，它会将事件发布到内部提交流，以便异步处理。这种流是用于内部目的的常规Pravega流。内部流的事件由提交事件处理器处理，提交事件处理器是处理流事件的控制器实例中的元素。提交事务事件包括合并事务段。在提交事件的处理被中断的情况下，例如，因为控制器实例崩溃，不同控制器流中的提交处理器可以拾取并执行它。合并操作是幂等的，并且在同一段上多次尝试时不会引起任何不一致。</p><p>同样，在事务中止的情况下，该过程类似于删除事务段。</p><p>对于同一流上的并发事务，控制器按顺序提交它们以保证两个或多个事务的事件在单个段中的排序不同。如果控制器同时合并两个事务t 1和t 2 ，那么一些段可能在t 2事件之前对t 1事件进行排序，而其他段可能具有相反的顺序。提交（和合并）的串行顺序保证满足此属性。</p><p>一个有趣的方面是在存在缩放的情况下处理事务。如果事务段和开放流段之间存在一对一映射，那么当流缩放并更改段数时会发生什么？在Pravega的原始设计中，我们选择阻止流的缩放，直到所有未完成的事务都已提交或中止。。我们有一个超时，如果事务在进行伸缩操作时调用时间过长，则会中止事务。这个超时可能导致的主要问题是应用程序花了太长时间来提交事务，即使它确实想要提交事务。这种情况在本质上存在正确性的问题，因为写入的数据是从应用程序获取的，而应用程序则指望将其公开。最近，我们添加了一项特性，使事务能够在缩放事件中“滚动”。在事务以一组给定的段开始，并且当事务提交时段的集合不同的情况下，我们就像对流的缩放一样处理它：我们密封当前的段集Σ，使事务段成为后继者，并创建一组新的后继段Σ’，使得| Σ| = | Σ’| 密钥空间的分割与Σ相同。</p><h2 id="段存储"><a href="#段存储" class="headerlink" title="段存储"></a>段存储</h2><p>段存储实现了Pravega的数据平面，并且正如名称所说的那样：它存储段。它在使分段数据持久并有效地提供服务方面发挥着关键作用。段存储与流的概念无关。控制器执行分段到流的组成。例如，当我们将一个段拆分为新段时，段存储会创建新段，但控制器有责任了解流中段的顺序。</p><p>段存储服务的一个角色是将事务段合并为流的段。控制器负责命令段存储在事务提交时合并事务段，并且段存储基于每个段执行必要的操作。</p><p>段存储有两个主存储依赖关系，我们给出了第1层和第2层的通用名称。第1层的主要目标是保证写入持久且低延迟。使写入持久意味着一旦应用程序获知写入请求成功，系统就会保证写入不会丢失，即使有错误。第1层的实现是段存储写入的仅附加数据结构。可以将其视为段存储更新的日志。</p><p>我们将附加的数据和一些其他Bookeeper数据同步记录到第1层，这些数据是我们为了正确操作服务而需要持久保存的。目前，Pravega使用Apache BookKeeper [1]来实现第1层.BookKeeper为少量数据提供了出色的写入延迟，这保证了写操作的持久性，同时为事件流提供低延迟。我们还使用了在打开BookKeeper分类帐时屏蔽旧陈述者的能力。这是BookKeeper提供的一个特性，即使存在错误的崩溃问题，也能使其一致性。</p><p>我们将数据异步迁移到第2层，一旦我们这样做，我们就会截断了来自第1层的相应数据。我们有一个第2层，原因有两个：</p><ul><li>我们设想一个可以存储大量数据的无限量数据的系统。因此，我们需要一个水平可扩展的大容量存储来容纳所有的这些数据，遵循更紧密的云存储选项。</li><li>我们需要为读取数据提供高吞吐量选项，特别是在我们需要赶上流时读取旧数据时。</li></ul><p>我们目前支持第2层的几个选项：HDFS [2]，NFS [3]和扩展S3 [4]。</p><p>在这一点上，重要的是要讨论我们预期的两种不同类型的读取，以便我们理解这种架构背后的动机。我们希望应用程序执行尾部读取和追赶或历史读取 [5]。尾部读取对应于最近写入的字节读取，正如术语所指示的那样尾随流的写入者。这样的读取器期望非常低的延迟，并且为了满足这个要求，我们保留最近写入内存的数据缓存以服务于这些读取。我们目前使用RocksDB [6]来实现这样的缓存。</p><p>下图说明了Pravega中的尾部和追赶读取。段存储服务的所有数据都来自缓存。对于尾部读取，期望它是足够新的，以便缓存命中，并且可以立即提供服务。对于历史数据，它可能是缓存未命中，其中它会引起对第2层的读取以填充缓存。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/flavio_fig2.png" alt="尾部和追赶读取"></p><p>第一层中的数据唯一地用于恢复的，并且如上所述，在缓存未命中的情况下，我们提供从缓存的读取和从第2层获取数据的服务。我们还开始实现一种不同类型的只读段存储（PDP-25）的实现。只读段存储不会缓存来自第2层的数据。这样的特性对于批处理读取量很大的设置很有用（例如，对于批处理作业），因为这种批量读取可能最终在常规段存储的情况下干扰新数据的摄取。只读段存储的工作尚未完成，在撰写本文时，客户端无法使用该功能。</p><p>段存储服务器中的工作负载在跨段容器之间进行拆分。在轻量级虚拟化环境中，这不会与容器混淆（例如， Docker容器）。段容器是Pravega的概念。它们是段的逻辑分组，并负责对这些段内的所有操作进行操作。容器是工作分配和恢复的单位; 控制器是负责在重新平衡时将容器分配给不同的段存储的元素，这是由于段存储崩溃导致新的段存储启动或重新分配。每个容器在任何时候都应该有一个所有者，我们使用围栏机制来防止僵尸进程的出现（仍然认为他们拥有它的旧所有者）。</p><p>段存储的每个实例都执行容器管理器，该管理器负责管理分配给该实例的段容器的生命周期。在重新分配容器的情况下，容器管理器需要通过关闭或引导段容器来做出反应，具体取决于段存储实例是新所有者还是容器的先前所有者。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>这篇文章介绍了Pravega内部的概要性的架构视图。它展现了控制器和段存储。它们是实现Pravega核心的两个主要组件：控制器实现控制平面，而段存储实现数据平面。正如之前的文章所讨论的那样，段抽象非常重要，可以灵活地开发kick-ass功能，以支持流作为存储原语。</p><p>未来的文章将详细介绍控制器和分段存储机制，这篇文章介绍一些概念，为即将发布的pravega的更深入的文章为读者提供背景上下文信息。</p><h3 id="About-the-Author"><a href="#About-the-Author" class="headerlink" title="About the Author"></a>About the Author</h3><p>Flavio Junqueira leads the Pravega team at Dell EMC. He holds a PhD in computer science from the University of California, San Diego and is interested in various aspects of distributed systems, including distributed algorithms, concurrency, and scalability. Previously, Flavio held a software engineer position with Confluent and research positions with Yahoo! Research and Microsoft Research. Flavio has contributed to a few important open-source projects. Most of his current contributions are to the Pravega open-source project, and previously he contributed and started Apache projects such as Apache ZooKeeper and Apache BookKeeper. Flavio coauthored the O’Reilly ZooKeeper: Distributed process coordination book.</p><h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><p>[1] Apache BookKeeper. <a href="http://bookkeeper.apache.org" target="_blank" rel="noopener">http://bookkeeper.apache.org</a><br>[2] Hadoop File System. <a href="https://hadoop.apache.org/" target="_blank" rel="noopener">https://hadoop.apache.org/</a><br>[3] R. Sandberg, D. Goldberg, S. Kleiman, D. Walsh, and B. Lyon. Design and Implementation of the Sun Network Filesystem. USENIX Conference and Exhibition, 1985.<br>[4] Extended S3. <a href="https://www.emc.com/techpubs/ecs/ecs_s3_supported_features-1.htm" target="_blank" rel="noopener">https://www.emc.com/techpubs/ecs/ecs_s3_supported_features-1.htm</a><br>[5] Leigh Stewart. Building DistributedLog: High-performance replicated log service, September 2016.<br>[6] RocksDB: A persistent key-value store for fast storage environments. <a href="https://rocksdb.org/" target="_blank" rel="noopener">https://rocksdb.org/</a><br>[7] Stephan Ewen and Flavio Junqueira, An elastic batch and stream processing stack with Pravega and Apache Flink, April 2018.</p><p>原文链接：<a href="http://blog.pravega.io/2018/10/" target="_blank" rel="noopener">http://blog.pravega.io/2018/10/</a></p>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>pravega handbook - 设计提案</title>
      <link href="/2018/10/09/pravega-pdp-design-proposals/"/>
      <url>/2018/10/09/pravega-pdp-design-proposals/</url>
      
        <content type="html"><![CDATA[<p>本文档描述了开发Pravega新特性所遵循的流程。我们的想法是在开始实现这个特性之前先提出设计方案，并与社区讨论这个设计，避免由于方案的分歧而导致的长时间的检视。流程如下：</p><h2 id="设计文档"><a href="#设计文档" class="headerlink" title="设计文档"></a>设计文档</h2><p>将设计文档编写为当前页面的子页面。页面标题应为：</p><blockquote><p>PDP-XX: 简要描述特性</p></blockquote><p>XX是我们通过递增先前提案的编号而生成的数字。第一个数字是01，希望在创建新PDP时不会有任何冲突。我们将使用PDP-XX作为标签来指代特定的设计。</p><p>该文件应包含：</p><ul><li>功能和提案的摘要（摘要）</li><li>API更改的说明（API更改）</li><li>内部变更说明（内部变更）</li><li>必要时有关向后兼容性和迁移计划的部分（兼容性和迁移）</li><li>关于解决问题的废弃方法的章节（废弃方法）</li><li>引用，例如，Github问题或pull请求（参考）</li></ul><p>如果某个部分不适用，请说“不适用”，但不要省略该部分。</p>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>pravega handbook - 开发pravega应用 - connector与readerGroup通知</title>
      <link href="/2018/10/02/pravega-working-with-connector-readergroupnotifications/"/>
      <url>/2018/10/02/pravega-working-with-connector-readergroupnotifications/</url>
      
        <content type="html"><![CDATA[<h1 id="ReaderGroup通知"><a href="#ReaderGroup通知" class="headerlink" title="ReaderGroup通知"></a>ReaderGroup通知</h1><p>ReaderGroup api支持不同类型的通知。目前，我们已经实现了两种类型，但我们计划添加更多类型。我们目前支持的类型如下：</p><h2 id="分段通知"><a href="#分段通知" class="headerlink" title="分段通知"></a>分段通知</h2><p>当ReaderGroup管理的段总数发生变化时，触发段通知。在缩放期间，可以将段拆分为多个或合并到某个其他段中，从而导致段的总数发生变化。当ReaderGroup的配置发生改变时（例如，添加或删除流时），段的总数也会发生变化。</p><p>订阅分段通知的方法如下所示</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>@Cleanup<br>ReaderGroupManager groupManager = new ReaderGroupManagerImpl(SCOPE, controller, clientFactory,<br>        connectionFactory);<br>groupManager.createReaderGroup(GROUP_NAME, ReaderGroupConfig.builder().<br>                                                            .stream(Stream.of(SCOPE, STREAM))<br>                                                            .build());<br><br>groupManager.getReaderGroup(GROUP_NAME).getSegmentNotifier(executor).registerListener(segmentNotification -&gt; &#123;<br>       int numOfReaders = segmentNotification.getNumOfReaders();<br>       int segments = segmentNotification.getNumOfSegments();<br>       if (numOfReaders &lt; segments) &#123;<br>          //Scale up number of readers based on application capacity<br>       &#125; else &#123;<br>         //More readers available time to shut down some<br>       &#125;<br>&#125;);<br></code></pre></td></tr></table></figure><p>应用程序可以使用registerListenerapi 注册一个监听器以通知SegmentNotification。这个 API 以<code>io.pravega.client.stream.notifications.Listener</code>作为参数。在这里，应用程序可以添加自定义逻辑，以根据段的数量更改在线reader的数量。例如，如果段数增加，则应用程序可能会考虑增加在线reader的数量。如果段的数量根据段通知而减少，则应用程序可能希望相应地更改该组在线reader的数量。</p><h2 id="EndOfData通知"><a href="#EndOfData通知" class="headerlink" title="EndOfData通知"></a>EndOfData通知</h2><p>当读者已读取readerGroup管理的流的所有数据时，将触发数据通知程序的结束。这对于使用批处理作业处理流数据很有用，其中应用程序想要读取密封流的数据。<br>订阅数据通知结束的方法如下所示：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>@Cleanup<br>ReaderGroupManager groupManager = new ReaderGroupManagerImpl(SCOPE, controller, clientFactory,<br>        connectionFactory);<br>groupManager.createReaderGroup(GROUP_NAME, ReaderGroupConfig.builder()<br>                                                            .stream(Stream.of(SCOPE, SEALED_STREAM))<br>                                                            .build());<br><br>groupManager.getReaderGroup(GROUP_NAME).getEndOfDataNotifier(executor).registerListener(notification -&gt; &#123;<br>      //custom action e.g: close all readers<br>&#125;);<br></code></pre></td></tr></table></figure><p>应用程序可以使用registerListener api注册一个监听器以通知EndOfDataNotification。这个api以<code>io.pravega.client.stream.notifications.Listener</code>作为参数。在这里，应用程序可以添加自定义逻辑，读取密封流的所有数据就可以调用该自定义逻辑。</p><h1 id="Pravega连接器"><a href="#Pravega连接器" class="headerlink" title="Pravega连接器"></a>Pravega连接器</h1><p>连接器允许将Pravega与不同的数据源和接收器集成。</p><h2 id="Flink连接器"><a href="#Flink连接器" class="headerlink" title="Flink连接器"></a>Flink连接器</h2><p>支持的初始连接器是Flink，它支持使用Pravega构建端到端流处理流水线。这还允许通过Flink流连接器读取和写入数据到外部数据源和接收器。</p><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><ul><li>Logstash</li><li>Hadoop连接器</li></ul><p>其他参考原文： <a href="http://pravega.io/docs/latest/connectors" target="_blank" rel="noopener">http://pravega.io/docs/latest/connectors</a></p><h1 id="Java-API参考"><a href="#Java-API参考" class="headerlink" title="Java API参考"></a>Java API参考</h1><h2 id="客户端"><a href="#客户端" class="headerlink" title="客户端"></a>客户端</h2><p>Writer是一个创建事件并将它们发布到Streams中的客户端。Reader是一个消费来自Streams的事件的客户端。我们提供了一个Java库，它为Writer和Reader应用程序实现了一个方便的API。客户端库封装了用于在Pravega客户端和Pravega服务之间传递请求和响应的有线协议。<br>Writer和Reader API</p><h1 id="Pravega控制器的API"><a href="#Pravega控制器的API" class="headerlink" title="Pravega控制器的API"></a>Pravega控制器的API</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>pravega控制器服务的管理REST API列表。</p><h2 id="版本信息"><a href="#版本信息" class="headerlink" title="版本信息"></a>版本信息</h2><p>版本：0.0.1</p><p>许可证信息</p><p>许可证：Apache 2.0 </p><p>许可证URL：http：//<a href="http://www.apache.org/licenses/LICENSE-2.0" target="_blank" rel="noopener">www.apache.org/licenses/LICENSE-2.0</a> </p><p>服务条款：null</p><p>其他参考原文： <a href="http://pravega.io/docs/latest/rest/restapis/" target="_blank" rel="noopener">http://pravega.io/docs/latest/rest/restapis/</a></p>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>pravega handbook - 开发pravega应用 - streamcuts</title>
      <link href="/2018/10/01/pravega-working-with-streamcuts/"/>
      <url>/2018/10/01/pravega-working-with-streamcuts/</url>
      
        <content type="html"><![CDATA[<p>本节介绍StreamCuts以及如何将它们与流客户端和批处理客户端一起使用。先决条件：您应该熟悉Pravega Concepts。</p><h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><p>Pravega流由一个或多个并行段形成，用于存储/读取事件。Pravega流是弹性的，这意味着并行段的数量可能随时间变化以适应波动的工作负载。也就是说，StreamCut表示流中的一致位置。它包含一组用于单个流的段和偏移对，它表示给定时间点的完整键空间。偏移量始终指向事件边界，因此没有指向不完整事件的偏移量。</p><p>表示流尾部的StreamCut（带有最新事件）是一个不断变化的流，因为事件可被连续地加入到流中，并且指向具有更新事件流的尾部的streamCuts将具有不同的值。类似地，StreamCut表示流的头部（具有最旧的事件）是不断变化的，因为流保留策略可以截断流并且StreamCut指向截断的流的头部将具有不同的值。 StreamCut.UNBOUNDED用于表示流中的这种位置，用户可以使用它来指定这个不断变化的流位置（流的头部和尾部）。</p><p>应当注意，StreamCut使用流客户端和批量客户端获得的流可以互换使用。</p><h2 id="StreamCut-with-reader"><a href="#StreamCut-with-reader" class="headerlink" title="StreamCut with reader"></a>StreamCut with reader</h2><p>ReaderGroup是一组命名的读者集合，它们并行地从给定的Stream中读取的事件。每个Reader始终与ReaderGroup相关联。StreamCut（s）可以使用以下api从ReaderGroup获得io.pravega.client.stream.ReaderGroup.getStreamCuts。此api返回一个 Map&lt;Stream, StreamCut&gt;表示ReaderGroup管理的所有流的reader的最后已知位置。</p><p>StreamCut可用于配置ReaderGroup以允许对Stream进行有界处理。StreamCutStream 的开始和/或结束可以作为ReaderGroup配置的一部分传递。以下示例显示了将StreamCuts用作</p><p>ReaderGroup配置的一部分的不同方法。</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>/*<br> * The below ReaderGroup configuration ensures that the readers belonging to<br> * the ReaderGroup read events from<br> *   - Stream &quot;s1&quot; from startStreamCut1 (representing the oldest event) upto<br>          endStreamCut1 (representing the newest event)<br> *   - Stream &quot;s2&quot; from startStreamCut2 upto the tail of the stream, this is similar to using StreamCut.UNBOUNDED<br> *        for endStreamCut.<br> *   - Stream &quot;s3&quot; from the current head of the stream upto endStreamCut2<br> *   - Stream &quot;s4&quot; from the current head of the stream upto the tail of the stream.<br> */<br>ReaderGroupConfig.builder()<br>                .stream(&quot;scope/s1&quot;, startStreamCut1, endStreamCut1)<br>                .stream(&quot;scope/s2&quot;, startStreamCut2)<br>                .stream(&quot;scope/s3&quot;, StreamCut.UNBOUNDED, endStreamCut2)<br>                .stream(&quot;scope/s4&quot;)<br>                .build();<br></code></pre></td></tr></table></figure><p>以下API可用于使用新的ReaderGroup配置重置现有ReaderGroup，而不是创建ReaderGroup。</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>/*<br> * ReaderGroup api used to reset a ReaderGroup to a newer ReaderGroup configuration.<br> */<br>io.pravega.client.stream.ReaderGroup.resetReaderGroup(ReaderGroupConfig config)<br></code></pre></td></tr></table></figure><h2 id="StreamCut-with-BatchClient"><a href="#StreamCut-with-BatchClient" class="headerlink" title="StreamCut with BatchClient"></a>StreamCut with BatchClient</h2><p>StreamCut 表示流的当前头部和当前尾部可以使用以下BatchClient API获得。</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>/*<br> * The API io.pravega.client.batch.BatchClient.getStreamInfo(Stream stream) fetches the StreamCut representing the<br> * current head and tail of the stream. StreamInfo.getHeadStreamCut() and StreamInfo.getTailStreamCut() can be<br> * used to fetch the StreamCuts.<br> */<br>CompletableFuture&lt;StreamInfo&gt; getStreamInfo(Stream stream);<br></code></pre></td></tr></table></figure><p>BatchClient可用于在给定开始和结束StreamCuts的情况下执行流的有界处理。BatchClient api io.pravega.client.batch.BatchClient.getSegments(stream, startStreamCut, endStreamCut)用于获取位于给定startStreamCut和endStreamCut之间的段。利用检索到的段信息，用户可以并行地消耗所有事件而不必遵守事件的时间排序。<br>必须注意的是，传递StreamCut.UNBOUNDED给startStreamCut和endStreamCut将分别导致使用流的当前头部和流的当前尾部。</p>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>pravega handbook - 开发pravega应用 - 事务</title>
      <link href="/2018/10/01/pravega-working-with-transactions/"/>
      <url>/2018/10/01/pravega-working-with-transactions/</url>
      
        <content type="html"><![CDATA[<h2 id="Pravega事务"><a href="#Pravega事务" class="headerlink" title="Pravega事务"></a>Pravega事务</h2><p>本文探讨了如何使用Pravega 事务以原子方式将一组事件写入Stream。<br>有关示例的说明，请参阅 Pravega Samples自述文件。</p><p>在阅读本页之前，您应该熟悉Pravega Concepts（请参阅  Pravega Concepts）。<br>Pravega事务和控制台writer和控制台reader APPs<br>我们编写了几个应用，ConsoleReader和ConsoleWriter，用于帮助说明使用Pravega读取和写入数据，特别是用于说明Pravega编程模型中的事务工具。你可以找到这些应用 在这里。</p><h2 id="ConsoleReader"><a href="#ConsoleReader" class="headerlink" title="ConsoleReader"></a>ConsoleReader</h2><p>ConsoleReader应用非常简单。它使用Pravega Java客户端库从Stream读取并将每个事件输出到控制台。它无限期运行，所以你必须终止进程才能终止程序。</p><h2 id="ConsoleWriter"><a href="#ConsoleWriter" class="headerlink" title="ConsoleWriter"></a>ConsoleWriter</h2><p>ConsoleWriter应用有点复杂。它使用Pravega Java客户端库将事件写入流，包括在Pravega事务的上下文中编写的事件。为了更轻松地操作事务，我们提供了一个基于控制台的CLI，CLI的帮助文本如下所示：</p><h3 id="ConsoleWriter帮助文本"><a href="#ConsoleWriter帮助文本" class="headerlink" title="ConsoleWriter帮助文本"></a>ConsoleWriter帮助文本</h3><p>在命令行提示符处输入以下命令之一：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>如果未输入任何命令，则将该行视为WRITE_EVENT命令的参数。<br><br>WRITE_EVENT &#123;event&#125;  - 将&#123;event&#125;写入Stream或当前的Transaction。<br>WRITE_EVENT_RK &lt;&lt; &#123;routingKey&#125; &gt;&gt;，&#123;event&#125;  - 使用&#123;routingKey&#125;将&#123;event&#125;写入Stream或当前Transaction。注意&#123;routingKey&#125;周围的&lt;&lt;和&gt;&gt;。<br>开始 - 开始交易。CLI支持一次只有一个事务。<br>GET_TXN_ID  - 输出当前交易的Id（如果交易正在运行）<br>FLUSH  - 刷新当前事务（如果事务正在运行）<br>COMMIT  - 提交事务（如果事务正在运行）<br>ABORT  - 中止事务（如果事务正在运行）<br>STATUS - 检查事务的状态（如果事务正在运行）<br>HELP - 打印出命令列表。<br>QUIT - 终止程序。<br>examples/someStream &gt;<br></code></pre></td></tr></table></figure><p>因此，编写单个事件很简单，只需键入一些文本（如果您不想，甚至不必键入WRITE_EVENT命令）。<br>但我们真的想谈谈Pravega事务，所以让我们深入研究一下。</p><h2 id="Pravega事务-1"><a href="#Pravega事务-1" class="headerlink" title="Pravega事务"></a>Pravega事务</h2><p>Pravega 事务的想法是允许应用程序准备一组可以“一次性”写入Stream的事件。这允许应用程序以原子方式“提交”一系列事件。这是通过将它们写入事务并调用commit以将它们追加到Stream来实现的。如果应用程序希望持久存储事件，并随后决定是否应将这些事件附加到Stream中，那么它可能期望这样操作。这允许应用程序控制何时对读者可见。</p><p>通过EventStreamWriter创建事务。回想一下，EventStreamWriter本身是通过ClientFactory创建的，并被构造为对Stream进行操作。因此，事务绑定到Stream。一旦创建了一个事务，它就像一个Writer。应用程序将事件写入事务，一旦确认，数据将被认为在事务中持久存在。请注意，在提交事务之前，写入事务的数据对读者来说是不可见的。除了使用路由键的writeEvent和writeEvent之外，还提供了几个特定于事务的操作：</p><table><thead><tr><th>操作</th><th>讨论</th></tr></thead><tbody><tr><td>getTxnId（）</td><td>检索事务的唯一标识符。Pravega为每个交易生成一个唯一的UUID。</td></tr><tr><td>flush()</td><td>确保所有写入都已持久化</td></tr><tr><td>ping()</td><td>延长交易的持续时间。请注意，在一定的空闲时间后，事务将自动中止。这是为了处理客户端崩溃的情况，并且不再适合持久化与事务关联的资源。</td></tr><tr><td>checkStatus()</td><td>返回交易状态。事务可以处于以下状态之一：打开，提交，提交，中止或中止。</td></tr><tr><td>commit()</td><td>将写入事务的所有事件附加到流中。要么所有的事件数据都要附加到Stream，要么都不会。</td></tr><tr><td>abort()</td><td>终止事务，将删除写入事务的数据。</td></tr></tbody></table><h2 id="使用ConsoleWriter来启动并提交事务"><a href="#使用ConsoleWriter来启动并提交事务" class="headerlink" title="使用ConsoleWriter来启动并提交事务"></a>使用ConsoleWriter来启动并提交事务</h2><p>所有事务API都反映在ConsoleWriter的CLI命令集中。<br>要开始事务，请键入BEGIN：</p><h3 id="开始事务"><a href="#开始事务" class="headerlink" title="开始事务"></a>开始事务</h3><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs undefined">examples/someStream &gt;begin<br>346d8561-3fd8-40b6-8c15-9343eeea2992 &gt;<br></code></pre></td></tr></table></figure><p>创建事务时，它返回一个事务对象，它将参数化的事务对象返回到Stream支持的Event类型。对于ConsoleWriter，Event的类型是Java String。</p><p>命令提示符将更改为显示事务的id。现在可以发出任何与事务相关的命令（GET_TXN_ID，FLUSH，PING，COMMIT，ABORT和STATUS）。请注意，BEGIN命令不起作用，因为ConsoleWriter一次只支持一个事务（这是应用的限制，而不是Pravega的限制）。当ConsoleWriter处于事务上下文时，WRITE_EVENT（请记住，如果不键入命令，ConsoleWriter假定您希望将文本写为事件），或者WRITE_EVENT_RK将被写入事务：</p><h3 id="将事件写入事务"><a href="#将事件写入事务" class="headerlink" title="将事件写入事务"></a>将事件写入事务</h3><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>346d8561-3fd8-40b6-8c15-9343eeea2992 &gt;m1<br>**** Wrote &apos;m1&apos;<br>346d8561-3fd8-40b6-8c15-9343eeea2992 &gt;m2<br>**** Wrote &apos;m2&apos;<br>346d8561-3fd8-40b6-8c15-9343eeea2992 &gt;m3<br>**** Wrote &apos;m3&apos;<br></code></pre></td></tr></table></figure><p>此时，如果您查看Stream（例如，通过调用Stream上的ConsoleReader应用程序），您将看不到写入Stream的那些事件。</p><h3 id="事件未写入流（尚未）"><a href="#事件未写入流（尚未）" class="headerlink" title="事件未写入流（尚未）"></a>事件未写入流（尚未）</h3><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>$ bin/consoleReader<br>...<br>******** Reading events from examples/someStream<br></code></pre></td></tr></table></figure><p>但是当给出COMMIT命令时，导致事务提交：</p><h3 id="提交"><a href="#提交" class="headerlink" title="提交"></a>提交</h3><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>346d8561-3fd8-40b6-8c15-9343eeea2992 &gt;commit<br>**** Transaction commit completed.<br></code></pre></td></tr></table></figure><p> 这些事件被附加到Stream，现在全部可用：<br>提交后，事件是可见的</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>******** Reading events from examples/someStream<br>&apos;m1&apos;<br>&apos;m2&apos;<br>&apos;m3&apos;<br></code></pre></td></tr></table></figure><h2 id="更多关于BeginTransaction"><a href="#更多关于BeginTransaction" class="headerlink" title="更多关于BeginTransaction"></a>更多关于BeginTransaction</h2><p>Begin 事务（beginTxn（））操作需要三个参数（ConsoleWriter选择一些合理的默认值，因此在CLI中这些是可选的）： </p><table><thead><tr><th>参数</th><th>讨论</th></tr></thead><tbody><tr><td>transactionTimeout</td><td>允许事务在Pravega自动中止之前运行的时间。这也称为“租约”。</td></tr><tr><td>maxExecutionTime</td><td>ping操作之间允许的时间量</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>pravega handbook - 开发pravega应用 - stateSynchronizer</title>
      <link href="/2018/10/01/pravega-working-with-state-synchronizer/"/>
      <url>/2018/10/01/pravega-working-with-state-synchronizer/</url>
      
        <content type="html"><![CDATA[<p>Pravega即可以作为流式存储系统，也可以作为 pub-sub消息系统，还可以将Pravega作为一种在分布式集群中共享多个进程状态的方法。<br>运行示例应用，请参阅 Pravega Samples文件。<br>在看本文之前，需要熟悉Pravega Concepts（请参考  Pravega Concepts）。特别是，对State Synchronizer 概念有所了解。</p><h2 id="共享的状态和Pravega"><a href="#共享的状态和Pravega" class="headerlink" title="共享的状态和Pravega"></a>共享的状态和Pravega</h2><p>State Synchronizer是Pravega编程模型提供的一种工具，它使得开发人员可以轻松地使用Pravega来协调进程之间的共享状态。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/state.synchronizer.png" alt=""></p><p>其思想是使用Stream来保持共享状态的变化序列，并且各种应用使用其Pravega Java客户端库以一致的方式同时读取和写入共享状态。 </p><h2 id="SharedStateMap和共享配置示例"><a href="#SharedStateMap和共享配置示例" class="headerlink" title="SharedStateMap和共享配置示例"></a>SharedStateMap和共享配置示例</h2><p>在深入了解如何使用状态同步器之前，我们先快速看一下一个使用状态同步器的简单示例 。<br>该示例使用State Synchronizer构建Java 映射数据结构的实现，称为SharedMap。我们使用该SharedMap数据结构来构建一个共享配置，该配置允许一组进程一致地读/写键/值对属性的共享配置对象。此外，作为该示例的一部分，我们提供了一个简单的基于命令行的应用程序，允许您使用SharedConfig。  </p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/state.sync.example.png" alt=""></p><p>以下是SharedConfigCLI中可用的命令菜单：<br><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs undefined">在命令行提示符处输入以下命令之一：<br><br>GET_ALL  - 打印出共享配置中的所有属性。<br>GET &#123;key&#125;  - 打印出给定键的配置属性。<br>PUT &#123;key&#125;，&#123;value&#125;  - 使用给定的键/值对更新共享配置。打印出以前的值（如果存在）。<br>PUT_IF_ABSENT &#123;key&#125;，&#123;value&#125;  - 仅在尚未定义属性的情况下，使用给定的键/值对更新共享配置。<br>REMOVE &#123;key&#125; [，&#123;currentValue&#125;]  - 从共享配置中删除给定的属性。如果给出&#123;currentValue&#125;，则仅在属性的当前值与&#123;currentValue&#125;匹配时删除。<br>REPLACE &#123;key&#125;，&#123;newValue&#125; [，&#123;currentValue&#125;]  - 更新属性的值。如果给出&#123;currentValue&#125;，则仅在属性的当前值与&#123;cuurentValue&#125;匹配时才更新。<br>CLEAR - 从共享配置中删除所有密钥。<br>REFRESH  - 强制从同步状态更新。<br>HELP - 打印出命令列表。<br>QUIT - 终止程序。<br></code></pre></td></tr></table></figure></p><p>安装Pravega-Samples并使用相同的范围和流名称启动SharedConfigCLI的两个实例。这将模拟两个不同的进程如何将SharedConfig的本地副本与一个共享状态对象进行协调。您可以按照以下步骤来了解SharedConfig的如何协调：</p><table><thead><tr><th>#</th><th>过程1</th><th>过程2</th><th>讨论</th></tr></thead><tbody><tr><td>1</td><td>GET_ALL</td><td>GET_ALL</td><td>显示两个进程都看到一个空的SharedConfig</td></tr><tr><td>2</td><td>PUT  p1, v1</td><td></td><td>进程1添加名为p1的属性</td></tr><tr><td>3</td><td>GET p1</td><td>GET p1</td><td>过程1看到属性的值v1, 进程2没有名为p1的属性。为什么？因为它没有, 使用共享状态刷新其状态</td></tr><tr><td>4</td><td></td><td>REFRESH</td><td>将进程2的状态与共享状态重新同步</td></tr><tr><td>5</td><td></td><td>GET p1</td><td>现在，流程2看到了步骤2中所做的更改流程1</td></tr><tr><td>6</td><td></td><td>REPLACE p1, newVal, v1</td><td>进程2尝试更改p1的值，但使用条件替换，这意味着仅当p1的旧值为v1（此时为此）时才应进行更改</td></tr><tr><td>7</td><td></td><td>GET p1</td><td>果然，p1的值改为newVal</td></tr><tr><td>8</td><td>REPLACE p1, anotherVal, v1</td><td></td><td>进程1尝试以与进程2在步骤6中所做的相同的方式更改p1的值。这将失败，因为共享状态中p1的值不再是v1</td></tr><tr><td>9</td><td>GET p1</td><td></td><td>步骤8中的失败替换操作导致进程1的共享状态, 副本被更新，由于步骤6，其值现在是newVal。</td></tr></tbody></table><p>您可以使用类似的序列，以探索PUT_IF_ABSENT的语义以及修改共享状态的其他操作。<br>这个想法是，只有在对最新的值进行操作时，对SharedConfig的修改才会成功。我们使用乐观并发来实现SharedConfig对象的多个消费者之间实现有效的一致性。<br>您可以同时运行多个不同的SharedConfig状态对象，每个单独的SharedConfig使用基于不同Pravega Stream的State Synchronizer对象。当然，如果使用由同一Stream支持的State Synchronizer对象启动两个应用，则两个进程会同时访问共享状态，这正是我们上面说明的情况。</p><h2 id="使用State-Synchronizer构建SharedMap"><a href="#使用State-Synchronizer构建SharedMap" class="headerlink" title="使用State Synchronizer构建SharedMap"></a>使用State Synchronizer构建SharedMap</h2><p>我们使用State Synchronizer在Pravega-Samples中构建SharedMap对象。State Synchronizer可用于构建几乎任何数据结构的共享版本。也许你的应用只需要共享一些简单的整数计数; 我们可以使用State Synchronizer来构建一个简单的共享计数器。也许您共享的数据是集群中当前运行的服务器集; 我们可以使用State Synchronizer来构建共享Set。可能性是多方面的。<br>让我们通过使用如何构建共享映射来探讨如何使用State Synchronizer构建共享对象。</p><h2 id="State-Synchronizer"><a href="#State-Synchronizer" class="headerlink" title="State Synchronizer"></a>State Synchronizer</h2><p>State Synchronizer是一种Pravega客户端，类似于EventStreamReader或EventStreamWriter。状态同步器是通过ClientFactory对象创建的。每个状态同步器在范围内都有唯一的名称。SynchronizerConfig对象用于定制StateSynchronizer的行为（尽管目前State Synchronizer上没有可配置的属性）。State Synchronizer使用Java泛型类型来允许开发人员指定类型特定的State Synchronizer。所有这些都以类似于使用EventStreamReaders和EventStreamWriters的方式进行。</p><h2 id="StateT"><a href="#StateT" class="headerlink" title="StateT"></a>StateT</h2><p>在设计使用State Synchronizer的应用时，开发人员需要决定要同步（共享）哪种类型的状态。我们共享一个map吗？一个 set ? 一个Pojo？正在共享的数据结构是什么？这定义了状态同步器的核心“类型”（状态同步器接口中的StateT泛型类型）。StateT对象可以是实现Pravega定义的Revisioned接口的任何Java对象。  Revisioned是一个简单的接口，允许Pravega确保它能够正确地比较两个不同的StateT对象。<br>在我们的示例中，SharedMap是State Synchronizer的一个应用。它定义了一个简单的Map对象，该对象表示您期望从键值对映射对象获得的典型get（key），set（key，value）等操作。它根据需要使用状态同步器的实现了  Revisioned接口，并使用简单的ConcurrentHashMap作为Map的内部实现。因此，在我们的示例中，StateT对应于SharedStateMap \&lt;K，V&gt;。</p><h2 id="UpdateT和InitialUpdateT"><a href="#UpdateT和InitialUpdateT" class="headerlink" title="UpdateT和InitialUpdateT"></a>UpdateT和InitialUpdateT</h2><p>除了StateT之外，还有另外两种需要由StateSynchronizer定义的泛型类型：Update类型和InitialUpdate类型。UpdateType表示Pravega Stream上持久存储的“delta”或更改对象。InitialUpdateType是一个特殊的更新对象，用于启动状态同步器。UpdateType和InitialUpdateType都是根据StateT定义的。<br>StateSynchronizer使用Stream上的单个Segment来将更新（更改）存储到共享状态对象的，以Initial或Update类型对象的形式进行的更改将根据更新是否与Stream中状态的最新副本相关而写入Stream。如果更新是基于旧版本的状态，则不进行更新。<br>StateSynchronizer对象本身在本地内存中保存状态的本地副本，它还保留有关该状态副本的版本元数据。可以使用getState（）操作检索本地状态。内存中的本地副本可能是过时的，应用可以使用fetchUpdates（）操作来刷新它，该操作将检索对给定版本的状态所做的所有更改。<br>应用的大多数更改都是通过updateState（）操作进行的。updateState（）操作将Function作为参数。使用最新的状态对象调用Function，并计算要应用的更新。<br>在我们的示例中，InitialUpdateT实现为：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>/**<br> * Create a Map. This is used by StateSynchronizer to initialize shared state.<br> */<br>private static class CreateState&lt;K, V&gt; implements InitialUpdate&lt;SharedStateMap&lt;K,V&gt;&gt;, Serializable &#123;<br>    private static final long serialVersionUID = 1L;<br>    private final ConcurrentHashMap&lt;K, V&gt; impl;<br><br>    public CreateState(ConcurrentHashMap&lt;K, V&gt; impl) &#123;<br>        this.impl = impl;<br>    &#125;<br><br>    @Override<br>    public SharedStateMap&lt;K, V&gt; create(String scopedStreamName, Revision revision) &#123;<br>        return new SharedStateMap&lt;K, V&gt;(scopedStreamName, impl, revision);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>在这种情况下，CreateState类用于通过创建一个新的、空的SharedStateMap对象来初始化Stream中的共享状态。您可以想象InitialUpdate的其他示例将计数器设置为1，或者将Set初始化为固定的初始成员集。<br>像“initialize”和“update”这样的函数表示为类似乎有点奇怪，但是当你考虑到它时，这是有意义的。这些更改（如初始化和更新）需要存储在Pravega中，因此它们需要的是可序列化的对象。客户端应用必须能够随时启动，计算当前状态，然后在将更改写入Stream时保持运行状态。如果我们只是在Stream中存储“最新状态值”，就不可能始终如一地提供使用乐观并发的并发更新和读取。<br>UpdateT有点棘手。不仅有一种对Map的更新，而是有各种更新：放置一个键/值对，放置一组键/值对，删除键/值对并清除所有键/值对，这些“更新类型”中的每一个都由它们自己的类表示。我们定义了一个名为StateUpdate的抽象类，所有这些“操作”更新类都从该类继承。  </p><h3 id="StateUpdate抽象类"><a href="#StateUpdate抽象类" class="headerlink" title="StateUpdate抽象类"></a>StateUpdate抽象类</h3><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>/**<br> * A base class for all updates to the shared state. This allows for several different types of updates.<br> */<br>private static abstract class StateUpdate&lt;K,V&gt; implements Update&lt;SharedStateMap&lt;K,V&gt;&gt;, Serializable &#123;<br>    private static final long serialVersionUID = 1L;<br><br>    @Override<br>    public SharedStateMap&lt;K,V&gt; applyTo(SharedStateMap&lt;K,V&gt; oldState, Revision newRevision) &#123;<br>        ConcurrentHashMap&lt;K, V&gt; newState = new ConcurrentHashMap&lt;K, V&gt;(oldState.impl);<br>        process(newState);<br>        return new SharedStateMap&lt;K,V&gt;(oldState.getScopedStreamName(), newState, newRevision);<br>    &#125;<br><br>    public abstract void process(ConcurrentHashMap&lt;K, V&gt; updatableList);<br>&#125;<br></code></pre></td></tr></table></figure><p>通过定义抽象类，我们可以用抽象StateUpdate类来定义UpdateT。抽象类实现StateSynchronizer调用的“applyTo”方法，以便将更新应用于当前状态对象并返回更新后的状态对象。实际的工作是在对旧状态的底层Map（impl）对象的副本上进行的，对impl对象和新版本的SharedState应用“特定于每个子类”的“进程”操作，使用后处理的impl作为内部状态。抽象类定义了一个process（）方法，该方法实际上需要应用任何更新的工作。此方法由表示共享映射上的Put，PutAll等操作的各种具体类实现。<br>例如，我们在SharedMap对象上实现Put（key，value）操作的方式：</p><h3 id="作为更新对象"><a href="#作为更新对象" class="headerlink" title="作为更新对象"></a>作为更新对象</h3><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>/**<br> * Add a key/value pair to the State.<br> */<br>private static class Put&lt;K,V&gt; extends StateUpdate&lt;K,V&gt; &#123;<br>    private static final long serialVersionUID = 1L;<br>    private final K key;<br>    private final V value;<br><br>    public Put(K key, V value) &#123;<br>        this.key = key;<br>        this.value = value;<br>    &#125;<br><br>    @Override<br>    public void process(ConcurrentHashMap&lt;K, V&gt; impl) &#123;<br>        impl.put(key, value);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>这里，process（）操作是向map添加键/值对，或者如果key已经存在，则更改该值。SharedMap上的每个“操作”都是根据创建StateUpdate的各个子类的实例来实现的。</p><h2 id="在SharedMap上执行操作"><a href="#在SharedMap上执行操作" class="headerlink" title="在SharedMap上执行操作"></a>在SharedMap上执行操作</h2><p>SharedMap演示了StateSynchronizer的典型操作。SharedMap提供了一个API，非常类似于Java的Map \ &lt;K，V&gt;接口。它通过操作StateSynchronizer来实现了Map操作，使用StateUpdate的各种子类来执行状态更改（写入）操作。</p><h3 id="创建-初始化"><a href="#创建-初始化" class="headerlink" title="创建/初始化"></a>创建/初始化</h3><h3 id="创建SharedMap"><a href="#创建SharedMap" class="headerlink" title="创建SharedMap"></a>创建SharedMap</h3><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>/**<br>  * Creates the shared state using a synchronizer based on the given stream name.<br>  *<br>  * @param clientFactory - the Pravega ClientFactory to use to create the StateSynchronizer.<br>  * @param streamManager - the Pravega StreamManager to use to create the Scope and the Stream used by the StateSynchronizer<br>  * @param scope - the Scope to use to create the Stream used by the StateSynchronizer.<br>  * @param name - the name of the Stream to be used by the StateSynchronizer.<br>  */<br> public SharedMap(ClientFactory clientFactory, StreamManager streamManager, String scope, String name)&#123;<br>     streamManager.createScope(scope);<br><br>     StreamConfiguration streamConfig = StreamConfiguration.builder().scope(scope).streamName(name)<br>             .scalingPolicy(ScalingPolicy.fixed(1))<br>             .build();<br><br>     streamManager.createStream(scope, name, streamConfig);<br><br>     this.stateSynchronizer = clientFactory.createStateSynchronizer(name,<br>                                             new JavaSerializer&lt;StateUpdate&lt;K,V&gt;&gt;(),<br>                                             new JavaSerializer&lt;CreateState&lt;K,V&gt;&gt;(),<br>                                             SynchronizerConfig.builder().build());<br><br>     stateSynchronizer.initialize(new CreateState&lt;K,V&gt;(new ConcurrentHashMap&lt;K,V&gt;()));<br> &#125;<br></code></pre></td></tr></table></figure><p>SharedMap对象是通过定义范围和流来创建的（几乎总是如此，范围和流可能已经存在，因此第10-16行中的步骤通常是无操作的）。StateSynchronizer对象本身使用ClientFactory以类似于创建Pravega Reader或Writer的方式在第18-21行中构造。请注意，UpdateT对象和InitialUpdateT对象可以指定单独的Java序列化程序。目前，SynchronizerConfig对象非常枯燥; StateSynchronizer上当前没有可用的配置选项。<br>StateSynchronizer提供了一个带InitialUpdate对象的初始化（）API。这在SharedMap构造函数中被调用，以确保SharedState被正确初始化。请注意，在许多情况下，SharedMap对象将在已经包含SharedMap的共享状态的流上创建。即使在这种情况下，也可以调用initialize（），因为initialize（）不会修改Stream中的共享状态。</p><h2 id="读操作"><a href="#读操作" class="headerlink" title="读操作"></a>读操作</h2><p>读操作，即不改变共享状态的操作，如get（key）containsValue（value）等，针对StateSynchronizer的本地副本工作。所有这些操作都使用getState（）检索当前本地状态，然后从该状态执行读取操作。StateSynchronizer的本地状态可能是过时的。在这些情况下，SharedMap客户端将使用refresh（）来强制StateSynchronizer使用StateSynchronizer对象上的fetchUpdates（）操作从共享状态刷新其状态。<br>请注意，这是一个设计决策，用于平衡响应性的单调性。我们可以很容易地实现读取操作，而不是在对本地状态执行读取之前总是执行刷新。如果开发人员预计将对共享状态进行频繁更新，这将是一种非常有效的策略。在我们的例子中，我们曾想象过，SharedMap会被频繁地读取，但更新相对较少，因此选择针对本地状态进行读取。</p><h2 id="写（更新）操作"><a href="#写（更新）操作" class="headerlink" title="写（更新）操作"></a>写（更新）操作</h2><p>每一个写操作都是根据我们前面讨论过的各种具体StateUpdate对象实现的。clear（）操作使用StateUpdate的Clear子类删除所有键/值对，put（）使用Put类等。<br>让我们深入了解put（）操作的实现，以更详细地讨论StateSynchronizer编程：</p><h3 id="实现put（键，值）"><a href="#实现put（键，值）" class="headerlink" title="实现put（键，值）"></a>实现put（键，值）</h3><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>/**<br> * Associates the specified value with the specified key in this map.<br> *<br> * @param key - the key at which the value should be found.<br> * @param value - the value to be entered into the map.<br> * @return - the previous value (if it existed) for the given key or null if the key did not exist before this operation.<br> */<br>public V put(K key, V value)&#123;<br>    final AtomicReference&lt;V&gt; oldValue = new AtomicReference&lt;V&gt;(null);<br>     stateSynchronizer.updateState((state, updates) -&gt; &#123;<br>        oldValue.set(state.get(key));<br>        updates.add(new Put&lt;K,V&gt;(key,value));<br>    &#125;);<br>    return oldValue.get();<br>&#125;<br></code></pre></td></tr></table></figure><p>需要注意的是，提供给StateSynchronizer的updateState（）的函数可能会被多次调用。将函数应用于旧状态的结果仅在对最新的状态修订应用时才会写入。如果存在竞争并且乐观并发检查失败，则将再次调用它。大多数时候只会有少量的调用。在某些情况下，开发人员可以选择使用fetchUpdates（）在运行updateState（）之前将StateSynchronizer与流中的最新共享状态副本同步。这是优化预期更新的频率与您希望更新效率之间的权衡的问题。如果您期望进行大量更新，请在调用updateState（）之前调用fetchUpdates（）。在我们的例子中，我们没有期望进行很多更新，因此每次调用put()时，都可能处理函数的几个调用。</p><h2 id="删除操作"><a href="#删除操作" class="headerlink" title="删除操作"></a>删除操作</h2><p>我们选择实现删除（删除）操作以利用StateSynchronizer的compact（）功能。我们有一个策略，在每5个删除操作之后，并且在每次clear（）操作之后，我们都会进行compact()操作。现在，我们可以选择在每5次更新操作后执行compact（）操作，但是我们希望隔离使用compact（）仅删除操作的说明。<br>您可以将compact（）视为StateSynchronizer中的“垃圾收集”形式。在将一定数量的更改写入SharedState之后，将新的初始状态（所有更改的累积表示）写入Stream可能是有效的。这样，可以忽略比compact()操作更旧的数据，并最终从Stream中删除。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/ss.compact.png" alt=""></p><p>作为compact（）操作的结果，新的初始状态（Initial2）被写入流。现在，来自Change3及更旧版本的所有数据不再相关，可以从Stream中回收垃圾。</p>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>pravega handbook - 开发pravega应用 - Basic reader and writer</title>
      <link href="/2018/10/01/pravega-working-with-reader-and-writer/"/>
      <url>/2018/10/01/pravega-working-with-reader-and-writer/</url>
      
        <content type="html"><![CDATA[<p>本文讲述如何构建简单的Pravega应用程序。最简单的Pravega应用程序使用Pravega Reader读取Pravega Stream或写入Pravega Stream的Pravega Writer。两个简单的例子都可以在Pravega Samples <code>“hello world”</code> 中找到。这些示例提供了一个非常基本的例子，说明Java应用程序如何使用Pravega Java Client Library来访问Pravega功能。</p><p>有关运行示例的说明，请参阅Pravega Samples自述文件。在阅读本页之前，您应该熟悉Pravega Concepts（请参阅Pravega Concepts）。</p><h2 id="HelloWorldWriter"><a href="#HelloWorldWriter" class="headerlink" title="HelloWorldWriter"></a>HelloWorldWriter</h2><p>HelloWorldWriter应用是使用EventStreamWriter将事件写入Pravega的简单演示。<br>首先看一下HelloWorldWriter示例应用，代码的关键部分在run（）方法中：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>public void run(String routingKey, String message) &#123;<br>    StreamManager streamManager = StreamManager.create(controllerURI);<br><br>    final boolean scopeCreation = streamManager.createScope(scope);<br>    StreamConfiguration streamConfig = StreamConfiguration.builder()<br>            .scalingPolicy(ScalingPolicy.fixed(1))<br>            .build();<br>    final boolean streamCreation = streamManager.createStream(scope, streamName, streamConfig);<br><br>    try (ClientFactory clientFactory = ClientFactory.withScope(scope, controllerURI);<br>         EventStreamWriter&lt;String&gt; writer = clientFactory.createEventWriter(streamName,<br>                                                          new JavaSerializer&lt;String&gt;(),<br>                                                   EventWriterConfig.builder().build())) &#123;<br><br>         System.out.format(&quot;Writing message: &apos;%s&apos; with routing-key: &apos;%s&apos; to stream &apos;%s / %s&apos;%n&quot;,<br>                message, routingKey, scope, streamName);<br>         final CompletableFuture&lt;Void&gt; writeFuture = writer.writeEvent(routingKey, message);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>run（）方法的目的是创建一个Stream（第2-9行）并将给定的Event输出到该Stream（第10-18行）。</p><h2 id="创建流和StreamManager接口"><a href="#创建流和StreamManager接口" class="headerlink" title="创建流和StreamManager接口"></a>创建流和StreamManager接口</h2><p>Stream是在Scope的上下文中创建的; Scope充当命名空间机制，以便可以为不同的目的对不同的Streams集进行分类。例如，对于每个应用程序都有可能有一个单独的作用域。可以选择创建一组Scopes，一个scope对应于一个组织中的一个部门。在多租户环境中，每个租户可能有一个单独的Scope。作为开发人员，我可以选择我需要的任何分类方案，并使用Scope概念在该分类方案中组织我的Streams。</p><p>通过StreamManager接口创建和操作Scopes和Streams到Pravega控制器。您需要为集群中的任何Pravega Controller实例提供URI才能创建StreamManager对象。这在第2行中显示。</p><p>在HelloWorld示例应用的设置中，在启动示例应用时，controllerURI被配置为命令行参数。对于Pravega的“单节点”部署，Controller正在侦听localhost，端口9090。</p><p>StreamManager提供对Pravega中与Scopes和Streams相关的各种控制平面功能的访问：</p><table><thead><tr><th>方法</th><th>参数</th><th>讨论</th></tr></thead><tbody><tr><td>(static) create</td><td>(URI controller)</td><td>给定Pravega集群中某个Pravega Controller实例的URI，创建一个Stream Manager对象。</td></tr><tr><td>createScope</td><td>（String scopeName）</td><td>创建具有给定名称的Scope。如果创建了Scope，则返回true;如果Scope已存在，则返回false。即使Scope已经存在，您也可以调用此方法，它不会对任何内容造成任何伤害。</td></tr><tr><td>deleteScope</td><td>（String scopeName）</td><td>删除具有给定名称的范围。如果删除范围，则返回true，否则返回false。请注意，如果Scope包含Streams，则deleteScope操作将失败并出现异常。如果删除不存在的Scope，则该方法将成功并返回false。</td></tr><tr><td>createStream</td><td>（String scopeName，String streamName，StreamConfiguration config）</td><td>在给定范围内创建流。请注意，范围名称和流名称都受以下模式限制：[a-zA-Z0-9] +（即仅字母和数字，没有标点符号）,另请注意：Scope必须存在，如果在不存在的作用域中创建Stream，则抛出异常。StreamConfiguration使用构建器模式构建.如果创建了Stream，则返回true;如果Stream已存在，则返回false。即使Stream已经存在，您也可以调用此方法，它不会损害任何内容。</td></tr><tr><td>updateStream</td><td>（String scopeName，String streamName，StreamConfiguration config）</td><td>交换Stream的配置。请注意，Stream必须已存在，如果更新不存在的流，则会引发异常。如果Stream已更改，则返回true</td></tr><tr><td>sealStream</td><td>（String scopeName，String streamName）</td><td>防止对Stream进行任何进一步写入,注意Stream必须已经存在，如果密封不存在的流，则抛出异常。如果Stream成功密封，则返回true</td></tr><tr><td>deleteStream</td><td>（String scopeName，String streamName）</td><td>从Pravega中删除Stream并恢复该Stream使用的所有资源,请注意，Stream必须已存在，如果删除不存在的流，则会引发异常。如果删除了流，则返回true。</td></tr></tbody></table><p>在代码中的第3行完成之后，我们已经建立Scope，然后我们可以继续在第5-8行创建Stream。 </p><p>StreamManager需要3个输入来创建Stream，Scope的名称，Stream的名称和StreamConfiguration。最有趣的任务是创建StreamConfiguration。</p><p>与Pravega中的许多对象一样，Stream使用配置对象，允许开发人员控制Stream的各种行为。Pravega中的所有配置对象都使用builder模式进行构造。实际上有两个与流相关的重要配置项：保留策略和扩展策略。 </p><p>保留策略允许开发人员控制数据在删除之前保存在Stream中的时间。他/她可以指定数据应保留一段时间（对于强制执行某些保留期的法规遵从性这样的情况是理想的）或保留数据直到消耗了一定数量的字节。目前，保留政策尚未完全实施。默认情况下，RetentionPolicy设置为“无限制”，意味着数据不会从Stream中删除。</p><p>缩放策略允许开发人员配置Stream以利用Pravega自动缩放功能的方式。在第6行中，我们使用固定策略，这意味着Stream配置了给定数量的流段，并且不会改变。其他选项是按每秒给定数量的事件或每秒给定的千字节数进行缩放。在这两个策略中，开发人员指定目标速率，缩放因子和最小段数。目标速率是直接的，如果摄取率在一段时间内超过一定数量的事件或几千字节的数据，Pravega将尝试向流添加新的流段。如果速率在一段持续的时间内降至该阈值以下，Pravega将尝试合并相邻的流段。缩放因子是缩放策略上的一个设置，用于确定在超过目标速率（事件或千字节）时应添加的流段数。最小段数是设置要保持的最小读取并行度的因素; 例如，如果此值设置为3，则流上始终会有3个Stream Segments可用。目前，此属性仅在创建流时有效; 在未来的某个时刻，更新流将允许使用此因子来更改现有流上的最小读取并行度。例如，如果此值设置为3，则流上始终会有3个Stream Segments可用。目前，此属性仅在创建流时有效; 在未来的某个时刻，更新流将允许使用此因子来更改现有流上的最小读取并行度。</p><p>一旦创建StreamConfiguration对象后，创建Stream是直接的（第8行）。在创建Stream之后，我们都准备开始向Stream写入Event。</p><h2 id="使用EventWriter编写事件"><a href="#使用EventWriter编写事件" class="headerlink" title="使用EventWriter编写事件"></a>使用EventWriter编写事件</h2><p>应用程序使用EventStreamWriter对象将事件写入Stream。创建EventStreamWriter的关键对象是ClientFactory。ClientFactory用于创建Readers，Writers和其他类型的Pravega Client对象，例如State Synchronizer（请参阅  使用Pravega：状态同步器）。</p><p>第10行显示了ClientFactory的创建。ClientFactory是在Scope的上下文中创建的，因为ClientFactory创建的所有Readers，Writers和其他客户端都是在该Scope的上下文中创建的。ClientFactory还需要一个Pravega控制器的URI，就像StreamManager一样。</p><p>因为ClientFactory及其创建的对象消耗Pravega的资源，所以在try-with-resources语句中创建这些对象。由于ClientFactory及其创建的对象都实现了Autocloseable，因此try-with-resources方法可确保无论应用程序如何结束，Pravega资源都将以正确的顺序正确关闭。<br>现在我们有了ClientFactory，我们可以用它来创建一个Writer。在创建Writer之前，开发人员需要了解一些事项：</p><ol><li>要写入的Stream的名称是什么？注意：在创建ClientFactory时已经确定了Scope</li><li>什么类型的Event对象将被写入Stream？</li><li>什么序列化器将用于将Event对象转换为字节？回想一下，Pravega只知道字节序列，它对Java对象一无所知。</li><li>Writer是否需要配置任何特殊行为？</li></ol><p>在我们的例子中，第11-13行显示了所有这些决定。此Writer写入在HelloWorldWriter对象本身的配置中指定的Stream（默认情况下，流在“示例”Scope中命名为“helloStream”）。Writer将Java String对象作为Events处理，并使用内置的Java序列化程序进行Strings。<br>EventWriterConfig允许开发人员指定诸如在放弃之前尝试重试请求的次数以及相关的指数返回设置。在连接失败或Pravega组件中断可能暂时阻止请求成功的情况下，Pravega会小心重试请求，因此应用程序逻辑不需要处理间歇性群集故障。在我们的例子中，我们在第13行中采用了EventWriterConfig的默认设置。</p><p>现在我们可以将事件写入Stream，如第17行所示.EventStreamWriter提供了一个writeEvent（）操作，它使用给定的路由键将给定的非null Event对象写入Stream，以确定它应该出现在哪个Stream Segment上。Pravega中的许多操作，例如writeEvent（），都是异步的，并返回某种Future对象。如果应用程序需要确保将事件持久地写入Pravega并可供读者使用，那么它可以在继续之前等待Future。在我们简单的“hello world”的例子中，我们不必等待。</p><p>EventStreamWriter也可用于开始事务。我们在其他地方更详细地介绍事务事务（使用Pravega：事务）。<br>这就是写事件的原因。现在让我们来看看如何使用Pravega读取事件。</p><h2 id="HelloWorldReader"><a href="#HelloWorldReader" class="headerlink" title="HelloWorldReader"></a>HelloWorldReader</h2><p>HelloWorldReader是使用EventStreamReader的简单演示。应用只是从给定的Stream读取事件，并将这些事件的字符串表示形式打印到控制台上。<br>就像HelloWorldWriter示例一样，HelloWorldReader应用的关键部分是在run（）方法中：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>public void run() &#123;<br>   StreamManager streamManager = StreamManager.create(controllerURI);<br><br>   final boolean scopeIsNew = streamManager.createScope(scope);<br>   StreamConfiguration streamConfig = StreamConfiguration.builder()<br>           .scalingPolicy(ScalingPolicy.fixed(1))<br>           .build();<br>   final boolean streamIsNew = streamManager.createStream(scope, streamName, streamConfig);<br><br>   final String readerGroup = UUID.randomUUID().toString().replace(&quot;-&quot;, &quot;&quot;);<br>   final ReaderGroupConfig readerGroupConfig = ReaderGroupConfig.builder()<br>                                                                .stream(Stream.of(scope, streamName))<br>                                                                .build();<br>   try (ReaderGroupManager readerGroupManager = ReaderGroupManager.withScope(scope, controllerURI)) &#123;<br>       readerGroupManager.createReaderGroup(readerGroup, readerGroupConfig);<br>   &#125;<br><br>   try (ClientFactory clientFactory = ClientFactory.withScope(scope, controllerURI);<br>        EventStreamReader&lt;String&gt; reader = clientFactory.createReader(&quot;reader&quot;,<br>                                                                      readerGroup,<br>                                                     new JavaSerializer&lt;String&gt;(),<br>                                                  ReaderConfig.builder().build())) &#123;<br>        System.out.format(&quot;Reading all the events from %s/%s%n&quot;, scope, streamName);<br>        EventRead&lt;String&gt; event = null;<br>        do &#123;<br>           try &#123;<br>               event = reader.readNextEvent(READER_TIMEOUT_MS);<br>               if (event.getEvent() != null) &#123;<br>                   System.out.format(&quot;Read event &apos;%s&apos;%n&quot;, event.getEvent());<br>               &#125;<br>           &#125; catch (ReinitializationRequiredException e) &#123;<br>               //There are certain circumstances where the reader needs to be reinitialized<br>               e.printStackTrace();<br>           &#125;<br>       &#125; while (event.getEvent() != null);<br>       System.out.format(&quot;No more events from %s/%s%n&quot;, scope, streamName);<br>   &#125;<br></code></pre></td></tr></table></figure><p>第2-8行设置了Scope和Stream，就像在HelloWorldWriter应用中一样。第10-15行设置ReaderGroup作为创建EventStreamReader并使用它从Stream读取事件的先决条件（第17-36行）。</p><h2 id="ReaderGroup基础"><a href="#ReaderGroup基础" class="headerlink" title="ReaderGroup基础"></a>ReaderGroup基础</h2><p>Pravega中的任何读者都属于某些ReaderGroup。ReaderGroup是一个或多个读取器的分组，它们并行使用Stream。在创建Reader之前，我们需要创建一个ReaderGroup（或者知道现有ReaderGroup的名称）。此应用仅使用ReaderGroup的基础知识。</p><p>第10-15行显示了基本的ReaderGroup创建。ReaderGroup对象是从ReaderGroupManager对象创建的。反过来，ReaderGroupManager对象是在给定的Scope上创建的，其中包含一个Pravega控制器的URI，就像创建ClientFactory一样。在第14行创建了ReaderGroupManager对象。请注意，创建也在try-with-resources语句中，以确保正确清理ReaderGroupManager。ReaderGroupManager允许开发人员按名称创建，删除和检索ReaderGroup对象。</p><p>要创建ReaderGroup，开发人员需要ReaderGroup的名称，该组件包含一组或多个要读取的Streams。  </p><p>ReaderGroup的名称可能对应用程序有意义，例如“WebClickStreamReaders”。在我们的例子中，在第10行，我们有一个简单的UUID作为名称（注意修改UUID字符串以删除“ - ”字符，因为ReaderGroup名称只能包含字母和数字）。如果您有多个读者并行阅读并且每个阅读器都在一个单独的过程中，那么为ReaderGroup提供一个可读的名称会很有帮助。在我们的例子中，我们有一个Reader，单独读取，因此UUID是一种安全的方式来命名ReaderGroup。由于ReaderGroup是通过ReaderGroupManager创建的，并且由于ReaderGroupManager是在Scope的上下文中创建的，因此我们可以安全地得出结论，ReaderGroup名称由该Scope命名。  </p><p>ReaderGroupConfig现在没有太多行为。开发人员指定Stream，它应该是ReaderGroup的一部分及其下限和上限。在我们的例子中，在第11行，我们从Stream的开头开始。其他配置项（例如指定检查点等）是可通过ReaderGroupConfig获得的选项。但就目前而言，我们保持简单。<br>ReaderGroup可以配置为从多个Streams读取这一事实很有意思。想象一下，我收集了来自工厂车间的传感器数据流，每台机器都有自己的传感器数据流。我可以构建每个Stream使用ReaderGroup的应用，以便应用可以从一台机器中获取数据。我可以构建其他使用ReaderGroup配置为从所有Streams读取的应用。在我们的例子中，在第14行，ReaderGroup只读取一个Stream。</p><p>您可以多次使用相同的参数调用createReaderGroup（），它不会造成任何损害，并且每次最初创建后都会返回相同的ReaderGroup。<br>请注意，在其他情况下，如果开发人员知道要使用的ReaderGroup的名称并且知道它已经创建，则他/她可以使用ReaderGroupManager上的getReaderGroup（）来按名称检索ReaderGroup对象。</p><p>所以在代码的这一点上，我们设置了Scope和Stream，我们创建了ReaderGroup，现在我们需要创建一个Reader并开始阅读Events。</p><h2 id="使用EventStreamReader读取事件"><a href="#使用EventStreamReader读取事件" class="headerlink" title="使用EventStreamReader读取事件"></a>使用EventStreamReader读取事件</h2><p>第17-36行显示了设置EventStreamReader并使用该EventStreamReader读取事件的示例。</p><p>首先，我们在第17行创建一个ClientFactory，就像我们在HelloWorldWriter应用中一样。  </p><p>然后我们使用ClientFactory创建一个EventStreamReader对象。开发人员需要创建Reader的四件事：读者的名称，它应该是readerGroup的一部分，Stream上预期的对象类型，用于将存储在Pravega中的字节转换为事件的序列化器对象和ReaderConfig。第18-21行显示了EventStreamReader的创建。Reader的名称可以是任何有效的Pravega名称（数字和字母）。当然，阅读器的名称在Scope中是命名空间。我们在上一节讨论了ReaderGroup的创建。与EventStreamWriter一样，EventStreamReader使用Java泛型类型来允许开发人员指定类型安全的Reader。在我们的例子中，我们从流中读取字符串并使用标准的Java String Serializer将从流中读取的字节转换为String对象。最后，创建了ReaderConfig，但目前没有与Reader关联的配置项，因此空的ReaderConfig只是一个占位符，因为Pravega演变为在读者上包含配置项。</p><p>请注意，您不能多次创建相同的Reader。基本上你需要调用createReader（）它会尝试将Reader添加到ReaderGroup。如果ReaderGroup已包含具有该名称的Reader，则会引发异常。</p><p>现在我们已经创建了一个EventStreamReader，我们可以开始使用它来从流中读取事件。这是在第26行完成的。readNextEvent（）操作返回Stream上可用的下一个Event，或者如果没有这样的Event，则阻塞指定的超时时间。如果在超时期限到期且没有可用于读取的事件之后，则返回null。这就是为什么在第27行进行空检查（以避免向控制台打印出虚假的“null”事件消息）。它也用作第34行循环的终止。请注意，Event本身包含在EventRead对象中。</p><p>值得注意的是，readNextEvent（）可能会抛出异常（在第30-33行中处理）。如果ReaderGroup中的Readers需要重置为检查点或者ReaderGroup本身已被更改并且因此读取的Streams集已被更改，则会处理此异常。</p><p>就是这样了。简单的HelloWorldReader循环，从Stream读取事件，直到不再有更多事件，然后应用程序终止。</p><h2 id="批量读取"><a href="#批量读取" class="headerlink" title="批量读取"></a>批量读取</h2><p>对于想要执行历史流数据批量读取的应用程序，BatchClient提供了执行此操作的方法。它允许列出流中的所有段，并读取其数据。<br>当以这种方式读取数据时，不是加入自动分区数据的读取器组，而是公开流的底层结构，由应用程序决定如何处理它。因此，以这种方式读取的事件不需要按顺序读取。</p><p>显然，这个API并不适用于所有应用，主要优点是它允许与批处理框架（如MapReduce）进行低级集成。</p><p>作为一个例子来遍历流中所有的段：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>//将null传递给fromStreamCut和toStreamCut将导致分别使用当前流的开始和流的当前结束。<br>//Passing null to fromStreamCut and toStreamCut will result in using the current start of stream and the current end of stream respectively.<br>Iterator&lt;SegmentRange&gt; segments = client.listSegments(stream, null, null).getIterator();<br>SegmentRange segmentInfo = segments.next();<br></code></pre></td></tr></table></figure><p>或者从段中读取事件：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br>SegmentIterator&lt;T&gt; events = client.readSegment(segmentInfo, deserializer);<br>while (events.hasNext()) &#123;<br>    processEvent(events.next());<br>&#125;<br></code></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>flink handbook - Flink分布式运行时</title>
      <link href="/2018/09/26/flink-concepts-distributed-runtime/"/>
      <url>/2018/09/26/flink-concepts-distributed-runtime/</url>
      
        <content type="html"><![CDATA[<h2 id="任务和算子链"><a href="#任务和算子链" class="headerlink" title="任务和算子链"></a>任务和算子链</h2><p>对于分布式执行，Flink将算子子任务链接到任务中。每个任务由一个线程执行。将算子链接到任务中是一项有用的优化：它可以减少线程到线程切换和缓冲的开销，并在降低延迟的同时提高整体吞吐量。可以配置链接行为; 有关详细信息，请参阅链接文档。</p><p>下图中的示例数据流由五个子任务执行，因此具有五个并行线程。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/flink/tasks_chains.svg" alt="算子链接到任务"></p><h2 id="作业管理器，任务管理器，客户端"><a href="#作业管理器，任务管理器，客户端" class="headerlink" title="作业管理器，任务管理器，客户端"></a>作业管理器，任务管理器，客户端</h2><p>Flink运行时包含两种类型的进程：</p><ul><li>JobManagers（也称为主作业）协调分布式执行。他们调度任务，协调检查点，协调故障恢复等。</li></ul><p>总是至少有一个Job Manager。高可用性配置将具有多个JobManagers，其中一个始终是领导者，其他人则是备用者。</p><ul><li>TaskManagers（也叫工作者）执行数据流的任务（或者更具体地说，子任务），并且缓冲和交换数据流。</li></ul><p>必须至少有一个TaskManager。</p><p>JobManagers和TaskManagers可以通过多种方式启动：直接作为独立集群、在容器中、或由YARN或Mesos等资源框架管理。TaskManagers连接到JobManagers，宣布它们自己是可用，并被分配工作。</p><p>客户端不是运行时和程序执行的一部分，而是被用来准备和发送的数据流的JobManager。之后，客户端可以断开连接或保持连接以接收进度报告。客户端既可以作为触发执行的Java / Scala程序的一部分运行，也可以在命令行进程中运行./bin/flink run …。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/flink/processes.svg" alt="执行Flink数据流所涉及的过程"></p><h2 id="任务槽和资源"><a href="#任务槽和资源" class="headerlink" title="任务槽和资源"></a>任务槽和资源</h2><p>每个worker（TaskManager）都是一个JVM进程，可以在不同的线程中执行一个或多个子任务。为了控制worker接受的任务数量，worker有所谓的任务槽（至少一个）。</p><p>每个任务槽代表TaskManager的固定资源子集。例如，具有三个插槽的TaskManager将其托管内存的1/3专用于每个插槽。对资源进行分隔意味着子任务不会与来自其他作业的子任务竞争托管内存，而是具有一定数量的保留托管内存。请注意，此处不会发生CPU隔离; 当前插槽只分离任务的托管内存。</p><p>通过调整任务槽的数量，用户可以定义子任务如何相互隔离。每个TaskManager有一个插槽意味着每个任务组在一个单独的JVM中运行（例如，可以在一个单独的容器中启动）。拥有多个插槽意味着更多子任务共享同一个JVM。同一JVM中的任务共享TCP连接（通过多路复用）和心跳消息。它们还可以共享数据集和数据结构，从而减少每任务开销。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/flink/tasks_slots.svg" alt="具有任务槽和任务的TaskManager"></p><p>默认情况下，Flink允许子任务共享插槽，即使它们是不同任务的子任务，只要它们来自同一个作业。结果是一个槽可以容纳整个作业的管道。允许此插槽共享有两个主要好处：</p><p>Flink集群需要与作业中使用的最高并行度一样多的任务槽。无需计算程序总共包含多少任务（具有不同的并行性）。</p><p>更容易获得更好的资源利用率。如果没有插槽共享，非密集型源/ map（）子任务将阻止与资源密集型窗口子任务一样多的资源。通过插槽共享，将示例中的基本并行性从2增加到6可以充分利用插槽资源，同时确保繁重的子任务在TaskManagers之间公平分配。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/flink/slot_sharing.svg" alt="具有共享任务槽的TaskManagers"></p><p>API还包括可用于防止不期望的插槽共享的资源组机制。</p><p>根据经验，一个好的默认任务槽数就是CPU核心数。使用超线程，每个插槽然后需要2个或更多硬件线程上下文。</p><h2 id="状态后端"><a href="#状态后端" class="headerlink" title="状态后端"></a>状态后端</h2><p>存储键/值索引的确切数据结构取决于所选的状态后端。一个状态后端将数据存储在内存中的哈希映射中，另一个状态后端使用RocksDB作为键/值存储。除了定义保存状态的数据结构之外，状态后端还实现逻辑以获取键/值状态的时间点快照，并将该快照存储为检查点的一部分逻辑。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/flink/checkpoints.svg" alt="检查点和快照"></p><h2 id="保存点"><a href="#保存点" class="headerlink" title="保存点"></a>保存点</h2><p>用Data Stream API编写的程序可以从保存点恢复执行。保存点允许更新程序和Flink群集，而不会丢失任何状态。</p><p>保存点是手动触发的检查点，它将程序的快照写入状态后端。他们依赖于常规的检查点机制。在执行期间，程序会周期性地在工作节点上创建快照并生成检查点。对于恢复，仅需要最后完成的检查点，并且一旦新的检查点完成，就可以安全地丢弃旧的检查点。</p><p>保存点与这些定期检查点类似，不同之处在于它们由用户触发，并且在完成较新的检查点时不会自动过期。可以从命令行或通过REST API取消作业时创建保存点。</p>]]></content>
      
      
      <categories>
          
          <category> flink </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flink </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>flink handbook - flink数据流编程模型</title>
      <link href="/2018/09/26/flink-concepts-programming-model/"/>
      <url>/2018/09/26/flink-concepts-programming-model/</url>
      
        <content type="html"><![CDATA[<h2 id="抽象层次"><a href="#抽象层次" class="headerlink" title="抽象层次"></a>抽象层次</h2><p>Flink提供不同级别的抽象来开发流/批处理应用程序。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/flink/levels_of_abstraction.svg" alt="抽象层次"></p><ul><li><p>最低级抽象只提供有状态流。它通过Process Function嵌入到DataStream API中。它允许用户自由处理来自一个或多个流的事件，并使用一致的容错状态。此外，用户可以注册事件时间和处理时间回调，允许程序实现复杂的计算。</p></li><li><p>实际上，大多数应用不需要上述低级抽象，而是针对Core API编程， 如DataStream API（有界/无界流）和DataSet API （有界数据集）。这些流动的API提供了用于数据处理的通用构建块，例如各种形式的用户指定的转换，连接，聚合，窗口，状态等。在这些API中处理的数据类型在相应的编程语言中表示为类。</p></li></ul><p>低级Process Function与DataStream API集成，因此只能对某些操作进行低级抽象。DataSet API提供的有限数据集的其他原语，如循环/迭代。</p><ul><li>Table API是以表为中心的声明性DSL，其可以是动态地改变的表（表示流时）。Table API遵循（扩展）关系模型：表附加了一个模式（类似于在关系数据库中的表），API提供了类似的操作，如选择，项目，连接，分组依据，聚合等。Table API程序以声明方式定义应该执行的逻辑操作，而不是准确指定 操作代码的外观。虽然Table API可以通过各种类型的用户定义函数进行扩展，但它的表现力不如Core API，但使用更简洁（编写的代码更少）。此外，Table API程序还会通过优化程序，在执行之前应用优化规则。</li></ul><p>可以在表和DataStream / DataSet之间无缝转换，允许程序混合Table API以及DataStream 和DataSet API。</p><ul><li>Flink提供的最高级抽象是SQL。这种抽象在语义和表达方面类似于Table API，但是将程序表示为SQL查询表达式。在SQL抽象与 Table API紧密地相互作用，和SQL查询可以在Table API中定义的表上执行。</li></ul><h2 id="程序和数据流"><a href="#程序和数据流" class="headerlink" title="程序和数据流"></a>程序和数据流</h2><p>Flink程序的基本构建块是流和转换。（请注意，Flink的DataSet API中使用的DataSet也是内部流 - 稍后会详细介绍。）从概念上讲，流是（可能永无止境的）数据记录流，而转换是将一个或多个流作为输入，并产生一个或多个流输出的结果。</p><p>执行时，Flink程序映射到流数据流，由流和转换运算符组成。每个数据流都以一个或多个源开头，并以一个或多个接收器结束。数据流类似于任意有向无环图 （DAG）。尽管通过迭代结构允许特殊形式的循环 ，但为了简单起见，我们将在大多数情况下对此进行掩饰。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/flink/program_dataflow.svg" alt="DataStream程序及其数据流"></p><p>通常，程序中的转换与数据流中的运算符之间存在一对一的对应关系。但是，有时一个转换可能包含多个转换运算符。</p><p>源流和接收器记录在流连接器和批处理连接器文档中。DataStream运算符和DataSet转换中记录了转换。</p><h2 id="并行数据流"><a href="#并行数据流" class="headerlink" title="并行数据流"></a>并行数据流</h2><p>Flink中的程序本质上是并行和分布式的。在执行期间，流具有一个或多个流分区，并且每个运算符具有一个或多个运算符子任务。运算符子任务彼此独立，并且可以在不同的线程中执行，并且可能在不同的机器或容器上执行。</p><p>运算符子任务的数量是该特定运算符的并行度。流的并行性始终是其生成运算符的并行性。同一程序的不同运算符可能具有不同的并行级别。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/flink/parallel_dataflow.svg" alt="并行数据流"></p><p>流可以以一对一（或转发）模式或以重新分发模式在两个算子之间传输数据：</p><ul><li><p>一对一流（例如，在上图中的Source和map（）算子之间）保留元素的分区和排序。这意味着map（）算子的subtask [1] 将以与Source算子的subtask [1]生成的顺序相同的顺序看到相同的元素。</p></li><li><p>重新分配流（在上面的map（）和keyBy / window之间，以及 keyBy / window和Sink之间）重新分配流。每个算子子任务将数据发送到不同的目标子任务，具体取决于所选的转换。实例是 keyBy（） （其通过散列密钥重新分区），广播（） ，或重新平衡（） （其重新分区随机地）。在重新分配交换中，元素之间的排序仅保留在每对发送和接收子任务中（例如，map（）的子任务[1] 和子任务[2]keyBy / window）。因此，在此示例中，保留了每个密钥内的排序，但并行性确实引入了关于不同密钥的聚合结果到达接收器的顺序的非确定性。</p></li></ul><p>有关配置和控制并行性的详细信息，请参阅并行执行的文档。</p><h2 id="视窗"><a href="#视窗" class="headerlink" title="视窗"></a>视窗</h2><p>聚合事件（例如，计数，总和）在流上的工作方式与批处理方式不同。例如，不可能计算流中的所有元素，因为流通常是无限的（无界）。相反，流上的聚合（计数，总和等）由窗口限定，例如“在最后5分钟内计数”或“最后100个元素的总和”。</p><p>Windows可以是时间驱动的（例如：每30秒）或数据驱动（例如：每100个元素）。一个典型地区分不同类型的窗口，例如翻滚窗口（没有重叠）， 滑动窗口（具有重叠）和会话窗口（由不活动的间隙打断）。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/flink/windows.svg" alt="时间和计数Windows"></p><p>更多窗口示例可以在此博客文章中找到。更多详细信息在窗口文档中。</p><h2 id="时间"><a href="#时间" class="headerlink" title="时间"></a>时间</h2><p>当在流程序中引用时间（例如定义窗口）时，可以参考不同的时间概念：</p><ul><li><p>事件时间是创建事件的时间。它通常由事件中的时间戳描述，例如由生产传感器或生产服务附加。Flink通过时间戳分配器访问事件时间戳。</p></li><li><p>摄取时间是事件在源操作员处输入Flink数据流的时间。</p></li><li><p>处理时间是执行基于时间的操作的每个算子的本地时间。</p></li></ul><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/flink/event_ingestion_processing_time.svg" alt="事件时间，摄取时间和处理时间"></p><p>有关如何处理时间的更多详细信息，请参阅<a href="https://ci.apache.org/projects/flink/flink-docs-master/dev/event_time.html" target="_blank" rel="noopener">事件时间文档</a>。</p><h2 id="有状态的操作"><a href="#有状态的操作" class="headerlink" title="有状态的操作"></a>有状态的操作</h2><p>虽然数据流中的许多操作只是一次查看一个单独的事件（例如事件解析器），但某些操作会记住多个事件（例如窗口操作符）的信息。这些操作称为有状态。</p><p>状态操作的状态保持在可以被认为是嵌入式键/值存储的状态中。状态被分区并严格地与有状态算子读取的流一起分发。因此，只有在keyBy（）函数之后才能在键控流上访问键/值状态，并且限制为与当前事件的键相关联的值。对齐流和状态的密钥可确保所有状态更新都是本地操作，从而保证一致性而无需事务开销。此对齐还允许Flink重新分配状态并透明地调整流分区。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/flink/state_partitioning.svg" alt="状态和分区"></p><p>有关更多信息，请参阅有关状态的文档。</p><h2 id="容错检查点"><a href="#容错检查点" class="headerlink" title="容错检查点"></a>容错检查点</h2><p>Flink使用流重放和检查点的组合实现容错。检查点与每个输入流中的特定点以及每个算子的对应状态相关。通过恢复算子的状态并从检查点重放事件，可以从检查点恢复流数据流，同时保持一致性（恰好一次处理语义）。</p><p>检查点间隔是在执行期间用恢复时间（需要重放的事件的数量）来折衷容错开销的手段。</p><p><a href="https://ci.apache.org/projects/flink/flink-docs-master/internals/stream_checkpointing.html" target="_blank" rel="noopener">容错内部</a>的描述提供了有关Flink如何管理检查点和相关主题的更多信息。有关启用和配置检查点的详细信息，请参阅检查点API文档。</p><h2 id="批处理流"><a href="#批处理流" class="headerlink" title="批处理流"></a>批处理流</h2><p>Flink执行<a href="https://ci.apache.org/projects/flink/flink-docs-master/dev/batch/index.html" target="_blank" rel="noopener">批处理程序</a>作为流程序的特殊情况，其中流是有界的（有限数量的元素）。数据集做为数据流在内部处理。因此，上述概念以适用于流程序相同的方式应用于批处理程序，只是少数例外：</p><ul><li><p><a href="https://ci.apache.org/projects/flink/flink-docs-master/dev/batch/fault_tolerance.html" target="_blank" rel="noopener">批处理程序的容错</a>不使用检查点。而是通过完全重放流来恢复。这是可能的，因为输入是有界的。这会使成本更多高，但却使常规处理更便宜，因为它避免了检查点。</p></li><li><p>DataSet API中的有状态操作使用简化的内存/核外数据结构，而不是键/值索引。</p></li><li><p>DataSet API引入了特殊的同步（基于超前的）迭代，这在有界流上是可行的。有关详细信息，请查看<a href="https://ci.apache.org/projects/flink/flink-docs-master/dev/batch/iterations.html" target="_blank" rel="noopener">迭代文档</a>。</p></li></ul><h2 id="下一步"><a href="#下一步" class="headerlink" title="下一步"></a>下一步</h2><p>Flink的Distributed Runtime。</p>]]></content>
      
      
      <categories>
          
          <category> flink </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flink </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Flink handbook - Apache Flink的文档</title>
      <link href="/2018/09/24/flink-apache-flink-home/"/>
      <url>/2018/09/24/flink-apache-flink-home/</url>
      
        <content type="html"><![CDATA[<h2 id="Apache-Flink文档"><a href="#Apache-Flink文档" class="headerlink" title="Apache Flink文档"></a>Apache Flink文档</h2><p>本文档适用于Apache Flink master版。</p><p>Apache Flink是一个用于分布式流和批处理数据处理的开源平台。Flink的核心是流数据流引擎，为数据流上的分布式计算提供数据分发，通信和容错。Flink在流引擎之上构建批处理，涵盖原生的迭代支持，受管理的内存和程序优化。</p><h2 id="第一步"><a href="#第一步" class="headerlink" title="第一步"></a>第一步</h2><p><strong>概念：</strong>从Flink的<a href="https://ci.apache.org/projects/flink/flink-docs-master/concepts/programming-model.html" target="_blank" rel="noopener">数据流编程模型</a>和<a href="https://ci.apache.org/projects/flink/flink-docs-master/concepts/runtime.html" target="_blank" rel="noopener">分布式运行时环境</a>的基本概念开始。这将有助于您了解文档的其他部分，包括配置和编程指南。我们建议您先阅读这部分内容。</p><p><strong>教程：</strong></p><ul><li><a href="https://ci.apache.org/projects/flink/flink-docs-master/tutorials/datastream_api.html" target="_blank" rel="noopener">实现并运行DataStream应用</a></li><li><a href="https://ci.apache.org/projects/flink/flink-docs-master/tutorials/local_setup.html" target="_blank" rel="noopener">配置本地Flink群集</a></li></ul><p><strong>编程指南：</strong>您可以阅读我们关于<a href="https://ci.apache.org/projects/flink/flink-docs-master/dev/api_concepts.html" target="_blank" rel="noopener">基本API概念</a>和<a href="https://ci.apache.org/projects/flink/flink-docs-master/dev/datastream_api.html" target="_blank" rel="noopener">DataStream API</a>或<a href="https://ci.apache.org/projects/flink/flink-docs-master/dev/batch/index.html" target="_blank" rel="noopener">DataSet API</a>的指南，以了解如何编写您的第一个Flink程序。</p><h2 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h2><p>在将Flink作业投入生产之前，请阅读<a href="https://ci.apache.org/projects/flink/flink-docs-master/ops/production_ready.html" target="_blank" rel="noopener">生产准备清单</a>。</p><h2 id="发行说明"><a href="#发行说明" class="headerlink" title="发行说明"></a>发行说明</h2><p>发行说明涵盖了Flink版本之间的重要更改。如果您计划将Flink升级到更高版本，请仔细阅读这些说明。</p><ul><li><a href="https://ci.apache.org/projects/flink/flink-docs-master/release-notes/flink-1.6.html" target="_blank" rel="noopener">Flink 1.6发行说明</a></li><li><a href="https://ci.apache.org/projects/flink/flink-docs-master/release-notes/flink-1.5.html" target="_blank" rel="noopener">Flink 1.5的发行说明</a></li></ul><h2 id="外部资源"><a href="#外部资源" class="headerlink" title="外部资源"></a>外部资源</h2><ul><li><p>Flink Forward：<a href="http://flink-forward.org/" target="_blank" rel="noopener">Flink Forward网站</a>和<a href="https://www.youtube.com/channel/UCY8_lgiZLZErZPF47a2hXMA" target="_blank" rel="noopener">YouTube</a>上提供了以往会议的讲座。<a href="http://2016.flink-forward.org/kb_sessions/robust-stream-processing-with-apache-flink/" target="_blank" rel="noopener">使用Apache Flink进行可靠的流处理</a>，那这些资料是一个很好的起点。</p></li><li><p>培训：data Artisans的<a href="http://training.data-artisans.com/" target="_blank" rel="noopener">培训材料</a>包括幻灯片，练习和示例。</p></li><li><p>博客：<a href="https://flink.apache.org/blog/" target="_blank" rel="noopener">Apache Flink</a>和<a href="https://data-artisans.com/blog/" target="_blank" rel="noopener">data Artisans</a>博客会比较频繁的发布flink相关的、深入的技术文章。</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> flink </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flink </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Flink handbook - flink常见问题</title>
      <link href="/2018/09/24/flink-faq/"/>
      <url>/2018/09/24/flink-faq/</url>
      
        <content type="html"><![CDATA[<p>关于Flink项目，一般会经常被问到以下问题。</p><h2 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h2><h2 id="Apache-Flink仅用于（近）实时处理用例吗？"><a href="#Apache-Flink仅用于（近）实时处理用例吗？" class="headerlink" title="Apache Flink仅用于（近）实时处理用例吗？"></a>Apache Flink仅用于（近）实时处理用例吗？</h2><p>Flink是一个非常通用的系统，用于数据处理和数据驱动的应用程序，数据流作为核心构建块。这些数据流可以是实时数据流,也可以是存储的历史数据流。例如，在Flink的视图中，文件是存储的字节流。因此，Flink支持实时数据处理和应用，以及批处理应用。</p><p>流可以是无界的（没有结束，事件不断发生）或受限制（流有开始和结束）。例如，来自消息队列的Twitter馈送或事件流通常是无界流，而来自文件的字节流是有界流。</p><h2 id="如果一切都是流，为什么Flink中有DataStream和DataSet-API？"><a href="#如果一切都是流，为什么Flink中有DataStream和DataSet-API？" class="headerlink" title="如果一切都是流，为什么Flink中有DataStream和DataSet API？"></a>如果一切都是流，为什么Flink中有DataStream和DataSet API？</h2><p>有界流通常比无界流更有效。在（近）实时处理无限事件流需要系统能够立即对事件起作用并产生中间结果（通常具有低延迟）。处理有界流通常不需要产生低延迟结果，因为无论如何数据都是旧的（相对而言）。这允许Flink以简单且更有效的方式处理数据。</p><p>DataStream API通过支持低延时的结果和对事件和时间（包括事件时间）灵活反应的模型捕获无界流和有界流的连续处理，</p><p>DataSet API具有加快有界数据流的处理的技术。将来，社区计划将这些优化与DataStream API中的技术相结合。</p><h2 id="Flink如何与Hadoop堆栈相关？"><a href="#Flink如何与Hadoop堆栈相关？" class="headerlink" title="Flink如何与Hadoop堆栈相关？"></a>Flink如何与Hadoop堆栈相关？</h2><p>Flink独立于Apache Hadoop，并且在没有任何Hadoop依赖性的情况下运行。</p><p>但是，Flink与许多Hadoop组件集成得非常好，例如HDFS，YARN或HBase。与这些组件一起运行时，Flink可以使用HDFS读取数据，或写入结果和检查点/快照。Flink可以通过YARN轻松部署，并与YARN和HDFS Kerberos安全模块集成。</p><h2 id="Flink运行的其他堆栈是什么？"><a href="#Flink运行的其他堆栈是什么？" class="headerlink" title="Flink运行的其他堆栈是什么？"></a>Flink运行的其他堆栈是什么？</h2><p>Flink可以在Kubernetes，Mesos， Docker上运行 ，甚至作为独立服务运行。</p><h2 id="使用Flink有哪些先决条件？"><a href="#使用Flink有哪些先决条件？" class="headerlink" title="使用Flink有哪些先决条件？"></a>使用Flink有哪些先决条件？</h2><p>您需要Java 8来运行Flink作业/应用。<br>Scala API（可选）依赖于Scala 2.11。<br>Apache ZooKeeper需要高度可用且没有单点故障的设置。<br>对于可以从故障中恢复的高可用流处理设置，Flink需要某种形式的分布式存储用于检查点（HDFS / S3 / NFS / SAN / GFS / Kosmos / Ceph / …）。</p><h2 id="Flink支持多大的规模？"><a href="#Flink支持多大的规模？" class="headerlink" title="Flink支持多大的规模？"></a>Flink支持多大的规模？</h2><p>用户在非常小的设置（少于5个节点）和1000个节点以及状态的TB上运行Flink作业。</p><h2 id="Flink是否仅限于内存数据集？"><a href="#Flink是否仅限于内存数据集？" class="headerlink" title="Flink是否仅限于内存数据集？"></a>Flink是否仅限于内存数据集？</h2><p>对于DataStream API，Flink支持大于内存的状态来配置RocksDB状态后端。</p><p>对于DataSet API，所有操作（delta迭代除外）都可以扩展到主内存之外。</p><h2 id="常见错误消息"><a href="#常见错误消息" class="headerlink" title="常见错误消息"></a>常见错误消息</h2><p>“ 获得帮助”页面上列出了常见错误消息。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1].<a href="https://flink.apache.org/faq.html" target="_blank" rel="noopener">https://flink.apache.org/faq.html</a></p>]]></content>
      
      
      <categories>
          
          <category> flink </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flink </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Flink handbook - flink用例</title>
      <link href="/2018/09/23/flink-use-cases/"/>
      <url>/2018/09/23/flink-use-cases/</url>
      
        <content type="html"><![CDATA[<h2 id="用例"><a href="#用例" class="headerlink" title="用例"></a>用例</h2><p>Apache Flink因其丰富的功能集而成为开发和运行多种不同类型应用程序的绝佳选择。Flink的功能包括对流和批处理的支持，复杂的状态管理，事件时间处理语义以及状态的恰好一次一致性保证。此外，Flink可以部署在各种资源管理集群（如YARN，Apache Mesos和Kubernetes）上，也可以部署为裸机硬件上的单个群集。Flink配置为高可用性，没有单点故障。Flink已经被证明可以扩展到数千个核心和万亿字节的应用状态，提供高吞吐量和低延迟，并为世界上一些最苛刻的流处理应用程序提供支持。</p><p>下面，我们将探讨由Flink提供支持的最常见类型的应用程序，并指出实际示例。</p><ul><li>事件驱动的应用</li><li>数据分析应用</li><li>数据管道应用</li></ul><h2 id="事件驱动的应用"><a href="#事件驱动的应用" class="headerlink" title="事件驱动的应用"></a>事件驱动的应用</h2><h3 id="什么是事件驱动的应用？"><a href="#什么是事件驱动的应用？" class="headerlink" title="什么是事件驱动的应用？"></a>什么是事件驱动的应用？</h3><p>事件驱动的应用程序是一个有状态的应用程序，它从一个或多个事件流中提取事件，并通过触发计算，状态更新或外部操作对传入事件做出响应。</p><p>事件驱动的应用程序是传统应用程序设计的演变，具有分离的计算和数据存储层。在传统应用的体系结构中，应用从远程事务数据库中读取数据并将数据持久化到远程事务数据库。</p><p>相比之下，事件驱动的应用程序基于有状态流处理应用程序。在这种设计中，数据和计算是共同定位的，这产生了本地（内存或磁盘）数据访问。通过定期将检查点写入远程持久存储来实现容错。下图描绘了传统应用程序体系结构和事件驱动应用程序之间的差异。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/flink%2Fusecases-eventdrivenapps.png" alt=""></p><h3 id="事件驱动的应用有哪些优点？"><a href="#事件驱动的应用有哪些优点？" class="headerlink" title="事件驱动的应用有哪些优点？"></a>事件驱动的应用有哪些优点？</h3><p>事件驱动的应用程序不是查询远程数据库，而是在本地访问其数据，从而在吞吐量和延迟方面发挥更好的性能。远程持久存储的定期检查点可以异步和递增完成。因此，检查点对常规事件处理的影响非常小。但是，事件驱动的应用程序设计提供的不仅仅是本地数据访问。在分层体系结构中，多个应用程序共享同一数据库是很常见的。因此，需要协调数据库的任何更改，例如由于应用程序更新或扩展服务而更改数据布局。由于每个事件驱动的应用程序都负责自己的数据，因此对数据表示的更改或扩展应用程序需要较少的协调。</p><h3 id="Flink如何支持事件驱动的应用？"><a href="#Flink如何支持事件驱动的应用？" class="headerlink" title="Flink如何支持事件驱动的应用？"></a>Flink如何支持事件驱动的应用？</h3><p>事件驱动应用程序的限制由流处理器处理时间和状态的程度来定义。Flink的许多杰出功能都围绕着这些概念。Flink提供了一组丰富的状态原语，可以管理非常大的数据量（最多几TB），并且具有恰好一次的一致性保证。此外，Flink支持事件时间，高度可定制的窗口逻辑，以及通过ProcessFunction实现高级业务逻辑提供的细粒度时间控制。此外，Flink还提供了一个用于复杂事件处理（CEP）的库，用于检测数据流中的模式。</p><p>但是，Flink针对事件驱动应用程序的突出特点是保存点功能。保存点是一致的状态图像，可用作兼容应用程序的起点。给定保存点，可以更新应用程序或调整其规模，或者可以启动应用程序的多个版本以进行A / B测试。</p><h3 id="什么是典型的事件驱动应用？"><a href="#什么是典型的事件驱动应用？" class="headerlink" title="什么是典型的事件驱动应用？"></a>什么是典型的事件驱动应用？</h3><ul><li>欺诈识别</li><li>异常检测</li><li>基于规则的警报</li><li>业务流程监控</li><li>Web应用程序（社交网络）</li></ul><h2 id="数据分析应用"><a href="#数据分析应用" class="headerlink" title="数据分析应用"></a>数据分析应用</h2><h3 id="什么是数据分析应用？"><a href="#什么是数据分析应用？" class="headerlink" title="什么是数据分析应用？"></a>什么是数据分析应用？</h3><p>分析工作从原始数据中提取信息和洞察力。传统上，分析是在有记录事件的有界数据集上作为批查询或应用程序来执行的。为了将最新数据合并到分析结果中，必须将其添加到分析的数据集中，并重新运行查询或应用程序。结果将写入存储系统或作为报告发出。</p><p>借助先进的流处理引擎，还可以实时地执行分析。流式查询或应用程序不是读取有限数据集，而是摄取实时事件流，并在消耗事件时不断生成和更新结果。结果要么写入外部数据库，要么保持为内部状态。仪表板应用程序可以从外部数据库读取最新结果或直接查询应用程序的内部状态。</p><p>Apache Flink支持流式和批量分析应用程序，如下图所示。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/flink%2Fusecases-analytics.png" alt=""></p><h3 id="流式分析应用有哪些优势？"><a href="#流式分析应用有哪些优势？" class="headerlink" title="流式分析应用有哪些优势？"></a>流式分析应用有哪些优势？</h3><p>与批量分析相比，连续流分析的优势不仅限于因消除定期导入和查询执行而从事件到洞察的低得多的延迟。与批量查询相比，流式查询不必处理输入数据中的人为边界，这些边界是由定期导入和输入的有界性质引起的。</p><p>另一方面是更简单的应用程序架构。批量分析管道由若干独立组件组成，以周期性地调度数据提取和查询执行。可靠地操作这样的管道并非易事，因为一个组件的故障会影响管道的后续步骤。相比之下，在像Flink这样的复杂流处理器上运行的流分析应用程序包含从数据摄取到连续结果计算的所有步骤。因此，它可以依赖于引擎的故障恢复机制。</p><h3 id="Flink如何支持数据分析应用？"><a href="#Flink如何支持数据分析应用？" class="headerlink" title="Flink如何支持数据分析应用？"></a>Flink如何支持数据分析应用？</h3><p>Flink为连续流式传输和批量分析提供了非常好的支持。具体来说，它具有符合ANSI标准的SQL接口，具有用于批处理和流式查询的统一语义。无论是在记录事件的静态数据集上还是在实时事件流上运行，SQL查询都会计算相同的结果。对用户定义函数的丰富支持可确保在SQL查询中执行自定义代码。如果需要更多的自定义逻辑，Flink的DataStream API或DataSet API提供更多的低级控制。此外，Flink的Gelly库为批量数据集上的大规模和高性能图形分析提供算法和构建块。</p><h3 id="什么是典型的数据分析应用？"><a href="#什么是典型的数据分析应用？" class="headerlink" title="什么是典型的数据分析应用？"></a>什么是典型的数据分析应用？</h3><ul><li>电信网络的质量监控</li><li>分析移动应用程序中的产品更新和实验评估</li><li>对消费者技术中的实时数据进行特别分析</li><li>大规模图分析</li></ul><h2 id="数据管道应用"><a href="#数据管道应用" class="headerlink" title="数据管道应用"></a>数据管道应用</h2><h3 id="什么是数据管道？"><a href="#什么是数据管道？" class="headerlink" title="什么是数据管道？"></a>什么是数据管道？</h3><p>提取 - 转换 - 加载（ETL）是在存储系统之间转换和移动数据的常用方法。通常会定期触发ETL作业，以便将数据从事务数据库系统复制到分析数据库或数据仓库。</p><p>数据管道与ETL作业具有相似的用途。它们可以转换和丰富数据，并可以将数据从一个存储系统移动到另一个存储系统 但是，它们以连续流模式运行，而不是周期性地触发。因此，他们能够从连续生成数据的源中读取记录，并以低延迟将其移动到目的地。例如，数据管道可能会监视文件系统目录中的新文件并将其数据写入事件日志。另一个应用程序可能会将事件流实现到数据库，或者逐步构建和优化搜索索引。</p><p>下图描述了定期ETL作业和连续数据管道之间的差异。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/flink%2Fusecases-datapipelines.png" alt=""></p><h3 id="数据管道有哪些优势？"><a href="#数据管道有哪些优势？" class="headerlink" title="数据管道有哪些优势？"></a>数据管道有哪些优势？</h3><p>连续数据流水线优于周期性ETL作业的显著优势是减少了将数据移动到目的地的延迟。此外，数据管道更加通用，可用于更多用例，因为它们能够连续消耗和发送数据。</p><h3 id="Flink如何支持数据管道？"><a href="#Flink如何支持数据管道？" class="headerlink" title="Flink如何支持数据管道？"></a>Flink如何支持数据管道？</h3><p>Flink的SQL接口（或表API）可以解决许多常见的数据转换或丰富任务，并支持用户定义的函数。通过使用更通用的DataStream API，可以实现具有更高级要求的数据管道。Flink为各种存储系统（如Kafka，Kinesis，Elasticsearch和JDBC数据库系统）提供了丰富的连接器。它还具有连续的文件系统源，用于监视以时间分区方式写入文件的目录和接收器。</p><h3 id="什么是典型的数据管道应用？"><a href="#什么是典型的数据管道应用？" class="headerlink" title="什么是典型的数据管道应用？"></a>什么是典型的数据管道应用？</h3><ul><li>电子商务中的实时搜索索引构建</li><li>电子商务中持续的ETL</li></ul><h2 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h2><p>[1].<a href="https://flink.apache.org/usecases.html" target="_blank" rel="noopener">https://flink.apache.org/usecases.html</a></p>]]></content>
      
      
      <categories>
          
          <category> flink </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flink </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Flink handbook - 什么是Apache Flink？</title>
      <link href="/2018/09/23/flink-what-is-apache-flink/"/>
      <url>/2018/09/23/flink-what-is-apache-flink/</url>
      
        <content type="html"><![CDATA[<p>Apache Flink是一个框架和分布式处理引擎，用于对无界和有界数据流进行有状态计算。Flink设计为在所有常见的集群环境中运行，以内存速度和任何规模执行计算。</p><p>在这里，我们解释了Flink架构的重要方面。</p><h2 id="无界和有界数据的处理"><a href="#无界和有界数据的处理" class="headerlink" title="无界和有界数据的处理"></a>无界和有界数据的处理</h2><p>任何类型的数据都是作为事件流产生的。信用卡交易，传感器测量，机器日志或网站或移动应用程序上的用户交互，所有这些数据都作为流生成。</p><p>数据可以作为无界或有界流处理。</p><ol><li><p><strong>无界流</strong> 有一个开始，但没有定义的结束。它们不会终止并提供其生成的数据。无界流必须持续处理，即必须在摄取事件后立即处理事件。不可能等待所有的输入数据都到达，因为输入是无界的，并且在任何时间点都不会结束。处理无界数据通常要求以特定顺序（例如事件发生的顺序）摄取事件，以便能够推断结果的完整性。</p></li><li><p><strong>有界流</strong>具有定义的开始和结束。可以在执行任何计算之前，通过摄取所有数据来处理有界流。有界数据集是可以被排序的，因此处理有界流不需要有序摄取。有界流的处理也称为批处理。</p></li></ol><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/flink%2Fbounded-unbounded.png" alt=""></p><p><strong>Apache Flink擅长处理无界和有界数据集</strong>。精确控制时间和状态使Flink的运行时能够在无界流上运行任何类型的应用程序。有界流由算法和数据结构在内部处理，这些算法和数据结构专门针对固定大小的数据集而设计，从而发挥出性能优势。</p><h2 id="随处部署应用"><a href="#随处部署应用" class="headerlink" title="随处部署应用"></a>随处部署应用</h2><p>Apache Flink是一个分布式系统，需要计算资源才能执行的应用程序。Flink可以与所有常见的集群资源管理器（如Hadoop YARN，Apache Mesos和Kubernetes）集成，但也可以设置为独立的集群运行。</p><p>Flink旨在很好地适用于之前列出的每个资源管理器，这是通过特定于资源管理器的部署模式实现的，这些模式允许Flink以其惯用的方式与每个资源管理器进行交互。</p><p>部署Flink应用程序时，Flink会根据应用程序配置的并行性自动识别所需资源，并从资源管理器里申请它们。如果发生故障，Flink会通过申请新资源来替换发生故障的容器。所有提交或控制应用程序的通信都是通过REST调用来进行，这简化了Flink在许多环境中的集成。</p><h2 id="以任何规模运行应用"><a href="#以任何规模运行应用" class="headerlink" title="以任何规模运行应用"></a>以任何规模运行应用</h2><p>Flink旨在以任何规模运行有状态的流应用，应用程序可以并行化为数千个在集群中分布和同时执行的任务。因此，应用程序可以利用几乎无限量的CPU、主内存、磁盘和网络IO。而且，Flink可以轻松维护数据量非常大的应用状态。其异步和增量检查点算法确保对处理的延迟影响最小，同时保证恰好一次状态的一致性。</p><p>用户报告了在其生产环境中运行的Flink集群的规模，这样的规模有点令人印象深刻，例如</p><ul><li>应用程序每天处理数万亿个事件，</li><li>应用程序维护多个TB的状态，以及</li><li>应用程序在数千个内核的运行。</li></ul><h2 id="内存的性能优势"><a href="#内存的性能优势" class="headerlink" title="内存的性能优势"></a>内存的性能优势</h2><p>有状态Flink应用针对本地状态的访问进行了优化。任务状态始终保留在内存中，或者，如果状态大小超过可用内存，则保存在可高效访问的磁盘上的数据结构中。因此，任务通过访问本地（通常是内存中）状态来执行所有计算，从而产生非常低的处理延迟。Flink通过定期并且异步地把本地状态打检查点并持久化到存储设备来保证在出现故障时的恰好一次状态的一致性。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/flink%2Flocal-state.png" alt=""></p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1].<a href="https://flink.apache.org/flink-architecture.html" target="_blank" rel="noopener">https://flink.apache.org/flink-architecture.html</a></p>]]></content>
      
      
      <categories>
          
          <category> flink </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flink </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>微服务-微服务解惑</title>
      <link href="/2018/09/23/microservice-weifuwunaxieshier/"/>
      <url>/2018/09/23/microservice-weifuwunaxieshier/</url>
      
        <content type="html"><![CDATA[<h2 id="微服务解惑"><a href="#微服务解惑" class="headerlink" title="微服务解惑"></a>微服务解惑</h2><h3 id="微服务与容器"><a href="#微服务与容器" class="headerlink" title="微服务与容器"></a>微服务与容器</h3><p>微服务又指的是在传统应用架构的基础上，按照业务能力将系统拆分成多个服务，每个服务都是一个独立的应用，对外提供一些列的公共服务API，服务之间以轻量的方式互相调用。<br>微服务里的每个服务都是一个组件，通过编排组合从而达到独立、解耦、组件化、易维护、可复用、可替换、高可用的设计原则。微服务后，自动化部署以及运维是比较头疼的事，容器技术解决了这个问题。</p><ul><li>好的架构需要考虑后面的扩展以及修改</li><li>好的架构是解耦的，需改一个地方不会影响另外一个地方</li><li>好的架构是轻便灵活的，一个应用最好只解决一个问题，而不是叠加功能</li></ul><h3 id="微服务的标签"><a href="#微服务的标签" class="headerlink" title="微服务的标签"></a>微服务的标签</h3><ul><li>单一职责</li><li>微</li><li>面向服务</li><li>自治</li><li>易扩展</li><li>流程化</li></ul><h3 id="微服务的不足"><a href="#微服务的不足" class="headerlink" title="微服务的不足"></a>微服务的不足</h3><ul><li>时效性·服务间的调用延时可能导致系统相应慢的问题</li><li>一致性·微服务在保证一致性上需要做更多的工作</li></ul><h3 id="微服务的价值"><a href="#微服务的价值" class="headerlink" title="微服务的价值"></a>微服务的价值</h3><ul><li>资源价值，资源不足是自动扩容，资源过量时自动缩容；</li><li>业务价值，工作量、人员数量、交付质量、交付周期；</li><li>技术价值，技术是为业务来服务的（个人标注：技术也是业务的一部分而不只是为业务而服务）</li><li>用户价值，用户体验好，服务上线快</li><li>未来价值，技术不成为业务的瓶颈</li></ul><h3 id="微服务的小目标"><a href="#微服务的小目标" class="headerlink" title="微服务的小目标"></a>微服务的小目标</h3><ul><li>持续交付</li><li>业务敏捷</li><li>独立演进</li><li>高可用</li><li>高性能</li></ul><h3 id="微服务的拆与不拆"><a href="#微服务的拆与不拆" class="headerlink" title="微服务的拆与不拆"></a>微服务的拆与不拆</h3><p>依据：数据模型、业务模型、关键指标，粒度平衡，边界合理</p><h3 id="DevOPS"><a href="#DevOPS" class="headerlink" title="DevOPS"></a>DevOPS</h3><p>开发与运维是一个整体，devops是一种思维方式，微服务与devops是天生一对</p><h3 id="SpringCloud特点"><a href="#SpringCloud特点" class="headerlink" title="SpringCloud特点"></a>SpringCloud特点</h3><ul><li>功能齐全</li><li>标准化</li><li>简单方便</li><li>按需取用</li><li>轻量</li><li>易扩展、易维护</li><li>可复用性</li></ul><h3 id="分布式系统组件及操作"><a href="#分布式系统组件及操作" class="headerlink" title="分布式系统组件及操作"></a>分布式系统组件及操作</h3><p>配置管理（Spring cloud config）、服务发现/调用(Feign)、断路器、智能路由（ZUUL）、微代理、控制总线、一次性Token、全局锁、决策竞选、分布式会话、集群状态。</p><p>注册中心(Eureka)、负载均衡(Ribbon)、断路器（Hystrix）、服务追踪（Sleuth，zipkin）、权限（string security）、接口可视化（Swagger）。</p><p>以上内容为《微服务那些事儿》读书笔记。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1]. 微服务那些事儿，纪晓峰著</p>]]></content>
      
      
      <categories>
          
          <category> microservice </category>
          
      </categories>
      
      
        <tags>
            
            <tag> microservice </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>从马斯克们的Hyperloop到用Flink加Pravega打造的“流原生”式大数据处理平台</title>
      <link href="/2018/09/22/streaming-native-platform/"/>
      <url>/2018/09/22/streaming-native-platform/</url>
      
        <content type="html"><![CDATA[<h1 id="开篇-马斯克们的Hyperloop"><a href="#开篇-马斯克们的Hyperloop" class="headerlink" title="开篇,马斯克们的Hyperloop"></a>开篇,马斯克们的Hyperloop</h1><p>我们先来看张图，下图上部分是现在的高铁，它是跑在露天的轨道上的，下图是Elon Musk’s 在正吹的<a href="https://hyperloop-one.com" target="_blank" rel="noopener">hyperloop</a>，类似于跑在真空管道里的未来高铁。相比跑在露天轨道里的高铁，跑真空管道里的高铁好处多了：快，节能，安全，比飞机便宜。。。<br>技术是可以自己进化的，相信类似hyperloop的”高铁+真空管道”的模式就是未来的一种交通出行方式。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/streaming%2Fstreaming-native-platform-0.jpg" alt="hyperloop"></p><p>那么HYPERLOOP跟本文又有什么关系呢？ 是不是有点扯远了？其实本文讲的就是类似给高铁加上真空管道的活，二者本质上是相同的。</p><h2 id="管道-Unix-Linux的设计哲学"><a href="#管道-Unix-Linux的设计哲学" class="headerlink" title="管道,Unix/Linux的设计哲学"></a>管道,Unix/Linux的设计哲学</h2><p>在Linux或者Unix系统里,有时候我们为了查询某个信息，会输入类似如下的命令行：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs undefined">#cat *.log | grep –v ‘pipeline’ | sort –nr | head –n 10 | tail -5 | awk ‘&#123;print $2&#125;’ | wc –l  &gt; /dev/stdout<br></code></pre></td></tr></table></figure><p>这个命令行通过“|”来分隔多个命令，前面命令的输出是紧接着的后面命令的输入，命令之间通过“|”彼此相连，并且一个命令只做一件事情。这里的“|”就是管道，把一个程序的输出和另一个程序的输入连起来的一根管子。</p><p>在Unix/Linux里存在这样的管道命令设计哲学：</p><ul><li>程序是个过滤器</li><li>一个程序只做一件事并且做到最好</li><li>一个程序的输入是另外一个程序的输出</li></ul><p>下图体现了这样的管道设计哲学，应用之间通过管道相连相互作用：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/streaming%2Fstreaming-native-platform-1.PNG" alt="Uniux/linux pipeline"></p><p>管道所要解决的问题是：<code>高内聚，低耦合</code>。它以一种“链”的方式将这些程序组合起来，让这些程序组成一条工作流，而每个程序又只作一件事情，给定输入，经过各个程序的先后处理，最终得到输出结果，如下图所示：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/streaming%2Fstreaming-native-platform-2.PNG" alt="Uniux/linux pipeline"></p><p>Unix/Linux在<code>&quot;每个程序只做一件事并且做好，每个程序的输出是对另一个程序的输入，可组合性&quot;</code>方面是做的非常成功的。但是，UNIX/Linux也存在一些局限性，比如：<code>&quot;仅单机，只支持一对一通信，无容错，仅字节流,数据处理能力有限等&quot;</code>。意思是说 linux/unix的这些管道命令只能在一台机器上跑，没有分布式，并且只能支持一个命令和另外一个命令之间的一对一的输入输出，无法一对多或多对一；无容错，假如管道坏了数据就出错不能恢复；只支持字节流，不支持数据格式的多样性；处理的数据量有限。</p><p>因此，我们希望可以找到一个数据处理解决方案，这个方案在保留这些Unix/linux管道的设计哲学优点的同时还能克服其缺点。 幸运的是，我们通过Flink+Pravega打造的第三代“流原生”(stream native)式的大数据处理平台实现了这种设计思想。</p><h2 id="流原生-第三代大数据处理平台"><a href="#流原生-第三代大数据处理平台" class="headerlink" title="流原生,第三代大数据处理平台"></a>流原生,第三代大数据处理平台</h2><p>下图体现了“流原生”(stream native)式的设计哲学，Flink是“流原生”的计算，Pravega是“流原生”的存储管道，Flink + pravega 是“流原生”的大数据处理平台。数据从pravega管道输入经过map算子计算，输出中间计算结果到pravega的管道里，数据又从pravega的管道里读入到filter算子里，再经过计算，中间结果放到了pravega管道里，再最后的计算结果经过聚合算子的计算放到了目的地的pravega的管道里。这个过程体现了算子编排和管道式编程的设计哲学。在这里pravega起了大数据处理平台里的管道的作用。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/streaming%2Fstreaming-native-platform-3.PNG" alt="Stream processing pipeline"></p><p>在Unix/Linux中，系统提供管道和命令，用于从一个进程到另一个进程获取字节流。</p><p>在“流原生”处理平台上，Flink提供流处理服务，pravega提供流存储服务，数据源自pravega，被Flink算子们处理后输出到pravega，这是一种将事件从一个流处理作业转移到另一个流处理作业的机制。 Flink和Pravega 所遵循的流处理平台设计哲学是：</p><ul><li>每个算子都只做一件事，并且做到最好</li><li>每个算子的输出是另一个算子的输入</li><li>可组合</li><li>流式传输：数据是动态的，算子是静态的</li><li>算子可编排</li><li>Pravega是最好的Flink搭档</li><li>分布式，扩展到多台机器</li><li>可进化的编码/解码</li></ul><p>当前的流式处理平台一般是 Flink 加传统的存储类型，这种是”半流原生“式的大数据处理平台，计算是原生的流计算而存储却不是原生的流存储。<br>而Pravega就是专门给Flink们设计的原生流存储，它的数据传输方式类似于“管道”，不同于传统的块存储，文件存储以及对象存储，它是一个”管道式流存储“。</p><p>通过Flink + Pravega的组合可以实现 “流原生”(stream native)式的第三代大数据处理平台，未来已来。。。。。</p><h2 id="思考题"><a href="#思考题" class="headerlink" title="思考题"></a>思考题</h2><p>最后给大家留个思考题，“流原生”(stream native)的概念有了，Flink + Pravega 也有了，而且二者的代码都是开源的（flink.apache.org, pravega.io），那么怎么把这些开源的东西产品化？ 或者这个问题太伤脑筋，我们换个简单的问题：“今天中午吃什么？”</p>]]></content>
      
      
      <categories>
          
          <category> streaming </category>
          
      </categories>
      
      
        <tags>
            
            <tag> streaming </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>算命先生的阴阳五行学说与码农们的分布式系统设计理论</title>
      <link href="/2018/09/22/distributed-tradeoff/"/>
      <url>/2018/09/22/distributed-tradeoff/</url>
      
        <content type="html"><![CDATA[<h2 id="阴阳五行"><a href="#阴阳五行" class="headerlink" title="阴阳五行"></a>阴阳五行</h2><p>一说到阴阳五行就容易让人想到大街上的算命先生，然而阴阳五行学说却是中国古代解释世间万物的起源和多样性的哲学理论依据，是中国古代朴素的唯物论和自发的辩证法思想。</p><p>中国古代哲学的核心思想之一用“老子”的话来说就是：</p><blockquote><p>“道生一、一生二、二生三、三生万物，万物负阴而抱阳，冲气以为和。”。</p></blockquote><p>而五行学说讲的是:<code>“金 木 水 火 土”</code>这五行,五行相生又相克。<code>木头烧火——木生火；火烧木头成灰——火生土，土长期聚在一起生石头、石头里炼金——土生金，金销水——金生水，水又生土。</code>,<code>水克火，火克金，金克木，木克土，土克水。</code></p><p>但是如下图,五行虽然相生相克但都是为“和”字而服务的，即平衡：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed%2Fdistributed-tradeoff-1.PNG" alt="五行"></p><p>解读开来就是：</p><p><code>“天道生阴阳，阴阳成五行，五行变化成万物，而万物的存在方式和相互关系一直在追求一种“和谐”。</code>“道”在阴阳的相互作用下，产生五行，五行之间相互作用产生世间万物的无穷变化，并且阴阳之间对立消长，五行之间相生相克，自此万物得以和谐发展。借助于阴阳五行的核心要素以及由此而生的非核心要素关系把宇宙看成一个统一的整体，这样的整体：<code>循环平衡、相生相克、有刚有柔、和谐统一</code>。</p><p>那么这些玄乎的哲学理论跟码农又有什么关系呢？对于本人这么个靠技术混饭吃卖身又卖艺的码农来说，这实在太重要，归纳成一个字就是”和”，对应到技术实现体系里就是一个理念 ”权衡“，英文叫<code>tradeoff</code>。<code>“tradeoff”</code>这词实在是太妙了，啥都可以往上套，比如你十一准备到哪旅游啦，中午到哪吃饭啦，买哪里的房子啦，准备追哪个姑娘做老婆啦…….，都需要 <code>tradeoff</code>。技术如此人生又何尝不如是。</p><h2 id="分布式系统"><a href="#分布式系统" class="headerlink" title="分布式系统"></a>分布式系统</h2><p>通常来讲设计分布式系统的时候需要考虑的最重要的<code>核心要素</code>有五个，这里不是说其他要素就不重要，这是指经过<code>tradeoff</code>过的五个最重要的核心要素，如下图：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed%2Fdistributed-tradeoff-2.PNG" alt="分布式系统要素"></p><ol><li><p><code>Capacity</code>，容量，其实这个词翻译成”能力“会更合适，指的是分布式系统里的CPU，内存，硬盘，网络，文件描述符，socket连接数，老板的预期，开发周期，成本预算之类的限制条件,以下所有的要素都受 “容量”的限制，这是前提条件，就比如一辆车最多能跑多快，一个人最多能跳多高都是受自身“容量/能力”的限制的；</p></li><li><p><code>Performant</code>, performance + conformant, performant这词也是造的，指的是合适的性能，分布式系统的IOPS，TPS, QPS，Latency,Jitter之类的性能指标要求，性能受限于容量，性能同时又影响了可靠性以及可用性；</p></li><li><p><code>Availability</code>，可用性，可用性通常指的是产品或服务在随机时间内调用时处于可服务状态的概率，通常被定义为正常运行时间除以总时间（正常运行时间加停机时间），比如 5个9，6个9，还有个厂家都喜欢的号称的9个9之类的，可用性受容量的限制同时也受可伸缩性的影响，可用性又影响了性能；</p></li><li><p><code>Reliability</code>，可靠性，一般指的是出保证不出故障的概率，比如，企业级产品 5个9是保底，可测试性和可维护性通常被定义为可靠性当中的一部分，可伸缩性影响了可靠性，而可靠性又影响了可用性，同时性能又影响了可靠性，可靠性也影响着性能。</p></li><li><p><code>Scalability</code>，可伸缩性，这里很容易跟“可扩展性”混淆，可伸缩性可以指的是集群处理越来越多或越来越少的工作的能力，或者是为了适应这种增长或减少而扩大或缩小其能力的能力。可伸缩性影响了可用性，也影响了性能与可靠性，受限于容量。</p></li></ol><p>当然还有另外一些由此而衍生的非核心要素，就不多做详细解释了，比如：</p><ul><li>Testability，可测试性</li><li>Security，安全性</li><li>Observability，可观测性</li><li>Predictability，可预测性</li><li>Extensibility，可扩展性</li><li>Maintainability，可维护性</li><li>Serviceability， 可服务性</li></ul><p>这些非核心要素虽然是非核心但是也不是说就不重要，是<code>开源产品与商业产品</code>差异的关键，关键在如何<code>tradeoff</code>。</p><h2 id="阴阳五行与分布式系统"><a href="#阴阳五行与分布式系统" class="headerlink" title="阴阳五行与分布式系统"></a>阴阳五行与分布式系统</h2><p>将阴阳五行理论与分布式系统设计理论结合起来解读就是：</p><p><code>分布式系统里的“道”就是“产品”，“阴阳“ 就是 ”功能“ 与 “非功能”，五行就是 ”容量、性能、可用性、可伸缩性以及可靠性“，阴阳五行衍生的一些其他关系对应分布式系统五要素衍生的一些其他要素。</code></p><p>用人话来讲就是 开发产品的时候需要考虑功能与非功能两个方面，而要保证产品质量又需要考虑”容量、性能、可用性、可伸缩性以及可靠性“这些核心要素，但是也不能忽略由此而生的一些非核心要素。</p><p>那么从这些理论到产品又需要怎么做才能落地呢？ 那自然是需要 <code>懂得如何把从这些概念性的、功能的、非功能的、这些核心的、非核心的要素进行设计实现成代码</code>，这就涉及到 “术”的层面了，“道”的层面可以通过看书看论文获得，而<code>“术”</code>的获得除了自身努力还得靠机会，而且每个人的悟性还不一样，这些个”术“以后有空慢慢讲。</p><h2 id="思考题"><a href="#思考题" class="headerlink" title="思考题"></a>思考题</h2><p>最后给大家留一个思考题： 前面提过老子曰：<code>”道生一、一生二、二生三、三生万物，万物负阴而抱阳，冲气以为和。“</code>， 三之后就是万物，为什么不是 五、不是六、不是七之类的呢？为什么三之后就是万物了？</p><hr><h4 id="注："><a href="#注：" class="headerlink" title="注："></a>注：</h4><ol><li>这个用五行解释分布式系统的观点，以前在一个业内微信群里提出并且聊过，所以这个解读的方式为本人原创非COPY.</li><li>个人愚钝，悟性有限，欢迎拍砖，砖多了我就拿回去砌墙。</li></ol><h3 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h3><p>[1]. <a href="https://baike.sogou.com/v7556185.htm" target="_blank" rel="noopener">https://baike.sogou.com/v7556185.htm</a></p>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>应该在同一个Kafka主题中放入几种事件类型吗？</title>
      <link href="/2018/09/21/streaming-put-several-event-types-kafka-topic/"/>
      <url>/2018/09/21/streaming-put-several-event-types-kafka-topic/</url>
      
        <content type="html"><![CDATA[<p>如果您采用Apache Kafka等流平台，有个很重要的问题是：将使用哪些主题？特别是，如果要将一堆不同的事件作为消息发布到Kafka，是将它们放在同一主题中，还是将它们拆分为不同的主题？</p><p>主题最重要的功能是允许使用者指定它想要使用的消息子集。在一个极端情况下，所有数据都放在一个主题中可不是一个好主意，因为这意味着消费者无法选择感兴趣的事件 - 给他们的只会是所有的内容。在另一个极端，拥有数百万个不同的主题也不是一个好事，因为Kafka中的每个主题都会消耗资源消耗，因此拥有大量的主题就会对性能不利。</p><p>实际上，从性能的角度来看，重要的是分区数量。但由于Kafka中的每个主题至少有一个分区，如果你有n个主题，那么就不可避免地至少有n个分区。不久之前，[Jun Rao撰写了一篇博文]，解释了拥有多个分区的成本（端到端延迟，文件描述符，内存开销，故障后的恢复时间）。根据经验，如果您关注延迟问题，您应该关注每个代理节点上的（数量级）数百个主题分区。如果每个节点有数万个甚至数千个分区，则延迟会受到影响。</p><p>该性能参数给设计主题的结构提供了一些指导：如果您发现自己有数千个主题，那么将一些细粒度，低吞吐量的主题合并到粗粒度主题中是明智之举，从而减少分区的扩散。</p><p>然而，性能问题并不是结束。在我看来，更重要的是您的主题结构的数据完整性和数据建模方面。我们将在本文的其余部分讨论这些内容。</p><h2 id="主题-相同类型的事件的集合？"><a href="#主题-相同类型的事件的集合？" class="headerlink" title="主题=相同类型的事件的集合？"></a>主题=相同类型的事件的集合？</h2><p>常见的想法（根据我所拥有的几个对话，并根据邮件列表）似乎是：将同类型的所有事件放在同一主题中，并针对不同的事件类型使用不同的主题。这种思路让人联想到关系数据库，其中表是具有相同类型（即同一组列）的记录的集合，因此我们在关系表和Kafka主题之间进行类比。</p><p>该<a href="https://www.confluent.io/confluent-schema-registry/" target="_blank" rel="noopener">融合模式的注册表</a>本质上强化了这种模式，因为它鼓励你在主题中的所有消息使用相同的Avro模式。该模式可以在保持兼容性的同时进化（例如，通过添加可选字段），但最终所有消息都必须符合某种记录类型。在我们介绍了更多背景之后，我们将在后面的帖子中再次讨论这个问题。</p><p>对于某些类型的流数据（例如记录的活动事件），要求同一主题中的所有消息都符合相同的模式是有意义的。但是，有些人正在使用Kafka来实现更多类似数据库的目的，例如事件溯源，或者在微服务之间交换数据。在这种情况下，我相信，它定义一个主题为一组具有相同模式的消息并不重要。更重要的是Kafka维护主题分区内的消息排序。</p><p>想象一下，您有一些事物（比如客户），并且该事物可能发生许多不同的事情：创建客户，客户更改地址，客户向其帐户添加新信用卡，客户进行客户支持查询，客户支付发票，客户关闭其帐户。</p><p>这些事件的顺序很重要。例如，我们期望在客户做任何动作之前创建客户，并且我们也期望在客户关闭其帐户之后不再发生任何其他事情。使用Kafka时，您可以通过将它们全部放在同一个分区中来保留这些事件的顺序。在此示例中，您将使用客户ID作为分区键，然后将所有这些不同的事件放在同一主题中。它们必须位于同一主题中，因为不同的主题意味着不同的分区，并且不会跨分区保留排序。</p><h2 id="排序问题"><a href="#排序问题" class="headerlink" title="排序问题"></a>排序问题</h2><p>如果你没有使用（比方说）不同的主题<code>customerCreated</code>，<code>customerAddressChanged</code>和<code>customerInvoicePaid</code>事件，然后这些议题的消费者可能会看到荒谬的事件顺序。例如，消费者可能会看到不存在的客户的地址更改（因为尚未创建，因为相应的<code>customerCreate</code>事件已被延迟）。</p><p>如果消费者暂停一段时间（可能是维护或部署新版本），则重新排序的风险尤其高。当消费者停止时，事件将继续发布，并且这些事件将存储在Kafka代理的选定主题分区中。当消费者再次启动时，它会消耗来自其所有输入分区的积压事件。如果消费者只有一个输入，那就没问题了：挂起的事件只是按照它们存储的顺序依次处理。但是，如果消费者有几个输入主题，它将选择输入主题以按任意顺序读取。它可以在读取另一个输入主题上的积压之前从一个输入主题读取所有挂起事件，或者它可以以某种方式交错输入。</p><p>因此，如果你把<code>customerCreated</code>，<code>customerAddressChanged</code>以及<code>customerInvoicePaid</code>事件在三个独立的主题，消费者可能会看到所有的<code>customerAddressChanged</code>事件，它看到任何之前<code>customerCreated</code>的事件。因此，消费者可能会看到一个<code>customerAddressChanged</code>客户的事件，根据其对世界的看法，尚未创建。</p><p>您可能想要为每条消息附加时间戳，并将其用于事件排序。如果要将事件导入数据仓库，您可以在事后对事件进行排序，这可能就可以了。但是在流进程中，时间戳是不够的：如果你得到一个具有特定时间戳的事件，你不知道你是否仍然需要等待一个时间戳较低的先前事件，或者所有之前的事件是否已到达而你是’准备好处理这个事件。依靠时钟同步通常会导致噩梦;</p><h2 id="何时分割主题，何时结合？"><a href="#何时分割主题，何时结合？" class="headerlink" title="何时分割主题，何时结合？"></a>何时分割主题，何时结合？</h2><p>鉴于这种背景，我将提出一些经验法则来帮助您确定在同一主题中放入哪些内容，以及将哪些内容拆分为单独的主题：</p><ol><li><p>最重要的规则是，  任何需要保持固定顺序的事件必须放在同一主题中（并且它们也必须使用相同的分区键）。最常见的是，如果事件的顺序与同一事物有关，则事件的顺序很重要。因此，根据经验，我们可以说关于同一事物的所有事件都需要在同一主题中。如果您使用事件排序方法进行数据建模，事件的排序尤为重要。这里，聚合对象的状态是通过以特定顺序重放它们来从事件日志中导出的。因此，即使可能存在许多不同的事件类型，定义聚合的所有事件也必须在同一主题中。</p></li><li><p>当您有关于不同事物的事件时，它们应该是相同的主题还是不同的主题？我想说，如果一个事物依赖于另一个事物（例如，一个地址属于一个客户），或者如果它们经常需要在一起，那么它们也可能会出现在同一个主题中。另一方面，如果它们不相关并由不同的团队管理，则最好将它们放在单独的主题中。它还取决于事件的吞吐量：如果一个事物类型具有比另一个事物类型高得多的事件，它们是更好地分成单独的主题，以避免压倒性的消费者只想要具有低写入吞吐量的事物（参见第4点）。但是，几个都具有低事件率的事物可以很容易地合并。</p></li><li><p>如果一个事件涉及多个事物怎么办？例如，购买涉及产品和客户，并且从一个帐户到另一个帐户的转移涉及至少那两个帐户。我建议最初将事件记录为单个原子消息，而不是将其分成几个消息。主题，最好以完全按照您收到的方式记录事件，并尽可能采用原始形式。您可以随后使用流处理器拆分复合事件 - 但如果您过早地将其拆分，则重建原始事件要困难得多。更好的是，您可以为初始事件提供唯一ID（例如UUID）; 以后，当您将原始事件拆分为每个涉及的事物的一个事件时，您可以将该ID转发，从而使每个事件的起源都可追溯。</p></li><li><p>查看消费者需要订阅的主题数量。如果几个消费者都阅读了一组特定的主题，这表明可能应该将这些主题组合在一起。如果将细粒度的主题组合成粗粒度的主题，一些消费者可能会收到他们需要忽略的不需要的事件。这不是什么大问题：消费来自Kafka的消息非常便宜，所以即使消费者最终忽略了一半的事件，这种过度消费的成本可能也不大。只有当消费者需要忽略绝大多数消息（例如99.9％是不需要的）时，我才建议从高容量流中分割低容量事件流。</p></li><li><p>Kafka Streams状态存储（KTable）的更改日志主题应与所有其他主题分开。在这种情况下，主题由Kafka Streams流程管理，不应与其他任何内容共享。</p></li><li><p>最后，如果上述规则都没有告诉您是否将某些事件放在同一主题或不同主题中，该怎么办？然后，通过将相同类型的事件放在同一主题中，通过所有方法将它们按事件类型分组。但是，我认为这条规则是最不重要的。</p></li></ol><h2 id="模式管理"><a href="#模式管理" class="headerlink" title="模式管理"></a>模式管理</h2><p>如果您使用的是数据编码（如JSON），而没有静态定义的模式，则可以轻松地将许多不同的事件类型放在同一主题中。但是，如果您使用的是基于模式的编码（如Avro），则需要更多地考虑在单个主题中处理多个事件类型。</p><p>如上所述，基于Avro的<code>Kafka Confluent Schema Registry</code>目前依赖于每个主题都有一个模式的假设（或者更确切地说，一个模式用于密钥，一个模式用于消息的值）。您可以注册新版本的模式，注册表会检查模式更改是向前还是向后兼容。这个设计的一个好处是，您可以让不同的生产者和消费者同时使用不同的模式版本，并且它们仍然保持彼此兼容。</p><p>更确切地说，当Confluent的Avro序列化程序在注册表中注册模式时，它会在主题名称下注册。默认情况下，该主题<code>&lt;topic&gt;-key</code>用于消息键和<code>&lt;topic&gt;-value</code>消息值。然后，模式注册表检查在特定主题下注册的所有模式的相互兼容性。</p><p>我最近对<a href="https://github.com/confluentinc/schema-registry/pull/680" target="_blank" rel="noopener">Avro序列化程序进行了修补</a>，使兼容性检查更加灵活。该补丁添加了两个新的配置选项:(<code>key.subject.name.strategy</code>定义如何构造消息键的主题名称），以及<code>value.subject.name.strategy</code>（如何构造消息值的主题名称）。选项可以采用以下值之一：</p><ul><li><p><code>io.confluent.kafka.serializers.subject.TopicNameStrategy</code>（默认值）：消息键的主题名称是<code>&lt;topic&gt;-key</code>，<code>&lt;topic&gt;-value</code>对于消息值。这意味着主题中所有消息的模式必须相互兼容。</p></li><li><p><code>io.confluent.kafka.serializers.subject.RecordNameStrategy</code>：主题名称是邮件的Avro记录类型的完全限定名称。因此，模式注册表会检查特定记录类型的兼容性，而不考虑主题。此设置允许同一主题中的任意数量的不同事件类型。</p></li><li><p><code>io.confluent.kafka.serializers.subject.TopicRecordNameStrategy</code>：主题名称是<code>&lt;topic&gt;-&lt;type&gt;</code>，<code>&lt;topic&gt;Kafka</code>主题名称在哪里，并且<type>是邮件的Avro记录类型的完全限定名称。此设置还允许同一主题中的任意数量的事件类型，并进一步将兼容性检查限制为仅当前主题。</type></p></li></ul><p>使用此新功能，可以轻松，干净地将特定事物的所有不同事件放在同一主题中。现在，可以根据上述条件自由选择主题的粒度，而不仅限于每个主题的单个事件类型。</p><h2 id="原文："><a href="#原文：" class="headerlink" title="原文："></a>原文：</h2><p>[1] <a href="https://www.confluent.io/blog/put-several-event-types-kafka-topic/" target="_blank" rel="noopener">https://www.confluent.io/blog/put-several-event-types-kafka-topic/</a>, Martin KleppmannMartin Kleppmann</p>]]></content>
      
      
      <categories>
          
          <category> streaming </category>
          
      </categories>
      
      
        <tags>
            
            <tag> streaming </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Pravega handbook - 控制器服务之三</title>
      <link href="/2018/09/20/pravega-controller-service-3/"/>
      <url>/2018/09/20/pravega-controller-service-3/</url>
      
        <content type="html"><![CDATA[<h2 id="角色和责任"><a href="#角色和责任" class="headerlink" title="角色和责任"></a>角色和责任</h2><h3 id="流操作"><a href="#流操作" class="headerlink" title="流操作"></a>流操作</h3><p>控制器是所有流相关元数据的真实存储。Pravega客户端（EventStreamReaders和EventStreamWriters）与控制器一起确保流不变量在流上工作时得到满足和尊重。控制器维护流的元数据，包括段的整个历史。访问流的客户端需要联系控制器以获取有关段的信息。<br>客户端查询控制器以了解如何导航流。为此，控制器公开适当的API以获取活动段，后继者，前驱者和段信息以及Uris。这些查询使用存储和通过流存储接口访问元数据来提供这些查询服务。<br>Controller还提供了修改流的状态和行为的工作流程。这些工作流程包括创建，缩放，截断，更新，密封和删除。这些工作流程既可以通过直接API调用，也可以通过后台策略管理器（自动调整和保留）调用。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega%2FRequestProcessing.png" alt="RequestProcessing"><br>请求处理流程</p><h2 id="创建流"><a href="#创建流" class="headerlink" title="创建流"></a>创建流</h2><p>创建流是作为任务框架上的任务来实现的。创建流工作流首先创建流状态设置为CREATING * 的初始流元数据。在此之后，它标识应该拥有的段容器并为此流创建段并同时调用create-segment。完成所有创建段后，创建流任务完成，从而将流移动到ACTIVE状态。所有故障都会以指数退避重试几次。但是，如果它无法完成任何步骤，则流将保持在CREATING状态。</p><h2 id="更新流"><a href="#更新流" class="headerlink" title="更新流"></a>更新流</h2><p>更新流被实现为序列化请求处理程序/并发事件处理器框架上的任务。更新流由显式API调用来调用到控制器中。它首先将更新请求事件发布到请求流中。之后，它尝试创建临时更新属性。如果它无法创建临时更新属性，则请求失败，并且会通知调用方由于与另一个正在进行的更新冲突而无法更新流。</p><p>事件由请求事件处理器选择。处理开始时，更新流任务期望找到要存在的临时更新流属性。如果找不到该属性，则通过将事件推回到内存中队列中来延迟更新处理，直到它认为事件已过期为止。如果在此期间找到要更新的属性，则在到期之前，处理该事件并执行更新流操作。现在处理开始，它首先将状态设置为UPDATING。在此之后，在元数据存储中更新流配置，然后通知段存储关于流的所有活动段关于策略的改变。现在状态重置为ACTIVE。</p><h3 id="缩放流"><a href="#缩放流" class="headerlink" title="缩放流"></a>缩放流</h3><p>可以通过显式API调用（称为手动缩放）调用缩放，也可以基于缩放策略自动执行缩放（称为自动缩放）。我们首先编写事件，然后通过为要创建的所需段创建新条目来更新段表。此步骤是幂等的，并确保如果正在进行现有的缩放操作，则此启动新的缩放的尝试失败。处理的开始类似于更新流中遵循的机制。如果更新元数据，则事件处理并继续执行任务。如果元数据未在期望的时间范围内更新，则事件被丢弃。</p><p>一旦缩放处理开始，它首先设置流状态SCALING。然后在段存储中创建新段。在成功创建新段之后，它使用对应于新时期的部分记录更新历史表，该新时期包含按比例显示的段列表。每个新的时期创建还创建新的根历元节点，在该节点下，来自该时期的所有事务的元数据驻留在该节点上。因此，当执行比例时，将存在与旧时期对应的节点，并且现在还将存在用于新时期的根节点。从这一点开始创建的任何事务都将针对新时期进行。现在，工作流尝试通过机会性地尝试删除旧时期来完成缩放。当且仅当其名下没有事务时，可以删除旧时期。一旦我们确定旧时期没有事务，我们就可以继续密封旧的段并完成规模。成功密封旧段后，历史表中的部分记录现已完成，从而完成了缩放工作流程。状态现在重置为ACTIVE。</p><h3 id="截断流"><a href="#截断流" class="headerlink" title="截断流"></a>截断流</h3><p>Truncate遵循类似的机制进行更新，并具有用于截断的临时流属性，用于为截断流提供输入。一旦截断工作流标识它可以继续，它首先将状态设置为TRUNCATING。然后截断工作流查看请求的流截断，并检查它是否大于或等于现有截断点，然后它才是截断的有效输入并且工作流程开始。截断工作流接受请求的流截断，并计算要作为此截断请求的一部分删除的所有段。然后它调用相应的段存储来删除已识别的段。删除后，我们称在截止流中截断的流中描述的截断段，如流截断中所述。在此之后，截断记录将使用新的截断点和已删除的段进行更新。状态重置为ACTIVE。</p><h2 id="密封流"><a href="#密封流" class="headerlink" title="密封流"></a>密封流</h2><p>可以通过对控制器的显式API调用来请求密封流。它首先将密封流事件发布到请求流中，然后尝试将流的状态设置为SEALING。如果事件被挑选并且没有找到流处于期望状态，则它通过将其重新发布在内存队列的后面来推迟密封流处理。一旦流被设置为密封状态，流的所有活动段都通过调用段存储来密封。在此之后，流在流元数据中被标记为SEALED。</p><h3 id="删除流"><a href="#删除流" class="headerlink" title="删除流"></a>删除流</h3><p>可以通过对控制器的显式API调用来请求删除流。请求首先验证流是否处于SEALED状态。只有密封的流才能被删除，并在请求流中发布这样的事件。当事件被处理，它会再次验证流状态，然后通过调用段存储来继续从一开始就删除属于该流的所有段。成功删除所有段后，将清除与此流对应的流元数据。</p><h2 id="流策略管理器"><a href="#流策略管理器" class="headerlink" title="流策略管理器"></a>流策略管理器</h2><p>如前所述，控制器负责执行的用户定义策略有两种类型，即自动缩放和自动保留。Controller不仅仅是流策略的存储，而是主动为其流实施这些用户定义的策略。</p><h3 id="缩放基础架构"><a href="#缩放基础架构" class="headerlink" title="缩放基础架构"></a>缩放基础架构</h3><p>缩放基础架构与段存储一起构建。当控制器在段存储中创建新段时，它会将用户定义的缩放策略传递给段存储。然后，段存储监视所述段的流量，并且如果违反了从策略确定的某些阈值，则向控制器报告。Controller通过在专用内部流中发布的事件接收这些通知。可以为段接收两种类型的流量报告。第一种类型标识是否应该按比例放大（拆分）段，第二种类型标识是否应按比例缩小段。对于符合条件进行缩放的段，控制器会立即在请求流中发布段缩放请求，以便处理请求事件处理器。但是，为了缩小规模，控制器需要等待至少两个相邻的段，才有资格进行缩小。为此，它只是在元数据存储中将该段标记为冷。如果有相邻的段标记为冷，控制器会将它们合并，并发布缩小请求。然后，在请求事件处理器上异步执行缩放处理请求。</p><h3 id="保留基础设施"><a href="#保留基础设施" class="headerlink" title="保留基础设施"></a>保留基础设施</h3><p>保留策略定义了应为给定流保留多少数据。这可以定义为基于时间或基于大小的。为了应用此策略，控制器定期收集流的流截断，并且如果策略指定，则有机会地对先前收集的流截断执行截断。由于这是需要为已定义保留策略的所有流执行的定期后台工作，因此迫切需要在所有可用的控制器实例之间公平地分配此工作负载。为实现这一点，我们依赖于将流转储到预定义集中，并在控制器实例之间分发这些集。这是通过使用zookeeper来存储此分发来完成的。在引导期间，每个控制器实例都尝试获取存储桶的所有权。拥有控制器监视桶下的所有流以保留机会。在每个周期里，控制器收集新的流截断并将其添加到所述流的保留集中。发布此消息后，它会查找存储在保留集中的候选流截断，这些流截断可以根据定义的保留策略进行截断。例如，在基于时间的保留中，选择早于指定保留期的最新流截断作为截断点。</p><h2 id="事务管理器"><a href="#事务管理器" class="headerlink" title="事务管理器"></a>事务管理器</h2><p>控制器扮演的另一个重要角色是事务管理器。它负责创建，提交和中止事务。由于控制器是我们集群中的核心大脑和机构，并且是关于流的真实的持有者，因此writer请求控制器执行关于事务的所有控制平面动作。从创建事务到提交或中止事务的时间起，控制器在为事务提供保证方面发挥着积极作用。控制器跟踪每个事务的指定超时，如果超时超过，它会自动中止事务。</p><p>控制器负责确保事务和潜在的并行规模操作相互配合，确保所有承诺都得到尊重和执行。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega%2FTransactionManagement.png" alt="TransactionManagement"></p><p>事务管理图</p><p>客户端调用控制器进程来创建，ping提交或中止事务。这些请求中的每一个都在控制器上接收并由Transaction Utility模块处理，该模块实现用于处理每个请求的业务逻辑。</p><h3 id="创建事务"><a href="#创建事务" class="headerlink" title="创建事务"></a>创建事务</h3><p>writer与Controller交互以创建新事务。Controller Service将创建事务请求传递给事务工具Utility模块。模块中的create transaction函数执行以下步骤以创建事务：1。为事务生成唯一的UUID。2.它从元数据存储中获取流的当前活动的一组段，并从历史中获取其对应的时期标识符。3.它使用元数据存储接口在zookeeper中创建新的事务记录。4.然后，它请求段存储创建特定的事务段，这些段本质上链接到父活动段。<br>在创建事务时，控制器确保在我们尝试创建相应的事务段时不会密封父段。并且在事务的生命周期中，如果缩放开始，它应该等待旧时期事务在缩放之前完成，以便从旧时期密封段。</p><h3 id="提交事务"><a href="#提交事务" class="headerlink" title="提交事务"></a>提交事务</h3><p>在收到提交事务的请求后，Controller Service将请求传递给Transaction Utility模块。该模块首先尝试通过元数据存储来标记事务特定元数据记录中的提交事务。在此之后，它在内部提交流中发布提交事件。提交事务工作流在提交事件处理器上实现，从而异步处理。提交事务工作流检查提交事务的是否合格，如果为true，则执行提交工作流，无限期重试，直到成功为止。如果事务不符合提交条件（通常在旧时期仍处于活动状态时在新时期上创建事务时发生），则此类事件将重新发布到内部流中以便稍后选取。</p><p>成功提交事务后，事务的记录将从其时期根下被删除。然后，如果存在一个正在进行的缩放，则它呼叫尝试完成正在进行的缩放。试图完成缩放取决于删除旧时期的能力，当且仅当没有针对所述时期的未完成的活动事务时才能删除（有关更多细节，请参阅缩放工作流程）。</p><h3 id="中止事务"><a href="#中止事务" class="headerlink" title="中止事务"></a>中止事务</h3><p>可以通过应用程序明确请求中止，类似于提交。但是，如果事务超时，则也可以自动启动中止。控制器跟踪系统中每个事务的超时，并且每当超时过去时，或者在显式用户请求时，事务实用程序模块在其各自元数据中将事务标记为中止。在此之后，事件被中止事件处理器处理，并立即尝试中止事务。中止事务没有排序要求，因此它同时并跨流执行。</p><p>与提交一样，一旦事务中止，其节点将从其时期根目录中删除，如果存在持续的缩放，则尝试完成缩放流。</p><h3 id="Ping事务"><a href="#Ping事务" class="headerlink" title="Ping事务"></a>Ping事务</h3><p>由于控制器对于正在写入事务中的段的数据没有对数据路径的可见性，因此控制器不知道是否正在主动处理事务，并且如果超时过去，它可能会尝试中止事务。为了使应用程序能够控制事务的命运，控制器公开API以允许应用程序更新事务超时期限。这种机制称为ping，只要应用程序ping事务，控制器就会为各自的事务重置其计时器。</p><h3 id="事务超时管理"><a href="#事务超时管理" class="headerlink" title="事务超时管理"></a>事务超时管理</h3><p>控制器跟踪每个事务的超时。这是作为定时轮服务实现的。创建后，每个事务都会在创建它的控制器上注册到计时器服务中。可以在不同的控制器实例上接收事务的后续ping，并且基于通过zookeeper实现的所有权机制将定时器管理转移到最新的控制器实例。超时到期后，将尝试自动中止，如果能够成功将事务状态设置为中止，则启动中止工作流。</p><p>控制器监视超时的每个事务都会添加到此进程索引中。如果此类控制器实例失败或崩溃，则其他控制器实例将收到节点失败通知，并尝试从失败的实例中扫描所有未完成的事务，并从该点开始监视其超时。</p><h2 id="段容器到主机映射"><a href="#段容器到主机映射" class="headerlink" title="段容器到主机映射"></a>段容器到主机映射</h2><p>Controller还负责将段容器分配给段存储节点。维护此映射的责任落在单个控制器实例上，该实例是通过使用zookeeper的领导者选举选择的。当段存储节点被添加到/从集群中移除时，该领导控制器监视段存储节点的生命周期，并且跨可用的段存储节点执行段容器的重新分配。此分发映射存储在专用ZNode中。每个段存储周期性地轮询此znode以查找更改，如果找到更改，它将关闭并放弃它不再拥有的容器，并尝试获取分配给它的容器的所有权。</p><p><a href="http://pravega.io/docs/latest/controller-service/#controllerClusterListener" target="_blank" rel="noopener">这里</a>已经讨论了有关实现的细节，特别是关于如何存储和管理元数据的细节。</p>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Pravega handbook - 控制器服务之二</title>
      <link href="/2018/09/20/pravega-controller-service-2/"/>
      <url>/2018/09/20/pravega-controller-service-2/</url>
      
        <content type="html"><![CDATA[<h2 id="流元数据"><a href="#流元数据" class="headerlink" title="流元数据"></a>流元数据</h2><p>客户端需要有关哪些段构成流的信息以开始其处理，并且他们从控制器存储在流存储中的时期信息中获取它。读取器客户端通常从流的头部开始，但它也可以选择从任意有趣的位置开始访问流。另一方面，writer总是附加到流的尾部。<br>客户端需要能够有效地查询和查找在以下三种场景中的任何一个段。为了启用这些查询，流存储提供API调用来获取这些段的初始集合、在特定时间获取段以及获取段的当前集合。</p><p>如前所述，流可以从一组段（epoch）转换到构成流的另一组段。如果至少一个段被密封，并且被一个或多个精确覆盖密封段的密钥空间的段替换，则流从一个时期移动到另一个时期。当客户在流上工作时，他们可能会遇到密封段的末端，因此需要找到新的段才能继续前进。为了使客户端能够查询下一个段，流存储库通过控制器服务公开有效查询，以查找任意段的直接后继和前驱。</p><p>为了启用上述服务查询，我们需要有效地存储这些段转换的时间序列，并将它们与时间进行索引。我们在一组表中存储有关流段的当前和历史状态的信息，这些表被设计为旨在针对上述查询进行优化。除了特定于段的元数据记录之外，流的当前状态包括此后描述的其他元数据类型。</p><h2 id="表"><a href="#表" class="headerlink" title="表"></a>表</h2><p>为了有效地存储和查询段信息，我们将段数据拆分为三个仅附加表，即段表，历史表和索引表。</p><ul><li><p>段表<br>segment-info：segmentid，time，keySpace-start，keySpace-end<br>控制器将段表存储在仅附加表中，第 i 行对应于段id i的元数据。值得注意的是，段表中的每一行都是固定大小的。当添加新的段时，它们将按严格增加的顺序分配新的段ID。因此，该表非常有效地创建新段并使用O（1）处理来查询段信息响应方面非常有效。</p></li><li><p>历史表<br>epoch：时间，历史中的片段列表<br>历史表在从一个时期过渡到另一个时期时存储一系列活动段。历史表中的每一行都存储一个epoch，该epoch捕获一组逻辑上一致的（如前面定义的）段，这些段组成流，并且在该epoch的生命周期内是有效的。此表旨在优化查询以查找在任意时间形成流的段集。有三种最常用的场景，我们希望有效地知道形成流的段集 - 初始的段集，当前的段和段的任意时间段。前两个查询在O（1）时间内非常有效地回答，因为它们对应于表中的第一行和最后一行。由于表中的行是按时间的增加顺序排序的，并且捕获了流段集变化的时间序列，因此我们可以很容易地执行二进制搜索来查找在任何任意时间对应于段集的行。</p></li></ul><ul><li>索引表<br>index：⟨time，offset-in-history-table⟩<br>由于历史行的长度是可变的，因此我们为索引表中的时间戳索引历史记录行。这使我们能够浏览历史表并执行二分查找以有效地回答查询以在任意时间获得段集。我们还对历史表执行二分查找以确定任何给定段的后继。</li></ul><h2 id="流配置"><a href="#流配置" class="headerlink" title="流配置"></a>流配置</h2><p>Znode，其中流配置被序列化并持久化。流配置包含需要强制实施的流策略。缩放策略和保留策略由应用程序在创建流时提供，并由控制器通过监视流中数据的速率和大小来强制执行。缩放策略描述了是否以及何时根据流中的传入流量条件自动缩放。该策略支持两种风格 -每秒事件的速率的流量和每秒的字节速率的流量。应用程序通过缩放策略将它们所需的流量指定到每个段，并选择所提供的值来计算确定何时缩放给定流的阈值。保留策略描述了需要保留到此流的pravega集群中的数据量。我们支持基于时间和基于大小的保留策略，其中应用程序可以选择是否希望通过选择适当的策略并提供其所需值来按大小或时间保留流中的数据。</p><h2 id="流状态"><a href="#流状态" class="headerlink" title="流状态"></a>流状态</h2><p>Znode捕获流的状态。它是一个枚举，包含来自创建，活动，更新，缩放，截断，密封和密封流的值。一旦激活，流在执行特定操作和活动之间转换，直到它被密封。转换映射在State 类中定义 ，允许和禁止各种状态转换。流状态描述了流的当前状态。它基于在流上执行的动作从ACTIVE转换到相应的动作。例如，在缩放期间，流的状态从ACTIVE转换为SCALING一旦缩放完成，它就会转换回ACTIVE。流状态用作屏障，以确保在任何时间点仅对给定流执行一种类型的操作。仅允许某些状态转换，并在状态转换对象中进行描述。只允许合法的状态转换，任何不允许转换的尝试都会导致适当的异常。</p><h2 id="截断记录"><a href="#截断记录" class="headerlink" title="截断记录"></a>截断记录</h2><p>这对应于最后用于截断给定流的流截断。所有流段查询都会叠加截断记录并返回严格大于或等于截断记录中的流截断的段。</p><h2 id="密封段记录"><a href="#密封段记录" class="headerlink" title="密封段记录"></a>密封段记录</h2><p>由于段表仅附加，因此在密封段时我们需要保留的任何其他信息都存储在密封段记录中。目前，它简单地包含了段号到其密封大小的映射。</p><h2 id="与事务相关的元数据记录："><a href="#与事务相关的元数据记录：" class="headerlink" title="与事务相关的元数据记录："></a>与事务相关的元数据记录：</h2><h3 id="活动事务"><a href="#活动事务" class="headerlink" title="活动事务"></a>活动事务</h3><p>每个新事务都是在此Znode下创建的。这将与每个事务相对应的元数据存储为ActiveTransactionRecord。事务完成后，将在全局完成事务znode节点下创建一个新节点，并从流特定活动事务节点下删除该节点。</p><h3 id="完成事务"><a href="#完成事务" class="headerlink" title="完成事务"></a>完成事务</h3><p>完成后，所有流的所有已完成事务都将在此单个znode下移动（通过提交或中止路径）。随后，我们可以根据我们认为合适的任何收集方案定期回收这些值。不过在这一点上，我们此时尚未实施任何计划。</p><h2 id="流存储缓存"><a href="#流存储缓存" class="headerlink" title="流存储缓存"></a>流存储缓存</h2><p>由于同一个控制器实例可以处理给定流的多个并发请求，因此每次通过查询zookeeper来读取该值是不合理的。因此，我们引入了每个流存储维护的内存缓存。它缓存每个流的检索元数据，使得缓存中每个流最多有一个数据副本。我们有两个内存缓存 - a）存储中多个流对象的缓存，b）流对象中流的缓存属性。</p><p>我们引入了操作上下文的概念，并且在任何新操作开始时创建了新的操作上下文。新操作上下文的创建使流的高速缓存实体无效，并且每当请求时都从存储中懒惰地检索每个实体。如果在操作过程中更新了值，则该值在缓存中再次无效，以便流上的其他并发读取/更新操作获取其后续步骤的新值。<br>流桶</p><p>为了启用某些场景，我们可能需要我们的后台工作人员定期处理群集中的每个流，以对它们执行某些特定操作。我们引入了一个桶的概念，以便在所有可用的控制器实例中分发此定期后台工作。为此，我们将每个流散列到一个预定义的存储桶中，然后在可用的控制器实例之间分配存储桶。<br>群集的桶数是群集生命周期的固定（可配置）值。<br>控制器实例将系统中的所有可用流映射到桶中，并在它们之间分配桶，以便所有长时间运行的后台工作可以在多个控制器实例之间均匀分布。每个桶对应于zookeeper中的唯一Znode。完全限定范围流名称用于计算散列以将流分配给桶。所有控制器实例在启动时都会尝试获取存储桶的所有权。在故障转移时，所有权都会转移，因为幸存的节点竞争以获取孤立桶的所有权。拥有存储桶的控制器实例负责与存储桶下所有节点相对应的所有长时间运行的调度后台工作。目前，这需要运行周期性工作流来捕获每个流的流截断（称为保留集）。</p><h2 id="保留集"><a href="#保留集" class="headerlink" title="保留集"></a>保留集</h2><p>每个流的一个保留集存储在相应的桶/流Znode下。当我们定期计算流截断时，我们会在此Znode下保留它们。在执行某些自动截断时，将从此集中清除不再有效的流截断。</p><h2 id="控制器群集Listener"><a href="#控制器群集Listener" class="headerlink" title="控制器群集Listener"></a>控制器群集Listener</h2><p>Pravega 集群中的每个节点都在集群Znode下作为短暂节点注册。这包括控制器和段存储节点。每个控制器实例在集群Znode上注册监视，以侦听集群更改通知。这些通知是关于节点添加和删除的。</p><p>一个控制器实例承担所有控制器实例的领导。此领导者控制器实例负责处理段存储节点更改通知。根据拓扑结构的变化，控制器实例会定期将段容器重新平衡为段存储节点映射。</p><p>所有控制器实例都侦听控制器节点更改通知。每个控制器实例都有多个子组件，用于实现故障转移 - 清除程序接口。目前有三个组件实现故障转移清除程序接口，即 TaskSweeper，EventProcessors和TransactionSweeper。每当识别出控制器实例已从群集中删除时，群集侦听器将调用所有已注册的故障转移清除程序，以便乐观地尝试清除先前由故障控制器主机拥有的所有孤儿工作。</p><h3 id="主机存储"><a href="#主机存储" class="headerlink" title="主机存储"></a>主机存储</h3><p>主机存储接口用于将Segment Container存储到Segment Store节点映射。它公开了像getHostForSegment这样的API，它计算了段ID的一致哈希值来计算所有者Segment Container。然后基于容器 - 主机映射，它将适当的URL返回给调用者。</p><h2 id="后台工作者"><a href="#后台工作者" class="headerlink" title="后台工作者"></a>后台工作者</h2><p>控制器进程有两种不同的机制/框架来处理后台工作。这些后台工作通常需要多个步骤和更新特定元数据根实体下的元数据，以及与一个或多个段存储的潜在交互。</p><p>首先，我们从一个简单的任务框架开始，该框架允许运行对给定资源（通常是流）拥有独占权的任务，并允许任务从一个控制器实例故障转移到另一个控制器实例。然而，这个模型限制了它的范围和锁定语义，并且没有固有的任务排序概念，因为多个任务可以竞争地同时获取资源上的工作权限（锁定），并且其中任何一个都可以成功。</p><p>为了克服这个限制，我们提出了一种新基础架构，称为Event Processor。事件处理器是经典的自己的狗食自己吃。它使用pravega流建造。这为我们提供了一个简洁的机制，以确保互斥和有序的处理。</p><h3 id="任务框架"><a href="#任务框架" class="headerlink" title="任务框架"></a>任务框架</h3><p>任务框架被设计为在每个资源上运行独占的后台处理， 以便在控制器实例失败的情况下，工作可以轻松地转移到另一个控制器实例并完成。框架本身并不保证幂等处理，并且如果需要，任务的作者必须处理它。任务模型被定义为只在给定资源上专门工作，这意味着没有其他任务可以在同一资源上并发运行。这是通过在zookeeper上实现的持久分布式锁实现的。任务的故障转移是通过遵循索引给定进程正在执行的工作的索引方案来实现的。因此，如果一个流程失败，另一个流程将扫描所有未完成的工作并尝试将所有权转移给自己。注意：控制器进程失败时，多个幸存的控制器进程可以同时尝试扫描孤立的任务。它们中的每一个都将在其主机索引中索引任务，但只有其中一个能够成功获取对资源的锁定，从而获得处理任务的权限。执行任务的参数被序列化并存储在资源下。</p><p>目前，我们仅将任务框架用于创建流任务。所有其他后台处理都是使用事件处理器框架完成的。</p><h2 id="事件处理器框架"><a href="#事件处理器框架" class="headerlink" title="事件处理器框架"></a>事件处理器框架</h2><p>事件处理器框架是后台工作子系统，它从内部流中读取事件并对其进行处理，因此称为事件处理器。我们系统中的所有事件处理器至少 提供一次 处理保证。并且在其基本风格方面，该框架还提供强大的顺序保证。但我们也有不同的事件处理器子类型，允许并发处理。</p><p>我们为不同类型的工作创建不同的事件处理器。目前，我们的系统中有三个不同的事件处理器，用于提交事务，中止事务和处理流特定请求，如扩展更新密封等。每个控制器实例都有一个每种类型的事件处理器。事件处理器框架允许为每个事件处理器创建多个读取器。跨控制器实例的特定事件处理器的所有读者共享相同的读取器组，这保证了跨控制器实例的互斥分配工作。每个读者都获得一个专用线程，在该线程中，它读取事件，调用其处理并在完成处理后更新其检查点。事件被发布在事件处理器特定的流中，并且基于使用作用域流名称作为路由密钥被路由到特定的段。</p><p>我们有两种类型的事件处理器，一种执行串行处理，这基本上意味着它会读取一个事件并启动它的处理，并等待它完成后再继续进行下一个事件。这为处理过程提供了强有力的顺序保证。处理完每个事件后的检查点。提交事务是使用事件处理器的这种基本风格实现的。处理这些事件的并行度上限为内容流中段数，下限为读者取器数量的限制。来自不同流的多个事件可以在同一段中出现，并且由于我们执行串行处理，串行处理的缺点是处理停顿或来自一个流的事件泛滥会对不相关流的延迟产生不利影响。</p><p>为了克服这些缺点，我们设计了Concurrent Event Processor作为串行事件处理器的叠加。顾名思义，并发事件处理器允许我们同时处理多个事件。这里读者线程读取一个事件，调度它的异步处理并返回读取下一个事件。在任何时间点同时处理的事件数量都有上限，并且当某个事件的处理完成时，允许获取更新的事件。这里的检查点方案变得更加复杂，因为我们希望保证至少一次处理。</p><p>但是，随着并发处理，顺序保证会被破坏。但是，重要的是要注意，我们只需要顺序保证来处理来自流而不是跨流的事件提供顺序保证。为了满足排序保证，我们将Concurrent Event Processor与Serialized Request Handler重叠，后者将来自内存队列中相同流的事件排队并按顺序处理它们。</p><p>提交事务处理是在专用串行事件处理器上实现的，因为我们需要提交顺序的强力保证，同时确保提交不会干扰流上其他类型请求的处理。</p><p>中止事务处理是在专用并发事件处理器上实现的，该处理器同时对来自跨流的事务执行中止处理。</p><p>对流的所有其他请求都在序列化请求处理程序上实现，该处理程序确保在任何给定时间正在处理每个流的一个请求，并且在请求处理期间存在排序保证。但是，它允许来自跨流的并发请求同时进行。实现缩放，截断，密封，更新和删除流等工作流程，以便在请求事件处理器上进行处理。</p>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Pravega handbook - 控制器服务之一</title>
      <link href="/2018/09/20/pravega-controller-service-1/"/>
      <url>/2018/09/20/pravega-controller-service-1/</url>
      
        <content type="html"><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>控制器服务是Pravega的核心组件，用于实现控制平面。它充当集群中执行的各种操作的中央协调器和管理器，主要分为两类：</p><ol><li>流管理</li><li>集群管理</li></ol><p>控制器服务，此后简称为控制器，负责提供<a href="http://pravega.io/docs/latest/pravega-concepts/#streams" target="_blank" rel="noopener">流</a>的抽象，这是Pravega向应用程序公开的主要抽象。流包括一个或多个<a href="http://pravega.io/docs/latest/pravega-concepts/#stream-segments" target="_blank" rel="noopener">段</a>。每个段都是仅附加数据结构，用于存储字节序列。一个段本身与其他段的存在无关，并且不知道它与其对等段的逻辑关系。拥有和管理这些段的段存储没有任何流的概念。流是由Controller概念化的逻辑视图通过组合动态变化的一组段来满足一组预定义的逻辑不变量。控制器提供流抽象并协调流上的所有生命周期操作，同时确保抽象保持一致。</p><p>控制器在流的生命周期中起着核心作用：创建，修改，<a href="http://pravega.io/docs/latest/pravega-concepts/#autoscalingthenumber-of-stream-segments-can-vary-over-time" target="_blank" rel="noopener">缩放</a>和删除。它通过维护每个流的元数据并在必要时对段执行必要的操作来完成这些操作。例如，作为流生命周期的一部分，可以创建新的段并密封现有的段。控制器决定何时执行这些操作，使得流继续可用并且对访问它们的客户端是一致的。</p><h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><p>控制器服务由一个或多个无状态工作节点实例组成。每个新的控制器实例都可以独立启动，并成为pravega集群的一部分，它只需要指向相同的Apache Zookeeper。对于高可用性，建议是每个群集具有不止一个控制器服务实例。</p><p>每个控制器实例都能够独立工作，并使用一个共享的持久存储作为控制器服务所拥有和管理的所属状态的真实来源。目前使用Apache ZooKeeper作为持久存储来保存所有的元数据。每个实例包括各种子系统，其负责对不同类别的元数据执行特定操作。这些子系统包括不同的API端点，元数据存储句柄，策略管理器和后台工作程序。</p><p>控制器暴露两个端点，这些端点可用于与控制器服务交互。第一个端口用于为pravega客户端提供编程访问，并使用gRPC实现为RPC。另一个端点用于管理操作，并作为REST端点实现。</p><h2 id="流管理"><a href="#流管理" class="headerlink" title="流管理"></a>流管理</h2><p>控制器拥有并管理流的概念，并负责维护每个流的元数据和生命周期。具体而言，它负责创建，更新，缩放，截断，密封和删除流。<br>流管理可以大致分为三类：</p><ol><li><p>流抽象<br>流可以被视为一系列动态变化的段集，其中流从一组一致的段转换到下一个。Controller是创建和管理此流抽象的地方。控制器决定流何时以及如何从一种状态转换到另一种状态，并负责执行这些转换，同时保持流的状态一致且可用。这些转换是受控制器强制执行的用户定义策略的支配。因此，作为流管理的一部分，控制器还会执行策略管理器的角色，以实现保留和缩放等策略。</p></li><li><p>自动策略管理<br>控制器负责通过主动监视流的状态来存储和实施用户定义的流策略。目前，我们有两个用户可以定义的策略，即<a href="https://github.com/pravega/pravega/blob/master/client/src/main/java/io/pravega/client/stream/ScalingPolicy.java" target="_blank" rel="noopener">缩放策略</a>和 <a href="https://github.com/pravega/pravega/blob/master/client/src/main/java/io/pravega/client/stream/RetentionPolicy.java" target="_blank" rel="noopener">保留策略</a>。缩放策略描述了流是否以及在何种情况下应自动缩放其段数。保留策略描述了有关在流中保留多少数据的策略。</p></li><li><p><a href="http://pravega.io/docs/latest/pravega-concepts/#transactions" target="_blank" rel="noopener">事务</a>管理<br>实现事务需要操作段。对于每个事务，Pravega创建一组事务段，这些事务段稍后在提交时合并到流段上或在中止时丢弃。控制器执行事务管理器的角色，负责在给定流上创建和提交事务。在创建事务时，控制器还跟踪事务超时并中止超时已过期的事务。事务管理的细节可以在文档的后面找到。</p></li></ol><h2 id="集群管理"><a href="#集群管理" class="headerlink" title="集群管理"></a>集群管理</h2><p>控制器负责管理段存储集群。控制器管理段存储节点的生命周期，因为它们被添加到群集/从群集中删除，并在可用的段存储节点上执行段容器的重新分发。</p><h2 id="系统图"><a href="#系统图" class="headerlink" title="系统图"></a>系统图</h2><p>下图显示了控制器进程的主要组件。我们接下来将详细讨论该图表的元素。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega%2FControllerSystemDiagram.png" alt="ControllerSystemDiagram"></p><p>控制器流程图</p><h1 id="组件"><a href="#组件" class="headerlink" title="组件"></a>组件</h1><h3 id="服务端点"><a href="#服务端点" class="headerlink" title="服务端点"></a>服务端点</h3><p>控制器公开了两个端口：客户端控制器API和管理API。客户端控制器通信被实现为RPC，RPC公开API以执行所有与流相关的控制平面操作。除此控制器外，还公开了一个作为REST实现的管理API集。</p><p>每个端点都对Controller Service后端子系统执行适当的调用，该控制器服务子系统 具有对控制器拥有和管理的实体进行各种创建，读取，更新和删除（CRUD）操作的实际实现。</p><h3 id="GRPC"><a href="#GRPC" class="headerlink" title="GRPC"></a>GRPC</h3><p>客户端控制器通信端点实现为gRPC 接口。完整的API列表可以在<a href="https://github.com/pravega/pravega/blob/master/shared/controller-api/src/main/proto/Controller.proto" target="_blank" rel="noopener">此处</a>找到 。这暴露了Pravega客户端（读者，写者和流管理器）使用的API，并启用了流管理。此API启用的请求包括创建，修改和删除流。底层gRPC框架提供同步和异步编程模型。我们在客户端控制器交互中使用异步模型，以便客户端线程不会阻止来自服务器的响应。</p><p>为了能够附加和读取来自流，writer和reader的数据，查询控制器以在使用流时获得活动的段集，后继段和前置段。对于事务，客户端使用特定的API调用来请求控制器创建和提交事务。</p><h3 id="REST"><a href="#REST" class="headerlink" title="REST"></a>REST</h3><p>对于管理，控制器实现并公开REST接口。这包括用于流管理的API调用以及主要处理范围创建和删除的其他管理API。我们使用swagger来描述我们的REST API。<a href="https://github.com/pravega/pravega/tree/master/shared/controller-api/src/main/swagger" target="_blank" rel="noopener">这里</a>可以找到swagger的yaml文件。</p><h3 id="控制器服务"><a href="#控制器服务" class="headerlink" title="控制器服务"></a>控制器服务</h3><p>Controller服务是控制器端点（gRPC和REST）后面的后端层。提供控制器API调用所需的所有业务逻辑都在此处实现。该层包含所有其他子系统的句柄，如各种存储实现（流存储，主机存储和检查点存储）和后台处理框架（任务框架，事件处理器框架）。存储是提供对Controller管理的各种类型元数据的访问的接口。后台处理框架用于执行异步处理，该异步处理通常实现涉及元数据更新和对分段存储的请求的工作流。</p><h3 id="流元数据存储"><a href="#流元数据存储" class="headerlink" title="流元数据存储"></a>流元数据存储</h3><p>流是动态改变的段序列，其中路由键空间的区域映射到开放段。随着流的段的集合发生变化，路由密钥空间到段的映射也会发生变化。<br>如果1）映射到集合中的段的关键空间区域的并集覆盖整个密钥空间，则该组段是一致的。2）密钥空间区域之间没有重叠。例如，假设集合S = { S 1，S 2，S 3 }，使得： - 区域[0,0.3]映射到区段S 1 - 区域[0.3,0.6]映射到区段S 2 - 区域[0.6 ，1.0）映射到段S 3<br>S是一致的段集。</p><p>随着时间的推移，流会经历转换。流以初始的段集合开始，这些初始段集合在创建时由流配置确定，并且随着对流执行缩放操作时转换为新的段集。在任何给定时间点构成流的每一段被认为属于一个时期。因此，流以初始时期开始，该初始时期是时期0，并且在每次转换时，它在其时期中向前移动以描述流中的段的生成的变化。</p><p>控制器维护流存储关于构成给定流的所有时期以及它们如何转换的信息。该存储旨在优化存储和查询与段及其相互关系相关的信息。<br>除了时期信息之外，它还保留了一些额外的元数据，例如状态及其策略以及流上的持续事务。</p><p>控制器的各种子组件通过定义良好的接口访问每个流的存储元数据 。我们目前有两个具体的流存储接口实现：内存和zookeeper支持的存储。两者共享一个公共的基础实现，该实现依赖于流对象，为所有特定于流的元数据提供特定于存储类型的实现。流存储的基本实现创建并缓存这些流对象。</p><p>流对象实现存储/流接口。具体的流实现特定于存储类型的，并负责实现存储特定的方法，以提供一致性和正确性。我们有一个提供乐观并发的所有存储类型的通用基础实现。此基类封装了针对支持Compare和Swap（CAS）的所有具体存储的流存储查询的逻辑。我们目前使用zookeeper作为我们的底层存储，它也支持CAS。我们在流特定的znodes（ZooKeeper数据节点）下以分层方式存储所有流元数据。</p><p>对于基于ZooKeeper的存储，我们将元数据组织到不同的组中，以支持针对此元数据的各种查询。所有特定于流的元数据都存储在作用域/流根节点下。针对该元数据的查询包括（但不限于）查询在不同时间点形成流的段集，段特定信息，段前驱和后继。有关流元数据存储公开的API的详细信息，请参阅流元数据接口。</p>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Flink handbook - flink集群与部署之kubernetes篇</title>
      <link href="/2018/09/20/flink-deployment-kubernetes/"/>
      <url>/2018/09/20/flink-deployment-kubernetes/</url>
      
        <content type="html"><![CDATA[<p>本页介绍如何在Kubernetes上部署Flink作业和会话群集。</p><h2 id="设置Kubernetes"><a href="#设置Kubernetes" class="headerlink" title="设置Kubernetes"></a>设置Kubernetes</h2><p>请参照<a href="https://kubernetes.io/docs/setup/" target="_blank" rel="noopener">Kubernetes的设置指南</a>来部署Kubernetes集群。如果您想在本地运行Kubernetes，我们建议使用<a href="https://kubernetes.io/docs/setup/minikube/" target="_blank" rel="noopener">MiniKube</a>来部署集群。</p><blockquote><p>注意：如果使用MiniKube，请确保<code>minikube ssh &#39;sudo ip link set docker0 promisc on&#39;</code>在部署Flink群集之前执行。否则，Flink组件无法通过Kubernetes服务自行引用。</p></blockquote><h2 id="Kubernetes上的Flink会话群集"><a href="#Kubernetes上的Flink会话群集" class="headerlink" title="Kubernetes上的Flink会话群集"></a>Kubernetes上的Flink会话群集</h2><p>Flink会话群集作为长期运行的Kubernetes部署来执行，请注意，可以在会话群集上运行多个Flink作业。在部署了集群之后，每个作业都需要提交到群集。</p><p>一个基本的部署在Kubernetes上的Flink会话群集一般会有三个组件：</p><ul><li>一个运行JobManager的deployment或job</li><li>一个TaskManagers池 deployment</li><li>一个公开JobManager的REST和UI端口的service</li></ul><h2 id="在Kubernetes上部署Flink会话群集"><a href="#在Kubernetes上部署Flink会话群集" class="headerlink" title="在Kubernetes上部署Flink会话群集"></a>在Kubernetes上部署Flink会话群集</h2><p>使用会话群集的资源定义，采用kubectl命令启动群集：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs undefined">kubectl create -f jobmanager-service.yaml<br>kubectl create -f jobmanager-deployment.yaml<br>kubectl create -f taskmanager-deployment.yaml<br></code></pre></td></tr></table></figure><p>然后，您可以通过kubectl proxy按以下方式访问Flink UI ：</p><p>第一步，保证kubectl proxy在终端中运行</p><p>第二步，在浏览器里输入 <code>http://localhost:8001/api/v1/namespaces/default/services/flink-jobmanager:ui/proxy</code></p><p>如果要终止Flink会话群集，可以使用如下命令：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs undefined">kubectl delete -f jobmanager-deployment.yaml<br>kubectl delete -f taskmanager-deployment.yaml<br>kubectl delete -f jobmanager-service.yaml<br></code></pre></td></tr></table></figure><h2 id="Kubernetes上的Flink作业集群"><a href="#Kubernetes上的Flink作业集群" class="headerlink" title="Kubernetes上的Flink作业集群"></a>Kubernetes上的Flink作业集群</h2><p>Flink作业集群是运行单个作业的专用集群，这项作业是打包在flink镜像里的，因此，不需要提交额外的作业对象，步骤如下：</p><h3 id="创建特定于作业的镜像"><a href="#创建特定于作业的镜像" class="headerlink" title="创建特定于作业的镜像"></a>创建特定于作业的镜像</h3><p>Flink作业集群镜像需要包含启动集群的作业的用户代码jar。因此，需要为每个作业构建专用的容器镜像。请按照这些<a href="https://github.com/apache/flink/blob/master/flink-container/docker/README.md" target="_blank" rel="noopener">说明</a>构建Docker镜像。</p><h3 id="在Kubernetes上部署Flink作业集群"><a href="#在Kubernetes上部署Flink作业集群" class="headerlink" title="在Kubernetes上部署Flink作业集群"></a>在Kubernetes上部署Flink作业集群</h3><p>要在Kubernetes上部署作业集群，请按照这些<a href="https://github.com/apache/flink/blob/master/flink-container/kubernetes/README.md#deploy-flink-job-cluster" target="_blank" rel="noopener">说明</a>进行操作。</p><h2 id="高级群集部署"><a href="#高级群集部署" class="headerlink" title="高级群集部署"></a>高级群集部署</h2><p>GitHub上提供了早期版本的<a href="https://github.com/docker-flink/examples" target="_blank" rel="noopener">Flink Helm chart</a>。</p><h1 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h1><h2 id="会话群集资源定义"><a href="#会话群集资源定义" class="headerlink" title="会话群集资源定义"></a>会话群集资源定义</h2><p>部署使用的最新镜像 <code>flink:latest</code> 可在<a href="https://hub.docker.com/r/_/flink/" target="_blank" rel="noopener">Docker Hub</a>上找到。该镜像是用这个工具 <code>https://github.com/docker-flink/docker-flink</code> 构建的</p><p>jobmanager-deployment.yaml</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs undefined">&quot;<br>apiVersion: extensions/v1beta1<br>kind: Deployment<br>metadata:<br>  name: flink-jobmanager<br>spec:<br>  replicas: 1<br>  template:<br>    metadata:<br>      labels:<br>        app: flink<br>        component: jobmanager<br>    spec:<br>      containers:<br>      - name: jobmanager<br>        image: flink:latest<br>        args:<br>        - jobmanager<br>        ports:<br>        - containerPort: 6123<br>          name: rpc<br>        - containerPort: 6124<br>          name: blob<br>        - containerPort: 6125<br>          name: query<br>        - containerPort: 8081<br>          name: ui<br>        env:<br>        - name: JOB_MANAGER_RPC_ADDRESS<br>          value: flink-jobmanager<br>&quot;<br></code></pre></td></tr></table></figure><p>taskmanager-deployment.yaml</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs undefined">&quot;<br>apiVersion: extensions/v1beta1<br>kind: Deployment<br>metadata:<br>  name: flink-taskmanager<br>spec:<br>  replicas: 2<br>  template:<br>    metadata:<br>      labels:<br>        app: flink<br>        component: taskmanager<br>    spec:<br>      containers:<br>      - name: taskmanager<br>        image: flink:latest<br>        args:<br>        - taskmanager<br>        ports:<br>        - containerPort: 6121<br>          name: data<br>        - containerPort: 6122<br>          name: rpc<br>        - containerPort: 6125<br>          name: query<br>        env:<br>        - name: JOB_MANAGER_RPC_ADDRESS<br>          value: flink-jobmanager<br>&quot;<br></code></pre></td></tr></table></figure><p>jobmanager-service.yaml</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs undefined">&quot;<br>apiVersion: v1<br>kind: Service<br>metadata:<br>  name: flink-jobmanager<br>spec:<br>  ports:<br>  - name: rpc<br>    port: 6123<br>  - name: blob<br>    port: 6124<br>  - name: query<br>    port: 6125<br>  - name: ui<br>    port: 8081<br>  selector:<br>    app: flink<br>    component: jobmanager<br>&quot;<br></code></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> flink </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flink </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Flink handbook - flink 集群与部署之docker篇</title>
      <link href="/2018/09/20/flink-deployment-docker/"/>
      <url>/2018/09/20/flink-deployment-docker/</url>
      
        <content type="html"><![CDATA[<h2 id="作者标注"><a href="#作者标注" class="headerlink" title="作者标注"></a>作者标注</h2><p>经过验证， 到当前版本为止 flink-1.7 snapshot，构建 flink docker镜像需要采用这个flink docker 构建工具 <code>https://github.com/docker-flink/docker-flink</code>，按照<a href="https://github.com/apache/flink/tree/master/flink-container" target="_blank" rel="noopener">flink官方代码库</a>里的构建出来的flink镜像有些功能不能用，比如 flink-standalone模式，report metrics等。</p><h2 id="Docker设置"><a href="#Docker设置" class="headerlink" title="Docker设置"></a>Docker设置</h2><p>Docker Hub上有关于Apache Flink的Docker镜像，可用于部署flink群集。Flink镜像库还包含用于创建容器映像以部署flink工作集群的一些工具以及说明。</p><h2 id="Flink-session群集"><a href="#Flink-session群集" class="headerlink" title="Flink session群集"></a>Flink session群集</h2><p>Flink会话群集可用于运行多个业务。在部署后，每个业务都需要提交到集群才能跑起来。</p><h2 id="Docker镜像"><a href="#Docker镜像" class="headerlink" title="Docker镜像"></a>Docker镜像</h2><p>该<a href="https://hub.docker.com/_/flink/" target="_blank" rel="noopener">Flink镜像库</a>托管在docker hub，提供了flink1.2.1以及之后的版本镜像。</p><p>注意： Docker镜像是由个人提供的社区项目，它们并不是Apache Flink PMC的官方版本（作者标注：所以需要用这个个人的<a href="https://github.com/docker-flink/docker-flink" target="_blank" rel="noopener">构建工具</a>，而不是官方代码库里的构建工具）。</p><h2 id="Flink作业集群"><a href="#Flink作业集群" class="headerlink" title="Flink作业集群"></a>Flink作业集群</h2><p>Flink作业集群是运行单个作业的专用集群，这是镜像内容的一部分，因此，不需要额外的工作。</p><h2 id="Docker镜像-1"><a href="#Docker镜像-1" class="headerlink" title="Docker镜像"></a>Docker镜像</h2><p>Flink作业集群镜像需要包含启动集群的作业的用户代码jar。因此，需要为每个作业构建专用的容器镜像。该flink-container模块包含一个build.sh脚本，可用于创建此类镜像。有关详细信息，请参阅<a href="https://github.com/apache/flink/blob/master/flink-container/docker/README.md" target="_blank" rel="noopener">说明</a>。（作者注：这个是官方的构建方式，试过有问题，比如跑 flink-standalone再 report metrics）</p><h2 id="Flink与Docker-Compose"><a href="#Flink与Docker-Compose" class="headerlink" title="Flink与Docker Compose"></a>Flink与Docker Compose</h2><p>Docker Compose是一种很方便的用于在本地启动一组Flink Docker容器的方式。</p><p>GitHub上提供了<a href="https://github.com/docker-flink/examples/blob/master/docker-compose.yml" target="_blank" rel="noopener">集群部署实例</a>和<a href="https://github.com/apache/flink/blob/master/flink-container/docker/docker-compose.yml" target="_blank" rel="noopener">作业群集示例</a>的配置文件。</p><h2 id="用法"><a href="#用法" class="headerlink" title="用法"></a>用法</h2><p>启动集群</p><p><code>$docker-compose up</code></p><p>以deamon的方式启动集群</p><p> <code>$docker-compose up -d</code></p><p>集群扩展 N 个 TaskManagers</p><p><code>$docker-compose scale taskmanager=&lt;N&gt;</code></p><p>销毁集群</p><p><code>$docker-compose kill</code></p><p>当拉起一个Flink群集后，您可以访问 <code>http：// localhost：8081</code>的Web UI ，在界面里您还可以将作业提交到群集。</p><p>如果要通过命令行将作业提交到会话群集，必须将JAR复制到JobManager容器里并从那里执行作业。</p><p>例如：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs undefined">$ JOBMANAGER_CONTAINER=$(docker ps --filter name=jobmanager --format=&#123;&#123;.ID&#125;&#125;)<br>$ docker cp path/to/jar &quot;$JOBMANAGER_CONTAINER&quot;:/job.jar<br>$ docker exec -t -i &quot;$JOBMANAGER_CONTAINER&quot; flink run /job.jar<br></code></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> flink </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flink </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>pravega handbook - 段容器</title>
      <link href="/2018/09/19/pravega-segment-containers/"/>
      <url>/2018/09/19/pravega-segment-containers/</url>
      
        <content type="html"><![CDATA[<h2 id="Pravega集群中的段容器"><a href="#Pravega集群中的段容器" class="headerlink" title="Pravega集群中的段容器"></a>Pravega集群中的段容器</h2><p>本文档描述了我们如何管理Pravega集群中Segment Containers生命周期的高级设计。</p><h2 id="平衡段容器"><a href="#平衡段容器" class="headerlink" title="平衡段容器"></a>平衡段容器</h2><h2 id="段容器"><a href="#段容器" class="headerlink" title="段容器"></a>段容器</h2><p>在本文档中，我们将段容器称为容器。对于给定的部署，容器的总数是固定的。每个容器只能由一个Pravega主机拥有，并且群集中的所有容器都应该在任何时刻都是运行着的。</p><h2 id="Pravega主机"><a href="#Pravega主机" class="headerlink" title="Pravega主机"></a>Pravega主机</h2><p>pravega主机是pravega服务的一个实例，它拥有并执行一组容器。</p><h2 id="检测活动的Pravega主机"><a href="#检测活动的Pravega主机" class="headerlink" title="检测活动的Pravega主机"></a>检测活动的Pravega主机</h2><p>启动时每个pravega主机都会使用临时节点向Zookeeper注册。只要zookeeper从Pravega主机接收到适当的心跳，临时的节点就会出现在zookeeper中。我们依靠这些临时的节点来检测哪些pravega主机当前在群集中是活动的。</p><h2 id="监控Pravega集群"><a href="#监控Pravega集群" class="headerlink" title="监控Pravega集群"></a>监控Pravega集群</h2><p>每个Pravega Controller都运行一项服务，监控zookeeper上的临时节点并检测集群中所有活动的pravega主机。在检测到对集群成员资格的任何更改时，我们会验证所有容器并将其重新映射到可用的pravega主机集。此信息以原子方式保存在HostStore中。它存储为单个blob，并包含主机拥有的主机到容器集的映射。</p><p>我们使用zookeeper来确保只有一个pravega控制器监视集群，以避免多个同时写入HostStore的写入器。这将避免竞争条件，并允许状态更快地收敛。</p><h2 id="再平衡频率"><a href="#再平衡频率" class="headerlink" title="再平衡频率"></a>再平衡频率</h2><p>当从群集中添加或删除pravega主机时，会发生容器所有权的重新平衡。由于这是一项代价高昂的操作，我们需要防止经常这样做。目前，我们确保在任何2次重新平衡操作之间保持配置的最小时间间隔。在最坏的情况下，这将按比例增加在集群中执行所有权更改所花费的时间。</p><h2 id="所有权变更通知"><a href="#所有权变更通知" class="headerlink" title="所有权变更通知"></a>所有权变更通知</h2><p>每个pravega主机都有一个长期运行的Segment Manager服务。这会不断轮询/监视HostStore，以便对容器所有权进行任何更改。在检测到自身的所有权变更（由map中的主机密钥标识）时，段管理器会相应地触发添加和删除容器。</p><h2 id="确保容器在另一台主机上启动之前在一台主机上停止"><a href="#确保容器在另一台主机上启动之前在一台主机上停止" class="headerlink" title="确保容器在另一台主机上启动之前在一台主机上停止"></a>确保容器在另一台主机上启动之前在一台主机上停止</h2><p>我们目前计划在Pravega主机上使用保守超时，以确保容器在另一个节点上停止之前不会启动。这需要进一步检阅/讨论。</p><h2 id="检测和处理容器启动-停止故障"><a href="#检测和处理容器启动-停止故障" class="headerlink" title="检测和处理容器启动/停止故障"></a>检测和处理容器启动/停止故障</h2><p>任何容器启动/停止故障都被视为本地故障，我们希望Pravega主机尽可能在本地处理这些情况。Pravega Controller控制器不需要通过在不同主机上运行来纠正这一点。这需要进一步检阅/讨论。</p>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>pravega handbook - wire protocol</title>
      <link href="/2018/09/19/pravega-wire-protocol/"/>
      <url>/2018/09/19/pravega-wire-protocol/</url>
      
        <content type="html"><![CDATA[<h2 id="流服务线协议"><a href="#流服务线协议" class="headerlink" title="流服务线协议"></a>流服务线协议</h2><p>本页描述了为流服务提出的有线协议。有关服务的描述，请参阅父页面。</p><h2 id="协议"><a href="#协议" class="headerlink" title="协议"></a>协议</h2><p>数据通过线路以独立的“消息”发送，这些消息是“请求”（从客户端到服务器的消息）或“回复”（响应请求并返回到客户端）。</p><p>所有请求和回复都有一个带有两个字段的8字节头，（所有数据都以BigEndian格式写入）：1。消息类型 -​​ 一个整数（4个字节）标识消息类型，这决定了后面的字段。（注意，协议可以通过添加新类型来扩展）2。长度 - 无符号整数4个字节（消息应该&lt;2 ^ 24，但高位保持为零）。此点前面的数据字节数是此消息的一部分。（可能为零，表示没有数据）</p><p>字段的其余部分是特定于消息类型。下面列出了一些重要信息。</p><h1 id="一般信息"><a href="#一般信息" class="headerlink" title="一般信息"></a>一般信息</h1><h2 id="部分消息-请求-应答"><a href="#部分消息-请求-应答" class="headerlink" title="部分消息 - 请求/应答"></a>部分消息 - 请求/应答</h2><ol><li>开始/中间/结尾 - 枚举（1个字节）</li><li>数据部分消息是通过线路发送时被分解的消息。（出于任何原因）。通过按依次读取部分消息并将它们组合成一个整体来重建整个消息。在完成上一个部分消息之前尝试启动新的部分消息是无效的。</li></ol><h2 id="KeepAlive-请求-回复"><a href="#KeepAlive-请求-回复" class="headerlink" title="KeepAlive - 请求/回复"></a>KeepAlive - 请求/回复</h2><ol><li>数据 - 消息长度的未解释数据。（通常为0字节）</li></ol><h1 id="读取"><a href="#读取" class="headerlink" title="读取"></a>读取</h1><h2 id="读段-请求"><a href="#读段-请求" class="headerlink" title="读段 - 请求"></a>读段 - 请求</h2><ol><li>要读取的段 - 字符串（2字节长度，后跟Java的修改后的UTF-8的多个字节）</li><li>读取偏移量 - 长（8个字节）</li><li>建议的回复长度 - int（4字节）<ul><li>这是客户端想要的数据量。他们不一定会获得那么多。</li></ul></li></ol><h2 id="段读-回复"><a href="#段读-回复" class="headerlink" title="段读 - 回复"></a>段读 - 回复</h2><ol><li>读取的段 - 字符串（长度为2个字节，后跟Java的修改后的UTF-8的多个字节）</li><li>从中读取的偏移量 - 长（8个字节）</li><li>在Tail - 布尔值（1位）</li><li>在EndOfSegment - （1位）</li><li>数据 - 二进制（消息中的剩余长度）</li></ol><p>客户端请求以特定偏移量从特定流中读取，然后以SegmentRead消息的形式接收一个或多个应答。这些包含他们请求的数据（假设它存在）。在合适的答复中，服务器可能决定给客户端提供比其要求更多或更少的数据。</p><h2 id="追加"><a href="#追加" class="headerlink" title="追加"></a>追加</h2><h2 id="设置追加-请求"><a href="#设置追加-请求" class="headerlink" title="设置追加 - 请求"></a>设置追加 - 请求</h2><ol><li>ConnectionId - UUID（16字节）标识此appender。</li><li>要追加的段。 - 字符串（长度为2个字节，后跟Java的Modified UTF-8的多个字节）</li></ol><h2 id="追加设置-答复"><a href="#追加设置-答复" class="headerlink" title="追加设置 - 答复"></a>追加设置 - 答复</h2><ol><li>可以附加到的段。 - 字符串（长度为2个字节，后跟Java的Modified UTF-8的多个字节）</li><li>ConnectionId - UUID（16字节）标识请求的appender。</li><li>ConnectionOffsetAckLevel - Long（8字节）此connectionId在此段上接收和存储的最后一个偏移量（如果是新的话，则为0）</li></ol><h2 id="BeginAppendBlock-请求"><a href="#BeginAppendBlock-请求" class="headerlink" title="BeginAppendBlock - 请求"></a>BeginAppendBlock - 请求</h2><p>仅在SetupAppend成功完成后才有效。</p><ol><li>ConnectionId - UUID（16字节）</li><li>ConnectionOffset - Long（8字节）到目前为止通过此连接写入此段的数据</li><li>EndAppendBlock消息之前的数据长度 - 整数（4个字节） </li></ol><h2 id="EndAppendBlock-请求"><a href="#EndAppendBlock-请求" class="headerlink" title="EndAppendBlock-请求"></a>EndAppendBlock-请求</h2><ol><li>ConnectionId - UUID（16字节）</li><li>ConnectionOffset - Long（8字节）到目前为止通过此连接写入的数据</li><li>块长度 - （4个字节）写入的块的总大小。（注意，这可能多于或少于BeginAppendBlock和此消息之间的字节数）</li></ol><h2 id="事件-请求"><a href="#事件-请求" class="headerlink" title="事件 - 请求"></a>事件 - 请求</h2><p>仅在块内有效</p><ol><li>数据</li></ol><h2 id="数据附加-答复"><a href="#数据附加-答复" class="headerlink" title="数据附加 - 答复"></a>数据附加 - 答复</h2><ol><li>ConnectionId - UUID（16字节）</li><li>ConnectionOffsetAckLevel - 长（8字节）此连接之前所有数据成功存储在此段上的最高偏移量</li></ol><h3 id="追加客户段时"><a href="#追加客户段时" class="headerlink" title="追加客户段时"></a>追加客户段时</h3><ol><li>建立与其认为正确的主机的连接。</li><li>发送安装追加请求。</li><li>等待追加设置回复。</li></ol><p>然后它可以1.发送BeginEventBlock请求2.发送尽可能多的消息以适应块3.发送EndEventBlock请求</p><p>在发生这种情况时，服务器将定期向其发送DataAppended回复acking消息。请注意，给定的TCP连接可以有多个“追加”设置。这允许客户端在生成多个段时共享连接。</p><p>客户端可以通过在其BeginAppendBlock消息中指定一个较大的值来优化其附加，因为块内的事件不需要单独处理。</p><p>EndEventBlock消息指定追加块的大小而不是BeginAppendBlock消息。这意味着不需要事先知道块中数据的大小。如果客户端正在生成小消息流，这将非常有用。它可以开始一个块，写入许多消息，然后当它结束块时，它可以在EndAppendBlock消息之后写入部分消息，然后是剩余的部分消息。这样可以避免在块中的所有消息上都有标题，而不必在其进程中将它们缓冲在ram中。</p>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>pravega handbook - 数据面段存储服务之三</title>
      <link href="/2018/09/18/pravega-segment-store-service-3/"/>
      <url>/2018/09/18/pravega-segment-store-service-3/</url>
      
        <content type="html"><![CDATA[<h2 id="与Controller集成"><a href="#与Controller集成" class="headerlink" title="与Controller集成"></a>与Controller集成</h2><p>关于如何将段容器映射到主机以及使用什么规则从一个迁移到另一个的实际方法超出了本文的范围。这里，我们只描述段存储服务如何与控制器交互，以及它如何基于外部事件管理段容器的生命周期。</p><h2 id="段容器管理"><a href="#段容器管理" class="headerlink" title="段容器管理"></a>段容器管理</h2><p>Segment Store Service的每个实例都需要Segment Container Manager。此组件的作用是管理分配给该节点（服务）的Segment Containers的生命周期。它履行以下职责：</p><ul><li>连接到Controller服务端客户端（即，仅处理Segment Container事件的客户端，而不是Streams的管理，并侦听与其自身实例相关的所有与Container相关的更改。</li><li>当它收到需要为特定Container Id启动Segment Container的通知时，它会启动引导此类对象的过程。在操作完成且没有错误之前，它不会通知请求客户端成功。</li><li>当它收到需要停止特定Container Id的Segment Container的通知时，它会启动关闭它的过程。在操作完成且没有错误之前，它不会通知请求客户端成功。</li><li>如果Segment Container意外关闭（无论是在Start期间还是在正常操作期间），它将不会尝试在本地重新启动它; 相反，它会通知控制器这个事实。</li></ul><h2 id="存储抽象"><a href="#存储抽象" class="headerlink" title="存储抽象"></a>存储抽象</h2><p>段存储不是专门针对TIER-1或TiR-2的实现而设计的。相反，所有这些组件都已经抽象出来并定义得很好，可以针对任何标准文件系统（Tier-2）或仅追加日志系统（Tier-1）实现。</p><p>第1层存储的可能候选者：</p><ul><li>Apache BookKeeper（首选，适配器完全实现为Pravega的一部分）</li><li>非持久性，非复制性解决方案：</li><li>内存中（只部署单个节点——Pravega成为二级存储的易失性缓冲区；在进程崩溃或系统重新启动的情况下，数据丢失是不可避免的和不可恢复的）。<ul><li>这仅用于单元测试。</li></ul></li><li>本地文件系统（仅单节点部署——Pravega成为二级存储的半持久缓冲区；在完全节点失败的情况下，数据丢失是不可避免的和不可恢复的）</li></ul><p>二级存储的可能候选者：</p><ul><li>HDFS（可实施）</li><li>扩展S3（可实现）</li><li>NFS（通用FileSystem）（可用实现）</li><li>内存中（单节点部署——有限的用途；在进程崩溃或系统重新启动的情况下，数据丢失是不可避免的和不可恢复的）<ul><li>这仅用于单元测试。</li></ul></li></ul><p>关于Tier-2 Truncation的注释：</p><ul><li><p>Segment Store支持在特定偏移量处的Segment截断，这意味着，一旦该请求完成，那么在该偏移量以下的偏移量将不可用于读取。<br>上面这只是一个元数据更新操作，但是这也需要由Tier-2支持，以便从其中物理删除截断的数据。</p></li><li><p>如果Tier-2实现从具有偏移量保存的文件开始就不支持截断（即，在偏移50处截断长度为100的段，则删除偏移0..49，但是偏移量50-99可用并且没有向下移动），然后Segment Store在通用的Tier-2实现之上提供了一个包装器，它可以做到这一点.</p></li><li><p>所述RollingStorage tier-2 分割segment成多个段组块并暴露它们作为一个单一的段到上层。已截断的段块将自动删除。这不是一个非常精确的应用程序（因为它在很大程度上依赖于规定粒度的翻转策略），但对于那些真正的第2层实现不提供我们需要的功能的情况，它是一个实用的解决方案。</p></li></ul><h2 id="数据流"><a href="#数据流" class="headerlink" title="数据流"></a>数据流</h2><p>以下是Pravega Segment Store Service中数据流动的几个示例。</p><h2 id="追加"><a href="#追加" class="headerlink" title="追加"></a>追加</h2><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega%2FSegment.Store.Appends.png" alt="Segment.Store.Appends"></p><p>上图描绘了这些步骤（注意步骤编号可能不匹配，但顺序相同）：</p><ol><li>Segment Store接收带有params的附加请求：Segment Name，Payload和AttributeUpdates。</li><li>Segment Store确定给定Segment的ContainerId，并验证Segment Container是否在本地注册。如果不是，则返回适当的错误代码。</li><li>Segment Store将请求委托给相应的Segment Container实例。<ul><li>Segment Container验证Segment是否属于Segment Container并且Segment实际存在。如果不是，则返回适当的错误代码。<ul><li>在此过程中，它还会获得现有的段ID或分配新段（通过使用段映射器组件）。</li></ul></li><li>Segment Container StreamSegmentAppendOperation使用输入数据创建a 并将其发送到Durable Log。</li></ul></li></ol><ol start="4"><li><p>持久日志采用追加操作并根据持久日志部分中描述的算法对其进行处理:</p><ul><li>将其放入其操作队列中。</li><li>操作处理器从队列中拉出所有操作。</li><li>操作处理器使用数据框构建器来构建具有其操作的数据框架。</li><li>Data Frame Builder将数据帧异步写入持久数据日志。</li><li>完成后，以下内容并行完成：<ul><li>元数据已更新。</li><li>操作被添加到内存操作日志和读取索引中。</li><li>触发操作的呼叫被激活。</li></ul></li><li>上述过程是异步的，这意味着操作处理器将具有多个未受控制的数据帧（未示出）。它将跟踪每一个的变化并根据需要应用或回滚。<br>此过程适用于Segment Store支持的每个操作。所有修改操作都通过操作处理器并具有类似的路径。</li></ul></li></ol><h2 id="读取"><a href="#读取" class="headerlink" title="读取"></a>读取</h2><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega%2FSegment.Store.Reads.png" alt="Segment.Store.Reads"></p><p>上图描绘了这些步骤（注意步骤编号可能不匹配，但顺序相同):</p><ol><li>段存储接收带有参数的读取请求：段名称，读取偏移量，最大长度。<ul><li>Segment Store确定给定Segment的ContainerId，并验证它是否是给定Segment Container的 Leader 。如果不是，则返回适当的错误代码。</li><li>Segment Store将请求委托给Segment Container实例。</li></ul></li><li><p>Segment Container验证Segment是否属于该Container并且它实际存在。如果没有，它会向客户端返回适当的错误代码。</p><ul><li>在此过程中，它还会获得现有的段ID或分配新段（通过使用段映射器组件）。</li></ul></li><li><p>段容器将请求委托给其读取索引，该索引按照“ 读取索引”部分中的描述处理读取，方法是从存储中发出读取（对于不在缓存中的数据），并根据需要查询/更新缓存。</p></li></ol><h2 id="与Tier-2（存储写入器）同步"><a href="#与Tier-2（存储写入器）同步" class="headerlink" title="与Tier-2（存储写入器）同步"></a>与Tier-2（存储写入器）同步</h2><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega%2FSegment.Store.SyncTier2.png" alt="Segment.Store.SyncTier2"></p><p>上图描绘了这些步骤（注意步骤编号可能不匹配，但顺序相同）：</p><ol><li>该存储写入的主循环是子组件触发所有这些操作</li><li>从持久日志中读取下一个操作（在每个循环之间，Writer会记住上次处理的操作的序列号是什么）</li><li>处理所有操作，并将其添加到内部段聚合器（每个段一个聚合器）</li><li>符合条件的段聚合器被刷新到存储（资格取决于每个聚合器中收集的数据量，以及是否有排队的Seal，Merge或Truncate操作）<ul><li>每次遇到Append操作时，可能需要访问Read Index以获取追加的内容</li></ul></li><li>在对storage的每次成功修改（写入/密封/连接/截断）之后，都会更新Container Metadata以反映更改。</li><li>该持久日志被截断（如果符合条件）。</li></ol><h2 id="容器启动（正常-恢复）"><a href="#容器启动（正常-恢复）" class="headerlink" title="容器启动（正常/恢复）"></a>容器启动（正常/恢复）</h2><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega%2FSegment.Store.Recovery.png" alt="Segment.Store.Recovery"></p><p>上图描绘了这些步骤（注意步骤编号可能不匹配，但顺序相同）：</p><ol><li>容器管理器接收在该段存储服务的这个实例中启动容器的请求。<ul><li>它创建，注册和启动Container。</li></ul></li><li>该容器启动持久日志组件。</li><li>持久日志启动恢复过程（由Recovery Executor协调）。</li><li>Recovery Executor从持久数据日志中读取所有数据帧。</li><li>读取数据帧中的反序列化操作将添加到“ 内存操作日志”中。</li><li>所述容器的元数据是由的方式更新操作元数据更新器（同运算处理器内使用的）。</li><li>该读取索引填充了那些适用于IT运营的内容。</li><li>该容器启动存储写入器。<ul><li>该存储写入的主循环开始从处理操作持久化日志，以及在第一次遇到一个新的segment时，它将其内容（和元数据）与存储中存在的实际情况调和。</li></ul></li><li>在Durable Log和Storage Writer都启动后，Container已准备好开始接受新的外部请求。</li></ol>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>pravega handbook - 数据面段存储服务之二</title>
      <link href="/2018/09/18/pravega-segment-store-service-2/"/>
      <url>/2018/09/18/pravega-segment-store-service-2/</url>
      
        <content type="html"><![CDATA[<h2 id="日志操作"><a href="#日志操作" class="headerlink" title="日志操作"></a>日志操作</h2><p>一个日志操作是在可持久化的日志里序列化的基本单元。它本身并不代表一个动作，而是几个可序列化操作的基础（我们可以序列化多种类型的操作，而不仅仅是Appends）。每个操作都是外部操作（表示更改段）或内部触发（如元数据维护操作）的结果。<br>每个日志操作都具有以下元素： <code>- SequenceNumber</code>：分配给此条目的唯一序列号（请参阅容器元数据下的更多信息）。</p><p>这些是各种类型的日志操作：</p><ul><li>存储操作表示需要应用于底下第2层存储的操作：</li><li>StreamSegmentAppendOperation：表示对特定段的附加。</li><li>CachedStreamSegmentAppendOperation：与StreamSegmentAppendOperation相同，但这是供内部使用的（它不是具有实际的数据有效负载，而是指向缓存中可以从中检索数据的位置）。</li><li>StreamSegmentSealOperation：处理后，它会在内存中的元数据中设置一个标记，以便不再接收附加内容。当Storage Writer处理它时，它会在第2层存储中将Segment标记为只读。</li><li>StreamSegmentTruncateOperation：截断特定偏移处的段。这会导致segment的StartOffset发生变化。</li><li>MergeTransactionOperation：表示要将事务合并到其父段中。</li><li>元数据操作是指示容器元数据更改的辅助操作。它们可能是外部操作的结果（我们之前收到了一个我们从未知道的段的请求，因此我们必须为其分配一个唯一的ID）或者对整个元数据进行快照（这有助于恢复和清理第1层）存储）。元数据操作的目的是减少故障转移恢复所需的时间（如果需要）：</li><li>StreamSegmentMapOperation：将Id映射到段名称。</li><li>TransactionMapOperation：将Id映射到事务及其父段。</li><li>UpdateAttributesOperation：更新segment上的任何属性。</li><li>MetadataCheckpoint包括元数据的整个快照。这在恢复期间非常有用 - 它包含到目前为止的所有元数据，这是之后所有操作的基础。</li></ul><h2 id="可持久化日志"><a href="#可持久化日志" class="headerlink" title="可持久化日志"></a>可持久化日志</h2><p>该可持久化日志是处理所有操作日志的核心组成部分。所有操作（由Container创建）都会添加到持久日志中，该日志按照接收顺序处理它们。它由一些其他组件组成，在不影响数据完整性的情况下，所有这些组件的唯一目标都是致力于尽快处理所有输入操作。</p><p>可持久化日志中的信息流:</p><ol><li>所有收到的操作都被添加到操作队列中 （调用方接收一个当操作持久地完成时将完成的未来）</li><li>该运算处理器选取目前在队列中可用的所有操作（如果队列为空，则等到至少一个操作被添加）。</li><li><p>所述操作处理器运行作为一个连续的环（在后台线程中），并且具有四个主要阶段。</p><ul><li>从操作队列中出列所有未完成的操作（如上所述）</li><li>预处理操作（验证它们是否正确并且不会导致意外行为，分配偏移量（如果需要），分配序列号等）</li><li>写操作的数据帧生成器，其序列化和包装的操作数据帧。数据框完成后（完整或不再需要添加操作），数据框构建器将数据框发送到_可持久化的数据日志。请注意，操作可能跨越多个DataFrame - 目标是通过尽可能大的写入（但也考虑到每次写入可能有最大大小限制）来充分利用持久数据日志吞吐量容量。</li></ul></li></ol><ol start="4"><li><p>当持久数据日志中的DataFrame持久存在时，操作处理器会对迄今为止完全写入的所有操作进行后处理（将它们添加到内存中结构，更新索引等）并完成与它们相关的未来。</p></li><li><p>Operation Processor异步工作，因为它在开始另一个数据帧并将其发送到持久数据日志之前不等待写入特定的数据帧。因此，多个DataFrame可能正在运行（但是以特定的顺序），并且操作处理器依赖于持久数据日志中的某些排序保证（如果特定DataFrame被攻击，那么在此之前的所有DataFrame也以正确的顺序被成功提交）。</p><ul><li>操作处理器不执行任何写入限制（将其留给持久数据日志实现），但它控制发送给它的数据帧的大小。</li></ul></li></ol><h2 id="截断"><a href="#截断" class="headerlink" title="截断"></a>截断</h2><p>根据提供的配置，Durable Log会自动添加一种特殊的操作，命名为MetadataCheckpointOperation。此操作在由操作处理器处理时，收集整个Container Metadata的快照，并将其序列化为Durable Data Log。此特殊操作标记一个截断点 - 日志操作流中的一个位置，我们可以在其中发出截断操作。非常重要的是，在每次截断之后，在日志中找到的第一个操作是一个 MetadataCheckpointOperation，因为没有先前的操作来重建元数据，这是能够处理后续操作的唯一方法。</p><p>注意：不应将持久数据日志（第1层）截断与段截断相混淆。它们用于不同的目的，适用于不同的目标。</p><h2 id="操作处理器"><a href="#操作处理器" class="headerlink" title="操作处理器"></a>操作处理器</h2><p>操作处理器是处理日志输入操作的可持久化的日志的子组件。其目的是基于每个操作的内容来验证、持久化和更新元数据和其他内部结构。<br>操作元数据更新器</p><p>操作元数据更新器是持久日志的子组件，负责基于元数据的当前状态验证操作，以及在成功提交操作之后更新元数据。在内部，它有各种机制来应对失败，并且它可以回滚失败情况下的某些变化。</p><h2 id="持久数据日志"><a href="#持久数据日志" class="headerlink" title="持久数据日志"></a>持久数据日志</h2><p>持久数据日志是一个外部组件的抽象层，提供仅附加语义。它是一个向日志提供非常快速附加的系统，它保证了写入数据的持久性和一致性。读取性能不是一个很重要的因素，因为我们不直接从该组件读取数据 - 我们只在需要恢复持久日志的内容时才从该组件读取日志数据。</p><p>如上所述，日志操作被序列化为数据框架（如果需要的话，单个操作能够跨越多个这样的框架），然后这些数据框架被序列化为持久数据日志的条目。这仅用作故障安全，并且我们只需要在需要执行恢复时才需要读回这些框架（在这种情况下，我们需要按照接收它们的相同顺序反序列化它们中包含的所有日志操作）。</p><h2 id="内存操作日志"><a href="#内存操作日志" class="headerlink" title="内存操作日志"></a>内存操作日志</h2><p>内存中操作日志包含提交（和复制）的日志操作，其顺序与添加到持久数据日志的顺序完全相同。虽然持久数据日志包含一系列数据帧（其中包含操作的序列化），但是内存日志包含实际的操作，这些操作可以在整个持久日志（以及存储写入器）中使用。</p><p>内存日志本质上是在接收操作时命令的日志操作链。我们总是在一端添加，然后从另一端移除。当我们截断持久数据日志时，内存日志也被截断在同一位置。</p><h2 id="读取索引"><a href="#读取索引" class="headerlink" title="读取索引"></a>读取索引</h2><p>读取索引有助于段容器在任意偏移量下执行从流读取。虽然耐用日志按照接收的顺序记录（并且只能重放）数据，但是Read Index可以以随机方式访问数据。读取索引由多个片段读取索引（每个活片段之一）构成。</p><p>段读取索引是一种数据结构，用于提供从内存的读取，以及从第2层存储中提取数据，并在数据尚未可用时提供未来读取（尾部读取）。当接收到读取请求时，段读取索引返回一个读取迭代器，只要读取请求参数尚未满足，该迭代器将返回数据。迭代器要么从存储器中取出立即可用的数据，要么从第2层存储器中请求数据（并将其带到存储器中），要么如果到达段当前末端，返回Future并在添加新数据时完成（从而提供尾随或未来读取）。</p><p>段读索引的核心是条目的排序索引（由它们的起始偏移量索引），用于在需要时定位所请求的数据。索引本身由定制的平衡二进制搜索树（更确切地说，是AVL树）实现，其目标是最小化内存使用而不牺牲插入或访问性能。条目本身不包含数据，而是一些少量的元数据，这些元数据用于定位缓存中的数据并确定使用模式（对缓存撤出很有好处）。</p><h2 id="高速缓存"><a href="#高速缓存" class="headerlink" title="高速缓存"></a>高速缓存</h2><p>缓存是一个组件，其中所有数据（无论是从新添加的还是从第二存储中提取的）都被存储。它是一个完全由读取索引管理的密钥值存储。</p><p>缓存被定义为抽象层，并且有两个实现：</p><ul><li>内存实现（通过哈希图）。目前只用于单元测试。</li><li>内存与磁盘混合，由ROCKSDB提供支持。这是首选的（默认的）实现，因为它不受可用堆空间或机器RAM的限制，其性能与内存大小成正比。</li></ul><h2 id="存储写入"><a href="#存储写入" class="headerlink" title="存储写入"></a>存储写入</h2><p>Pravega绝不是数据的最终安放位置，也不是存储服务。Tier-2 Storage是我们希望数据长期存在的地方而Pravega仅用于存储非常短的尾部（使用第1层存储），足够快速追加并将它们聚合成更大的块以便提交给第2层存储。为了执行此操作，它需要另一个组件（存储写入），该组件按照接收顺序从持久日志中读取数据，对其进行聚合，并将其发送到第2层存储。</p><p>就像持久日志一样，每个段容器都有一个存储写入器。每个写入器从内存操作日志中读取日志操作（通过持久日志中的read()方法公开），按照它们被处理的顺序。它通过它的序列号来跟踪最后一个读项目。此状态不被持久化，并且在恢复时，它可以从可用的持久日志的开始开始。</p><p>Storage Writer可以处理任何存储操作（附加，密封，合并），并且由于Pravega是在第2层中修改此类数据的唯一参与者，因此它可以不受约束地应用它们。它有几种机制可以检测和恢复可能的数据丢失或外部参与者同时修改数据。</p>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>pravega handbook - 数据面段存储服务之一</title>
      <link href="/2018/09/18/pravega-segment-store-service-1/"/>
      <url>/2018/09/18/pravega-segment-store-service-1/</url>
      
        <content type="html"><![CDATA[<p>Pravega Segment Store Service是Pravega的核心子系统，它提供了创建，删除和修改/访问其内容的功能，是管理流段的主要入口。Pravega客户端与Pravega stream controller互动以确定需要使用哪些段（对于流），流控制面和客户端一起处理段存储服务从而操作这些流段。<br>Segment Store Service背后的基本思想是，它将输入的数据缓存在一个非常快速且持久化的append only介质（第1层存储）中，并将其与高吞吐量（但不一定是低延迟）存储系统（第2层存储）同步，同时将多个小流段合并到大的流段里。</p><p>Pravega Segment Store Service可提供以下保证：</p><ul><li>流段长度不受限制，仅具有附加语义，但支持任意偏移读取</li><li>无论底层第2层存储系统的性能如何，执行小型附加时都不会降低吞吐量</li><li>多个并发写入到同一个段</li><li>在单个写入的上下文中保证顺序，但是来自多个并发写入的附加数据行为将按照接收它们的顺序来添加（附加是原子的而不交错其内容）。</li><li>并发写入和读取段，写入和读取之间的延迟相对较低。</li></ul><h2 id="术语"><a href="#术语" class="headerlink" title="术语"></a>术语</h2><p>在本文档的其余部分中，我们将使用以下术语：</p><ul><li>流段或段：连续的字节序列。类似于没有大小限制的文件。这是Stream的一部分，限制是暂时的并且是横向的（根据key值）。Streams的 范围 和如何将Stream Segments映射到此Streams超出了本文档需要阐述的内容。</li><li>第2层存储或永久存储：数据的最终存储位置。</li><li>第1层存储：快速附加存储，用于在将数据刷到第2层存储之前持久缓冲输入的append only数据。</li><li>缓存：键值本地缓存，不期望持久性。</li><li>Pravega Segment Store服务或Segment Store：本文档描述的服务。</li><li>事务：与段相关的一系列附加操作，如果持久化，它将在段中构成连续的字节范围。这用于摄取非常大的记录或用于累积可能或可能不会持久存储到段中的数据（但其如何使用以后才能确定）。</li></ul><p>请注意，在Pravega级别，事务适用于整个流。在本文档中，事务适用于单个段。</p><h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><p>段储存由以下几部分组成：</p><ul><li>Pravega Node：运行Pravega进程的主机。</li><li>流段容器（或段容器）：流段的逻辑分组。Segments到Containers的映射是确定性的，不需要任何持久存储; 段通过hash函数（基于段的名称）映射到容器。</li><li>持久数据日志适配器（或DurableDataLog）：第1层存储的抽象层。</li><li>存储适配器：第2层存储的抽象层。</li><li>缓存：用于追加数据缓存的抽象层。</li><li>Streaming Client：可用于与Pravega Segment Store通信的API。</li><li>Segment Container Manager：可用于确定Pravega节点上Segment Containers生命周期的组件。该组件用于启动或停止Segment Containers， 而这些段容器是基于外部协调服务（例如Pravega控制器）的。</li></ul><p>首先段存储通过将数据写入快速存储（最好是SSD）上的日志层（持久数据日志），并在数据被持久存储后立即返回给客户端。随后，这些写入的数据被合并成更大的数据块并在后台刷新到第2层存储。已经确认（并且在第1层中）但尚未在第2层中的附加数据存储在缓存中（除了第1层）。一旦将此类数据写入第2层存储，它可能会也可能不会保留在缓存中，具体取决于许多因素，例如缓存利用率/压力和访问模式。<br>有关上述每个组件的更多详细信息，请参阅“ 组件”部分（下面）。</p><h2 id="系统图"><a href="#系统图" class="headerlink" title="系统图"></a>系统图</h2><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega%2FSegment.Store.Components.png" alt="Segment.Store.Components"></p><p>在此图中，我们显示了Segment Store的主要组件（为简单起见，仅描绘了一个Segment Container）。显示所有Container组件和它们之间的主要链接（它们如何相互交互）。所述容器的元数据组件未示出。<br>更详细的图表可以在数据流部分（下面）中找到。</p><h1 id="组件"><a href="#组件" class="headerlink" title="组件"></a>组件</h1><h2 id="段容器"><a href="#段容器" class="headerlink" title="段容器"></a>段容器</h2><p>段容器是段的逻辑组，负责跨越这些段的所有操作。Segment Container由多个子组件组成：</p><ul><li>段容器元数据：一组段的元数据，用于描述每个段的当前状态（第2层中的数据量，第1层中的数量，是否密封等），以及关于每个容器的其他错误信息。</li><li>可持久化日志：Container将其接收的每个操作都写入此日志，并仅在日志显示已被接受且持久化存储时才返回。</li><li>读索引：可从中读取数据的内存索引。Container将所有读取请求委托给它，它负责从当前所在的任何位置（Cache，Tier-1 Storage或Tier-2 Storage）获取数据。</li><li>缓存：用于存储仅在第1层（尚未存在于第2层）中的附加数据，以及支持读取的数据块。</li><li>Storage Writer：处理持久日志操作并将它们应用于第2层存储（按接收顺序）。此组件也是将多个操作合并在一起的组件，以获得更好的后端吞吐量。</li></ul><h2 id="段容器元数据"><a href="#段容器元数据" class="headerlink" title="段容器元数据"></a>段容器元数据</h2><p>段容器元数据对其组件的良好运行和同步至关重要。此元数据在所有组件之间共享，它分为两个级别：容器范围的元数据和每个段的元数据。每个服务都有不同的用途，如下所述。<br>容器元数据<br>每个Segment Container都需要保存一些影响容器内所有操作的通用元数据：</p><ul><li>操作序列号：持久日志分配的最大序列号。每次通过持久日志接收并成功处理新操作时，此数字都会递增（其值永远不会减少或以其他方式回滚，即使操作未能保存）。</li><li>操作序列号保证严格单调递增（没有两个操作具有相同的值，并且操作将始终具有比之前的所有操作更大的序列号）。</li><li>Epoch：每次成功恢复（Container Start）时会增加的数字。该值可以持续递增并作为恢复的一部分进行存储，并且可以用于许多场景（例如作为HDFS的第2层防护，HDFS不能为此提供良好的原生保护机制）。</li><li>活动段元数据：有关每个活动段的信息（请参阅下一节）。如果Segment最近有活动（读取或写入）并且当前已加载到内存中，则它处于活动状态。如果这个段有一段时间内未使用，或者当前有太多个段处于活动状态，那么通过将段的元数据刷新到第2层存储并且将段的元数据从内存中淘汰，从而可以使得这个段变为非活动状态。</li><li>第1层元数据：在该点之前的所有操作已经持久存储到第2层，可用于准确截断第1层存储日志的各种信息。</li><li>检查点：通过将容器元数据的整个快照（包括活动段）序列化到第1层存储来定期对容器元数据打检查点。检查点充当第1层的截断点，这意味着它包含通过之前所有已处理的操作对Container进行的所有更新，因此我们不再需要这些操作来重建元数据。如果我们在Checkpoint上截断Tier-1，那么我们可以使用来自Tier-2和此Checkpoint的信息来重建先前元数据中的内容，而不依赖于Tier-1中之前的任何操作。</li></ul><h2 id="段元数据"><a href="#段元数据" class="headerlink" title="段元数据"></a>段元数据</h2><p>每个段容器都需要保留每个段的元数据，用于在处理每个段的操作时跟踪每个段的状态。元数据可以是易失性的（可以在恢复时完全重建），并且包含当前正在使用的每个段的以下属性：</p><ul><li>Name 段的名称。</li><li>Id：内部分配的唯一段ID。这用于指代Segments，它比段的名称更受欢迎。此ID在段的生命周期内是不会改变的，这意味着即使段变为非活动状态，将来重新激活也会将其映射到相同的Id。</li><li>StartOffset（也称为TruncationOffset）：可用于读取的数据的最低偏移量。非截断段的Start Offset将等于0，而后续Truncate操作将增加（但永不减少）此数字。</li><li>StorageLength：第2层存储中存在的数据的最高偏移量。</li><li>Length：第1层存储中已提交数据的最高偏移量。</li><li>LastModified：上次处理（和确认）附加的时间戳。</li><li>IsSealed：segment是否已关闭追加数据（此值可能尚未应用于Tier-2存储）。</li><li>IsSealedInStorage：Segment是否已关闭追加数据（并且这已在第2层存储中保留）。</li><li>IsMerged：此段是否已合并到另一个段中（但尚未在第2层存储中保留）。这仅适用于事务。一旦合并持续到第2层，事务段就不再存在（因此IsDeleted将成为现实）。</li><li>IsDeleted：segment是否被删除或最近是否已合并到另一个segment中。这仅适用于最近删除的segment，而不适用于从未存在过的segment。<br>对于任何segment，以下内容  始终为true：</li><li>StorageLength &lt;= Length</li><li>StartOffset &lt;= Length</li></ul>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>pravega handbook - reader groups设计</title>
      <link href="/2018/09/17/pravega-reader-groups/"/>
      <url>/2018/09/17/pravega-reader-groups/</url>
      
        <content type="html"><![CDATA[<h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h2><p>可以将一组读者组合在一起，以便可以并行读取流中的事件集。读者群组称为读者群。Pravega保证流中的每个事件都由读者组中的一个读者读取。<br>ReaderGroup中的每个Reader都分配了零个或多个段。分配给Segment的Reader是ReaderGroup中唯一一个从该Segment读取事件的Reader,这是Pravega向读者提供事件传递的顺序保证的基本机制,读者将按照他们发布到segment中的顺序接收事件。<br>这种机制存在以下几个挑战：</p><ul><li>如何维护ReaderGroup中哪个Reader的映射分配哪个Segment </li><li>如何在Segments拆分和合并时管理上述映射 </li><li>如何在将读者添加到ReaderGroup </li><li>当读者通过显式操作离开ReaderGroup或reader因网络中断或Reader进程失败而变得不可用时，如何管理上述映射</li></ul><p>为了解决这些问题，我们可以使用[[StateSynchronizer | StateSynchronizer-design]]使读者能够相互协调。</p><h2 id="如何使用一致的复制状态来解决问题"><a href="#如何使用一致的复制状态来解决问题" class="headerlink" title="如何使用一致的复制状态来解决问题"></a>如何使用一致的复制状态来解决问题</h2><p>每个reader中都创建了表示ReaderGroup元数据的一致复制状态对象,此ReaderGroup元数据包括：</p><ul><li>在线读者的映射表，他们拥有的segment可以接管的segment中的位置列表。</li><li>每次ReaderGroup中的读者更改时，都可以更新状态。</li><li>类似地，每当其中一个读者开始从一个新段读取时，它就可以更新复制状态。</li></ul><p>这允许所有读者了解ReaderGroup中的所有其他读者以及他们拥有的哪些片段。</p><p>假设这样的信息：</p><ul><li><p>新读者可以知道哪些片段可读取,（因为无状态）处理合并的段变得容易，因为到达其合并前段的末尾的最后一个读者知道它可以自由地获得新段的所有权。</p></li><li><p>读者可以看到他们的相对负载以及他们相对于他们小组中其他读者的进展情况，并且如果事情失衡，他们可以决定转移segment。</p></li><li><p>这允许读者直接采取行动，以确保所有事件都被读取，而无需一些外部跟踪器。</p></li></ul><h2 id="ReaderGroup的API"><a href="#ReaderGroup的API" class="headerlink" title="ReaderGroup的API"></a>ReaderGroup的API</h2><p>可以将用于管理ReaderGroup的外部API添加到StreamManager对象。它们包括：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs undefined">ReaderGroup createReaderGroup（String name，Stream stream，ReaderGroupConfig config）;<br>ReaderGroup getReaderGroup（String name，Stream stream）;<br>void deleteReaderGroup（ReaderGroup group）;<br></code></pre></td></tr></table></figure><p>创建ReaderGroup时，它会创建一个由读者共享的[[StateSynchronizer | StateSynchronizer-design]]。要加入ReaderGroup，读者只需在其配置中指定它：</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs undefined">ReaderConfig cc = new ReaderConfig（props）;<br>Reader &lt;T&gt; reader = a_stream.createReader（“my_reader_id”，“my_reader_group”，cc）;<br></code></pre></td></tr></table></figure><p>当读者加入组时，他们使用状态来确定要读取的segment。当他们关闭时，他们会更新状态，以便其他读者可以接管他们的segment。</p><h2 id="故障检测器"><a href="#故障检测器" class="headerlink" title="故障检测器"></a>故障检测器</h2><p>我们仍然需要某种心跳机制来判断读者是否还在线。问题大大简化，因为它不需要生成集群视图或管理任何状态。该组件只需要检测失败并调用<code>void readerOffline(String readerId, Position lastPosition);</code>ReaderGroup上的api</p><p>为保持一致性，故障检测器不应将仍在处理事件的主机声明为死机，这样做可能会违反恰好一次处理保证。</p><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><h2 id="新读者"><a href="#新读者" class="headerlink" title="新读者"></a>新读者</h2><ol><li>当读者加入组时，其在线状态将添加到共享状态</li><li>其他读者会收到共享状态的更新。</li><li>当具有超过平均段数的读者看到新读者时，它可以通过将该段的位置写入共享状态来放弃段。</li><li>新的读者可以通过记录它在共享状态下执行此操作来接管一个段。</li><li>新读者可以从它从所拾取的段的共享状态读取的位置开始读取。</li><li>多个读者之间没有同时上线的比赛，因为只有其中一个可以成功声明任何给定片段的所有权。</li></ol><h2 id="合并段"><a href="#合并段" class="headerlink" title="合并段"></a>合并段</h2><ol><li>当读者到达其片段的末尾时，它会将此信息记录在共享状态中。</li><li>当所有合并在一起的段完成后，读者可以声明对以下段的所有权。</li></ol><p>关于拥有者是谁，因为它存储在共享状态中没有歧义。不存在遗忘某个段的风险，因为任何读者都可以通过查看共享状态并声明它们来查看哪些段可用。</p><h2 id="读者离线"><a href="#读者离线" class="headerlink" title="读者离线"></a>读者离线</h2><ol><li>当读者离线时，readerOffline（）方法将由读者本身在正常关闭（在close方法内部）或通过活动检测器调用。在任何一种情况下，读者的最后位置都会被传入。</li><li>最后一个位置写入状态。</li><li>其他读者在更新本地状态时会看到这一点。</li><li>他们中的任何一个都可以通过记录他们在状态对象中的意图来决定接管旧读者所拥有的一个或多个片段。</li><li>状态更新后，新读者将被视为该segment受众群的所有者，并可随意阅读。</li></ol><h2 id="如果读者没有及时了解会发生什么"><a href="#如果读者没有及时了解会发生什么" class="headerlink" title="如果读者没有及时了解会发生什么"></a>如果读者没有及时了解会发生什么</h2><p>具有过期状态的读者可以从其现有段中读取而不受干扰。唯一的缺点是，如果有可用的话，它们不会给另一个读者带来负担。但是，因为他们必须写入共享状态才能从他们尚未拥有的任何段开始读取，所以他们必须在转移到新段之前获取最新信息。</p><h2 id="可用性和延迟的影响"><a href="#可用性和延迟的影响" class="headerlink" title="可用性和延迟的影响"></a>可用性和延迟的影响</h2><p>读取和更新状态对象可以与读取并行发生，因此可能没有可见的延迟影响。如果Pravega以包含ReaderGroup信息的段落下并且保持离线足够长时间以使读者耗尽其现有段中的所有事件的方式失败，则流将无法读取。当然，如果Pravega以这种方式失败，那么至少某些部分流也会受到直接影响，并且无法读取任何事件。这种故障模式将表现为读者的延迟，类似于他们到达流尾部时会发生的情况。</p><p>这比使用外部系统来管理这种协调更为可取，因为这需要添加可能以不同方式失败的新组件，而不是进一步依赖我们需要高度可用的小组。在网络分区的情况下，这尤其值得注意。如果网络被分开，与Pravega服务器位于分区同一侧的任何reader都可以继续工作。如果我们要利用外部服务，那么该服务可能被切断，即使他们可以与Pravega交互，读者也可能无法取得进展。</p>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>分布式系统中DHT算法改进</title>
      <link href="/2018/09/16/distributed-dht-update/"/>
      <url>/2018/09/16/distributed-dht-update/</url>
      
        <content type="html"><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>通常，分布式存储系统以及分布式缓存系统习惯采用分布式哈希（DHT）算法来实现数据的分区分配（路由）以及负载均衡，普通的分布式hash算法通过增添虚拟节点，对物理的热点区间进行划分，将负载分配至其他节点，从而达到负载均衡的状态，但是这并不能保证集群的负载就一定很是的均衡。</p><p>而一种改进过的一致性Hash算法，即带边界因子的一致性Hash算法，其严格控制每个节点的负载从而能获得更好的负载均衡效果[1][2]。</p><h2 id="普通的DHT算法"><a href="#普通的DHT算法" class="headerlink" title="普通的DHT算法"></a>普通的DHT算法</h2><p>假设有8个Object，通过下图的DHT算法:</p><ol><li>object 0,1,2映射到了虚拟节点vNode0 ： object 0,1,2 –&gt; vNode0</li><li>Object 3,4,5 映射到了vNode1：object 3,4,5 –&gt; vNode1</li><li>Object 6映射到 vNode2：object 6 –&gt; vNode2</li><li>Object 7映射到 vNodeN：object 7 –&gt; vNodeN</li></ol><p><img src="http://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed%2Fdistributed-DHT-1.png" alt="distributed-DHT-1"></p><p><img src="http://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed%2Fdistributed-DHT-2.png" alt="distributed-DHT-2"></p><p>很明显，Vnode0和vNode1 都落了三个 object，而 vNode2和vNodeN 都只落了 1个Object，这里的DHT算法负债均衡因子并不是很好。</p><h2 id="带负载边界因子的DHT算法"><a href="#带负载边界因子的DHT算法" class="headerlink" title="带负载边界因子的DHT算法"></a>带负载边界因子的DHT算法</h2><p>假设有8个Object，通过如下图的DHT with bounded loads算法:</p><p><img src="http://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed%2Fdistributed-DHT-3.png" alt="distributed-DHT-3"></p><p><img src="http://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed%2Fdistributed-DHT-4.png" alt="distributed-DHT-4"></p><p>第一轮映射：</p><ol><li>object 0,1,2 需要映射到了虚拟节点vNode0，但是vNode0的权重因子是 2，因此只完成了 object 0,1 –&gt; vNode0， object 2不能映射到节点 vNode0；</li><li>Object 3,4,5 需要映射到了虚拟节点vNode1：但是vNode1的权重因子是 2，因此只完成了 object 3,4 –&gt; vNode1， object 5不能映射到节点 vNode1；</li><li>Object 6映射到 vNode2：object 6 –&gt; vNode2</li><li>Object 7映射到 vNodeN：object 7 –&gt; vNodeN</li></ol><p>第二轮映射：</p><ol><li>Object 2 映射到 vNode1，但是vNode1权重因子=0， 不能被接收，继续往下一个节点走，发现vNode2 权重因子是2,还剩权重因子1，可以被映射，因此 object 2–&gt;vNode2</li><li>Object 5 映射到 vNode2，但是vNode2现在的权重因子=0， 不能被接收，继续往下一个节点走，发现vNodeN 权重因子是2,还剩权重因子1，可以被映射，因此 object 5–&gt;vNodeN</li></ol><p>最终的映射结果是:</p><ol><li>object 0,1映射到了虚拟节点vNode0 ： object 0,1 –&gt; vNode0</li><li>Object 3,4 映射到了vNode1：object 3,4 –&gt; vNode1</li><li>Object 2,6映射到 vNode2：object 2,6 –&gt; vNode2</li><li>Object 5,7映射到 vNodeN：object 5,7 –&gt; vNodeN</li></ol><p>很明显，Vnode0，vNode1，vNode2, vNodeN 每个节点都分到2个 object，<br>显然带负载边界因子的DHT算法负债均衡比普通的DHT算法来的好。</p><p>这些节点的负载因子可以从IO，CPU，MEM，Disk，Network等输入因子计算出来。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1] <a href="https://research.googleblog.com/2017/04/consistent-hashing-with-bounded-loads.html" target="_blank" rel="noopener">https://research.googleblog.com/2017/04/consistent-hashing-with-bounded-loads.html</a></p><p>[2] <a href="https://medium.com/vimeo-engineering-blog/improving-load-balancing-with-a-new-consistent-hashing-algorithm-9f1bd75709ed" target="_blank" rel="noopener">https://medium.com/vimeo-engineering-blog/improving-load-balancing-with-a-new-consistent-hashing-algorithm-9f1bd75709ed</a></p>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>是时候把分布式系统的理论指导从CAP升级到PACELC</title>
      <link href="/2018/09/16/distributed-cap-pacelc/"/>
      <url>/2018/09/16/distributed-cap-pacelc/</url>
      
        <content type="html"><![CDATA[<h2 id="从-CAP到-PACELC"><a href="#从-CAP到-PACELC" class="headerlink" title="从 CAP到 PACELC"></a>从 CAP到 PACELC</h2><p>CAP理论是当前分布式系统设计的理论指导，而PACELC理论是CAP理论的扩展，分布式系统设计的理论依据是时候从CAP理论扩展为PACELC理论, PACELC在wiki上的定义是:</p><blockquote><p>It states that in case of network partitioning (P) in a distributed computer system, one has to choose between availability (A) and consistency (C) (as per the CAP theorem), but else (E), even when the system is running normally in the absence of partitions, one has to choose between latency (L) and consistency (C).</p></blockquote><p>简单来说这里的意思就是：</p><blockquote><p>如果有分区partition (P)，系统就必须在availability 和consistency (A and C)之间取得平衡; 否则else (E) 当系统运行在无分区情况下,系统需要在 latency (L) 和 consistency (C)之间取得平衡</p></blockquote><p>CAP理论认为以下三者不能同时满足：</p><ul><li><p>一致性(Consistency): 所有的节点在同一时刻看到同样的数据。</p></li><li><p>可用性(Availability):  节点失效不会影响系统的读写。</p></li><li><p>分区容忍性(Partition Tolerance): 系统能支持网络分区，即使分区之间的消息丢失系统也正常工作。</p></li></ul><p>根据业务场景的不同，不同的分布式系统会根据自身业务的需求在CAP三者中进行权衡， CAP理论的意义是一种在分布式系统设计时权衡的因素，而非绝对的三者必舍其一，并且在CAP理论中是没有提到系统的时延（Latency）的，而访问时延（Latency）却是很重要的可用性(Availability)因素。</p><p>因此重新定义一个新的模型PACELC，添加了系统中的Latency，如下图：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed%2Fcap-pacelc.png" alt="cap-pacelc"></p><p>当前分布式系统设计指导理论应当用PACELC理论替代CAP理论，理由如下：</p><ol><li><p>PACELC更能满足实际操作中分布式系统的工作场景是更好的工程实现策略；</p></li><li><p>当partition (P)存在的场景下，需要在availability 和consistency (A and C)之间获得权衡，当时实际上分布式系统中绝大多数时间里partition (P)是不存在的，那么就需要在latency (L) 和 consistency (C)之间取得权衡。</p></li><li><p>availability在不存在partition (P)的场景下跟 latency关联,在partition (P)时跟reliable指标关联。</p></li><li><p>PACELC 可以在 latency vs consistency之间获得平衡</p></li><li><p>CAP 理论忽略了 一致性和时延之间的权衡</p></li></ol><p>PACELC建立在CAP之上，二者都描述了在一致性(Consistency)，可用性(Availability)和分区容忍性(Partition Tolerance)之间的限制和权衡。而PACELC更进一步描述了即使在没有Partition的场景下，也存在Latency和Consistency之间的权衡，从而为分布式系统的Consistency模型提供了一个更为完整的理论依据。</p><p>要保证系统的高可用（high availability）那么就必须复制数据，而分布式系统进行数据复制复制，就会出现在Consistency和Latency之间做个权衡的要求。</p><p>举个栗子，如下图所示，</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed%2Fconsistency-latency.png" alt="consistency-latency"></p><ol><li><p>在强一致性复制场景下，需要三副本都下盘才能返回ok给client端，Master向 Slave 复制数据，Latancy的限制是 20ms，有时候，slave 2 硬盘或网络出现故障，Master 往 Slave 复制数据的时延超过 20ms了，这个时候如果还一致等待 slave 2 返回结果再notify 给client就会出现性能和时延抖动，而且这种抖动是经常发生的长尾效应。</p></li><li><p>依据PACELC理论，我们可以在 consistency和Latency之间做个权衡，比如 slave 2 节点的时延超过 20ms了，就不等待slave 2 返回，master 和 slave 1 返回结果给client即可，如果 slave 2 出现 超时的 次数超过 5次那么就认为 这个节点可能出现故障，打个故障标签，进行后续的处理。</p></li></ol><h3 id="参考文献："><a href="#参考文献：" class="headerlink" title="参考文献："></a>参考文献：</h3><p>[1] <a href="https://en.wikipedia.org/wiki/PACELC_theorem" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/PACELC_theorem</a></p><p>[2] CAP理论与分布式系统设计，S先生</p>]]></content>
      
      
      <categories>
          
          <category> distributed </category>
          
      </categories>
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>pravega handbook - stateSynchronizer</title>
      <link href="/2018/09/16/pravega-statesynchronizer/"/>
      <url>/2018/09/16/pravega-statesynchronizer/</url>
      
        <content type="html"><![CDATA[<h2 id="StateSynchronizer的设计"><a href="#StateSynchronizer的设计" class="headerlink" title="StateSynchronizer的设计"></a>StateSynchronizer的设计</h2><p>StateSynchronizer提供了一种方法，通过这种方法可以支持多个进程同时对一份数据进行写入和读取，并且使用了一种乐观检查的方法来保证数据的一致性。</p><p>这项工作保证每个进程都有一份数据的副本。所有的数据更新都是通过StateSynchronizer写入，它将这些数据附加到Pravega的段里。通过从段里消费数据来跟踪数据的最新变化，并且使用了有条件追加数据的方法提供了一致性保证。<br>这样可确保更新的过程只有在有最新数据时才可以继续执行更新。最后，为了防止段数据无节制地增长，我们使用了一种重写最新数据的简单方法，并截断旧数据，以便可以删除它。</p><p>当大多数更新与存储的总数据大小相比较小时，此模型运行良好，因为它们可以写成小的增量。与任何乐观并发系统一样，当众多进程都试图同时尝试更新相同的信息时，工作状态最差。</p><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>这里有一个同步集合内容的具体示例，此外我们还有一个示例，即同步一组主机的成员资格。</p><p>想象一下，许多进程同时共享一个映射表的场景。这可以通过StateSynchronizer创建来完成，这将有助于协调对映射表的更改。每个客户端在内存中都有自己的一份映射表副本，可以通过将映射表生成器传递给StateSynchronizer来更新。每次尝试更新时，更新都会先记录到段中。除非传递给进程的映射表与已记录到段中的映射表一致，否则更新将失败。如果发生这种情况，则使用最新状态调用生成器以再次尝试。因此，更新的顺序由它们写入段的顺序定义。</p><h2 id="如何实现"><a href="#如何实现" class="headerlink" title="如何实现"></a>如何实现</h2><p>为此，我们使用了Pravega Segment Store Service的两个功能。</p><h3 id="条件追加"><a href="#条件追加" class="headerlink" title="条件追加"></a>条件追加</h3><p>附加方法可以指定追加期望的偏移量，如果追加数据失败，则不执行任何操作而是返回失败给客户端。</p><h3 id="截断段"><a href="#截断段" class="headerlink" title="截断段"></a>截断段</h3><p>截断段删除给定偏移之前的所有数据（此操作不会影响现有偏移量），对于低于此值的偏移量的任何读取都将失败，并且在此偏移下的任何数据都可以删除。</p>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>pravega handbook - 常见问题</title>
      <link href="/2018/09/16/pravega-faq/"/>
      <url>/2018/09/16/pravega-faq/</url>
      
        <content type="html"><![CDATA[<h2 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h2><p><strong>什么是Pravega？</strong> Pravega是一个开源存储原语，为连续和无界数据实现Streams。</p><p><strong>“Pravega”是什么意思？</strong> “Pravega”是梵文中的一句话，指的是“速度快”的意思。</p><p><strong>Pravega与Kafka和Kinesis等系统类似吗？</strong> Pravega是以企业级存储为目标从头开始构建的流存储系统，支持恰好一次性，持久化等功能.Pravega是一个理想的流存储系统，专门用于流式数据的存储，比如来自实时应用的数据和物联网数据。</p><p><strong>我怎样才能参与这个开源系统？</strong> 开源加速了颠覆性创新。当Pravega创建时，毫无疑问，将它作为开源是有道理的。我们欢迎经验丰富的新开发人员的贡献。查看Github中的代码。有关如何参与的更多细节可以在这里找到。</p><p><strong>我该如何开始使用pravega？</strong>有关更多信息，请阅读入门指南，并访问一些示例应用程序的sample-apps repo。</p><p><strong>如果遇到问题，我在哪里可以获得帮助？</strong> 不要犹豫！如果您需要任何帮助，请联系邮件列表上的开发人员和社区。有关详细信息，请参阅加入社区。</p><p><strong>Pravega支持恰好一次语义吗？</strong> 绝对的支持。有关Pravega如何支持语义的讨论，请参阅主要功能。</p><p><strong>Pravega如何与Apache Flink等流处理器配合使用？</strong> Pravega的很多功能特性使其成为流处理器的理想选择。首先，通过flink connector, Pravega支持开箱即用。更加重要的是，Pravega支持恰好一次语义，使得开发精确的流处理应用变得更加容易。恰好一次语义，持久化和事务的这些特性的组合使得Pravega成为了Flink很好的合作伙伴，通过pravega可以提供端到端的一致性和恰好一次的语义。</p><p><strong>如何在流处理器和Flink之间进行自动缩放？</strong> 自动缩放是Pravega的一项基本功能，其流中的段数根据数据的摄取率的变化而变化。如果负载更高，速度更快，Pravega会通过添加段来增加流的容量。当数据速率或系统负载下降时，Pravega可以减少流的容量。当Pravega扩展和缩小流的容量时，如Flink的应用程序可以观察到此变化并且通过添加或减少使用流的作业实例的数量来响应。有关自动缩放的更多讨论，请参阅主要功能中的“Auto Scaling”部分。</p><p><strong>Pravega提供哪些一致性保证？</strong> Pravega提供了几项保证。持久化 - 一旦客户端确认数据，Pravega保证这个数据是受到保护的。排序 - 具有相同路由密钥的事件将始终按其编写顺序读取。恰好一次 - 写给Pravega的数据不会重复。</p><p><strong>为什么支持一致性和持久化对Pravega等存储系统如此重要？</strong> 主要是因为它使构建应用更容易。一致性和持久性是支持恰好一次语义的关键。如果没有恰好一次语义，就很难构建容错性应用程序，以确保一致性产生准确的结果。有关一致性和持久性保证的讨论，请参阅主要功能 .Pravega支持恰好一次的语义。</p><p><strong>Pravega支持事务吗？</strong> 是的。Pravega API允许应用程序在流上创建事务并将数据写入事务。数据被持久存储，就像写入Pravega的任何其他数据一样。当应用程序选择时，它可以提交或中止事务。提交事务时，事务中的数据将原子地附加到流中。有关Pravega事务支持的更多详细信息，请参见此处。</p><p><strong>Pravega是否支持跨不同路由键的事务？</strong> 是的。Pravega的事务本身就是一个流; 它可以有1个或多个段，写入事务的数据被放入与数据路由键关联的段中。提交事务时，事务数据将附加到流中的相应段。</p><p><strong>我是否需要安装HDFS才能使用Pravega？</strong> 是的。通常，您将为Pravega部署HDFS以用作其第2层存储。但是，对于简单的测试/开发环境，Pravega的所谓standAlone版本实现了自己的模拟HDFS。有关详细信息，请参阅Running Pravega指南。</p><p><strong>Pravega支持哪些第2层存储系统？</strong> Pravega旨在支持各种类型的第2层存储系统。目前，我们已将HDFS作为第2层存储。</p><p><strong>Pravega提供了哪些分布式计算原语？</strong> Pravega提供了一个名为StateSynchronizer的API结构。使用StateSynchronizer，开发人员可以使用Pravega在多个进程之间构建同步共享状态。此原语可用于构建各种分布式计算解决方案，如共享配置，领导者选举等。有关详细信息，请参阅主要功能中的“分布式计算原语”部分。</p><p><strong>Pravega推荐什么硬件配置？</strong> 对比控制面，数据面Segment Store 的要求更高，最少需要1GB内存和2核CPU，存储10GB起。控制面资源消耗少点，推荐的配置是1 CPU和0.5 GB内存起。</p>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Pravega handbook - 关键特性二</title>
      <link href="/2018/09/16/pravega-key-features-2/"/>
      <url>/2018/09/16/pravega-key-features-2/</url>
      
        <content type="html"><![CDATA[<h2 id="自动缩放"><a href="#自动缩放" class="headerlink" title="自动缩放"></a>自动缩放</h2><p>与静态分区的系统不同，Pravega可以动态扩展单个数据流以适应数据摄取率的变化。</p><p>想象一下物联网的应用场景，数百万台设备为数千个数据流提供这些设备的相关信息。</p><p>想象一下Flink作业的管道，它处理这些流以从所有原始IoT数据中获取业务价值：预测设备故障，优化通过这些设备的服务交付，或在与这些设备交互时定制客户的体验。如果没有组件能够随着数据速率增加和减少的情况下自动伸缩的情况下，大规模地构建这样的应用程序是很困难的。</p><p>使用Pravega，可以轻松地弹性地和独立地扩展数据的摄取，存储和处理 - 协调数据管道中每个组件的扩展。</p><p>Pravega对自动缩放的支持始于Streams被划分为StreamSegments的想法。流可以具有一个或多个流段; 回想一下，Stream Segment是Stream的一个分区，与一系列路由密钥相关联。</p><p>写入Stream的任何数据都将写入与数据路由密钥关联的Stream Segment。写入者使用应用程序有意义的路由密钥，如customer-id，timestamp，machine-id等，以确保将类似数据组合在一起。 </p><p>流段是Pravega Streams中基本的并行度单位，具有多个流段的流可以支持更多的数据并行写入; 多个写入者将数据写入不同的流段，可能涉及群集中的所有Pravega服务器。在Reader端，Stream Segments的数量表示可能的最大读取并行度。如果Stream具有N个流段，则具有N个读取器的ReaderGroup可以并行地从流中消费数据。增加Stream Segments的数量，可以增加ReaderGroup中的Readers数量，以增加处理来自该Stream的数据的规模。当然，如果Stream Segments的数量减少，那么可以相应地减少读取器的数量。</p><p>Stream可以配置为更多数据写入Stream，那么就增加StreamSegments的数量，在数据量下降时就缩小segments规模。我们将此配置称为Stream的服务级别目标或SLO。Pravega监控输入到Stream的数据速率，并使用SLO从流中添加或删除流段。通过拆分流段来增加流段的数量。通过合并两个流段来减少流段的数量。请参阅  AutoScaling：有关Pravega如何管理StreamSegments的更多详细信息，Stream Segments的数量可能会随时间变化。</p><p>协调Pravega中Streams的自动缩放和应用程序缩小（在工作中）。这一点是可以实现的。使用Pravega提供的元数据，应用程序可以配置其应用程序组件的扩展; 例如，驱动Flink作业的实例数。或者，您可以使用Cloud Foundry，Mesos / Marathon，Kubernetes或Docker堆栈等软件来部署应用程序的新实例，以响应Pravega级别增加的并行性，或者减少Pravega规模以响应速率降低时终止实例数据的摄取。</p><h2 id="分布式计算原语"><a href="#分布式计算原语" class="headerlink" title="分布式计算原语"></a>分布式计算原语</h2><p>Pravega非常适合分布式应用，例如微服务; 它可以用作数据存储机制，用于微服务之间的消息传递和其他分布式计算服务，例如领导者选举。</p><p>State Synchronizer是Pravega API的一部分，它是在集群中以一致性和乐观并发性共享状态的基础。状态同步器基于Pravega中的基本条件写操作，因此只有当数据出现在Stream中的给定位置时才会写入数据。如果条件写入操作不满足条件，则失败。</p><p>因此，状态同步器是一种强大的同步原语，可用于群集中的共享状态，成员资格管理，领导者选举和其他分布式计算方案。</p><h2 id="写效率"><a href="#写效率" class="headerlink" title="写效率"></a>写效率</h2><p>Pravega写入延迟大约为毫秒级，无缝扩展以处理来自数千个并发客户端的高吞吐量读取和写入，使其成为物联网和其他时间敏感型应用的理想选择。</p><p>流是轻量级的，Pravega可以支持数百万个流，这可以避免静态配置流和需要预先分配少量固定数量的流以及管理或限制流资源。</p><p>Pravega中的写操作的时延是很低的，可以做到在10ms以下返回结果返回给Writer。此外，优化写入可以使的I / O吞吐量只受到网络带宽的限制; 持久性机制不是瓶颈。Pravega使用Apache BookKeeper来持久化所有写操作。BookKeeper可以非常有效地保留和保护数据。由于数据在写入操作被Writer确认之前受到保护，因此数据始终是持久的。正如我们在下面讨论的那样，数据持久性是存储原语的基本特征。为了进一步提高效率，对BookKeeper的写入通常涉及来自多个流段的数据，因此将数据保存到磁盘的成本可以通过多次写入操作来分摊。Pravega避免了持久化数据与性能的权衡问题。</p><p>读取也很有效，读取器可以在Stream的尾部或Stream历史的任何部分读取Stream。与一些基于日志的系统不同，它使用相同类型的存储进行尾部读写以及读取历史数据，而Pravega使用两种类型的存储。Stream的尾部位于所谓的第1层存储中。如上所述，写入由Apache BookKeeper实现。尾部读取由Pravega管理的内存缓存提供。事实上，BookKeeper仅在故障恢复方案中提供读取功能，Pravega Server已经崩溃并且正在恢复。BookKeeper的这种使用正是它的设计目标：快速写入，偶尔读取。Stream的历史部分在所谓的第2层存储中，针对具有高吞吐量的低成本存储进行了优化。Pravega使用高效的内存预读缓存，也获利于Streams通常以大的连续块读取的场景，并且HDFS非常适合那些大型，高吞吐量的读取。值得注意的是，尾部读取不会影响写入的性能。</p><h2 id="无限保留"><a href="#无限保留" class="headerlink" title="无限保留"></a>无限保留</h2><p>Streams中的数据可以在应用程序需要时保留，受限于可用数据量，这在第2层中使用云存储是无限制的.Pravega提供了一个方便的API来访问实时和历史数据。使用Pravega，可以有效地处理批量和实时应用程序; 另一个原因是Pravega是Kappa架构的优秀存储原语。</p><p>如果保留旧数据有价值，为什么不保留它？例如，在机器学习示例中，您可能希望定期更改模型并针对尽可能多的历史数据训练模型的新版本，以产生更准确的模型预测能力。使用Pravega自动分层，保留大量历史数据不会影响尾部读写的性能。</p><p>流的大小不受单个服务器的存储容量限制，而是仅受存储群集或云提供商的存储容量的限制。随着存储成本的降低，删除数据的经济动机也随之消失</p><h2 id="存储效率"><a href="#存储效率" class="headerlink" title="存储效率"></a>存储效率</h2><p>使用Pravega构建数据处理管道，结合批处理，实时和其他应用程序，而无需为管道的每个步骤复制数据。</p><p>考虑以下数据处理环境，它结合了使用Spark，Flink和/或Storm的实时处理; Haddoop批量; 某种基于Lucene的搜索机制，如弹性搜索全文搜索; 也许一个（或几个）NoSQL数据库支持微服务应用程序。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega%2Fpipeline.separate.replicas.png" alt="pipeline.separate.replicas"></p><p>使用传统方法，每个系统将单独摄取和复制一组源数据，例如来自IoT应用的传感器数据。您最终将获得pub / sub系统中受保护数据的3个副本，HDFS中的3个副本，Lucene中的3个副本，NoSQL数据库中的3个副本。当我们考虑以千兆字节为单位测量源数据时，由中间件类别分隔的数据复制成本变得非常昂贵。</p><p>考虑使用Pravega和适用于Pravega存储的中间件的相同管道：</p><p> <img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega%2Fpipeline.single.source.png" alt="pipeline.single.source"></p><p>使用Pravega，数据在一个地方被摄取和保护; Pravega为整个管道提供单一的事实来源。此外，由于大量数据存储在使用擦除编码的第2层中以有效地保护数据，因此数据的存储成本大大降低。</p><h2 id="持久化"><a href="#持久化" class="headerlink" title="持久化"></a>持久化</h2><p>使用Pravega，您无需在性能，持久化和一致性之间达成妥协。Pravega提供持久的流数据存储，具有强大的一致性、顺序保证和出色的性能。</p><p>持久化是基本的存储原始要求。可能丢失数据的存储不是可靠的存储，基于这种存储的系统不能满足生产要求。</p><p>一旦确认写入操作，即使发生故障，数据也不会丢失。这是因为Pravega总是在写入操作返回到Writer之前将数据保存在受保护的持久存储中。</p><p>使用Pravega，Stream中的数据受到保护。可以将Stream视为记录系统，就像处理存储在数据库或文件中的数据一样。</p><h2 id="事务支持"><a href="#事务支持" class="headerlink" title="事务支持"></a>事务支持</h2><p>开发人员使用Pravega Transaction来确保将一组事件原子地写入流中。</p><p>Pravega事务是Pravega的Writer API的一部分。数据可以直接通过API写入Stream，或者应用程序可以通过Transaction写入数据。使用事务，Writer可以立即保留数据，然后决定是将数据附加到Stream还是放弃。</p><p>使用事务，仅在提交事务时才将数据写入Stream。提交事务时，写入事务的所有数据都以原子方式附加到Stream。由于事务的实现方式与Stream Segments相同，因此写入事务的数据与直接写入Stream的数据一样耐用。如果放弃了事务（例如，如果Writer崩溃），则中止事务并丢弃所有数据。当然，如果出现表明Writer应该丢弃数据的情况，应用程序可以选择通过API中止事务。</p><p>事务是将Flink工作链接在一起的关键。当Flink作业使用Pravega作为接收器时，它可以开始一个Transaction，如果它成功完成处理，则提交Transaction，将数据写入其基于Pravega的接收器。如果作业由于某种原因失败，则事务超时并且不写入数据。重新启动作业时，接收器中没有需要管理或清理的“部分结果”。</p><p>结合事务和Pravega的其他主要功能，可以将Flink工作链接在一起，让一个工作的基于Pravega的接收器成为下游Flink工作的来源。这使得整个Flink作业管道能够恰好具有一次端到端，保证了数据处理的顺序。</p><p>当然，跨多个Streams的事务可以与事务协调，因此Flink作业可以使用2个或更多基于Pravega的接收器为下游Flink作业提供源输入。此外，应用程序逻辑可以将Pravega事务与外部数据库（如Flink的检查点存储）进行协调。</p>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Pravega handbook - 关键特性一</title>
      <link href="/2018/09/16/pravega-key-features-1/"/>
      <url>/2018/09/16/pravega-key-features-1/</url>
      
        <content type="html"><![CDATA[<p>本系列介绍了Pravega的一些关键特性。如果您已经熟悉Pravega的核心概念，那么这些概念对于理解本文会有所帮助。</p><h2 id="Pravega设计原则"><a href="#Pravega设计原则" class="headerlink" title="Pravega设计原则"></a>Pravega设计原则</h2><p>Pravega旨在支持新一代流式应用：这些应用处理大量的连续到达的数据，并且这些应用还对迟到的数据、无序到达的数据和发生故障时生成的数据进行准确的分析。有几个开源工具可以让开发人员构建这样的应用场景，例如Apache Flink，Apache Beam，Spark Streaming等。迄今为止，这些流式应用使用Apache Kafka，Apache ActiveMQ，RabbitMQ，Apache Cassandra和Apache HDFS等系统来摄取和存储数据。在pravega里，我们设想将摄取和存储这两个概念统一起来，因而pravega的工作重点是摄取和存储流数据。</p><p>Pravega从存储的角度处理流应用。它使这些流式应用能够连续不断的摄取流数据并永久地保存下来。作为分析历史数据的一部分，可以以低延迟（毫秒级）的方式访问这样的流数据，也可以提前几个月，甚至几年分析这样的历史数据。</p><p>Pravega的设计结合了使用Lambda架构构建流应用时的经验教训，也参考了大规模部署流应用时的挑战，这些应用始终以容错方式提供准确的结果。Pravega架构提供强大的持久化和一致性保证，为构建流式应用提供坚实的基础。</p><p>在Lambda架构里，开发人员使用复杂的中间件组合，其中包括批处理中间件以及Storm，Samza，Kafka等连续处理中间件。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega%2Flambda.png" alt="lambda"></p><p>在lambda体系结构中，批处理用于提供准确但可能过时的数据分析，第二条路径在摄取数据时处理数据，原则上结果是无效的，这证明了第一条路径的合理性。使用此方法，应用程序逻辑上有两个副本，因为速度层的编程模型与批处理层中使用的编程模型不同。Lambda架构很难在生产中维护和管理。因此，这种大数据处理架构一直在对用户失去吸引力。最近，一种不同类型的大数据体系结构越来越受到关注，此架构不依赖于批处理数据路径。这种架构称为Kappa架构。</p><p>Kappa架构风格是针对Lambda架构太过于复杂的一种改进，依赖于专为流式传输而设计的组件，支持更强大的语义并提供快速准确的数据分析能力，Kappa架构是一种更简单的方法：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega%2Fkappa.png" alt="kappa"></p><p>在Kappa架构里只有一个数据路径要执行，而应用程序逻辑的实现只需要维护一个，而不是两个。借助适当的工具，为需要快速而准确地处理流数据的需求而构建，使得物联网，联网汽车，金融，风险管理，在线服务等领域设计和运行大数据应用变得更加简单。通过合适的工具，可以构建这样的流水线并为需要高容量和低延迟的大数据应用提供服务。</p><p>Kappa架构里流式应用通常需要处理多个阶段，任何实用的流分析系统都必须能够以数据流水线的形式适应各阶段的组合：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega%2Fpipeline.png" alt="pipeline"></p><p>对于数据管道，重要的是要考虑端到端的保证而不是每个组件的保证。例如，一个阶段保证exactly once语义而另一个阶段又不保证，这样是不行的。Pravega的目标是实现数据管道的设计和实现，并提供端到端的强一致保证。</p><p>Pravega - 为流世界重新设想的存储</p><p>Pravega引入了一个新的存储原语，即流，可以匹配无限数据的连续处理。在Pravega中，流是一个命名的，持久的，仅附加的和无限制的字节序列。有了这个原语，以及本文档中讨论的关键特性，Pravega是Flink等流处理引擎的最佳拍档。基于Pravega的关键特性，我们认为它将成为新一代面向流的中间件的基础存储原语。</p><h1 id="让我们来看看Pravega的主要特色。"><a href="#让我们来看看Pravega的主要特色。" class="headerlink" title="让我们来看看Pravega的主要特色。"></a>让我们来看看Pravega的主要特色。</h1><h2 id="Exactly-once语义"><a href="#Exactly-once语义" class="headerlink" title="Exactly once语义"></a>Exactly once语义</h2><p>恰好一次语义，我们的意思是Pravega确保数据不会重复，并且尽管失败也不会丢失任何事件。当然，这个声明附带了许多警告，就像任何其他承诺完全一次语义的系统一样，但是我们不要在这里深挖细节。一个重要的考虑因素是，一次性语义是Pravega的自然组成部分，是pravega从零开始设计时就考虑的首要目标之一。</p><p>为了实现一次性语义，Pravega Streams具有持久性，有序性，一致性和事务性。我们在下面的单独部分讨论持久性和事务性。</p><p>通过排序，我们的意思是Reader按照写入的顺序观测数据。在Pravega中，数据是与应用定义的路由密钥一起写入的，Pravega根据路由密钥提供顺序保证。两个具有相同密钥的数据总是被Reader按照它们写入的顺序读取。Pravega的排序保证允许数据被重放（例如，当应用程序崩溃时）并且重放的结果是相同的。</p><p>通过一致性，我们的意思是所有的reader都可以看到给定路由密钥的相同有序数据视图，即使失败也是如此。“大多数一致”的系统不足以构建准确的数据处理。</p><p>提供“至少一次”语义的系统可能会出现重复。在这样的系统中，数据生产者可能在某些情况下两次写入相同的数据。在Pravega中，写入是幂等的，由于重新连接而导致的重写不会造成数据重复。请注意，我们不保证来自源的数据是否已包含重复项。源数据对Pravega是不透明，pravega不会尝试删除源数据里的重复项。</p><p>然而，我们并没有将我们的注意力限制在写的完全一次语义上。我们还提供并正在积极致力于扩展功能，这些功能可实现数据管道的端到端的一次性。强一致性保证了Praveg的数据分析引擎的语义，如Flink实现了这种端到端的保证。</p>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>pravega handbook - 相关术语</title>
      <link href="/2018/09/16/pravega-terminology/"/>
      <url>/2018/09/16/pravega-terminology/</url>
      
        <content type="html"><![CDATA[<h3 id="以下是与Pravega相关的术语表："><a href="#以下是与Pravega相关的术语表：" class="headerlink" title="以下是与Pravega相关的术语表："></a>以下是与Pravega相关的术语表：</h3><table><thead><tr><th style="text-align:left">术语</th><th style="text-align:left">定义</th></tr></thead><tbody><tr><td style="text-align:left">Pravega</td><td style="text-align:left">Pravega是一个开源存储原语，为连续和无界数据实现流式存储,Pravega是Flink最好的拍档。</td></tr><tr><td style="text-align:left">流</td><td style="text-align:left">一种可持久化，弹性，append-only，无限制的字节序列，具有良好的性能和强一致性。</td></tr><tr><td style="text-align:left"></td><td style="text-align:left">流通过名称和范围来标识。</td></tr><tr><td style="text-align:left"></td><td style="text-align:left">流由一个或多个数据流段组成。</td></tr><tr><td style="text-align:left">流段</td><td style="text-align:left">流的碎片</td></tr><tr><td style="text-align:left"></td><td style="text-align:left">流中流段的数量会随着负载和缩放策略的变化而变化</td></tr><tr><td style="text-align:left"></td><td style="text-align:left">当没有发生缩放事件时，事件写入流中，具有相同路由密钥的事件存储在同一流段中，并且这些事件全部都是有序的. 当发生缩放事件时，与事件之后使用相同路由密钥K写入的事件相比，在缩放事件之前使用给定路由密钥K写入的流段数量发生了变化，给定路由密钥K写入的事件被存储在不同的流段中。流段可与Reader Groups相结合，流段的数量是并发读取流的最大的Reader数量。</td></tr><tr><td style="text-align:left">Scope</td><td style="text-align:left">流名称的命名空间。在一个scope内的流的名称必须是独一无二的。</td></tr><tr><td style="text-align:left">事件</td><td style="text-align:left">Stream中的字节集合。 事件与路由密钥相关联。</td></tr><tr><td style="text-align:left">路由密钥</td><td style="text-align:left">用于将消息路由到Reader的事件的属性。两个具有相同路由密钥的事件将以与它们所写的完全相同的顺序被Reader所读取</td></tr><tr><td style="text-align:left">Reader</td><td style="text-align:left">从一个或多个Streams读取数据的应用程序。</td></tr><tr><td style="text-align:left">Writer</td><td style="text-align:left">将数据写入一个或多个Streams的应用程序。</td></tr><tr><td style="text-align:left">Pravega Java客户端库</td><td style="text-align:left">应用程序用于与Pravega交互的 Java库</td></tr><tr><td style="text-align:left">ReaderGroup</td><td style="text-align:left">一个或多个Reader的命名集合，它们并发读取Stream。 Pravega为Reader分配了Stream  Segments，确保一个Stream Segments至少对应一个Reader，并且保证reader之间的平衡。</td></tr><tr><td style="text-align:left">位置</td><td style="text-align:left">Stream中的偏移量，代表了Reader的恢复点。如果Reader崩溃，可以从这个位置来恢复Reader，以便从这个故障点恢复对流的持续处理。</td></tr><tr><td style="text-align:left">1层存储</td><td style="text-align:left">短期，低延迟的数据存储，可确保写入Streams的数据的持久性。 第1层的当前实现使用   Apache Bookkeeper。 第1层存储保留了Pravega中最新的流。随着第1层中的数据老化，它将从第1 层移到第2层。</td></tr><tr><td style="text-align:left">2层存储</td><td style="text-align:left">Pravega存储的一部分，基于比较便宜的磁盘介质，如HDFS，DellEMC的Isilon或DellEMC的弹性云存储。</td></tr><tr><td style="text-align:left">PravegaServer</td><td style="text-align:left">Pravega的一个组件，其实现了Pravega数据面API，用于读取和写入Streams等操作。Pravega的数据面，也称为Segment Store，由一个或多个Pravega  Server实例组成。</td></tr><tr><td style="text-align:left">Segment Store</td><td style="text-align:left">PravegaServer的集合，它们聚合形成Pravega集群的数据面。</td></tr><tr><td style="text-align:left">Controller</td><td style="text-align:left">Pravega的一个组件，其实现了Pravega控制面API，用于创建和检索有关Streams的信息。 Pravega的控制面由Zookeeper协调的一个或多个Controller实例组成。</td></tr><tr><td style="text-align:left">Auto Scaling</td><td style="text-align:left">一个Pravega概念，基于缩放策略，它允许流中流段的数量随时间的推移而改变</td></tr><tr><td style="text-align:left">缩放策略</td><td style="text-align:left">一个流的配置项，它确定一个流中流段的数量如何随着时间的改变而改变 。  缩放策略有三种，Stream在任何给定时间都有其中一种。 - 固定数量的流段- 根据写入流的每秒字节数更改流段数 - 根据写入流的每秒的事件数更改流段数</td></tr><tr><td style="text-align:left">缩放事件</td><td style="text-align:left">缩放事件有两种类型：Scale-Up Event和Scale-Down Event。一个缩放事件触发自动缩放。放大事件是一种情况，其中负载的增加导致一个或多个流段被分割，从而增加流中的流段的数量。缩小事件是负载减少导致一个或多个流段合并的情况，从而减少流中的流段数。</td></tr><tr><td style="text-align:left">事务</td><td style="text-align:left">Stream写操作的集合，以原子的方式应用于Stream。事务中的所有字节要么都成功写入Stream，要么都没写入。</td></tr><tr><td style="text-align:left">状态同步器</td><td style="text-align:left">在Pravega之上构建的抽象，使用Pravega 段来支持复制状态的实现，以支持状态转换。状态同步器允许在多个进程之间共享一段数据，具有很强的一致性和乐观的并发性</td></tr><tr><td style="text-align:left">checkpoint</td><td style="text-align:left">一种事件，表示reader group内的所有reader都要持久化它们的状态。</td></tr><tr><td style="text-align:left">StreamCut</td><td style="text-align:left">StreamCut代表了流中的一致性位置。它包含一组针对单个流的段和偏移对，这些对表示给定时间点上的完整密钥空间。偏移总是指向事件边界，因此将没有偏移指向不完整事件。</td></tr></tbody></table><a id="more"></a> ]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Pravega handbook - 基本概念四 - 架构，小结</title>
      <link href="/2018/09/16/pravega-concepts-4/"/>
      <url>/2018/09/16/pravega-concepts-4/</url>
      
        <content type="html"><![CDATA[<h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><p>下图描述了Pravega的物理结构图：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega%2Fpravega.arch.new.png" alt="pravega.arch.new"></p><p>Pravega的架构符合软件定义存储（SDS）的语义，其控制面与数据面是分开的，Pravega数据面的集合统称为Segment Store。</p><p>controller实例组构成了Pravega的控制面，提供了创建、更新和删除Streams、检索有关Streams的信息、监控Pravega集群的健康状况、收集指标等的功能。为了实现高可用，通常有多个（建议至少3个）controller实例同时提供服务。 </p><p>Segment store实现Pravega的数据面。PravegaServers提供了在Streams中读写数据的API。Pravega中的数据存储由两层组成：第1层存储，提供短期、低延迟的数据存储，保证写入Streams。第2层存储提供数据的持久性、流数据的长期存储。Pravega使用 Apache Bookkeeper  实施第1层存储，并且支持使用HDFS，戴尔EMC的Isilon或戴尔EMC的弹性云存储（ECS）来实施第2层存储。第1层存储通常在Pravega集群内运行。第2层存储通常部署在Pravega集群之外。</p><p>分层存储对于提供快速访问Stream数据的组合非常重要，但也允许Streams存储大量数据。第1层存储会保留最近的Stream数据。随着第1层存储中的数据老化，它将进入第2层存储。</p><p>Pravega使用Apache Zookeeper作为Pravega集群中组件的协调机制。 </p><p>Pravega首先被构建为数据存储原语。Pravega经过精心设计，可充分利用软件定义存储，因此Pravega中存储的数据量仅受数据中心总存储容量的限制。就像您所期望的所有存储系统一样，一旦将数据写入Pravega，数据就会被持久存储。如果没有遇到连数据中心都被毁坏的灾难，Pravega中存储的数据永远不会丢失。</p><p>Pravega提供了一个用Java编写的客户端库，用于构建客户端应用程序，例如使用Flink作为分析应用程序。Pravega Java客户端库通过自我定制的TCP协议管理应用程序与Pravega之间的交互。</p><h2 id="概念小结"><a href="#概念小结" class="headerlink" title="概念小结"></a>概念小结</h2><p>Pravega中的概念总结如下：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega%2Fputting.all.together.new.png" alt="putting.all.together.new"></p><p>Pravega的客户端是writer和reader。writer将事件写入流中。Reader读取Stream中的事件。Reader被分组到ReaderGroups中以并行读取Stream。</p><p>Controller是服务端组件，用于管理Pravega的控制面。使用ControllerAPI创建、更新和列出流。</p><p>Pravega Server是一个服务端组件，用于实现读、写和其他数据面操作。</p><p>Streams是Pravega中的基本存储原语。Streams包含一组名为Events的数据元素。事件被writer附加到Stream的“尾部”。reader可以从Stream中的任何位置读取事件。</p><p>Stream被划分为一组Stream Segments。流中的stream segments数可以随时间变化。事件基于路由码写入到一个stream segment中。对于读取Stream的任何ReaderGroup，每个Stream Segment都分配给该ReaderGroup中的一个Reader。</p><p>每个流段都存储在Tier1和Tier2存储的组合中。Segment的尾部存储在Tier1中，提供低延迟的读写操作。Segment的其余部分存储在Tier2中，提供具有水平可扩展性和低成本的高吞吐量读取访问。</p><h2 id="关于分层存储的注意事项"><a href="#关于分层存储的注意事项" class="headerlink" title="关于分层存储的注意事项"></a>关于分层存储的注意事项</h2><p>为了实现Streams的有效实现，Pravega基于分层存储模型。事件存储于低延迟/高IOPS存储（第1层存储）和更高吞吐量存储（第2层存储）中。从API的角度来看，writer和reader对分层存储模型无需知晓。</p><p>Pravega基于仅附加日志数据结构。正如所观察到的，Log中实际上有三种数据访问机制：</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega%2Fanatomy.of.log.png" alt="anatomy.of.log"></p><p>所有写入活动以及大部分读取活动都发生在日志的尾部。写入被附加到日志中，并且许多客户端希望以到达日志的速度读取数据。这两种数据访问机制主要是需要低延迟 - 写入器的低延迟写入和读者对发布数据的近实时访问。</p><p>并非所有Reader都从日志的尾部读取; 一些reader想要从日志中的任意位置开始阅读。这些读取称为追赶读取。传统上访问历史数据是通过批量分析作业完成的，通常使用HDFS和Map / Reduce。但是，对于新的流应用程序，您只需访问日志即可访问历史数据和当前数据。一种方法是将所有历史数据存储在SSD中，就像我们使用尾部数据一样，但这可能会成本较高并迫使客户通过删除历史数据来节省成本。Pravega提供了一种机制，允许客户在日志的历史部分使用经济高效，高度可扩展的高吞吐量存储，这样他们就不必决定何时删除历史数据。基本上，如果存储足够便宜，为什么不保留所有的历史数据？</p><p>第1层存储用于快速持久地写入Streams，并确保从Stream的尾部读取尽可能快。第1层存储基于开源Apache BookKeeper。虽然不是必需的，但通常我们假设第1层存储通常在更快的SSD或甚至非易失性RAM上实现。</p><p>第2层存储提供高度可扩展，高吞吐量的经济高效存储。我们希望此层通常部署在机械磁盘上。Pravega异步迁移事件从第1层到第2层，以反映Stream数据的不同访问模式。第2层存储基于HDFS模型。</p>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Pravega handbook - 基本概念三 - ReaderGroup，Transactions，State Synchronizers</title>
      <link href="/2018/09/16/pravega-concepts-3/"/>
      <url>/2018/09/16/pravega-concepts-3/</url>
      
        <content type="html"><![CDATA[<h2 id="ReaderGroup以及Checkpoint"><a href="#ReaderGroup以及Checkpoint" class="headerlink" title="ReaderGroup以及Checkpoint"></a>ReaderGroup以及Checkpoint</h2><p>Pravega为应用提供了在ReaderGroup上初始化Checkpoint的功能。使用Checkpoint的意图是通过使用一种特殊事件（检查点事件）来确保每个Reader能保存原来的使用状态，ReaderGroup中的每个Reader都可以创建一个“时间点”，借助这个“时间点“可以为reader提供状态的持久化以及保证这个状态一致性的功能。检查点完成后，应用可以通过恢复checkpoint(检查点)将ReaderGroup中的所有Reader恢复成这个检查点所代表的一致状态。</p><h2 id="Transactions（事务）"><a href="#Transactions（事务）" class="headerlink" title="Transactions（事务）"></a>Transactions（事务）</h2><p>Pravega支持事务。事务的想法是，Writer可以“批处理”一堆event并将它们作为一个处理单元提交到Stream中。这在某些场景是很有用的，例如，使用Pravega作为Flink作业的接收器。Flink作业可以不断产生一些数据的处理结果，并使用事务功能来持久化累积的处理结果。当在某个时间窗口（例如）的末尾时，Flink作业可以提交事务，因此使的处理结果可用于数据的下游处理，或者在出现错误的场景下，退出事务并且放弃整个处理结果。</p><p>Pravega的事务和类似方法（例如Kafka的生产者方式批处理）之间的关键区别在于能否持久化。当事件回到Writer时，添加到事务的事件是持久的。但是，在Writer提交Transaction之前，Reader不会看到事务中的事件。事务很像流; 事务与多个流段相关联。将事件发布到事务中时，事件本身将附加到事务的流段。假设Stream有5个段，当在该流上创建事务时，那么表示该事务也有5个段。当事件发布到事务中时，它被路由到相同编号的段，就像它被发布到Stream本身一样（如果事件将被放置在“真实”流中的段3中，那么它将出现在事务的段3中）。提交事务时，每个事务的段将自动附加到实际流中的相应段。如果流被中止，则事务其所有段以及发布到事务中的所有事件都将被从Pravega中删除。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega%2Ftrx.commit.new.png" alt="trx.commit.new"></p><p>在提交事务之前，发布到事务中的事件永远不会被Reader看到。有关使用事务的更多详细信息，请参阅  使用Pravega：事务。</p><h2 id="State-Synchronizers（状态同步器）"><a href="#State-Synchronizers（状态同步器）" class="headerlink" title="State Synchronizers（状态同步器）"></a>State Synchronizers（状态同步器）</h2><p>Pravega是一个流存储; 但是Pravega也提供了在分布式计算环境中作为协调器的功能（类似zookeeper,etcd）。Pravega的State Synchronizer功能属于后一种。</p><p>状态同步器使用Pravega Stream为在集群中运行的多个进程之间共享的状态提供同步机制，从而使得更加的容易构建分布式应用。使用State Synchronizer，开发人员可以使用Pravega来读取状态，并且借助一致性和乐观锁功能对这些共享状态进行更改。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega%2Fstate.synchronizer.png" alt="state.synchronizer"></p><p>状态同步器可用于维护和保存应用的配置副本，状态同步器还可用于存储一个数据或具有数千个不同键值对的映射数据。实际上，Pravega本身就在内部使用State Synchronizer来管理分布在整个网络中的ReaderGroups和Readers的状态。</p><p>应用开发人员以类似于创建Writer的方式在Stream上创建State Synchronizer。状态同步器保留共享状态的本地副本，以便为应用提供快速访问数据的功能。对共享状态的任何修改都将通过StateSynchronizer写入Stream，以便跟踪对共享状态的所有更改。每个应用实例都使用状态同步器通过将更新提取到共享状态并修改数据的本地副本来保持最新的更改。通过状态同步器对共享状态的追加样式进行维护，保持一致性，确保仅对共享状态的最新版本进行更新。</p><p>状态同步器还支持可以“压缩”，压缩和删除旧的状态更新，以便只有最新版本的状态保留在后备流中。此功能可帮助应用开发人员确保共享状态不会未经检查。</p><p>在存储的总数据大小比较小时，状态同步器对共享状态的更新可以工作得最好，允许将这些数据写为小的增量。与任何乐观并发系统一样，当许多进程都试图同时更新同一条数据时，状态同步器并不是最佳状态。</p><p>更多有关使用状态同步器的详细信息，请参阅  使用Pravega：状态同步器。</p>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Pravega handbook - 基本概念二 - Events, Segments, AutoScaling, Ordering</title>
      <link href="/2018/09/16/pravega-concepts-2/"/>
      <url>/2018/09/16/pravega-concepts-2/</url>
      
        <content type="html"><![CDATA[<h2 id="Stream-segments"><a href="#Stream-segments" class="headerlink" title="Stream segments"></a>Stream segments</h2><p>如下图，Stream由Stream Segments组成，而流段是流的分片或分区。</p><p><img src="http://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega%2Fstream.segment.png" alt="stream.segment"></p><h2 id="Event-event组成了stream-segment"><a href="#Event-event组成了stream-segment" class="headerlink" title="Event: event组成了stream segment"></a>Event: event组成了stream segment</h2><p>Stream Segment是事件（Event）的容器，event组成了流段，event存储在stream segment里，当事件被写入流时，会进行hash计算生成一个路由码，根据这个路由码，事件会被路由到一个流段中。Pravega使用一致性哈希算法将事件分配给流段。事件路由码被哈希后会生成一个“密钥空间”。然后密钥空间会被划分为多个分区，这些分区又对应于多个流段，采用一致性哈希算法可以确定将事件分配给哪个流段。</p><h2 id="AutoScaling：流段数量可变"><a href="#AutoScaling：流段数量可变" class="headerlink" title="AutoScaling：流段数量可变"></a>AutoScaling：流段数量可变</h2><p>当了流中的I/O负载上升或下降时，Stream中stream segments的数量会随着I/O负载增长或收缩 ，我们将此特性称之为AutoScaling。</p><p>参考下图，图中体现了路由码和时间之间的关系。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega%2Fsegment.split.merge.overtime.new.png" alt="segment.split.merge.overtime.new"></p><p>流在时间t0开始，具有可配置数量的段。如果写入流的数据速率不变，则段的数量不会改变。然而，在时间t1，系统注意到摄取率的增加并且选择将段1分成两部分。我们称之为Scale-up事件。在t1之前，具有哈希到密钥空间上部的路由密钥（值0.5-0.99）的事件将被放置在段1中，而散列到密钥空间下部的值（值0-0.49）将是放置在段0中。在t1之后，段1被分成段2和段3.段1被密封，它不再接受写入。此时，具有路由密钥0.7及以上的事件被写入段3，而在0.5和0.69之间的事件将被写入段2。  </p><p>我们还在时间t2看到另一个Scale-up事件，因为段0的路由键范围被分成段5和段4.此时，段0被封闭，因此它不接受进一步的写入。</p><p>覆盖密钥空间的连续范围的段也可以合并。在时间t3，段2和段5被合并到段6中以适应流上的负载的减少。</p><p>创建Stream时，会使用Scaling Policy配置Stream，该策略确定Stream如何响应其负载变化。目前有三种扩展策略：</p><ol><li><p>固定，流段的数量不随负载而变化</p></li><li><p>基于大小，当写入流的每秒数据字节数增量超过某个目标速率时，流段的数量增加。如果它低于某个流速时，会减少流段数。</p></li><li><p>基于事件的，与基于大小的扩展策略类似，不同之处在于它使用事件数而不是字节数。</p></li></ol><h2 id="Events-Stream-Segments-and-AutoScaling"><a href="#Events-Stream-Segments-and-AutoScaling" class="headerlink" title="Events, Stream Segments and AutoScaling"></a>Events, Stream Segments and AutoScaling</h2><p>我们之前提到当一个event被写入Stream的一个段中时，有时候需要AutoScaling，Stream Segments可以被看作是基于路由密钥和时间的事件的分组。在任何给定时间，在给定值的Routing Key内发布到Stream的event都将出现在同一个Stream Segment中。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega%2Frk.segment.new.png" alt="rk.segment.new"></p><p>还值得强调的是，事件仅写入活动的流段。密封的段不接受写入。在上图中，在“现在”时，只有流段3,6和4处于活动状态，并且这三个流段覆盖了整个密钥空间。  </p><h2 id="Stream-Segments-and-ReaderGroups"><a href="#Stream-Segments-and-ReaderGroups" class="headerlink" title="Stream Segments and ReaderGroups"></a>Stream Segments and ReaderGroups</h2><p>流段对于理解ReaderGroup的工作方式非常重要。</p><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega%2Fsegment.readergroup.png" alt="segment.readergroup"></p><p>Pravega给ReaderGroup中的每个Reader分配了零个或多个Stream Segments用于读取数据。Pravega尝试平衡每个Reader分配的Stream Segments的数量。在上图中，Reader B1从2个Stream Segments中读取，而Reader Group中的每个其他读者只有1个Stream Segment可供读取。Pravega确保每个Stream Segment都会被配置给这个Stream的ReaderGroup中的一个Reader读取。当Reader被添加到ReaderGroup或Reader崩溃并从ReaderGroup中删除时，Pravega会重新分配流段，以便在Reader之间平衡流段。</p><p>流中的流段数确定了ReaderGroup中Reader的并行度的上限 - 流段越多，我们可以使用Stream的Reader的并行集合就越多。在上图中，Stream1有4个Stream Segments。这意味着最大的有效ReaderGroup将包含4个读者。上图中名为“B”的ReaderGroup并不是最优的。如果将另外一个Reader添加到ReaderGroup，则每个Reader将有1个Stream Segment进行处理，从而最大化读取并行性。但是，ReaderGroup中的读者数量增加到4以上，至少有一个读者不会被分配一个流段。</p><p>如果上图中的Stream1经历了Scale-Down事件，将Stream Segments的数量减少到3，那么所描绘的Reader Group B将具有理想数量的Readers。</p><p>借助AutoScaling特性，Pravega开发人员无需预先使用固定的流段个数配置其Streams - Pravega可以动态确定正确的流段个数。借助此特性，Pravega Streams可以自动增长或收缩以匹配数据输入的行为。任何Stream的大小仅受Pravega集群可用的总存储容量的限制; 如果您需要更大的流，只需向群集添加更多存储空间即可。</p><p>应用程序可以响应Stream中segments数量的变化，调整ReaderGroup中的Readers数量，以便在资源允许时保持最佳读取并行度。例如，在Flink应用程序中，这很有用，允许Flink增加或减少并行处理Stream的任务的数量，因为随着时间的推移会缩放事件。</p><h2 id="顺序保证Odering-Guarantees"><a href="#顺序保证Odering-Guarantees" class="headerlink" title="顺序保证Odering Guarantees"></a>顺序保证Odering Guarantees</h2><p>流包括可以随时间变化的一组段，在键区空间区域重叠的段具有已定义的顺序。</p><p>写入流的事件将写入单个段，并且相对于该段的事件具有顺序性，段内事件的存在和位置是强一致性的。</p><p>可以为Reader分配多个并行段（来自键空间的不同部分）。从多个段读取的Reader将交错段的事件，但每个段事件的顺序关联了一个段中。具体来说，如果s是一个片段，s的事件e~1和e~2使得e~1在e~2之前， Reader读取e~1和e~2，然后Reader将在e~2之前读取e~1。</p><p>这导致以下顺序保证：</p><ol><li><p>具有相同路由密钥的事件按其编写顺序被消费。</p></li><li><p>发送到特定段的具有不同路由键的事件将始终以相同的顺序被可见，即使Reader备份并重新读取它们也是如此。</p></li><li><p>如果某个事件已经被其Writer激活或已被Reader读取，则可以保证它将在所有后续读取的同一位置继续存在，直到被删除为止。</p></li><li><p>如果有多个读者读一个流并且他们都回到任何给定点，他们将永远不会看到关于该点的任何重新排序。（永远不会发生所选点之前读取的事件现在又再次出现的情况，反之亦然。）</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Pravega handbook - 基本概念一 - Streams, Events, Writers, Readers, ReaderGroups</title>
      <link href="/2018/09/16/pravega-concepts-1/"/>
      <url>/2018/09/16/pravega-concepts-1/</url>
      
        <content type="html"><![CDATA[<p>Pravega是一个开源的流式存储系统，为连续和无界数据实现流式存储。本章节将分为一个系列讲述Pravega的一些基本概念。</p><h2 id="Streams"><a href="#Streams" class="headerlink" title="Streams"></a>Streams</h2><p>Pravega将数据组织到Streams中。Stream是一种持久，有弹性，append-only，无限制的字节序列，具有良好的性能和强大的一致性。Pravega Stream这个语义与当前很流行的面向消息的中间件（如RabbitMQ或Apache Kafka）中的“topic”类似但更灵活。</p><p>Pravega Streams是基于append-only的日志数据结构。通过使用append-only日志，Pravega可以快速将数据提取到可持久化的存储中，也可以支持流处理，工作流引擎，面向事件的应用程序，比如Flink，发布/订阅消息，NoSQL数据库（如时间序列数据库）（TSDB）等。</p><p>当开发人员在Pravega中创建Stream时，他/她会先给Stream定义一个名称，例如“IoTSensorData”或“WebApplicationLog20170330”。Stream的名称可以帮助其他开发人员了解存储在Stream中的数据类别。值得注意的是，Pravega Stream名称是在一个Scope内组织的。Scope是一个字符串，用于数据分类，它会向开发人员传达某种含义，比如“FactoryMachines”或“HRWebsitelogs”。Scope用作Stream名称的命名空间 - 所有Stream名称在Scope中都是唯一的。因此，Stream通过其Stream名称和Scope的组合唯一标识。Scope可用于按租户（在多租户环境中），按组织中的部门，按地理位置或开发人员选择的任何其他分类来命名。</p><p>Pravega的Stream大小无限制 – Pravega本身不会对Stream中可以有多少event或Stream中存储的总字节数施加以任何的限制。Pravega的设计原则是支持从几台机器的小规模到整个数据中心的大规模。</p><p>为了处理Stream中潜在的大量数据，Pravega Streams分为Stream Segments。Segment是stream中的Shard或Partition。我们稍后将在本文档中详细介绍Stream Segments。Stream Segments是一个重要的概念，但在我们深入了解Stream Segments之前，我们还需要介绍一些其他概念。</p><p>应用程序（例如从IoT传感器读取的Java程序）将数据写入Stream的尾部（前端）。应用程序（如Flink）也可以从Stream中的任何位置读取数据。多个应用程序还可以并行读写相同的Stream。弹性且可扩展地支持大量的Streams，支持大规模的数据和应用程序是Pravega的核心设计思想。在详细介绍reader和writer时，我们将会介绍应用程序如何读取和写入Streams。</p><h2 id="Event"><a href="#Event" class="headerlink" title="Event"></a>Event</h2><p>Pravega的客户端API允许应用程序根据event在Pravega中读取和写入数据。event是Stream中的一组字节。event可以像来自IoT传感器的温度读数只包含少量的字节一样简单，该传感器由时间戳，度量标识符和值组成。event可以是与用户点击网站相关联的Web日志数据，也可以是表示为一组字节的任何事物。应用程序使用标准Java序列化器和反序列化器来理解event，允许它们使用类似的技术在Pravega中读取和写入对象，以便从文件中读取和写入对象。</p><p>每个event都有一个路由码。路由码允许Pravega和应用程序开发人员推断哪些event是关联的。路由码只是开发人员用于将类似event组合在一起的字符串。路由码通常是从event中自然发生的数据派生出来的，例如“customer-id”或“machine-id”，但它也可能是一些人工字符串。路由码也可以类似于日期（按时间将event组合在一起），或者路由码可能是IoT传感器ID（按机器对event进行分组）。路由码对于定义Pravega 保证的精确读写语义非常重要，稍后我们将详细介绍。</p><h2 id="Writer-Reader-and-ReaderGroups"><a href="#Writer-Reader-and-ReaderGroups" class="headerlink" title="Writer Reader and ReaderGroups"></a>Writer Reader and ReaderGroups</h2><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega%2Fproducer.consumer.client.new.png" alt="producer.consumer.client.new"></p><p>Pravega提供了一个用Java编写的客户端库，它为Writer和Reader应用程序实现了一个方便的API。Pravega Java客户端库封装了用于Pravega客户端和Pravega之间通信的协议。</p><p>Writer是一个创建event并将其写入Stream的应用。所有数据都可以通过append到Stream的尾部（前面）来写入。</p><p>Reader是一个从Stream读取event的应用。读者可以从Stream中的任何一点读取。一些Reader从Stream的尾部读取event。这些events将会尽可能快地被发送给这些reader。一些Reader从Stream的头部读取（称为追赶读取）。应用开发人员可以控制Reader开始读取的Stream中的位置。Pravega具有Position的概念，它表示Reader当前所在的Stream中的位置。位置对象可以用作恢复机制-应用保留Reader最后成功读取的位置，如果读失败了就从这个保存的位置从新开始读。</p><p>使用这种持久化Position对象的模式，Reader被组织成ReaderGroups。ReaderGroup是一个命名的Reader集合，它们一起并行读取给定Stream的事件。当通过Pravega数据平面API创建Reader时，开发人员包含它所属的ReaderGroup的名称。我们保证发布到Stream的每个事件都被发送到ReaderGroup中的一个Reader。ReaderGroup中可能有1个Reader，也可能有多个Reader。同一个Stream可以同时被不同的ReaderGroup读取。</p><p>您可以将ReaderGroup视为“复合阅读器”或“分布式阅读器”，它允许分布式应用程序并行读取和处理流数据，以便协调的ReaderGroup可以使用大量的流数据。在ReaderGroup中，并行处理流数据的Flink是ReaderGroup的一个很好的用例。</p><p>更多关于Pravega Reader和Writer如何使用的详细信息，请参阅  使用Pravega：基本Reader和Writer章节。</p><p>我们需要更详细地讨论Reader，ReaderGroup和Streams之间的关系以及Pravega提供的顺序保证。但是，我们需要先描述一下segment是什么。</p>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>pravega handbook - 入门</title>
      <link href="/2018/09/16/pravega-usage/"/>
      <url>/2018/09/16/pravega-usage/</url>
      
        <content type="html"><![CDATA[<h2 id="Pravega入门"><a href="#Pravega入门" class="headerlink" title="Pravega入门"></a>Pravega入门</h2><p>了解Pravega最好方法就是自己动手部署一个，然后跑一把Pravega示例。</p><p>部署Pravega其实很简单，以下是步骤：</p><p>Java版本：Java 8</p><h3 id="下载Pravega"><a href="#下载Pravega" class="headerlink" title="下载Pravega"></a>下载Pravega</h3><p>可以从 <a href="https://github.com/pravega/pravega/releases" target="_blank" rel="noopener">https://github.com/pravega/pravega/releases</a> 下载Pravega编译好的发行版。如果您想自己构建Pravega，也可以自己下载代码并运行:</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs undefined">$./gradlew distribution<br></code></pre></td></tr></table></figure><p>多细节可以查看Pravega <a href="https://github.com/pravega/pravega/blob/master/README.md" target="_blank" rel="noopener">README.md</a>。</p><p>解压:</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs undefined">$ tar xfvz pravega-0.1.0.tgz<br></code></pre></td></tr></table></figure><p>然后以standalone模式运行Pravega，这种模式会在本地机器上启动Pravega的所有组件。注意：这仅用于测试/演示目的，请勿在生产环境中使用！更多内容请 <a href="http://pravega.io/docs/latest/deployment/deployment/" target="_blank" rel="noopener">查看</a></p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs undefined">$ cd pravega-0.1.0<br>$ bin / pravega-standalone<br></code></pre></td></tr></table></figure><p>执行这个命令即可拉起一个本地化的pravega 集群， 这样就可以跑pravega。</p><h3 id="Pravega“Hello-World”示例"><a href="#Pravega“Hello-World”示例" class="headerlink" title="Pravega“Hello World”示例"></a>Pravega“Hello World”示例</h3><p>Pravega为示例维护一个单独的github库：https：//github.com/pravega/pravega-samples</p><p>Pravega依赖关系会自动从maven中心拉下来。注意：示例还可以使用本地编译的Pravega。有关这方面的更多信息，请参阅<a href="https://github.com/pravega/pravega/blob/master/README.md" target="_blank" rel="noopener">README.md</a>中maven发布的注释。</p><p>下载Pravega-Samples git库</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs undefined">$ git clone https://github.com/pravega/pravega-samples<br>$ cd pravega-samples<br></code></pre></td></tr></table></figure><p>生成示例程序</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs undefined">$ ./gradlew installDist<br></code></pre></td></tr></table></figure><p>运行示例“HelloWorldWriter”，将“hello world”消息作为事件写入Pravega stream。</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs undefined">$ cd pravega-samples/standalone-examples/build/install/pravega-standalone-examples<br>$ bin/helloWorldWriter<br></code></pre></td></tr></table></figure><p>HelloWorldWriter的输出</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs undefined">...<br>Writing message: &apos;hello world&apos; with routing-key: &apos;helloRoutingKey&apos; to stream &apos;examples / helloStream&apos;<br>...<br></code></pre></td></tr></table></figure><p>若想使用不同的参数运行HelloWorldWriter，更多信息请参阅pravegs-samples中的readme.md文件</p><p>运行示例“HelloWorldReader”</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs undefined">$ cd pravega-samples/standalone-examples/build/install/pravega-standalone-examples<br>$ bin/helloWorldReader<br></code></pre></td></tr></table></figure><p>示例HelloWorldReader的输出</p><figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs undefined">...<br>Reading all the events from examples/helloStream<br>...<br>Read event &apos;hello world&apos;<br>No more events from examples/helloStream<br>...<br></code></pre></td></tr></table></figure><p>有关HelloWorldReader的更多详细信息，请参阅pravega-samples中的readme.md文件</p>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>pravega handbook - overview</title>
      <link href="/2018/09/15/pravega-overview/"/>
      <url>/2018/09/15/pravega-overview/</url>
      
        <content type="html"><![CDATA[<p>当前的大数据处理系统无论是Lamda架构还是Kappa架构都面临一个问题，即：“计算是原生的流计算，而存储却不是原生的流存储” 。</p><p>作为存储业界首屈一指的领导者，DELL EMC的存储专家们重新思考了这一基本的数据处理和存储规则，为这一场景重新设计了一种新的存储类型，即原生的流存储，命名为”Pravega”，在梵语里是“Good Speed”的意思。</p><p>Pravega是一种流数据存储系统，其具有可持久化，弹性，数据只追加，字节序列无限制，性能良好和强一致性的特点。并且根据Apache 2.0许可证开源，DELLEMC的存储专家们相信这一颠覆性的技术应该开源出来与开源社区一起拥有与推动，Pravega相应的介绍以及代码可以从pravega.io获得。</p><h2 id="主要特性"><a href="#主要特性" class="headerlink" title="主要特性"></a>主要特性</h2><ul><li><p>正好一次 – 不管是客户端、服务端还是网络出现了故障，Pravega都能确保每个事件都只被传递和处理正好一次（exactly-once）。</p></li><li><p>自动伸缩 – 不同于静态分区系统只有固定大小的存储空间，当数据采集速率发生变化时Pravega可以根据场景自动调整空间大小以自动适应数据规模的变化。</p></li><li><p>分布式计算原语 – Pravega具有和zookeeper一样的选主功能，支持进程间传递消息，支持数据存储，非常适用于分布式计算场景。</p></li><li><p>写入效率好 – 目前Pravega 的写入时延在毫秒级，还能无缝的扩展以支持数千个客户端的同时并发读写，是IOT和其他时延敏感型应用的理想选择。</p></li><li><p>无限保存 – 数据永远都在流中采集、处理和保存，对于实时数据和历史数据使用一样的处理范式。</p></li><li><p>高效存储 – Pravega构建了一种数据处理通道，支持将批处理，实时处理以及其他应用比如数据检索，都构建在一个数据处理通道内，无需为每个处理模式都保留一份数据副本。</p></li><li><p>持久化 – Pravega保证无需在高性能，可持久化和一致性之间做权衡，在客户端确认写入操作已完成之前，Pravega将一直存留并保护数据。</p></li><li><p>支持事务 - 开发人员使用Pravega事务来确保一组事件原子性的写入流中。</p></li></ul><a id="more"></a> <h2 id="Pravega的逻辑架构"><a href="#Pravega的逻辑架构" class="headerlink" title="Pravega的逻辑架构"></a>Pravega的逻辑架构</h2><p><img src="https://wuchangping.oss-cn-hangzhou.aliyuncs.com/pravega/pravega_overview_1.jpg" alt="Pravega的逻辑架构"></p><p>计算与存储解耦，计算包括 Flink,Spark,一个自我开发的分布式检索系统。<br>存储层实现了一个流抽象层，一级高性能存储采用Bookeeper，二级冷数据存储<br>可以支持开源的HDFS，CEPH，GlusterFS，Swift，云存储等。与Kafka对比，最大区别在于Pravega是专门为流数据而生的原生的流存储。</p>]]></content>
      
      
      <categories>
          
          <category> pravega </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pravega </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Hello World</title>
      <link href="/2018/09/13/hello-world/"/>
      <url>/2018/09/13/hello-world/</url>
      
        <content type="html"><![CDATA[<h2 id="Hello-World"><a href="#Hello-World" class="headerlink" title="Hello World"></a>Hello World</h2><p><strong>启动新的技术网站:[<a href="http://www.changping.me]">www.changping.me]</a>, [<a href="http://www.yuncunchu.org]以及微信公众号上的文章将迁移到本站。" target="_blank" rel="noopener">www.yuncunchu.org]以及微信公众号上的文章将迁移到本站。</a></strong></p>]]></content>
      
      
      
    </entry>
    
  
  
    
    <entry>
      <title></title>
      <link href="/404.html"/>
      <url>/404.html</url>
      
        <content type="html"><![CDATA[<!DOCTYPE HTML><html><head>  <meta http-equiv="content-type" content="text/html;charset=utf-8;">  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">  <meta name="robots" content="all">  <meta name="robots" content="index,follow">  <link rel="stylesheet" type="text/css" href="https://qzone.qq.com/gy/404/style/404style.css"></head><body>  <script type="text/plain" src="http://www.qq.com/404/search_children.js" charset="utf-8" homepageurl="/" homepagename="�ص��ҵ���ҳ">  </script>  <script src="https://qzone.qq.com/gy/404/data.js" charset="utf-8"></script>  <script src="https://qzone.qq.com/gy/404/page.js" charset="utf-8"></script></body></html>]]></content>
      
    </entry>
    
    <entry>
      <title>about</title>
      <link href="/about/index.html"/>
      <url>/about/index.html</url>
      
        <content type="html"><![CDATA[<h2 id="关于作者"><a href="#关于作者" class="headerlink" title="关于作者"></a>关于作者</h2><ul><li>毕业于中国科学技术大学，获硕士研究生学历学位</li><li>主要工作背景：分布式系统、存储、云计算以及大数据</li><li>曾就职于Marvell、AMD等，现就职于EMC，职级：资深首席工程师，主要负责流式大数据处理平台的架构设计、实现及产品交付</li></ul><h2 id="联系方式"><a href="#联系方式" class="headerlink" title="联系方式"></a>联系方式</h2><ul><li>Email : <a href="mailto:wu@changping.me" target="_blank" rel="noopener">wu@changping.me</a></li><li>Blog : <a href="https://www.changping.me">https://www.changping.me</a></li><li>Github : <a href="https://github.com/wuchangping" target="_blank" rel="noopener">https://github.com/wuchangping</a></li></ul><h2 id="网站声明"><a href="#网站声明" class="headerlink" title="网站声明"></a>网站声明</h2><p>文章内容仅为作者愚见，与任何组织机构无关，如有错误及不足之处欢迎发信批评指正。</p><h2 id="版权声明"><a href="#版权声明" class="headerlink" title="版权声明"></a>版权声明</h2><p>非商业用途在注明作者及本网站前提下无需授权即可转载。</p><h2 id="免责声明"><a href="#免责声明" class="headerlink" title="免责声明"></a>免责声明</h2><p>文章坚持原创，且仅供技术交流及研究使用，如有不小心侵犯您的版权， 请联系：<a href="mailto:wu@changping.me" target="_blank" rel="noopener">wu@changping.me</a>，会尽快删除。</p><p>–</p>]]></content>
      
    </entry>
    
    <entry>
      <title>categories</title>
      <link href="/categories/index.html"/>
      <url>/categories/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    <entry>
      <title>archives</title>
      <link href="/archives/index.html"/>
      <url>/archives/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    <entry>
      <title>tags</title>
      <link href="/tags/index.html"/>
      <url>/tags/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
  
</search>
